diff --git a/subprojects/gst-plugins-bad/docs/plugins/gst_plugins_cache.json b/subprojects/gst-plugins-bad/docs/plugins/gst_plugins_cache.json
index bd07b689b9..3b147a8c9d 100644
--- a/subprojects/gst-plugins-bad/docs/plugins/gst_plugins_cache.json
+++ b/subprojects/gst-plugins-bad/docs/plugins/gst_plugins_cache.json
@@ -675,7 +675,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             },
             "amfh265enc": {
                 "author": "Seungha Yang <seungha@centricular.com>",
@@ -909,7 +909,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             }
         },
         "filename": "gstamfcodec",
@@ -1124,7 +1124,7 @@
                     }
                 },
                 "properties": {},
-                "rank": "primary"
+                "rank": "secondary"
             },
             "av1enc": {
                 "author": "Sean DuBois <sean@siobud.com>",
@@ -7323,12 +7323,12 @@
                 "klass": "Filter/Converter/Video/Hardware",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -7379,7 +7379,7 @@
                 "klass": "Filter/Editor/Video/Compositor",
                 "pad-templates": {
                     "sink_%%u": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "request",
                         "type": "GstD3D11CompositorPad"
@@ -7440,12 +7440,12 @@
                 "klass": "Filter/Converter/Scaler/Effect/Video/Hardware",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -7521,12 +7521,12 @@
                 "klass": "Filter/Effect/Video/Deinterlace/Hardware",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -7722,12 +7722,12 @@
                 "klass": "Filter/Video",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -7963,12 +7963,12 @@
                 "klass": "Filter/Converter/Video/Scaler/Hardware",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -8017,7 +8017,7 @@
                 "klass": "Source/Video",
                 "pad-templates": {
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: BGRA\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: BGRA\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: BGRA\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\npixel-aspect-ratio: 1/1\nvideo/x-raw:\n         format: BGRA\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\npixel-aspect-ratio: 1/1\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -8188,7 +8188,7 @@
                 "klass": "Source/Video",
                 "pad-templates": {
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -8250,12 +8250,12 @@
                 "klass": "Filter/Video",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -8281,7 +8281,7 @@
                 "klass": "Sink/Video",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:D3D11Memory):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:SystemMemory, meta:GstVideoOverlayComposition):\n         format: { RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, GBRA, GBRA_10LE, GBRA_12LE, Y410, YUY2 }\n          width: [ 1, 16384 ]\n         height: [ 1, 16384 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     }
@@ -10954,7 +10954,7 @@
                 "long-name": "Video CODEC Test Sink",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw:\n         format: { I422_10LE, I420_10LE, Y42B, I420, NV12 }\n",
+                        "caps": "video/x-raw:\n         format: { Y444_12LE, I422_12LE, I420_12LE, Y444_10LE, I422_10LE, I420_10LE, Y444, Y42B, I420, NV12 }\n",
                         "direction": "sink",
                         "presence": "always"
                     }
@@ -31312,6 +31312,18 @@
                         "readable": true,
                         "type": "gboolean",
                         "writable": true
+                    },
+                    "skip-vsync": {
+                        "blurb": "When enabled will not wait internally for vsync. Should be used for atomic drivers to avoid double vsync.",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "false",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
                     }
                 },
                 "rank": "secondary"
@@ -216835,7 +216847,7 @@
                 "description": "Converts video from one colorspace to another using CUDA",
                 "hierarchy": [
                     "GstCudaConvert",
-                    "GstCudaBaseFilter",
+                    "GstCudaBaseConvert",
                     "GstCudaBaseTransform",
                     "GstBaseTransform",
                     "GstElement",
@@ -216844,21 +216856,62 @@
                     "GObject"
                 ],
                 "klass": "Filter/Converter/Video/Hardware",
-                "long-name": "CUDA Colorspace converter",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
                 },
                 "rank": "none"
             },
+            "cudaconvertscale": {
+                "author": "Seungha Yang <seungha@centricular.com>",
+                "description": "Resizes video and allow color conversion using CUDA",
+                "hierarchy": [
+                    "GstCudaConvertScale",
+                    "GstCudaBaseConvert",
+                    "GstCudaBaseTransform",
+                    "GstBaseTransform",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Filter/Converter/Video/Scaler/Colorspace/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "add-borders": {
+                        "blurb": "Add black borders if necessary to keep the display aspect ratio",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "true",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            },
             "cudadownload": {
                 "author": "Seungha Yang <seungha.yang@navercorp.com>",
                 "description": "Downloads data from NVIDA GPU via CUDA APIs",
@@ -216873,15 +216926,14 @@
                     "GObject"
                 ],
                 "klass": "Filter/Video",
-                "long-name": "CUDA downloader",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:GLMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, Y444, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory):\n         format: { I420, YV12, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, BGRx, RGBx, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:GLMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, Y444, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory):\n         format: { I420, YV12, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, BGRx, RGBx, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -216890,10 +216942,10 @@
             },
             "cudascale": {
                 "author": "Seungha Yang <seungha.yang@navercorp.com>",
-                "description": "Resizes Video using CUDA",
+                "description": "Resize video using CUDA",
                 "hierarchy": [
                     "GstCudaScale",
-                    "GstCudaBaseFilter",
+                    "GstCudaBaseConvert",
                     "GstCudaBaseTransform",
                     "GstBaseTransform",
                     "GstElement",
@@ -216902,19 +216954,32 @@
                     "GObject"
                 ],
                 "klass": "Filter/Converter/Video/Scaler/Hardware",
-                "long-name": "CUDA Video scaler",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
                 },
+                "properties": {
+                    "add-borders": {
+                        "blurb": "Add black borders if necessary to keep the display aspect ratio",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "true",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    }
+                },
                 "rank": "none"
             },
             "cudaupload": {
@@ -216931,15 +216996,14 @@
                     "GObject"
                 ],
                 "klass": "Filter/Video",
-                "long-name": "CUDA uploader",
                 "pad-templates": {
                     "sink": {
-                        "caps": "video/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:GLMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, Y444, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory):\n         format: { I420, YV12, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, BGRx, RGBx, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:GLMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, Y444, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:D3D11Memory):\n         format: { I420, YV12, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, BGRx, RGBx, Y42B, I422_10LE, I422_12LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "sink",
                         "presence": "always"
                     },
                     "src": {
-                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "caps": "video/x-raw(memory:CUDAMemory):\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
                         "direction": "src",
                         "presence": "always"
                     }
@@ -219634,7 +219698,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC h264 Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-h264:\n  stream-format: byte-stream\n      alignment: au\n        profile: { (string)constrained-baseline, (string)baseline, (string)main, (string)high, (string)constrained-high, (string)progressive-high }\n          width: [ 48, 4096 ]\n         height: [ 16, 4096 ]\n",
@@ -219666,7 +219729,6 @@
                     "GstPreset"
                 ],
                 "klass": "Codec/Encoder/Video/Hardware",
-                "long-name": "NVENC H.264 Video Encoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-raw:\n         format: { NV12, YV12, I420, BGRA, RGBA, Y444, VUYA }\n          width: [ 145, 4096 ]\n         height: [ 49, 4096 ]\n      framerate: [ 0/1, 2147483647/1 ]\n interlace-mode: { (string)progressive }\n\nvideo/x-raw(memory:GLMemory):\n         format: { NV12, YV12, I420, BGRA, RGBA, Y444, VUYA }\n          width: [ 145, 4096 ]\n         height: [ 49, 4096 ]\n      framerate: [ 0/1, 2147483647/1 ]\n interlace-mode: { (string)progressive }\n\nvideo/x-raw(memory:CUDAMemory):\n         format: { NV12, YV12, I420, BGRA, RGBA, Y444, VUYA }\n          width: [ 145, 4096 ]\n         height: [ 49, 4096 ]\n      framerate: [ 0/1, 2147483647/1 ]\n interlace-mode: { (string)progressive }\n",
@@ -219786,7 +219848,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC H.264 Stateless Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-h264:\n  stream-format: { (string)avc, (string)avc3, (string)byte-stream }\n      alignment: au\n        profile: { (string)high, (string)main, (string)constrained-high, (string)constrained-baseline, (string)baseline }\n      framerate: [ 0/1, 2147483647/1 ]\n          width: [ 48, 4096 ]\n         height: [ 16, 4096 ]\n",
@@ -219830,7 +219891,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC h265 Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-h265:\n  stream-format: byte-stream\n      alignment: au\n        profile: { (string)main, (string)main-10, (string)main-12, (string)main-444, (string)main-444-10, (string)main-444-12 }\n          width: [ 144, 8192 ]\n         height: [ 144, 8192 ]\n",
@@ -219862,7 +219922,6 @@
                     "GstPreset"
                 ],
                 "klass": "Codec/Encoder/Video/Hardware",
-                "long-name": "NVENC HEVC Video Encoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-raw:\n         format: { NV12, P010_10LE, P016_LE, Y444, Y444_16LE, Y444_16LE }\n          width: [ 144, 8192 ]\n         height: [ 144, 8192 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:GLMemory):\n         format: { NV12, P010_10LE, P016_LE, Y444, Y444_16LE, Y444_16LE }\n          width: [ 144, 8192 ]\n         height: [ 144, 8192 ]\n      framerate: [ 0/1, 2147483647/1 ]\n\nvideo/x-raw(memory:CUDAMemory):\n         format: { NV12, P010_10LE, P016_LE, Y444, Y444_16LE, Y444_16LE }\n          width: [ 144, 8192 ]\n         height: [ 144, 8192 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
@@ -219982,7 +220041,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC H.265 Stateless Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-h265:\n  stream-format: { (string)hev1, (string)hvc1, (string)byte-stream }\n      alignment: au\n        profile: { (string)main, (string)main-10, (string)main-12, (string)main-444, (string)main-444-10, (string)main-444-12 }\n          width: [ 144, 8192 ]\n         height: [ 144, 8192 ]\n",
@@ -220026,7 +220084,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC jpeg Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "image/jpeg:\n          width: [ 64, 32768 ]\n         height: [ 64, 16384 ]\n",
@@ -220054,7 +220111,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC mpeg2video Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/mpeg:\n    mpegversion: 2\n   systemstream: false\n          width: [ 48, 4080 ]\n         height: [ 16, 4080 ]\n",
@@ -220082,7 +220138,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC mpeg4video Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/mpeg:\n    mpegversion: 4\n   systemstream: false\n          width: [ 48, 2032 ]\n         height: [ 16, 2032 ]\n",
@@ -220110,7 +220165,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC mpegvideo Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/mpeg:\n    mpegversion: 1\n   systemstream: false\n          width: [ 48, 4080 ]\n         height: [ 16, 4080 ]\n",
@@ -220138,7 +220192,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC vp8 Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-vp8:\n          width: [ 48, 4096 ]\n         height: [ 16, 4096 ]\n",
@@ -220166,7 +220219,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC VP8 Stateless Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-vp8:\n          width: [ 48, 4096 ]\n         height: [ 16, 4096 ]\n",
@@ -220210,7 +220262,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC vp9 Video Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-vp9:\n          width: [ 128, 8192 ]\n         height: [ 128, 8192 ]\n        profile: { (string)0, (string)2 }\n",
@@ -220238,7 +220289,6 @@
                     "GObject"
                 ],
                 "klass": "Codec/Decoder/Video/Hardware",
-                "long-name": "NVDEC VP9 Stateless Decoder",
                 "pad-templates": {
                     "sink": {
                         "caps": "video/x-vp9:\n          width: [ 128, 8192 ]\n         height: [ 128, 8192 ]\n        profile: { (string)0, (string)2 }\n      alignment: frame\n",
@@ -220273,9 +220323,9 @@
         "filename": "gstnvcodec",
         "license": "LGPL",
         "other-types": {
-            "GstCudaBaseFilter": {
+            "GstCudaBaseConvert": {
                 "hierarchy": [
-                    "GstCudaBaseFilter",
+                    "GstCudaBaseConvert",
                     "GstCudaBaseTransform",
                     "GstBaseTransform",
                     "GstElement",
@@ -225326,7 +225376,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             },
             "qsvh264dec": {
                 "author": "Seungha Yang <seungha@centricular.com>",
@@ -225725,7 +225775,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             },
             "qsvh265dec": {
                 "author": "Seungha Yang <seungha@centricular.com>",
@@ -226058,7 +226108,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             },
             "qsvjpegdec": {
                 "author": "Seungha Yang <seungha@centricular.com>",
@@ -226131,7 +226181,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             },
             "qsvvp9dec": {
                 "author": "Seungha Yang <seungha@centricular.com>",
@@ -226300,7 +226350,7 @@
                         "writable": true
                     }
                 },
-                "rank": "none"
+                "rank": "primary"
             }
         },
         "filename": "gstqsv",
@@ -233273,10 +233323,966 @@
     },
     "va": {
         "description": "VA-API codecs plugin",
-        "elements": {},
+        "elements": {
+            "vaav1dec": {
+                "author": "He Junyan <junyan.he@intel.com>",
+                "description": "VA-API based AV1 video decoder",
+                "hierarchy": [
+                    "GstVaAV1Dec",
+                    "GstAV1Decoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-av1:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, P010_10LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12, P010_10LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            },
+            "vacompositor": {
+                "author": "U. Artie Eoff <ullysses.a.eoff@intel.com>",
+                "description": "VA-API based video compositor",
+                "hierarchy": [
+                    "GstVaCompositor",
+                    "GstVideoAggregator",
+                    "GstAggregator",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "interfaces": [
+                    "GstChildProxy"
+                ],
+                "klass": "Filter/Editor/Video/Compositor/Hardware",
+                "pad-templates": {
+                    "sink_%%u": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, I420, YV12, YUY2, RGBA, BGRA, P010_10LE, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { VUYA, GRAY8, NV12, NV21, YUY2, UYVY, YV12, I420, P010_10LE, RGBA, BGRA, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "sink",
+                        "presence": "request",
+                        "type": "GstVaCompositorPad"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, I420, YV12, YUY2, RGBA, BGRA, P010_10LE, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { VUYA, GRAY8, NV12, NV21, YUY2, UYVY, YV12, I420, P010_10LE, RGBA, BGRA, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always",
+                        "type": "GstAggregatorPad"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    },
+                    "scale-method": {
+                        "blurb": "Scale method to use",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "default (0)",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "GstVaScaleMethod",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            },
+            "vadeinterlace": {
+                "author": "Vctor Jquez <vjaquez@igalia.com>",
+                "description": "VA-API based deinterlacer",
+                "hierarchy": [
+                    "GstVaDeinterlace",
+                    "GstVaBaseTransform",
+                    "GstBaseTransform",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Filter/Effect/Video/Deinterlace",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, I420, YV12, YUY2, RGBA, BGRA, P010_10LE, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { VUYA, GRAY8, NV12, NV21, YUY2, UYVY, YV12, I420, P010_10LE, RGBA, BGRA, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, I420, YV12, YUY2, RGBA, BGRA, P010_10LE, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { VUYA, GRAY8, NV12, NV21, YUY2, UYVY, YV12, I420, P010_10LE, RGBA, BGRA, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "method": {
+                        "blurb": "Deinterlace Method",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "bob (1)",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "GstVaDeinterlaceMethods",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            },
+            "vah264dec": {
+                "author": "Vctor Jquez <vjaquez@igalia.com>",
+                "description": "VA-API based H.264 video decoder",
+                "hierarchy": [
+                    "GstVaH264Dec",
+                    "GstH264Decoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-h264:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, P010_10LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12, P010_10LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            },
+            "vah264enc": {
+                "author": "He Junyan <junyan.he@intel.com>",
+                "description": "VA-API based H.264 video encoder",
+                "hierarchy": [
+                    "GstVaH264Enc",
+                    "GstVaBaseEnc",
+                    "GstVideoEncoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "interfaces": [
+                    "GstPreset"
+                ],
+                "klass": "Codec/Encoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-h264:\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "aud": {
+                        "blurb": "Insert AU (Access Unit) delimeter for each frame",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "false",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "b-frames": {
+                        "blurb": "Number of B frames between I and P reference frames",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "0",
+                        "max": "31",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "b-pyramid": {
+                        "blurb": "Enable the b-pyramid reference structure in the GOP",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "false",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "bitrate": {
+                        "blurb": "The desired bitrate expressed in kbps (0: auto-calculate)",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "0",
+                        "max": "2048000",
+                        "min": "0",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "cabac": {
+                        "blurb": "Enable CABAC entropy coding mode",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "true",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "cc-insert": {
+                        "blurb": "Insert CEA-708 Closed Captions",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "true",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "cpb-size": {
+                        "blurb": "The desired max CPB size in Kb (0: auto-calculate)",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "0",
+                        "max": "2048000",
+                        "min": "0",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "dct8x8": {
+                        "blurb": "Enable adaptive use of 8x8 transforms in I-frames",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "true",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "i-frames": {
+                        "blurb": "Force the number of I frames insertion within one GOP, not including the first IDR frame",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "0",
+                        "max": "1023",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "key-int-max": {
+                        "blurb": "The maximal distance between two keyframes. It decides the size of GOP (0: auto-calculate)",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "0",
+                        "max": "1024",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "max-qp": {
+                        "blurb": "Maximum quantizer value for each frame",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "51",
+                        "max": "51",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "mbbrc": {
+                        "blurb": "Macroblock level Bitrate Control. It is not compatible with CQP",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "disabled (0)",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "GstVaFeature",
+                        "writable": true
+                    },
+                    "min-qp": {
+                        "blurb": "Minimum quantizer value for each frame",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "1",
+                        "max": "51",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "num-slices": {
+                        "blurb": "Number of slices per frame",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "1",
+                        "max": "200",
+                        "min": "1",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "qpb": {
+                        "blurb": "The quantizer value for B frame. This is available only in CQP mode",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "26",
+                        "max": "51",
+                        "min": "0",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "qpi": {
+                        "blurb": "The quantizer value for I frame. In CQP mode, it specifies the QP of I frame, in other mode, it specifies the init QP of all frames",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "26",
+                        "max": "51",
+                        "min": "0",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "qpp": {
+                        "blurb": "The quantizer value for P frame. This is available only in CQP mode",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "26",
+                        "max": "51",
+                        "min": "0",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "ref-frames": {
+                        "blurb": "Number of reference frames, including both the forward and the backward",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "3",
+                        "max": "16",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "target-percentage": {
+                        "blurb": "The percentage for 'target bitrate'/'maximum bitrate' (Only in VBR)",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "66",
+                        "max": "100",
+                        "min": "50",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "target-usage": {
+                        "blurb": "The target usage to control and balance the encoding speed/quality",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "4",
+                        "max": "7",
+                        "min": "1",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint",
+                        "writable": true
+                    },
+                    "trellis": {
+                        "blurb": "Enable the trellis quantization method",
+                        "conditionally-available": false,
+                        "construct": true,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "false",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            },
+            "vah265dec": {
+                "author": "Nicolas Dufresne <nicolas.dufresne@collabora.com>",
+                "description": "VA-API based H.265 video decoder",
+                "hierarchy": [
+                    "GstVaH265Dec",
+                    "GstH265Decoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-h265:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, P010_10LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12, P010_10LE }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            },
+            "vajpegdec": {
+                "author": "Vctor Jquez <vjaquez@igalia.com>",
+                "description": "VA-API based JPEG image decoder",
+                "hierarchy": [
+                    "GstVaJpegDec",
+                    "GstJpegDecoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Image/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "image/jpeg:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            },
+            "vampeg2dec": {
+                "author": "He Junyan <junyan.he@intel.com>",
+                "description": "VA-API based Mpeg2 video decoder",
+                "hierarchy": [
+                    "GstVaMpeg2Dec",
+                    "GstMpeg2Decoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-mpeg2:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            },
+            "vapostproc": {
+                "author": "Vctor Jquez <vjaquez@igalia.com>",
+                "description": "VA-API based video postprocessor",
+                "hierarchy": [
+                    "GstVaPostProc",
+                    "GstVaBaseTransform",
+                    "GstBaseTransform",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "interfaces": [
+                    "GstColorBalance"
+                ],
+                "klass": "Effect/Converter/Filter/Colorspace/Scaler/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, I420, YV12, YUY2, RGBA, BGRA, P010_10LE, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { VUYA, GRAY8, NV12, NV21, YUY2, UYVY, YV12, I420, P010_10LE, RGBA, BGRA, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12, I420, YV12, YUY2, RGBA, BGRA, P010_10LE, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { VUYA, GRAY8, NV12, NV21, YUY2, UYVY, YV12, I420, P010_10LE, RGBA, BGRA, ARGB, ABGR }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "add-borders": {
+                        "blurb": "Add black borders if necessary to keep the display aspect ratio",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "false",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "disable-passthrough": {
+                        "blurb": "Forces passing buffers through the postprocessor",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "false",
+                        "mutable": "ready",
+                        "readable": true,
+                        "type": "gboolean",
+                        "writable": true
+                    },
+                    "scale-method": {
+                        "blurb": "Scale method to use",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "default (0)",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "GstVaScaleMethod",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            },
+            "vavp8dec": {
+                "author": "He Junyan <junyan.he@intel.com>",
+                "description": "VA-API based VP8 video decoder",
+                "hierarchy": [
+                    "GstVaVp8Dec",
+                    "GstVp8Decoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-vp8:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            },
+            "vavp9dec": {
+                "author": "Vctor Jquez <vjaquez@igalia.com>",
+                "description": "VA-API based VP9 video decoder",
+                "hierarchy": [
+                    "GstVaVp9Dec",
+                    "GstVp9Decoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Codec/Decoder/Video/Hardware",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-vp9:\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    },
+                    "src": {
+                        "caps": "video/x-raw(memory:VAMemory):\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\nvideo/x-raw:\n         format: { NV12 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                },
+                "rank": "none"
+            }
+        },
         "filename": "gstva",
         "license": "LGPL",
-        "other-types": {},
+        "other-types": {
+            "GstJpegDecoder": {
+                "hierarchy": [
+                    "GstJpegDecoder",
+                    "GstVideoDecoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "kind": "object"
+            },
+            "GstVaBaseEnc": {
+                "hierarchy": [
+                    "GstVaBaseEnc",
+                    "GstVideoEncoder",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "interfaces": [
+                    "GstPreset"
+                ],
+                "kind": "object",
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                }
+            },
+            "GstVaBaseTransform": {
+                "hierarchy": [
+                    "GstVaBaseTransform",
+                    "GstBaseTransform",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "kind": "object",
+                "properties": {
+                    "device-path": {
+                        "blurb": "DRM device path",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": false
+                    }
+                }
+            },
+            "GstVaCompositorPad": {
+                "hierarchy": [
+                    "GstVaCompositorPad",
+                    "GstVideoAggregatorPad",
+                    "GstAggregatorPad",
+                    "GstPad",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "kind": "object",
+                "properties": {
+                    "alpha": {
+                        "blurb": "Alpha of the picture",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": true,
+                        "default": "1",
+                        "max": "1",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gdouble",
+                        "writable": true
+                    },
+                    "height": {
+                        "blurb": "Height of the picture (0, to use the height of the input frame)",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": true,
+                        "default": "0",
+                        "max": "2147483647",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gint",
+                        "writable": true
+                    },
+                    "width": {
+                        "blurb": "Width of the picture (0, to use the width of the input frame)",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": true,
+                        "default": "0",
+                        "max": "2147483647",
+                        "min": "0",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gint",
+                        "writable": true
+                    },
+                    "xpos": {
+                        "blurb": "X Position of the picture",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": true,
+                        "default": "0",
+                        "max": "2147483647",
+                        "min": "-2147483648",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gint",
+                        "writable": true
+                    },
+                    "ypos": {
+                        "blurb": "Y Position of the picture",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": true,
+                        "default": "0",
+                        "max": "2147483647",
+                        "min": "-2147483648",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gint",
+                        "writable": true
+                    }
+                }
+            },
+            "GstVaDeinterlaceMethods": {
+                "kind": "enum",
+                "values": [
+                    {
+                        "desc": "Bob: Interpolating missing lines by using the adjacent lines.",
+                        "name": "bob",
+                        "value": "1"
+                    },
+                    {
+                        "desc": "Adaptive: Interpolating missing lines by using spatial/temporal references.",
+                        "name": "adaptive",
+                        "value": "3"
+                    },
+                    {
+                        "desc": "Compensation: Recreating missing lines by using motion vector.",
+                        "name": "compensated",
+                        "value": "4"
+                    }
+                ]
+            },
+            "GstVaScaleMethod": {
+                "kind": "enum",
+                "values": [
+                    {
+                        "desc": "Default scaling method",
+                        "name": "default",
+                        "value": "0"
+                    },
+                    {
+                        "desc": "Fast scaling method",
+                        "name": "fast",
+                        "value": "256"
+                    },
+                    {
+                        "desc": "High quality scaling method",
+                        "name": "hq",
+                        "value": "512"
+                    }
+                ]
+            }
+        },
         "package": "GStreamer Bad Plug-ins",
         "source": "gst-plugins-bad",
         "tracers": {},
@@ -235714,6 +236720,18 @@
                         "type": "GstWebRTCSessionDescription",
                         "writable": false
                     },
+                    "http-proxy": {
+                        "blurb": "A HTTP proxy for use with TURN/TCP of the form http://[username:password@]hostname[:port]",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "NULL",
+                        "mutable": "null",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": true
+                    },
                     "ice-agent": {
                         "blurb": "The WebRTC ICE agent",
                         "conditionally-available": false,
@@ -236667,6 +237685,102 @@
         "tracers": {},
         "url": "Unknown package origin"
     },
+    "win32ipc": {
+        "description": "Windows IPC plugin",
+        "elements": {
+            "win32ipcvideosink": {
+                "author": "Seungha Yang <seungha@centricular.com>",
+                "description": "Send video frames to win32ipcvideosrc elements",
+                "hierarchy": [
+                    "GstWin32IpcVideoSink",
+                    "GstBaseSink",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Sink/Video",
+                "pad-templates": {
+                    "sink": {
+                        "caps": "video/x-raw:\n         format: { ABGR64_LE, BGRA64_LE, AYUV64, ARGB64_LE, ARGB64, RGBA64_LE, ABGR64_BE, BGRA64_BE, ARGB64_BE, RGBA64_BE, GBRA_12LE, GBRA_12BE, Y412_LE, Y412_BE, A444_10LE, GBRA_10LE, A444_10BE, GBRA_10BE, A422_10LE, A422_10BE, A420_10LE, A420_10BE, RGB10A2_LE, BGR10A2_LE, Y410, GBRA, ABGR, VUYA, BGRA, AYUV, ARGB, RGBA, A420, AV12, Y444_16LE, Y444_16BE, v216, P016_LE, P016_BE, Y444_12LE, GBR_12LE, Y444_12BE, GBR_12BE, I422_12LE, I422_12BE, Y212_LE, Y212_BE, I420_12LE, I420_12BE, P012_LE, P012_BE, Y444_10LE, GBR_10LE, Y444_10BE, GBR_10BE, r210, I422_10LE, I422_10BE, NV16_10LE32, Y210, v210, UYVP, I420_10LE, I420_10BE, P010_10LE, NV12_10LE32, NV12_10LE40, P010_10BE, NV12_10BE_8L128, Y444, RGBP, GBR, BGRP, NV24, xBGR, BGRx, xRGB, RGBx, BGR, IYU2, v308, RGB, Y42B, NV61, NV16, VYUY, UYVY, YVYU, YUY2, I420, YV12, NV21, NV12, NV12_8L128, NV12_64Z32, NV12_4L4, NV12_32L32, NV12_16L32S, Y41B, IYU1, YVU9, YUV9, RGB16, BGR16, RGB15, BGR15, RGB8P, GRAY16_LE, GRAY16_BE, GRAY10_LE32, GRAY8 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "sink",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "pipe-name": {
+                        "blurb": "The name of Win32 named pipe to communicate with clients. Validation of the pipe name is caller's responsibility",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "\\\\.\\pipe\\gst.win32.ipc.video",
+                        "mutable": "ready",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            },
+            "win32ipcvideosrc": {
+                "author": "Seungha Yang <seungha@centricular.com>",
+                "description": "Receive video frames from the win32ipcvideosink",
+                "hierarchy": [
+                    "GstWin32IpcVideoSrc",
+                    "GstBaseSrc",
+                    "GstElement",
+                    "GstObject",
+                    "GInitiallyUnowned",
+                    "GObject"
+                ],
+                "klass": "Source/Video",
+                "pad-templates": {
+                    "src": {
+                        "caps": "video/x-raw:\n         format: { ABGR64_LE, BGRA64_LE, AYUV64, ARGB64_LE, ARGB64, RGBA64_LE, ABGR64_BE, BGRA64_BE, ARGB64_BE, RGBA64_BE, GBRA_12LE, GBRA_12BE, Y412_LE, Y412_BE, A444_10LE, GBRA_10LE, A444_10BE, GBRA_10BE, A422_10LE, A422_10BE, A420_10LE, A420_10BE, RGB10A2_LE, BGR10A2_LE, Y410, GBRA, ABGR, VUYA, BGRA, AYUV, ARGB, RGBA, A420, AV12, Y444_16LE, Y444_16BE, v216, P016_LE, P016_BE, Y444_12LE, GBR_12LE, Y444_12BE, GBR_12BE, I422_12LE, I422_12BE, Y212_LE, Y212_BE, I420_12LE, I420_12BE, P012_LE, P012_BE, Y444_10LE, GBR_10LE, Y444_10BE, GBR_10BE, r210, I422_10LE, I422_10BE, NV16_10LE32, Y210, v210, UYVP, I420_10LE, I420_10BE, P010_10LE, NV12_10LE32, NV12_10LE40, P010_10BE, NV12_10BE_8L128, Y444, RGBP, GBR, BGRP, NV24, xBGR, BGRx, xRGB, RGBx, BGR, IYU2, v308, RGB, Y42B, NV61, NV16, VYUY, UYVY, YVYU, YUY2, I420, YV12, NV21, NV12, NV12_8L128, NV12_64Z32, NV12_4L4, NV12_32L32, NV12_16L32S, Y41B, IYU1, YVU9, YUV9, RGB16, BGR16, RGB15, BGR15, RGB8P, GRAY16_LE, GRAY16_BE, GRAY10_LE32, GRAY8 }\n          width: [ 1, 2147483647 ]\n         height: [ 1, 2147483647 ]\n      framerate: [ 0/1, 2147483647/1 ]\n",
+                        "direction": "src",
+                        "presence": "always"
+                    }
+                },
+                "properties": {
+                    "pipe-name": {
+                        "blurb": "The name of Win32 named pipe to communicate with server. Validation of the pipe name is caller's responsibility",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "\\\\.\\pipe\\gst.win32.ipc.video",
+                        "mutable": "ready",
+                        "readable": true,
+                        "type": "gchararray",
+                        "writable": true
+                    },
+                    "processing-deadline": {
+                        "blurb": "Maximum processing time for a buffer in nanoseconds",
+                        "conditionally-available": false,
+                        "construct": false,
+                        "construct-only": false,
+                        "controllable": false,
+                        "default": "20000000",
+                        "max": "18446744073709551615",
+                        "min": "0",
+                        "mutable": "playing",
+                        "readable": true,
+                        "type": "guint64",
+                        "writable": true
+                    }
+                },
+                "rank": "none"
+            }
+        },
+        "filename": "gstwin32ipc",
+        "license": "LGPL",
+        "other-types": {},
+        "package": "GStreamer Bad Plug-ins",
+        "source": "gst-plugins-bad",
+        "tracers": {},
+        "url": "Unknown package origin"
+    },
     "winks": {
         "description": "Windows kernel streaming plugin",
         "elements": {
diff --git a/subprojects/gst-plugins-bad/ext/aes/gstaesdec.c b/subprojects/gst-plugins-bad/ext/aes/gstaesdec.c
index 9383f047af..66bd327c0b 100644
--- a/subprojects/gst-plugins-bad/ext/aes/gstaesdec.c
+++ b/subprojects/gst-plugins-bad/ext/aes/gstaesdec.c
@@ -583,11 +583,10 @@ gst_aes_dec_init_cipher (GstAesDec * filter)
     GST_ERROR_OBJECT (filter, "Could not initialize openssl cipher");
     return FALSE;
   }
-  if (filter->per_buffer_padding) {
-    if (!EVP_CIPHER_CTX_set_padding (filter->evp_ctx, 0)) {
-      GST_ERROR_OBJECT (filter, "Could not set padding");
-      return FALSE;
-    }
+  if (!EVP_CIPHER_CTX_set_padding (filter->evp_ctx,
+          filter->per_buffer_padding ? 0 : 1)) {
+    GST_ERROR_OBJECT (filter, "Could not set padding");
+    return FALSE;
   }
 
   return TRUE;
diff --git a/subprojects/gst-plugins-bad/ext/aom/gstav1dec.c b/subprojects/gst-plugins-bad/ext/aom/gstav1dec.c
index 40d6e4e87c..cf3339fad1 100644
--- a/subprojects/gst-plugins-bad/ext/aom/gstav1dec.c
+++ b/subprojects/gst-plugins-bad/ext/aom/gstav1dec.c
@@ -94,7 +94,7 @@ static gboolean gst_av1_dec_get_valid_format (GstAV1Dec * dec,
 
 #define gst_av1_dec_parent_class parent_class
 G_DEFINE_TYPE (GstAV1Dec, gst_av1_dec, GST_TYPE_VIDEO_DECODER);
-GST_ELEMENT_REGISTER_DEFINE (av1dec, "av1dec", GST_RANK_PRIMARY,
+GST_ELEMENT_REGISTER_DEFINE (av1dec, "av1dec", GST_RANK_SECONDARY,
     GST_TYPE_AV1_DEC);
 
 static void
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/ccutils.c b/subprojects/gst-plugins-bad/ext/closedcaption/ccutils.c
new file mode 100644
index 0000000000..20d8880ed9
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/ccutils.c
@@ -0,0 +1,999 @@
+/*
+ * GStreamer
+ * Copyright (C) 2022 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#  include <config.h>
+#endif
+
+#include <gst/base/base.h>
+
+#include "ccutils.h"
+
+#define GST_CAT_DEFAULT ccutils_debug_cat
+GST_DEBUG_CATEGORY (GST_CAT_DEFAULT);
+
+typedef struct cdp_fps_entry cdp_fps_entry;
+
+#define VAL_OR_0(v) ((v) ? (*(v)) : 0)
+
+static const struct cdp_fps_entry cdp_fps_table[] = {
+  {0x1f, 24000, 1001, 25, 22, 3 /* FIXME: alternating max cea608 count! */ },
+  {0x2f, 24, 1, 25, 22, 2},
+  {0x3f, 25, 1, 24, 22, 2},
+  {0x4f, 30000, 1001, 20, 18, 2},
+  {0x5f, 30, 1, 20, 18, 2},
+  {0x6f, 50, 1, 12, 11, 1},
+  {0x7f, 60000, 1001, 10, 9, 1},
+  {0x8f, 60, 1, 10, 9, 1},
+};
+const struct cdp_fps_entry null_fps_entry = { 0, 0, 0, 0 };
+
+const struct cdp_fps_entry *
+cdp_fps_entry_from_fps (guint fps_n, guint fps_d)
+{
+  int i;
+  for (i = 0; i < G_N_ELEMENTS (cdp_fps_table); i++) {
+    if (cdp_fps_table[i].fps_n == fps_n && cdp_fps_table[i].fps_d == fps_d)
+      return &cdp_fps_table[i];
+  }
+  return &null_fps_entry;
+}
+
+const struct cdp_fps_entry *
+cdp_fps_entry_from_id (guint8 id)
+{
+  int i;
+  for (i = 0; i < G_N_ELEMENTS (cdp_fps_table); i++) {
+    if (cdp_fps_table[i].fps_idx == id)
+      return &cdp_fps_table[i];
+  }
+  return &null_fps_entry;
+}
+
+/* Converts raw CEA708 cc_data and an optional timecode into CDP */
+guint
+convert_cea708_cc_data_to_cdp (GstObject * dbg_obj, GstCCCDPMode cdp_mode,
+    guint16 cdp_hdr_sequence_cntr, const guint8 * cc_data, guint cc_data_len,
+    guint8 * cdp, guint cdp_len, const GstVideoTimeCode * tc,
+    const cdp_fps_entry * fps_entry)
+{
+  GstByteWriter bw;
+  guint8 flags, checksum;
+  guint i, len;
+
+  GST_DEBUG_OBJECT (dbg_obj, "writing out cdp packet from cc_data with "
+      "length %u", cc_data_len);
+
+  gst_byte_writer_init_with_data (&bw, cdp, cdp_len, FALSE);
+  gst_byte_writer_put_uint16_be_unchecked (&bw, 0x9669);
+  /* Write a length of 0 for now */
+  gst_byte_writer_put_uint8_unchecked (&bw, 0);
+
+  gst_byte_writer_put_uint8_unchecked (&bw, fps_entry->fps_idx);
+
+  if (cc_data_len / 3 > fps_entry->max_cc_count) {
+    GST_WARNING_OBJECT (dbg_obj, "Too many cc_data triplets for framerate: %u. "
+        "Truncating to %u", cc_data_len / 3, fps_entry->max_cc_count);
+    cc_data_len = 3 * fps_entry->max_cc_count;
+  }
+
+  /* caption_service_active */
+  flags = 0x02;
+
+  /* ccdata_present */
+  if ((cdp_mode & GST_CC_CDP_MODE_CC_DATA))
+    flags |= 0x40;
+
+  /* time_code_present */
+  if ((cdp_mode & GST_CC_CDP_MODE_TIME_CODE) && tc && tc->config.fps_n > 0)
+    flags |= 0x80;
+
+  /* reserved */
+  flags |= 0x01;
+
+  gst_byte_writer_put_uint8_unchecked (&bw, flags);
+
+  gst_byte_writer_put_uint16_be_unchecked (&bw, cdp_hdr_sequence_cntr);
+
+  if ((cdp_mode & GST_CC_CDP_MODE_TIME_CODE) && tc && tc->config.fps_n > 0) {
+    guint8 u8;
+
+    gst_byte_writer_put_uint8_unchecked (&bw, 0x71);
+    /* reserved 11 - 2 bits */
+    u8 = 0xc0;
+    /* tens of hours - 2 bits */
+    u8 |= ((tc->hours / 10) & 0x3) << 4;
+    /* units of hours - 4 bits */
+    u8 |= (tc->hours % 10) & 0xf;
+    gst_byte_writer_put_uint8_unchecked (&bw, u8);
+
+    /* reserved 1 - 1 bit */
+    u8 = 0x80;
+    /* tens of minutes - 3 bits */
+    u8 |= ((tc->minutes / 10) & 0x7) << 4;
+    /* units of minutes - 4 bits */
+    u8 |= (tc->minutes % 10) & 0xf;
+    gst_byte_writer_put_uint8_unchecked (&bw, u8);
+
+    /* field flag - 1 bit */
+    u8 = tc->field_count < 2 ? 0x00 : 0x80;
+    /* tens of seconds - 3 bits */
+    u8 |= ((tc->seconds / 10) & 0x7) << 4;
+    /* units of seconds - 4 bits */
+    u8 |= (tc->seconds % 10) & 0xf;
+    gst_byte_writer_put_uint8_unchecked (&bw, u8);
+
+    /* drop frame flag - 1 bit */
+    u8 = (tc->config.flags & GST_VIDEO_TIME_CODE_FLAGS_DROP_FRAME) ? 0x80 :
+        0x00;
+    /* reserved0 - 1 bit */
+    /* tens of frames - 2 bits */
+    u8 |= ((tc->frames / 10) & 0x3) << 4;
+    /* units of frames 4 bits */
+    u8 |= (tc->frames % 10) & 0xf;
+    gst_byte_writer_put_uint8_unchecked (&bw, u8);
+  }
+
+  if ((cdp_mode & GST_CC_CDP_MODE_CC_DATA)) {
+    gst_byte_writer_put_uint8_unchecked (&bw, 0x72);
+    gst_byte_writer_put_uint8_unchecked (&bw, 0xe0 | fps_entry->max_cc_count);
+    gst_byte_writer_put_data_unchecked (&bw, cc_data, cc_data_len);
+    while (fps_entry->max_cc_count > cc_data_len / 3) {
+      gst_byte_writer_put_uint8_unchecked (&bw, 0xfa);
+      gst_byte_writer_put_uint8_unchecked (&bw, 0x00);
+      gst_byte_writer_put_uint8_unchecked (&bw, 0x00);
+      cc_data_len += 3;
+    }
+  }
+
+  gst_byte_writer_put_uint8_unchecked (&bw, 0x74);
+  gst_byte_writer_put_uint16_be_unchecked (&bw, cdp_hdr_sequence_cntr);
+  /* We calculate the checksum afterwards */
+  gst_byte_writer_put_uint8_unchecked (&bw, 0);
+
+  len = gst_byte_writer_get_pos (&bw);
+  gst_byte_writer_set_pos (&bw, 2);
+  gst_byte_writer_put_uint8_unchecked (&bw, len);
+
+  checksum = 0;
+  for (i = 0; i < len; i++) {
+    checksum += cdp[i];
+  }
+  checksum &= 0xff;
+  checksum = 256 - checksum;
+  cdp[len - 1] = checksum;
+
+  return len;
+}
+
+/* Converts CDP into raw CEA708 cc_data */
+guint
+convert_cea708_cdp_to_cc_data (GstObject * dbg_obj,
+    const guint8 * cdp, guint cdp_len, guint8 * cc_data,
+    GstVideoTimeCode * tc, const cdp_fps_entry ** out_fps_entry)
+{
+  GstByteReader br;
+  guint16 u16;
+  guint8 u8;
+  guint8 flags;
+  guint len = 0;
+  const struct cdp_fps_entry *fps_entry;
+
+  *out_fps_entry = &null_fps_entry;
+  memset (tc, 0, sizeof (*tc));
+
+  /* Header + footer length */
+  if (cdp_len < 11) {
+    GST_WARNING_OBJECT (dbg_obj, "cdp packet too short (%u). expected at "
+        "least %u", cdp_len, 11);
+    return 0;
+  }
+
+  gst_byte_reader_init (&br, cdp, cdp_len);
+  u16 = gst_byte_reader_get_uint16_be_unchecked (&br);
+  if (u16 != 0x9669) {
+    GST_WARNING_OBJECT (dbg_obj, "cdp packet does not have initial magic bytes "
+        "of 0x9669");
+    return 0;
+  }
+
+  u8 = gst_byte_reader_get_uint8_unchecked (&br);
+  if (u8 != cdp_len) {
+    GST_WARNING_OBJECT (dbg_obj, "cdp packet length (%u) does not match passed "
+        "in value (%u)", u8, cdp_len);
+    return 0;
+  }
+
+  u8 = gst_byte_reader_get_uint8_unchecked (&br);
+  fps_entry = cdp_fps_entry_from_id (u8);
+  if (!fps_entry || fps_entry->fps_n == 0) {
+    GST_WARNING_OBJECT (dbg_obj, "cdp packet does not have a valid framerate "
+        "id (0x%02x", u8);
+    return 0;
+  }
+
+  flags = gst_byte_reader_get_uint8_unchecked (&br);
+  /* No cc_data? */
+  if ((flags & 0x40) == 0) {
+    GST_DEBUG_OBJECT (dbg_obj, "cdp packet does have any cc_data");
+    return 0;
+  }
+
+  /* cdp_hdr_sequence_cntr */
+  gst_byte_reader_skip_unchecked (&br, 2);
+
+  /* time_code_present */
+  if (flags & 0x80) {
+    guint8 hours, minutes, seconds, frames, fields;
+    gboolean drop_frame;
+
+    if (gst_byte_reader_get_remaining (&br) < 5) {
+      GST_WARNING_OBJECT (dbg_obj, "cdp packet does not have enough data to "
+          "contain a timecode (%u). Need at least 5 bytes",
+          gst_byte_reader_get_remaining (&br));
+      return 0;
+    }
+    u8 = gst_byte_reader_get_uint8_unchecked (&br);
+    if (u8 != 0x71) {
+      GST_WARNING_OBJECT (dbg_obj, "cdp packet does not have timecode start "
+          "byte of 0x71, found 0x%02x", u8);
+      return 0;
+    }
+
+    u8 = gst_byte_reader_get_uint8_unchecked (&br);
+    if ((u8 & 0xc0) != 0xc0) {
+      GST_WARNING_OBJECT (dbg_obj, "reserved bits are not 0xc0, found 0x%02x",
+          u8);
+      return 0;
+    }
+
+    hours = ((u8 >> 4) & 0x3) * 10 + (u8 & 0xf);
+
+    u8 = gst_byte_reader_get_uint8_unchecked (&br);
+    if ((u8 & 0x80) != 0x80) {
+      GST_WARNING_OBJECT (dbg_obj, "reserved bit is not 0x80, found 0x%02x",
+          u8);
+      return 0;
+    }
+    minutes = ((u8 >> 4) & 0x7) * 10 + (u8 & 0xf);
+
+    u8 = gst_byte_reader_get_uint8_unchecked (&br);
+    if (u8 & 0x80)
+      fields = 2;
+    else
+      fields = 1;
+    seconds = ((u8 >> 4) & 0x7) * 10 + (u8 & 0xf);
+
+    u8 = gst_byte_reader_get_uint8_unchecked (&br);
+    if (u8 & 0x40) {
+      GST_WARNING_OBJECT (dbg_obj, "reserved bit is not 0x0, found 0x%02x", u8);
+      return 0;
+    }
+
+    drop_frame = !(!(u8 & 0x80));
+    frames = ((u8 >> 4) & 0x3) * 10 + (u8 & 0xf);
+
+    gst_video_time_code_init (tc, fps_entry->fps_n, fps_entry->fps_d, NULL,
+        drop_frame ? GST_VIDEO_TIME_CODE_FLAGS_DROP_FRAME :
+        GST_VIDEO_TIME_CODE_FLAGS_NONE, hours, minutes, seconds, frames,
+        fields);
+  }
+
+  /* ccdata_present */
+  if (flags & 0x40) {
+    guint8 cc_count;
+
+    if (gst_byte_reader_get_remaining (&br) < 2) {
+      GST_WARNING_OBJECT (dbg_obj, "not enough data to contain valid cc_data");
+      return 0;
+    }
+    u8 = gst_byte_reader_get_uint8_unchecked (&br);
+    if (u8 != 0x72) {
+      GST_WARNING_OBJECT (dbg_obj, "missing cc_data start code of 0x72, "
+          "found 0x%02x", u8);
+      return 0;
+    }
+
+    cc_count = gst_byte_reader_get_uint8_unchecked (&br);
+    if ((cc_count & 0xe0) != 0xe0) {
+      GST_WARNING_OBJECT (dbg_obj, "reserved bits are not 0xe0, found 0x%02x",
+          u8);
+      return 0;
+    }
+    cc_count &= 0x1f;
+
+    len = 3 * cc_count;
+    if (gst_byte_reader_get_remaining (&br) < len) {
+      GST_WARNING_OBJECT (dbg_obj, "not enough bytes (%u) left for the "
+          "number of byte triples (%u)", gst_byte_reader_get_remaining (&br),
+          cc_count);
+      return 0;
+    }
+
+    memcpy (cc_data, gst_byte_reader_get_data_unchecked (&br, len), len);
+  }
+
+  *out_fps_entry = fps_entry;
+
+  /* skip everything else we don't care about */
+  return len;
+}
+
+#define CC_DATA_EXTRACT_TOO_MANY_FIELD1 -2
+#define CC_DATA_EXTRACT_TOO_MANY_FIELD2 -3
+
+static gint
+cc_data_extract_cea608 (const guint8 * cc_data, guint cc_data_len,
+    guint8 * cea608_field1, guint * cea608_field1_len,
+    guint8 * cea608_field2, guint * cea608_field2_len)
+{
+  guint i, field_1_len = 0, field_2_len = 0;
+
+  if (cea608_field1_len) {
+    field_1_len = *cea608_field1_len;
+    *cea608_field1_len = 0;
+  }
+  if (cea608_field2_len) {
+    field_2_len = *cea608_field2_len;
+    *cea608_field2_len = 0;
+  }
+
+  if (cc_data_len % 3 != 0) {
+    GST_WARNING ("Invalid cc_data buffer size %u. Truncating to a multiple "
+        "of 3", cc_data_len);
+    cc_data_len = cc_data_len - (cc_data_len % 3);
+  }
+
+  for (i = 0; i < cc_data_len / 3; i++) {
+    guint8 byte0 = cc_data[i * 3 + 0];
+    guint8 byte1 = cc_data[i * 3 + 1];
+    guint8 byte2 = cc_data[i * 3 + 2];
+    gboolean cc_valid = (byte0 & 0x04) == 0x04;
+    guint8 cc_type = byte0 & 0x03;
+
+    GST_TRACE ("0x%02x 0x%02x 0x%02x, valid: %u, type: 0b%u%u", byte0, byte1,
+        byte2, cc_valid, (cc_type & 0x2) == 0x2, (cc_type & 0x1) == 0x1);
+
+    if (cc_type == 0x00) {
+      if (!cc_valid)
+        continue;
+
+      if (cea608_field1 && cea608_field1_len) {
+        if (*cea608_field1_len + 2 > field_1_len) {
+          GST_WARNING ("Too many cea608 input bytes %u for field 1",
+              *cea608_field1_len + 2);
+          return CC_DATA_EXTRACT_TOO_MANY_FIELD1;
+        }
+
+        if (byte1 != 0x80 || byte2 != 0x80) {
+          cea608_field1[(*cea608_field1_len)++] = byte1;
+          cea608_field1[(*cea608_field1_len)++] = byte2;
+        }
+      }
+    } else if (cc_type == 0x01) {
+      if (!cc_valid)
+        continue;
+
+      if (cea608_field2 && cea608_field2_len) {
+        if (*cea608_field2_len + 2 > field_2_len) {
+          GST_WARNING ("Too many cea608 input bytes %u for field 2",
+              *cea608_field2_len + 2);
+          return CC_DATA_EXTRACT_TOO_MANY_FIELD2;
+        }
+        if (byte1 != 0x80 || byte2 != 0x80) {
+          cea608_field2[(*cea608_field2_len)++] = byte1;
+          cea608_field2[(*cea608_field2_len)++] = byte2;
+        }
+      }
+    } else {
+      /* all cea608 packets must be at the beginning of a cc_data */
+      break;
+    }
+  }
+
+  g_assert_cmpint (i * 3, <=, cc_data_len);
+
+  GST_LOG ("Extracted cea608-1 of length %u and cea608-2 of length %u, "
+      "ccp_offset %i", VAL_OR_0 (cea608_field1_len),
+      VAL_OR_0 (cea608_field2_len), i * 3);
+
+  return i * 3;
+}
+
+gint
+drop_ccp_from_cc_data (guint8 * cc_data, guint cc_data_len)
+{
+  return cc_data_extract_cea608 (cc_data, cc_data_len, NULL, NULL, NULL, NULL);
+}
+
+#define DEFAULT_MAX_BUFFER_TIME (100 * GST_MSECOND)
+
+struct _CCBuffer
+{
+  GstObject parent;
+  GArray *cea608_1;
+  GArray *cea608_2;
+  GArray *cc_data;
+  /* used for tracking which field to write across output buffer boundaries */
+  gboolean last_cea608_written_was_field1;
+
+  /* properties */
+  GstClockTime max_buffer_time;
+  gboolean output_padding;
+};
+
+G_DEFINE_TYPE (CCBuffer, cc_buffer, G_TYPE_OBJECT);
+
+CCBuffer *
+cc_buffer_new (void)
+{
+  return g_object_new (cc_buffer_get_type (), NULL);
+}
+
+static void
+cc_buffer_init (CCBuffer * buf)
+{
+  buf->cea608_1 = g_array_new (FALSE, FALSE, sizeof (guint8));
+  buf->cea608_2 = g_array_new (FALSE, FALSE, sizeof (guint8));
+  buf->cc_data = g_array_new (FALSE, FALSE, sizeof (guint8));
+
+  buf->max_buffer_time = DEFAULT_MAX_BUFFER_TIME;
+  buf->output_padding = TRUE;
+}
+
+static void
+cc_buffer_finalize (GObject * object)
+{
+  CCBuffer *buf = GST_CC_BUFFER (object);
+
+  g_array_unref (buf->cea608_1);
+  buf->cea608_1 = NULL;
+  g_array_unref (buf->cea608_2);
+  buf->cea608_2 = NULL;
+  g_array_unref (buf->cc_data);
+  buf->cc_data = NULL;
+
+  G_OBJECT_CLASS (cc_buffer_parent_class)->finalize (object);
+}
+
+static void
+cc_buffer_class_init (CCBufferClass * buf_class)
+{
+  GObjectClass *gobject_class = (GObjectClass *) buf_class;
+
+  gobject_class->finalize = cc_buffer_finalize;
+}
+
+/* remove padding bytes from a cc_data packet. Returns the length of the new
+ * data in @cc_data */
+static guint
+compact_cc_data (guint8 * cc_data, guint cc_data_len)
+{
+  gboolean started_ccp = FALSE;
+  guint out_len = 0;
+  guint i;
+
+  if (cc_data_len % 3 != 0) {
+    GST_WARNING ("Invalid cc_data buffer size");
+    cc_data_len = cc_data_len - (cc_data_len % 3);
+  }
+
+  for (i = 0; i < cc_data_len / 3; i++) {
+    gboolean cc_valid = (cc_data[i * 3] & 0x04) == 0x04;
+    guint8 cc_type = cc_data[i * 3] & 0x03;
+
+    if (!started_ccp && (cc_type == 0x00 || cc_type == 0x01)) {
+      if (cc_valid) {
+        /* copy over valid 608 data */
+        cc_data[out_len++] = cc_data[i * 3];
+        cc_data[out_len++] = cc_data[i * 3 + 1];
+        cc_data[out_len++] = cc_data[i * 3 + 2];
+      }
+      continue;
+    }
+
+    if (cc_type & 0x10)
+      started_ccp = TRUE;
+
+    if (!cc_valid)
+      continue;
+
+    if (cc_type == 0x00 || cc_type == 0x01) {
+      GST_WARNING ("Invalid cc_data.  cea608 bytes after cea708");
+      return 0;
+    }
+
+    cc_data[out_len++] = cc_data[i * 3];
+    cc_data[out_len++] = cc_data[i * 3 + 1];
+    cc_data[out_len++] = cc_data[i * 3 + 2];
+  }
+
+  GST_LOG ("compacted cc_data from %u to %u", cc_data_len, out_len);
+
+  return out_len;
+}
+
+static guint
+calculate_n_cea608_doubles_from_time_ceil (CCBuffer * buf, GstClockTime ns)
+{
+  /* cea608 has a maximum bitrate of 60000/1001 * 2 bytes/s */
+  guint ret = gst_util_uint64_scale_ceil (ns, 120000, 1001 * GST_SECOND);
+
+  return GST_ROUND_UP_2 (ret);
+}
+
+static guint
+calculate_n_cea708_doubles_from_time_ceil (CCBuffer * buf, GstClockTime ns)
+{
+  /* ccp has a maximum bitrate of 9600000/1001 bits/s */
+  guint ret = gst_util_uint64_scale_ceil (ns, 9600000 / 8, 1001 * GST_SECOND);
+
+  return GST_ROUND_UP_2 (ret);
+}
+
+static void
+push_internal (CCBuffer * buf, const guint8 * cea608_1,
+    guint cea608_1_len, const guint8 * cea608_2, guint cea608_2_len,
+    const guint8 * cc_data, guint cc_data_len)
+{
+  guint max_cea608_bytes;
+
+  GST_DEBUG_OBJECT (buf, "pushing cea608-1: %u cea608-2: %u ccp: %u",
+      cea608_1_len, cea608_2_len, cc_data_len);
+  max_cea608_bytes =
+      calculate_n_cea608_doubles_from_time_ceil (buf, buf->max_buffer_time);
+
+  if (cea608_1_len > 0) {
+    if (cea608_1_len + buf->cea608_1->len > max_cea608_bytes) {
+      GST_WARNING_OBJECT (buf, "cea608 field 1 overflow, dropping all "
+          "previous data, max %u, attempted to hold %u", max_cea608_bytes,
+          cea608_1_len + buf->cea608_1->len);
+      g_array_set_size (buf->cea608_1, 0);
+    }
+    g_array_append_vals (buf->cea608_1, cea608_1, cea608_1_len);
+  }
+  if (cea608_2_len > 0) {
+    if (cea608_2_len + buf->cea608_2->len > max_cea608_bytes) {
+      GST_WARNING_OBJECT (buf, "cea608 field 2 overflow, dropping all "
+          "previous data, max %u, attempted to hold %u", max_cea608_bytes,
+          cea608_2_len + buf->cea608_2->len);
+      g_array_set_size (buf->cea608_2, 0);
+    }
+    g_array_append_vals (buf->cea608_2, cea608_2, cea608_2_len);
+  }
+  if (cc_data_len > 0) {
+    guint max_cea708_bytes =
+        calculate_n_cea708_doubles_from_time_ceil (buf, buf->max_buffer_time);
+    if (cc_data_len + buf->cc_data->len > max_cea708_bytes) {
+      GST_WARNING_OBJECT (buf, "ccp data overflow, dropping all "
+          "previous data, max %u, attempted to hold %u", max_cea708_bytes,
+          cc_data_len + buf->cc_data->len);
+      g_array_set_size (buf->cea608_2, 0);
+    }
+    g_array_append_vals (buf->cc_data, cc_data, cc_data_len);
+  }
+}
+
+gboolean
+cc_buffer_push_separated (CCBuffer * buf, const guint8 * cea608_1,
+    guint cea608_1_len, const guint8 * cea608_2, guint cea608_2_len,
+    const guint8 * cc_data, guint cc_data_len)
+{
+  guint8 cea608_1_copy[MAX_CEA608_LEN];
+  guint8 cea608_2_copy[MAX_CEA608_LEN];
+  guint8 cc_data_copy[MAX_CDP_PACKET_LEN];
+  guint i;
+
+  if (cea608_1 && cea608_1_len > 0) {
+    guint out_i = 0;
+    for (i = 0; i < cea608_1_len / 2; i++) {
+      if (cea608_1[i] != 0x80 || cea608_1[i + 1] != 0x80) {
+        cea608_1_copy[out_i++] = cea608_1[i];
+        cea608_1_copy[out_i++] = cea608_1[i + 1];
+      }
+    }
+    cea608_1_len = out_i;
+  } else {
+    cea608_1_len = 0;
+  }
+
+  if (cea608_2 && cea608_2_len > 0) {
+    guint out_i = 0;
+    for (i = 0; i < cea608_2_len / 2; i++) {
+      if (cea608_2[i] != 0x80 || cea608_2[i + 1] != 0x80) {
+        cea608_2_copy[out_i++] = cea608_2[i];
+        cea608_2_copy[out_i++] = cea608_2[i + 1];
+      }
+    }
+    cea608_2_len = out_i;
+  } else {
+    cea608_2_len = 0;
+  }
+
+  if (cc_data && cc_data_len > 0) {
+    memcpy (cc_data_copy, cc_data, cc_data_len);
+    cc_data_len = compact_cc_data (cc_data_copy, cc_data_len);
+  } else {
+    cc_data_len = 0;
+  }
+
+  push_internal (buf, cea608_1_copy, cea608_1_len, cea608_2_copy,
+      cea608_2_len, cc_data_copy, cc_data_len);
+
+  return cea608_1_len > 0 || cea608_2_len > 0 || cc_data_len > 0;
+}
+
+gboolean
+cc_buffer_push_cc_data (CCBuffer * buf, const guint8 * cc_data,
+    guint cc_data_len)
+{
+  guint8 cea608_1[MAX_CEA608_LEN];
+  guint8 cea608_2[MAX_CEA608_LEN];
+  guint8 cc_data_copy[MAX_CDP_PACKET_LEN];
+  guint cea608_1_len = MAX_CEA608_LEN;
+  guint cea608_2_len = MAX_CEA608_LEN;
+  int ccp_offset;
+
+  memcpy (cc_data_copy, cc_data, cc_data_len);
+
+  cc_data_len = compact_cc_data (cc_data_copy, cc_data_len);
+
+  ccp_offset = cc_data_extract_cea608 (cc_data_copy, cc_data_len, cea608_1,
+      &cea608_1_len, cea608_2, &cea608_2_len);
+
+  if (ccp_offset < 0) {
+    GST_WARNING_OBJECT (buf, "Failed to extract cea608 from cc_data");
+    return FALSE;
+  }
+
+  push_internal (buf, cea608_1, cea608_1_len, cea608_2,
+      cea608_2_len, &cc_data_copy[ccp_offset], cc_data_len - ccp_offset);
+
+  return cea608_1_len > 0 || cea608_2_len > 0 || cc_data_len - ccp_offset > 0;
+}
+
+void
+cc_buffer_get_stored_size (CCBuffer * buf, guint * cea608_1_len,
+    guint * cea608_2_len, guint * cc_data_len)
+{
+  if (cea608_1_len)
+    *cea608_1_len = buf->cea608_1->len;
+  if (cea608_2_len)
+    *cea608_2_len = buf->cea608_2->len;
+  if (cc_data_len)
+    *cc_data_len = buf->cc_data->len;
+}
+
+void
+cc_buffer_discard (CCBuffer * buf)
+{
+  g_array_set_size (buf->cea608_1, 0);
+  g_array_set_size (buf->cea608_2, 0);
+  g_array_set_size (buf->cc_data, 0);
+}
+
+#if 0
+void
+cc_buffer_peek (CCBuffer * buf, guint8 ** cea608_1, guint * cea608_1_len,
+    guint8 ** cea608_2, guint * cea608_2_len, guint8 ** cc_data,
+    guint * cc_data_len)
+{
+  if (cea608_1_len) {
+    if (cea608_1) {
+      *cea608_1 = (guint8 *) buf->cea608_1->data;
+    }
+    *cea608_1_len = buf->cea608_1->len;
+  }
+  if (cea608_1_len) {
+    if (cea608_2) {
+      *cea608_2 = (guint8 *) buf->cea608_2->data;
+    }
+    *cea608_2_len = buf->cea608_2->len;
+  }
+  if (cc_data_len) {
+    if (cc_data) {
+      *cc_data = (guint8 *) buf->cc_data->data;
+    }
+    *cc_data_len = buf->cc_data->len;
+  }
+}
+#endif
+static void
+cc_buffer_get_out_sizes (CCBuffer * buf, const struct cdp_fps_entry *fps_entry,
+    guint * cea608_1_len, guint * field1_padding, guint * cea608_2_len,
+    guint * field2_padding, guint * cc_data_len)
+{
+  gint extra_ccp = 0, extra_cea608_1 = 0, extra_cea608_2 = 0;
+  gint write_ccp_size = 0, write_cea608_1_size = 0, write_cea608_2_size = 0;
+  gboolean wrote_first = FALSE;
+
+  if (buf->cc_data->len) {
+    extra_ccp = buf->cc_data->len - 3 * fps_entry->max_ccp_count;
+    extra_ccp = MAX (0, extra_ccp);
+    write_ccp_size = buf->cc_data->len - extra_ccp;
+  }
+
+  extra_cea608_1 = buf->cea608_1->len;
+  extra_cea608_2 = buf->cea608_2->len;
+  *field1_padding = 0;
+  *field2_padding = 0;
+
+  wrote_first = !buf->last_cea608_written_was_field1;
+  /* try to push data into the packets.  Anything 'extra' will be
+   * stored for later */
+  while (TRUE) {
+    gint avail_1, avail_2;
+
+    avail_1 = buf->cea608_1->len - extra_cea608_1 + *field1_padding;
+    avail_2 = buf->cea608_2->len - extra_cea608_2 + *field2_padding;
+    if (avail_1 + avail_2 >= 2 * fps_entry->max_cea608_count)
+      break;
+
+    if (wrote_first) {
+      if (extra_cea608_1 > 0) {
+        extra_cea608_1 -= 2;
+        g_assert_cmpint (extra_cea608_1, >=, 0);
+        write_cea608_1_size += 2;
+        g_assert_cmpint (write_cea608_1_size, <=, buf->cea608_1->len);
+      } else {
+        *field1_padding += 2;
+      }
+    }
+
+    avail_1 = buf->cea608_1->len - extra_cea608_1 + *field1_padding;
+    avail_2 = buf->cea608_2->len - extra_cea608_2 + *field2_padding;
+    if (avail_1 + avail_2 >= 2 * fps_entry->max_cea608_count)
+      break;
+
+    if (extra_cea608_2 > 0) {
+      extra_cea608_2 -= 2;
+      g_assert_cmpint (extra_cea608_2, >=, 0);
+      write_cea608_2_size += 2;
+      g_assert_cmpint (write_cea608_2_size, <=, buf->cea608_2->len);
+    } else {
+      /* we need to insert field 2 padding if we don't have data and are
+       * requested to start with field2 */
+      *field2_padding += 2;
+    }
+    wrote_first = TRUE;
+  }
+
+  if (!buf->output_padding && write_cea608_1_size == 0
+      && write_cea608_2_size == 0) {
+    *field1_padding = 0;
+    *field2_padding = 0;
+  }
+
+  GST_TRACE_OBJECT (buf, "allocated sizes ccp:%u, cea608-1:%u (pad:%u), "
+      "cea608-2:%u (pad:%u)", write_ccp_size, write_cea608_1_size,
+      *field1_padding, write_cea608_2_size, *field2_padding);
+
+  *cea608_1_len = write_cea608_1_size;
+  *cea608_2_len = write_cea608_2_size;
+  *cc_data_len = write_ccp_size;
+}
+
+void
+cc_buffer_take_separated (CCBuffer * buf,
+    const struct cdp_fps_entry *fps_entry, guint8 * cea608_1,
+    guint * cea608_1_len, guint8 * cea608_2, guint * cea608_2_len,
+    guint8 * cc_data, guint * cc_data_len)
+{
+  guint write_cea608_1_size, write_cea608_2_size, write_ccp_size;
+  guint field1_padding, field2_padding;
+
+  cc_buffer_get_out_sizes (buf, fps_entry, &write_cea608_1_size,
+      &field1_padding, &write_cea608_2_size, &field2_padding, &write_ccp_size);
+
+  if (cea608_1_len) {
+    if (*cea608_1_len < write_cea608_1_size + field1_padding) {
+      GST_WARNING_OBJECT (buf, "output cea608 field 1 buffer (%u) is too "
+          "small to hold output (%u)", *cea608_1_len,
+          write_cea608_1_size + field1_padding);
+      *cea608_1_len = 0;
+    } else if (cea608_1) {
+      memcpy (cea608_1, buf->cea608_1->data, write_cea608_1_size);
+      memset (&cea608_1[write_cea608_1_size], 0x80, field1_padding);
+      *cea608_1_len = write_cea608_1_size + field1_padding;
+    } else {
+      *cea608_1_len = 0;
+    }
+  }
+  if (cea608_2_len) {
+    if (*cea608_2_len < write_cea608_2_size + field2_padding) {
+      GST_WARNING_OBJECT (buf, "output cea608 field 2 buffer (%u) is too "
+          "small to hold output (%u)", *cea608_2_len, write_cea608_2_size);
+      *cea608_2_len = 0;
+    } else if (cea608_2) {
+      memcpy (cea608_2, buf->cea608_2->data, write_cea608_2_size);
+      memset (&cea608_2[write_cea608_2_size], 0x80, field2_padding);
+      *cea608_2_len = write_cea608_2_size + field2_padding;
+    } else {
+      *cea608_2_len = 0;
+    }
+  }
+  if (cc_data_len) {
+    if (*cc_data_len < write_ccp_size) {
+      GST_WARNING_OBJECT (buf, "output ccp buffer (%u) is too "
+          "small to hold output (%u)", *cc_data_len, write_ccp_size);
+      *cc_data_len = 0;
+    } else if (cc_data) {
+      memcpy (cc_data, buf->cc_data->data, write_ccp_size);
+      *cc_data_len = write_ccp_size;
+    } else {
+      *cc_data_len = 0;
+    }
+  }
+
+  g_array_remove_range (buf->cea608_1, 0, write_cea608_1_size);
+  g_array_remove_range (buf->cea608_2, 0, write_cea608_2_size);
+  g_array_remove_range (buf->cc_data, 0, write_ccp_size);
+
+  GST_LOG_OBJECT (buf, "bytes currently stored, cea608-1:%u, cea608-2:%u "
+      "ccp:%u", buf->cea608_1->len, buf->cea608_2->len, buf->cc_data->len);
+}
+
+void
+cc_buffer_take_cc_data (CCBuffer * buf,
+    const struct cdp_fps_entry *fps_entry, guint8 * cc_data,
+    guint * cc_data_len)
+{
+  guint write_cea608_1_size, write_cea608_2_size, write_ccp_size;
+  guint field1_padding, field2_padding;
+  gboolean wrote_first;
+
+  cc_buffer_get_out_sizes (buf, fps_entry, &write_cea608_1_size,
+      &field1_padding, &write_cea608_2_size, &field2_padding, &write_ccp_size);
+
+  {
+    guint cea608_1_i = 0, cea608_2_i = 0;
+    guint out_i = 0;
+    guint8 *cea608_1 = (guint8 *) buf->cea608_1->data;
+    guint8 *cea608_2 = (guint8 *) buf->cea608_2->data;
+    guint cea608_output_count =
+        write_cea608_1_size + write_cea608_2_size + field1_padding +
+        field2_padding;
+
+    wrote_first = !buf->last_cea608_written_was_field1;
+    while (cea608_1_i + cea608_2_i < cea608_output_count) {
+      if (wrote_first) {
+        if (cea608_1_i < write_cea608_1_size) {
+          cc_data[out_i++] = 0xfc;
+          cc_data[out_i++] = cea608_1[cea608_1_i];
+          cc_data[out_i++] = cea608_1[cea608_1_i + 1];
+          cea608_1_i += 2;
+          buf->last_cea608_written_was_field1 = TRUE;
+        } else if (cea608_1_i < write_cea608_1_size + field1_padding) {
+          cc_data[out_i++] = 0xf8;
+          cc_data[out_i++] = 0x80;
+          cc_data[out_i++] = 0x80;
+          cea608_1_i += 2;
+          buf->last_cea608_written_was_field1 = TRUE;
+        }
+      }
+
+      if (cea608_2_i < write_cea608_2_size) {
+        cc_data[out_i++] = 0xfd;
+        cc_data[out_i++] = cea608_2[cea608_2_i];
+        cc_data[out_i++] = cea608_2[cea608_2_i + 1];
+        cea608_2_i += 2;
+        buf->last_cea608_written_was_field1 = FALSE;
+      } else if (cea608_2_i < write_cea608_2_size + field2_padding) {
+        cc_data[out_i++] = 0xf9;
+        cc_data[out_i++] = 0x80;
+        cc_data[out_i++] = 0x80;
+        cea608_2_i += 2;
+        buf->last_cea608_written_was_field1 = FALSE;
+      }
+
+      wrote_first = TRUE;
+    }
+
+    if (write_ccp_size > 0)
+      memcpy (&cc_data[out_i], buf->cc_data->data, write_ccp_size);
+    *cc_data_len = out_i + write_ccp_size;
+  }
+
+  g_array_remove_range (buf->cea608_1, 0, write_cea608_1_size);
+  g_array_remove_range (buf->cea608_2, 0, write_cea608_2_size);
+  g_array_remove_range (buf->cc_data, 0, write_ccp_size);
+
+  GST_LOG_OBJECT (buf, "bytes currently stored, cea608-1:%u, cea608-2:%u "
+      "ccp:%u", buf->cea608_1->len, buf->cea608_2->len, buf->cc_data->len);
+}
+
+void
+cc_buffer_take_cea608_field1 (CCBuffer * buf,
+    const struct cdp_fps_entry *fps_entry, guint8 * cea608_1,
+    guint * cea608_1_len)
+{
+  guint write_cea608_1_size, field1_padding;
+  guint write_cea608_2_size, field2_padding;
+  guint cc_data_len;
+
+  cc_buffer_get_out_sizes (buf, fps_entry, &write_cea608_1_size,
+      &field1_padding, &write_cea608_2_size, &field2_padding, &cc_data_len);
+
+  if (*cea608_1_len < write_cea608_1_size + field1_padding) {
+    GST_WARNING_OBJECT (buf,
+        "Not enough output space to write cea608 field 1 data");
+    *cea608_1_len = 0;
+    return;
+  }
+
+  if (write_cea608_1_size > 0) {
+    memcpy (cea608_1, buf->cea608_1->data, write_cea608_1_size);
+    g_array_remove_range (buf->cea608_1, 0, write_cea608_1_size);
+  }
+  *cea608_1_len = write_cea608_1_size;
+  if (buf->output_padding && field1_padding > 0) {
+    memset (&cea608_1[write_cea608_1_size], 0x80, field1_padding);
+    *cea608_1_len += field1_padding;
+  }
+}
+
+void
+cc_buffer_take_cea608_field2 (CCBuffer * buf,
+    const struct cdp_fps_entry *fps_entry, guint8 * cea608_2,
+    guint * cea608_2_len)
+{
+  guint write_cea608_1_size, field1_padding;
+  guint write_cea608_2_size, field2_padding;
+  guint cc_data_len;
+
+  cc_buffer_get_out_sizes (buf, fps_entry, &write_cea608_1_size,
+      &field1_padding, &write_cea608_2_size, &field2_padding, &cc_data_len);
+
+  if (*cea608_2_len < write_cea608_2_size + field2_padding) {
+    GST_WARNING_OBJECT (buf,
+        "Not enough output space to write cea608 field 2 data");
+    *cea608_2_len = 0;
+    return;
+  }
+
+  if (write_cea608_2_size > 0) {
+    memcpy (cea608_2, buf->cea608_2->data, write_cea608_2_size);
+    g_array_remove_range (buf->cea608_2, 0, write_cea608_2_size);
+  }
+  *cea608_2_len = write_cea608_2_size;
+  if (buf->output_padding && field1_padding > 0) {
+    memset (&cea608_2[write_cea608_2_size], 0x80, field2_padding);
+    *cea608_2_len += field2_padding;
+  }
+}
+
+gboolean
+cc_buffer_is_empty (CCBuffer * buf)
+{
+  return buf->cea608_1->len == 0 && buf->cea608_2->len == 0
+      && buf->cc_data->len == 0;
+}
+
+void
+cc_buffer_set_max_buffer_time (CCBuffer * buf, GstClockTime max_time)
+{
+  buf->max_buffer_time = max_time;
+}
+
+void
+cc_buffer_set_output_padding (CCBuffer * buf, gboolean output_padding)
+{
+  buf->output_padding = output_padding;
+}
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/ccutils.h b/subprojects/gst-plugins-bad/ext/closedcaption/ccutils.h
new file mode 100644
index 0000000000..c5374a41a8
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/ccutils.h
@@ -0,0 +1,136 @@
+/*
+ * GStreamer
+ * Copyright (C) 2022 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#include <gst/gst.h>
+#include <gst/video/video.h>
+
+#ifndef __CCUTILS_H__
+#define __CCUTILS_H__
+
+G_BEGIN_DECLS
+
+GST_DEBUG_CATEGORY_EXTERN(ccutils_debug_cat);
+
+struct cdp_fps_entry
+{
+  guint8 fps_idx;               /* value stored in cdp */
+  guint fps_n, fps_d;
+  guint max_cc_count;
+  guint max_ccp_count;
+  guint max_cea608_count;
+};
+
+G_GNUC_INTERNAL
+const struct cdp_fps_entry * cdp_fps_entry_from_fps (guint fps_n, guint fps_d);
+G_GNUC_INTERNAL
+const struct cdp_fps_entry * cdp_fps_entry_from_id  (guint8 id);
+
+extern const struct cdp_fps_entry null_fps_entry;
+
+typedef enum {
+  GST_CC_CDP_MODE_TIME_CODE   = (1<<0),
+  GST_CC_CDP_MODE_CC_DATA     = (1<<1),
+  GST_CC_CDP_MODE_CC_SVC_INFO = (1<<2)
+} GstCCCDPMode;
+
+G_GNUC_INTERNAL
+guint           convert_cea708_cc_data_to_cdp  (GstObject * dbg_obj,
+                                                GstCCCDPMode cdp_mode,
+                                                guint16 cdp_hdr_sequence_cntr,
+                                                const guint8 * cc_data,
+                                                guint cc_data_len,
+                                                guint8 * cdp,
+                                                guint cdp_len,
+                                                const GstVideoTimeCode * tc,
+                                                const struct cdp_fps_entry *fps_entry);
+
+G_GNUC_INTERNAL
+guint           convert_cea708_cdp_to_cc_data  (GstObject * dbg_obj,
+                                                const guint8 * cdp,
+                                                guint cdp_len,
+                                                guint8 *cc_data,
+                                                GstVideoTimeCode * tc,
+                                                const struct cdp_fps_entry **out_fps_entry);
+G_GNUC_INTERNAL
+gint           drop_ccp_from_cc_data           (guint8 * cc_data,
+                                                 guint cc_data_len);
+
+#define MAX_CDP_PACKET_LEN 256
+#define MAX_CEA608_LEN 32
+
+G_DECLARE_FINAL_TYPE (CCBuffer, cc_buffer, GST, CC_BUFFER, GObject);
+
+G_GNUC_INTERNAL
+CCBuffer *      cc_buffer_new                   (void);
+G_GNUC_INTERNAL
+void            cc_buffer_get_stored_size       (CCBuffer * buf,
+                                                 guint * cea608_1_len,
+                                                 guint * cea608_2_len,
+                                                 guint * cc_data_len);
+G_GNUC_INTERNAL
+gboolean        cc_buffer_push_separated        (CCBuffer * buf,
+                                                 const guint8 * cea608_1,
+                                                 guint cea608_1_len,
+                                                 const guint8 * cea608_2,
+                                                 guint cea608_2_len,
+                                                 const guint8 * cc_data,
+                                                 guint cc_data_len);
+G_GNUC_INTERNAL
+gboolean        cc_buffer_push_cc_data          (CCBuffer * buf,
+                                                 const guint8 * cc_data,
+                                                 guint cc_data_len);
+G_GNUC_INTERNAL
+void            cc_buffer_take_cc_data          (CCBuffer * buf,
+                                                 const struct cdp_fps_entry * fps_entry,
+                                                 guint8 * cc_data,
+                                                 guint * cc_data_len);
+G_GNUC_INTERNAL
+void            cc_buffer_take_separated        (CCBuffer * buf,
+                                                 const struct cdp_fps_entry * fps_entry,
+                                                 guint8 * cea608_1,
+                                                 guint * cea608_1_len,
+                                                 guint8 * cea608_2,
+                                                 guint * cea608_2_len,
+                                                 guint8 * cc_data,
+                                                 guint * cc_data_len);
+G_GNUC_INTERNAL
+void            cc_buffer_take_cea608_field1    (CCBuffer * buf,
+                                                 const struct cdp_fps_entry * fps_entry,
+                                                 guint8 * cea608_1,
+                                                 guint * cea608_1_len);
+G_GNUC_INTERNAL
+void            cc_buffer_take_cea608_field2    (CCBuffer * buf,
+                                                 const struct cdp_fps_entry * fps_entry,
+                                                 guint8 * cea608_2,
+                                                 guint * cea608_2_len);
+G_GNUC_INTERNAL
+gboolean        cc_buffer_is_empty              (CCBuffer * buf);
+G_GNUC_INTERNAL
+void            cc_buffer_discard               (CCBuffer * buf);
+G_GNUC_INTERNAL
+void            cc_buffer_set_max_buffer_time   (CCBuffer * buf,
+                                                 GstClockTime max_time);
+G_GNUC_INTERNAL
+void            cc_buffer_set_output_padding    (CCBuffer * buf,
+                                                 gboolean output_padding);
+
+G_END_DECLS
+
+#endif
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.c b/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.c
index 9d673a3084..b484ffe2ba 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.c
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.c
@@ -28,6 +28,7 @@
 #include <gst/video/video.h>
 #include <string.h>
 
+#include "ccutils.h"
 #include "gstcccombiner.h"
 
 GST_DEBUG_CATEGORY_STATIC (gst_cc_combiner_debug);
@@ -87,236 +88,50 @@ caption_data_clear (CaptionData * data)
   gst_buffer_unref (data->buffer);
 }
 
-static void
-clear_scheduled (CaptionQueueItem * item)
-{
-  gst_buffer_unref (item->buffer);
-}
-
 static void
 gst_cc_combiner_finalize (GObject * object)
 {
   GstCCCombiner *self = GST_CCCOMBINER (object);
 
-  gst_queue_array_free (self->scheduled[0]);
-  gst_queue_array_free (self->scheduled[1]);
   g_array_unref (self->current_frame_captions);
   self->current_frame_captions = NULL;
 
+  gst_clear_object (&self->cc_buffer);
+
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
 
 #define GST_FLOW_NEED_DATA GST_FLOW_CUSTOM_SUCCESS
 
-static const guint8 *
-extract_cdp (const guint8 * cdp, guint cdp_len, guint * cc_data_len)
+static guint
+extract_cdp (GstCCCombiner * self, const guint8 * cdp, guint cdp_len,
+    guint8 * cc_data)
 {
-  GstByteReader br;
-  guint16 u16;
-  guint8 u8;
-  guint8 flags;
-  guint len = 0;
-  const guint8 *cc_data = NULL;
-
-  *cc_data_len = 0;
-
-  /* Header + footer length */
-  if (cdp_len < 11) {
-    goto done;
-  }
-
-  gst_byte_reader_init (&br, cdp, cdp_len);
-  u16 = gst_byte_reader_get_uint16_be_unchecked (&br);
-  if (u16 != 0x9669) {
-    goto done;
-  }
-
-  u8 = gst_byte_reader_get_uint8_unchecked (&br);
-  if (u8 != cdp_len) {
-    goto done;
-  }
-
-  gst_byte_reader_skip_unchecked (&br, 1);
-
-  flags = gst_byte_reader_get_uint8_unchecked (&br);
-
-  /* No cc_data? */
-  if ((flags & 0x40) == 0) {
-    goto done;
-  }
-
-  /* cdp_hdr_sequence_cntr */
-  gst_byte_reader_skip_unchecked (&br, 2);
-
-  /* time_code_present */
-  if (flags & 0x80) {
-    if (gst_byte_reader_get_remaining (&br) < 5) {
-      goto done;
-    }
-    gst_byte_reader_skip_unchecked (&br, 5);
-  }
-
-  /* ccdata_present */
-  if (flags & 0x40) {
-    guint8 cc_count;
-
-    if (gst_byte_reader_get_remaining (&br) < 2) {
-      goto done;
-    }
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if (u8 != 0x72) {
-      goto done;
-    }
-
-    cc_count = gst_byte_reader_get_uint8_unchecked (&br);
-    if ((cc_count & 0xe0) != 0xe0) {
-      goto done;
-    }
-    cc_count &= 0x1f;
-
-    if (cc_count == 0)
-      return 0;
-
-    len = 3 * cc_count;
-    if (gst_byte_reader_get_remaining (&br) < len)
-      goto done;
-
-    cc_data = gst_byte_reader_get_data_unchecked (&br, len);
-    *cc_data_len = len;
-  }
+  const struct cdp_fps_entry *out_fps_entry;
+  GstVideoTimeCode tc = GST_VIDEO_TIME_CODE_INIT;
 
-done:
-  return cc_data;
+  return convert_cea708_cdp_to_cc_data (GST_OBJECT (self), cdp, cdp_len,
+      cc_data, &tc, &out_fps_entry);
 }
 
-#define MAX_CDP_PACKET_LEN 256
 #define MAX_CEA608_LEN 32
-
-static const struct cdp_fps_entry cdp_fps_table[] = {
-  {0x1f, 24000, 1001, 25, 22, 3 /* FIXME: alternating max cea608 count! */ },
-  {0x2f, 24, 1, 25, 22, 2},
-  {0x3f, 25, 1, 24, 22, 2},
-  {0x4f, 30000, 1001, 20, 18, 2},
-  {0x5f, 30, 1, 20, 18, 2},
-  {0x6f, 50, 1, 12, 11, 1},
-  {0x7f, 60000, 1001, 10, 9, 1},
-  {0x8f, 60, 1, 10, 9, 1},
-};
-static const struct cdp_fps_entry null_fps_entry = { 0, 0, 0, 0 };
-
-static const struct cdp_fps_entry *
-cdp_fps_entry_from_fps (guint fps_n, guint fps_d)
-{
-  int i;
-  for (i = 0; i < G_N_ELEMENTS (cdp_fps_table); i++) {
-    if (cdp_fps_table[i].fps_n == fps_n && cdp_fps_table[i].fps_d == fps_d)
-      return &cdp_fps_table[i];
-  }
-  return &null_fps_entry;
-}
-
+#define CDP_MODE (GST_CC_CDP_MODE_CC_DATA | GST_CC_CDP_MODE_TIME_CODE)
 
 static GstBuffer *
-make_cdp (GstCCCombiner * self, const guint8 * cc_data, guint cc_data_len,
-    const struct cdp_fps_entry *fps_entry, const GstVideoTimeCode * tc)
+make_cdp_buffer (GstCCCombiner * self, const guint8 * cc_data,
+    guint cc_data_len, const struct cdp_fps_entry *fps_entry,
+    const GstVideoTimeCode * tc)
 {
-  GstByteWriter bw;
-  guint8 flags, checksum;
-  guint i, len;
+  guint len;
   GstBuffer *ret = gst_buffer_new_allocate (NULL, MAX_CDP_PACKET_LEN, NULL);
   GstMapInfo map;
 
   gst_buffer_map (ret, &map, GST_MAP_WRITE);
 
-  gst_byte_writer_init_with_data (&bw, map.data, MAX_CDP_PACKET_LEN, FALSE);
-  gst_byte_writer_put_uint16_be_unchecked (&bw, 0x9669);
-  /* Write a length of 0 for now */
-  gst_byte_writer_put_uint8_unchecked (&bw, 0);
-
-  gst_byte_writer_put_uint8_unchecked (&bw, fps_entry->fps_idx);
-
-  /* caption_service_active */
-  flags = 0x02;
-
-  /* ccdata_present */
-  flags |= 0x40;
-
-  if (tc && tc->config.fps_n > 0)
-    flags |= 0x80;
-
-  /* reserved */
-  flags |= 0x01;
-
-  gst_byte_writer_put_uint8_unchecked (&bw, flags);
-
-  gst_byte_writer_put_uint16_be_unchecked (&bw, self->cdp_hdr_sequence_cntr);
-
-  if (tc && tc->config.fps_n > 0) {
-    guint8 u8;
-
-    gst_byte_writer_put_uint8_unchecked (&bw, 0x71);
-    /* reserved 11 - 2 bits */
-    u8 = 0xc0;
-    /* tens of hours - 2 bits */
-    u8 |= ((tc->hours / 10) & 0x3) << 4;
-    /* units of hours - 4 bits */
-    u8 |= (tc->hours % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-
-    /* reserved 1 - 1 bit */
-    u8 = 0x80;
-    /* tens of minutes - 3 bits */
-    u8 |= ((tc->minutes / 10) & 0x7) << 4;
-    /* units of minutes - 4 bits */
-    u8 |= (tc->minutes % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-
-    /* field flag - 1 bit */
-    u8 = tc->field_count < 2 ? 0x00 : 0x80;
-    /* tens of seconds - 3 bits */
-    u8 |= ((tc->seconds / 10) & 0x7) << 4;
-    /* units of seconds - 4 bits */
-    u8 |= (tc->seconds % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-
-    /* drop frame flag - 1 bit */
-    u8 = (tc->config.flags & GST_VIDEO_TIME_CODE_FLAGS_DROP_FRAME) ? 0x80 :
-        0x00;
-    /* reserved0 - 1 bit */
-    /* tens of frames - 2 bits */
-    u8 |= ((tc->frames / 10) & 0x3) << 4;
-    /* units of frames 4 bits */
-    u8 |= (tc->frames % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-  }
-
-  gst_byte_writer_put_uint8_unchecked (&bw, 0x72);
-  gst_byte_writer_put_uint8_unchecked (&bw, 0xe0 | fps_entry->max_cc_count);
-  gst_byte_writer_put_data_unchecked (&bw, cc_data, cc_data_len);
-  while (fps_entry->max_cc_count > cc_data_len / 3) {
-    gst_byte_writer_put_uint8_unchecked (&bw, 0xfa);
-    gst_byte_writer_put_uint8_unchecked (&bw, 0x00);
-    gst_byte_writer_put_uint8_unchecked (&bw, 0x00);
-    cc_data_len += 3;
-  }
-
-  gst_byte_writer_put_uint8_unchecked (&bw, 0x74);
-  gst_byte_writer_put_uint16_be_unchecked (&bw, self->cdp_hdr_sequence_cntr);
+  len = convert_cea708_cc_data_to_cdp (GST_OBJECT (self), CDP_MODE,
+      self->cdp_hdr_sequence_cntr, cc_data, cc_data_len, map.data, map.size,
+      tc, fps_entry);
   self->cdp_hdr_sequence_cntr++;
-  /* We calculate the checksum afterwards */
-  gst_byte_writer_put_uint8_unchecked (&bw, 0);
-
-  len = gst_byte_writer_get_pos (&bw);
-  gst_byte_writer_set_pos (&bw, 2);
-  gst_byte_writer_put_uint8_unchecked (&bw, len);
-
-  checksum = 0;
-  for (i = 0; i < len; i++) {
-    checksum += map.data[i];
-  }
-  checksum &= 0xff;
-  checksum = 256 - checksum;
-  map.data[len - 1] = checksum;
 
   gst_buffer_unmap (ret, &map);
 
@@ -326,157 +141,79 @@ make_cdp (GstCCCombiner * self, const guint8 * cc_data, guint cc_data_len,
 }
 
 static GstBuffer *
-make_padding (GstCCCombiner * self, const GstVideoTimeCode * tc, guint field)
+make_buffer (GstCCCombiner * self, const guint8 * cc_data, guint cc_data_len)
 {
-  GstBuffer *ret = NULL;
-
-  switch (self->caption_type) {
-    case GST_VIDEO_CAPTION_TYPE_CEA708_CDP:
-    {
-      const guint8 cc_data[6] = { 0xfc, 0x80, 0x80, 0xf9, 0x80, 0x80 };
-
-      ret = make_cdp (self, cc_data, 6, self->cdp_fps_entry, tc);
-      break;
-    }
-    case GST_VIDEO_CAPTION_TYPE_CEA708_RAW:
-    {
-      GstMapInfo map;
-
-      ret = gst_buffer_new_allocate (NULL, 3, NULL);
-
-      gst_buffer_map (ret, &map, GST_MAP_WRITE);
-
-      map.data[0] = 0xfc | (field & 0x01);
-      map.data[1] = 0x80;
-      map.data[2] = 0x80;
-
-      gst_buffer_unmap (ret, &map);
-      break;
-    }
-    case GST_VIDEO_CAPTION_TYPE_CEA608_S334_1A:
-    {
-      GstMapInfo map;
-
-      ret = gst_buffer_new_allocate (NULL, 3, NULL);
-
-      gst_buffer_map (ret, &map, GST_MAP_WRITE);
-
-      map.data[0] = field == 0 ? 0x80 : 0x00;
-      map.data[1] = 0x80;
-      map.data[2] = 0x80;
+  GstBuffer *ret = gst_buffer_new_allocate (NULL, cc_data_len, NULL);
+  gst_buffer_fill (ret, 0, cc_data, cc_data_len);
+  return ret;
+}
 
-      gst_buffer_unmap (ret, &map);
-      break;
-    }
-    case GST_VIDEO_CAPTION_TYPE_CEA608_RAW:
-    {
-      GstMapInfo map;
+static void
+write_cc_data_to (GstCCCombiner * self, GstBuffer * buffer)
+{
+  GstMapInfo map;
+  guint len;
 
-      ret = gst_buffer_new_allocate (NULL, 2, NULL);
+  gst_buffer_map (buffer, &map, GST_MAP_WRITE);
+  len = map.size;
+  cc_buffer_take_cc_data (self->cc_buffer, self->cdp_fps_entry, map.data, &len);
+  gst_buffer_unmap (buffer, &map);
+  gst_buffer_set_size (buffer, len);
+}
 
-      gst_buffer_map (ret, &map, GST_MAP_WRITE);
+static void
+prepend_s334_to_cea608 (guint field, guint8 * data, guint * len,
+    guint alloc_len)
+{
+  int i;
 
-      map.data[0] = 0x80;
-      map.data[1] = 0x80;
+  g_assert (*len / 2 * 3 <= alloc_len);
 
-      gst_buffer_unmap (ret, &map);
-      break;
-    }
-    default:
-      break;
+  for (i = *len / 2; i >= 0; i--) {
+    data[i * 3 + 0] = field == 0 ? 0x80 : 0x00;
+    data[i * 3 + 1] = data[i * 2 + 0];
+    data[i * 3 + 2] = data[i * 2 + 1];
   }
-
-  return ret;
 }
 
 static void
-queue_caption (GstCCCombiner * self, GstBuffer * scheduled, guint field)
+take_s334_both_fields (GstCCCombiner * self, GstBuffer * buffer)
 {
-  GstAggregatorPad *caption_pad;
-  CaptionQueueItem item;
-
-  if (self->progressive && field == 1) {
-    gst_buffer_unref (scheduled);
-    return;
+  GstMapInfo out = GST_MAP_INFO_INIT;
+  guint s334_len, cc_data_len, i;
+
+  gst_buffer_map (buffer, &out, GST_MAP_READWRITE);
+
+  cc_data_len = out.size;
+  cc_buffer_take_cc_data (self->cc_buffer, self->cdp_fps_entry, out.data,
+      &cc_data_len);
+  s334_len = drop_ccp_from_cc_data (out.data, cc_data_len);
+  if (s334_len < 0) {
+    s334_len = 0;
+    goto out;
   }
 
-  caption_pad =
-      GST_AGGREGATOR_PAD_CAST (gst_element_get_static_pad (GST_ELEMENT_CAST
-          (self), "caption"));
-
-  g_assert (gst_queue_array_get_length (self->scheduled[field]) <=
-      self->max_scheduled);
-
-  if (gst_queue_array_get_length (self->scheduled[field]) ==
-      self->max_scheduled) {
-    CaptionQueueItem *dropped =
-        gst_queue_array_pop_tail_struct (self->scheduled[field]);
-
-    GST_WARNING_OBJECT (self,
-        "scheduled queue runs too long, dropping %" GST_PTR_FORMAT, dropped);
-
-    gst_element_post_message (GST_ELEMENT_CAST (self),
-        gst_message_new_qos (GST_OBJECT_CAST (self), FALSE,
-            dropped->running_time, dropped->stream_time,
-            GST_BUFFER_PTS (dropped->buffer), GST_BUFFER_DURATION (dropped)));
-
-    gst_buffer_unref (dropped->buffer);
+  for (i = 0; i < s334_len / 3; i++) {
+    guint byte = out.data[i * 3];
+    /* We have to assume a line offset of 0 */
+    out.data[i * 3] = (byte == 0xfc || byte == 0xf8) ? 0x80 : 0x00;
   }
 
-  gst_object_unref (caption_pad);
-
-  item.buffer = scheduled;
-  item.running_time =
-      gst_segment_to_running_time (&caption_pad->segment, GST_FORMAT_TIME,
-      GST_BUFFER_PTS (scheduled));
-  item.stream_time =
-      gst_segment_to_stream_time (&caption_pad->segment, GST_FORMAT_TIME,
-      GST_BUFFER_PTS (scheduled));
-
-  gst_queue_array_push_tail_struct (self->scheduled[field], &item);
+out:
+  gst_buffer_unmap (buffer, &out);
+  gst_buffer_set_size (buffer, s334_len);
 }
 
 static void
 schedule_cdp (GstCCCombiner * self, const GstVideoTimeCode * tc,
     const guint8 * data, guint len, GstClockTime pts, GstClockTime duration)
 {
-  const guint8 *cc_data;
+  guint8 cc_data[MAX_CDP_PACKET_LEN];
   guint cc_data_len;
-  gboolean inject = FALSE;
-
-  if ((cc_data = extract_cdp (data, len, &cc_data_len))) {
-    guint8 i;
 
-    for (i = 0; i < cc_data_len / 3; i++) {
-      gboolean cc_valid = (cc_data[i * 3] & 0x04) == 0x04;
-      guint8 cc_type = cc_data[i * 3] & 0x03;
-
-      if (!cc_valid)
-        continue;
-
-      if (cc_type == 0x00 || cc_type == 0x01) {
-        if (cc_data[i * 3 + 1] != 0x80 || cc_data[i * 3 + 2] != 0x80) {
-          inject = TRUE;
-          break;
-        }
-        continue;
-      } else {
-        inject = TRUE;
-        break;
-      }
-    }
-  }
-
-  if (inject) {
-    GstBuffer *buf =
-        make_cdp (self, cc_data, cc_data_len, self->cdp_fps_entry, tc);
-
-    /* We only set those for QoS reporting purposes */
-    GST_BUFFER_PTS (buf) = pts;
-    GST_BUFFER_DURATION (buf) = duration;
-
-    queue_caption (self, buf, 0);
-  }
+  cc_data_len = extract_cdp (self, data, len, cc_data);
+  if (cc_buffer_push_cc_data (self->cc_buffer, cc_data, cc_data_len))
+    self->current_scheduled++;
 }
 
 static void
@@ -486,7 +223,6 @@ schedule_cea608_s334_1a (GstCCCombiner * self, guint8 * data, guint len,
   guint8 field0_data[3], field1_data[3];
   guint field0_len = 0, field1_len = 0;
   guint i;
-  gboolean field0_608 = FALSE, field1_608 = FALSE;
 
   if (len % 3 != 0) {
     GST_WARNING ("Invalid cc_data buffer size %u. Truncating to a multiple "
@@ -496,158 +232,40 @@ schedule_cea608_s334_1a (GstCCCombiner * self, guint8 * data, guint len,
 
   for (i = 0; i < len / 3; i++) {
     if (data[i * 3] & 0x80) {
-      if (field0_608)
-        continue;
-
-      field0_608 = TRUE;
-
       if (data[i * 3 + 1] == 0x80 && data[i * 3 + 2] == 0x80)
         continue;
 
-      field0_data[field0_len++] = data[i * 3];
       field0_data[field0_len++] = data[i * 3 + 1];
       field0_data[field0_len++] = data[i * 3 + 2];
     } else {
-      if (field1_608)
-        continue;
-
-      field1_608 = TRUE;
-
       if (data[i * 3 + 1] == 0x80 && data[i * 3 + 2] == 0x80)
         continue;
 
-      field1_data[field1_len++] = data[i * 3];
       field1_data[field1_len++] = data[i * 3 + 1];
       field1_data[field1_len++] = data[i * 3 + 2];
     }
   }
 
-  if (field0_len > 0) {
-    GstBuffer *buf = gst_buffer_new_allocate (NULL, field0_len, NULL);
-
-    gst_buffer_fill (buf, 0, field0_data, field0_len);
-    GST_BUFFER_PTS (buf) = pts;
-    GST_BUFFER_DURATION (buf) = duration;
-
-    queue_caption (self, buf, 0);
-  }
-
-  if (field1_len > 0) {
-    GstBuffer *buf = gst_buffer_new_allocate (NULL, field1_len, NULL);
-
-    gst_buffer_fill (buf, 0, field1_data, field1_len);
-    GST_BUFFER_PTS (buf) = pts;
-    GST_BUFFER_DURATION (buf) = duration;
-
-    queue_caption (self, buf, 1);
-  }
+  if (cc_buffer_push_separated (self->cc_buffer, field0_data, field0_len,
+          field1_data, field1_len, NULL, 0))
+    self->current_scheduled++;
 }
 
 static void
 schedule_cea708_raw (GstCCCombiner * self, guint8 * data, guint len,
     GstClockTime pts, GstClockTime duration)
 {
-  guint8 field0_data[MAX_CDP_PACKET_LEN], field1_data[3];
-  guint field0_len = 0, field1_len = 0;
-  guint i;
-  gboolean field0_608 = FALSE, field1_608 = FALSE;
-  gboolean started_ccp = FALSE;
-
-  if (len % 3 != 0) {
-    GST_WARNING ("Invalid cc_data buffer size %u. Truncating to a multiple "
-        "of 3", len);
-    len = len - (len % 3);
-  }
-
-  for (i = 0; i < len / 3; i++) {
-    gboolean cc_valid = (data[i * 3] & 0x04) == 0x04;
-    guint8 cc_type = data[i * 3] & 0x03;
-
-    if (!started_ccp) {
-      if (cc_type == 0x00) {
-        if (!cc_valid)
-          continue;
-
-        if (field0_608)
-          continue;
-
-        field0_608 = TRUE;
-
-        if (data[i * 3 + 1] == 0x80 && data[i * 3 + 2] == 0x80)
-          continue;
-
-        field0_data[field0_len++] = data[i * 3];
-        field0_data[field0_len++] = data[i * 3 + 1];
-        field0_data[field0_len++] = data[i * 3 + 2];
-      } else if (cc_type == 0x01) {
-        if (!cc_valid)
-          continue;
-
-        if (field1_608)
-          continue;
-
-        field1_608 = TRUE;
-
-        if (data[i * 3 + 1] == 0x80 && data[i * 3 + 2] == 0x80)
-          continue;
-
-        field1_data[field1_len++] = data[i * 3];
-        field1_data[field1_len++] = data[i * 3 + 1];
-        field1_data[field1_len++] = data[i * 3 + 2];
-      }
-
-      continue;
-    }
-
-    if (cc_type & 0x10)
-      started_ccp = TRUE;
-
-    if (!cc_valid)
-      continue;
-
-    if (cc_type == 0x00 || cc_type == 0x01)
-      continue;
-
-    field0_data[field0_len++] = data[i * 3];
-    field0_data[field0_len++] = data[i * 3 + 1];
-    field0_data[field0_len++] = data[i * 3 + 2];
-  }
-
-  if (field0_len > 0) {
-    GstBuffer *buf = gst_buffer_new_allocate (NULL, field0_len, NULL);
-
-    gst_buffer_fill (buf, 0, field0_data, field0_len);
-    GST_BUFFER_PTS (buf) = pts;
-    GST_BUFFER_DURATION (buf) = duration;
-
-    queue_caption (self, buf, 0);
-  }
-
-  if (field1_len > 0) {
-    GstBuffer *buf = gst_buffer_new_allocate (NULL, field1_len, NULL);
-
-    gst_buffer_fill (buf, 0, field1_data, field1_len);
-    GST_BUFFER_PTS (buf) = pts;
-    GST_BUFFER_DURATION (buf) = duration;
-
-    queue_caption (self, buf, 1);
-  }
+  if (cc_buffer_push_cc_data (self->cc_buffer, data, len))
+    self->current_scheduled++;
 }
 
 static void
-schedule_cea608_raw (GstCCCombiner * self, guint8 * data, guint len,
-    GstBuffer * buffer)
+schedule_cea608_raw (GstCCCombiner * self, guint8 * data, guint len)
 {
-  if (len < 2) {
-    return;
-  }
-
-  if (data[0] != 0x80 || data[1] != 0x80) {
-    queue_caption (self, gst_buffer_ref (buffer), 0);
-  }
+  if (cc_buffer_push_separated (self->cc_buffer, data, len, NULL, 0, NULL, 0))
+    self->current_scheduled++;
 }
 
-
 static void
 schedule_caption (GstCCCombiner * self, GstBuffer * caption_buf,
     const GstVideoTimeCode * tc)
@@ -658,6 +276,34 @@ schedule_caption (GstCCCombiner * self, GstBuffer * caption_buf,
   pts = GST_BUFFER_PTS (caption_buf);
   duration = GST_BUFFER_DURATION (caption_buf);
 
+  if (self->current_scheduled + 1 >= self->max_scheduled) {
+    GstClockTime stream_time, running_time;
+    GstAggregatorPad *caption_pad;
+
+    caption_pad =
+        GST_AGGREGATOR_PAD_CAST (gst_element_get_static_pad (GST_ELEMENT_CAST
+            (self), "caption"));
+
+    GST_WARNING_OBJECT (self,
+        "scheduled queue runs too long, discarding stored");
+
+    running_time =
+        gst_segment_to_running_time (&caption_pad->segment, GST_FORMAT_TIME,
+        pts);
+    stream_time =
+        gst_segment_to_stream_time (&caption_pad->segment, GST_FORMAT_TIME,
+        pts);
+
+    gst_element_post_message (GST_ELEMENT_CAST (self),
+        gst_message_new_qos (GST_OBJECT_CAST (self), FALSE,
+            running_time, stream_time, pts, duration));
+
+    cc_buffer_discard (self->cc_buffer);
+    self->current_scheduled = 0;
+
+    gst_clear_object (&caption_pad);
+  }
+
   gst_buffer_map (caption_buf, &map, GST_MAP_READ);
 
   switch (self->caption_type) {
@@ -671,7 +317,7 @@ schedule_caption (GstCCCombiner * self, GstBuffer * caption_buf,
       schedule_cea608_s334_1a (self, map.data, map.size, pts, duration);
       break;
     case GST_VIDEO_CAPTION_TYPE_CEA608_RAW:
-      schedule_cea608_raw (self, map.data, map.size, caption_buf);
+      schedule_cea608_raw (self, map.data, map.size);
       break;
     default:
       break;
@@ -681,64 +327,119 @@ schedule_caption (GstCCCombiner * self, GstBuffer * caption_buf,
 }
 
 static void
-dequeue_caption_one_field (GstCCCombiner * self, const GstVideoTimeCode * tc,
-    guint field, gboolean drain)
-{
-  CaptionQueueItem *scheduled;
-  CaptionData caption_data;
-
-  if ((scheduled = gst_queue_array_pop_head_struct (self->scheduled[field]))) {
-    caption_data.buffer = scheduled->buffer;
-    caption_data.caption_type = self->caption_type;
-    g_array_append_val (self->current_frame_captions, caption_data);
-  } else if (!drain && self->output_padding) {
-    caption_data.caption_type = self->caption_type;
-    caption_data.buffer = make_padding (self, tc, field);
-    g_array_append_val (self->current_frame_captions, caption_data);
-  }
-}
-
-static void
-dequeue_caption_both_fields (GstCCCombiner * self, const GstVideoTimeCode * tc,
-    gboolean drain)
+dequeue_caption (GstCCCombiner * self, GstVideoTimeCode * tc, gboolean drain)
 {
-  CaptionQueueItem *field0_scheduled, *field1_scheduled;
-  GstBuffer *field0_buffer = NULL, *field1_buffer = NULL;
+  guint8 cea608_1[MAX_CEA608_LEN], cea608_2[MAX_CEA608_LEN];
+  guint8 cc_data[MAX_CDP_PACKET_LEN];
+  guint cea608_1_len = MAX_CEA608_LEN, cea608_2_len = MAX_CEA608_LEN;
+  guint cc_data_len = MAX_CDP_PACKET_LEN;
   CaptionData caption_data;
 
-  field0_scheduled = gst_queue_array_pop_head_struct (self->scheduled[0]);
-  field1_scheduled = gst_queue_array_pop_head_struct (self->scheduled[1]);
+  g_assert (self->current_frame_captions->len == 0);
 
-  if (drain && !field0_scheduled && !field1_scheduled) {
+  if (drain && cc_buffer_is_empty (self->cc_buffer))
     return;
-  }
 
-  if (field0_scheduled) {
-    field0_buffer = field0_scheduled->buffer;
-  } else if (self->output_padding) {
-    field0_buffer = make_padding (self, tc, 0);
-  }
-
-  if (field1_scheduled) {
-    field1_buffer = field1_scheduled->buffer;
-  } else if (self->output_padding) {
-    field1_buffer = make_padding (self, tc, 1);
-  }
-
-  if (field0_buffer || field1_buffer) {
-    if (field0_buffer && field1_buffer) {
-      caption_data.buffer = gst_buffer_append (field0_buffer, field1_buffer);
-    } else if (field0_buffer) {
-      caption_data.buffer = field0_buffer;
-    } else if (field1_buffer) {
-      caption_data.buffer = field1_buffer;
-    } else {
-      g_assert_not_reached ();
+  caption_data.caption_type = self->caption_type;
+  switch (self->caption_type) {
+    case GST_VIDEO_CAPTION_TYPE_CEA708_CDP:
+    {
+      /* Only relevant in alternate and mixed mode, no need to look at the caps */
+      if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
+              GST_VIDEO_BUFFER_FLAG_INTERLACED)) {
+        if (!GST_VIDEO_BUFFER_IS_BOTTOM_FIELD (self->current_video_buffer)) {
+          cc_buffer_take_cc_data (self->cc_buffer, self->cdp_fps_entry, cc_data,
+              &cc_data_len);
+          caption_data.buffer =
+              make_cdp_buffer (self, cc_data, cc_data_len, self->cdp_fps_entry,
+              tc);
+          g_array_append_val (self->current_frame_captions, caption_data);
+        }
+      } else {
+        cc_buffer_take_cc_data (self->cc_buffer, self->cdp_fps_entry, cc_data,
+            &cc_data_len);
+        caption_data.buffer =
+            make_cdp_buffer (self, cc_data, cc_data_len, self->cdp_fps_entry,
+            tc);
+        g_array_append_val (self->current_frame_captions, caption_data);
+      }
+      break;
     }
-
-    caption_data.caption_type = self->caption_type;
-
-    g_array_append_val (self->current_frame_captions, caption_data);
+    case GST_VIDEO_CAPTION_TYPE_CEA708_RAW:
+    {
+      /* Only relevant in alternate and mixed mode, no need to look at the caps */
+      if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
+              GST_VIDEO_BUFFER_FLAG_INTERLACED)) {
+        if (!GST_VIDEO_BUFFER_IS_BOTTOM_FIELD (self->current_video_buffer)) {
+          caption_data.buffer =
+              gst_buffer_new_allocate (NULL, MAX_CDP_PACKET_LEN, NULL);
+          write_cc_data_to (self, caption_data.buffer);
+          g_array_append_val (self->current_frame_captions, caption_data);
+        }
+      } else {
+        caption_data.buffer =
+            gst_buffer_new_allocate (NULL, MAX_CDP_PACKET_LEN, NULL);
+        write_cc_data_to (self, caption_data.buffer);
+        g_array_append_val (self->current_frame_captions, caption_data);
+      }
+      break;
+    }
+    case GST_VIDEO_CAPTION_TYPE_CEA608_S334_1A:
+    {
+      if (self->progressive) {
+        cc_buffer_take_separated (self->cc_buffer, self->cdp_fps_entry,
+            cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, cc_data,
+            &cc_data_len);
+        prepend_s334_to_cea608 (0, cea608_1, &cea608_1_len, sizeof (cea608_1));
+        caption_data.buffer = make_buffer (self, cea608_1, cea608_1_len);
+        g_array_append_val (self->current_frame_captions, caption_data);
+      } else if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
+              GST_VIDEO_BUFFER_FLAG_INTERLACED) &&
+          GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
+              GST_VIDEO_BUFFER_FLAG_ONEFIELD)) {
+        cc_buffer_take_separated (self->cc_buffer, self->cdp_fps_entry,
+            cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, cc_data,
+            &cc_data_len);
+        if (GST_VIDEO_BUFFER_IS_TOP_FIELD (self->current_video_buffer)) {
+          prepend_s334_to_cea608 (0, cea608_1, &cea608_1_len,
+              sizeof (cea608_1));
+          caption_data.buffer = make_buffer (self, cea608_1, cea608_1_len);
+        } else {
+          prepend_s334_to_cea608 (1, cea608_2, &cea608_2_len,
+              sizeof (cea608_2));
+          caption_data.buffer = make_buffer (self, cea608_2, cea608_2_len);
+        }
+        g_array_append_val (self->current_frame_captions, caption_data);
+      } else {
+        caption_data.buffer =
+            gst_buffer_new_allocate (NULL, MAX_CDP_PACKET_LEN, NULL);
+        take_s334_both_fields (self, caption_data.buffer);
+        g_array_append_val (self->current_frame_captions, caption_data);
+      }
+      break;
+    }
+    case GST_VIDEO_CAPTION_TYPE_CEA608_RAW:
+    {
+      cc_buffer_take_separated (self->cc_buffer, self->cdp_fps_entry,
+          cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, cc_data,
+          &cc_data_len);
+      if (self->progressive) {
+        caption_data.buffer = make_buffer (self, cea608_1, cea608_1_len);
+        g_array_append_val (self->current_frame_captions, caption_data);
+      } else if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
+              GST_VIDEO_BUFFER_FLAG_INTERLACED)) {
+        if (!GST_VIDEO_BUFFER_IS_BOTTOM_FIELD (self->current_video_buffer)) {
+          caption_data.buffer = make_buffer (self, cea608_1, cea608_1_len);
+          g_array_append_val (self->current_frame_captions, caption_data);
+        }
+      } else {
+        caption_data.buffer = make_buffer (self, cea608_1, cea608_1_len);
+        g_array_append_val (self->current_frame_captions, caption_data);
+      }
+      break;
+    }
+    default:
+      break;
   }
 }
 
@@ -889,60 +590,8 @@ gst_cc_combiner_collect_captions (GstCCCombiner * self, gboolean timeout)
     }
   } while (TRUE);
 
-  /* FIXME pad correctly according to fps */
   if (self->schedule) {
-    g_assert (self->current_frame_captions->len == 0);
-
-    switch (self->caption_type) {
-      case GST_VIDEO_CAPTION_TYPE_CEA708_CDP:
-      {
-        /* Only relevant in alternate and mixed mode, no need to look at the caps */
-        if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
-                GST_VIDEO_BUFFER_FLAG_INTERLACED)) {
-          if (!GST_VIDEO_BUFFER_IS_BOTTOM_FIELD (self->current_video_buffer)) {
-            dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-          }
-        } else {
-          dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-        }
-        break;
-      }
-      case GST_VIDEO_CAPTION_TYPE_CEA708_RAW:
-      case GST_VIDEO_CAPTION_TYPE_CEA608_S334_1A:
-      {
-        if (self->progressive) {
-          dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-        } else if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
-                GST_VIDEO_BUFFER_FLAG_INTERLACED) &&
-            GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
-                GST_VIDEO_BUFFER_FLAG_ONEFIELD)) {
-          if (GST_VIDEO_BUFFER_IS_TOP_FIELD (self->current_video_buffer)) {
-            dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-          } else {
-            dequeue_caption_one_field (self, tc, 1, caption_pad_is_eos);
-          }
-        } else {
-          dequeue_caption_both_fields (self, tc, caption_pad_is_eos);
-        }
-        break;
-      }
-      case GST_VIDEO_CAPTION_TYPE_CEA608_RAW:
-      {
-        if (self->progressive) {
-          dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-        } else if (GST_BUFFER_FLAG_IS_SET (self->current_video_buffer,
-                GST_VIDEO_BUFFER_FLAG_INTERLACED)) {
-          if (!GST_VIDEO_BUFFER_IS_BOTTOM_FIELD (self->current_video_buffer)) {
-            dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-          }
-        } else {
-          dequeue_caption_one_field (self, tc, 0, caption_pad_is_eos);
-        }
-        break;
-      }
-      default:
-        break;
-    }
+    dequeue_caption (self, tc, caption_pad_is_eos);
   }
 
   gst_aggregator_selected_samples (GST_AGGREGATOR_CAST (self),
@@ -956,6 +605,9 @@ gst_cc_combiner_collect_captions (GstCCCombiner * self, gboolean timeout)
   if (self->current_frame_captions->len > 0) {
     guint i;
 
+    if (self->schedule)
+      self->current_scheduled = MAX (1, self->current_scheduled) - 1;
+
     video_buf = gst_buffer_make_writable (self->current_video_buffer);
     self->current_video_buffer = NULL;
 
@@ -1177,6 +829,15 @@ gst_cc_combiner_sink_event (GstAggregator * aggregator,
         self->video_fps_d = fps_d;
 
         self->cdp_fps_entry = cdp_fps_entry_from_fps (fps_n, fps_d);
+        if (!self->cdp_fps_entry || self->cdp_fps_entry->fps_n == 0) {
+          GST_WARNING_OBJECT (self, "Missing valid caption framerate in "
+              "video caps");
+
+          GST_ELEMENT_WARNING (self, CORE, NEGOTIATION, (NULL),
+              ("Missing valid caption framerate in video caps"));
+
+          self->cdp_fps_entry = cdp_fps_entry_from_fps (60, 1);
+        }
 
         gst_aggregator_set_src_caps (aggregator, caps);
       }
@@ -1213,8 +874,8 @@ gst_cc_combiner_stop (GstAggregator * aggregator)
   g_array_set_size (self->current_frame_captions, 0);
   self->caption_type = GST_VIDEO_CAPTION_TYPE_UNKNOWN;
 
-  gst_queue_array_clear (self->scheduled[0]);
-  gst_queue_array_clear (self->scheduled[1]);
+  cc_buffer_discard (self->cc_buffer);
+  self->current_scheduled = 0;
   self->cdp_fps_entry = &null_fps_entry;
 
   return TRUE;
@@ -1236,8 +897,9 @@ gst_cc_combiner_flush (GstAggregator * aggregator)
   src_pad->segment.position = GST_CLOCK_TIME_NONE;
 
   self->cdp_hdr_sequence_cntr = 0;
-  gst_queue_array_clear (self->scheduled[0]);
-  gst_queue_array_clear (self->scheduled[1]);
+
+  cc_buffer_discard (self->cc_buffer);
+  self->current_scheduled = 0;
 
   return GST_FLOW_OK;
 }
@@ -1433,6 +1095,8 @@ gst_cc_combiner_change_state (GstElement * element, GstStateChange transition)
       self->schedule = self->prop_schedule;
       self->max_scheduled = self->prop_max_scheduled;
       self->output_padding = self->prop_output_padding;
+      cc_buffer_set_max_buffer_time (self->cc_buffer, GST_CLOCK_TIME_NONE);
+      cc_buffer_set_output_padding (self->cc_buffer, self->prop_output_padding);
       break;
     default:
       break;
@@ -1623,14 +1287,9 @@ gst_cc_combiner_init (GstCCCombiner * self)
   self->prop_schedule = DEFAULT_SCHEDULE;
   self->prop_max_scheduled = DEFAULT_MAX_SCHEDULED;
   self->prop_output_padding = DEFAULT_OUTPUT_PADDING;
-  self->scheduled[0] =
-      gst_queue_array_new_for_struct (sizeof (CaptionQueueItem), 0);
-  self->scheduled[1] =
-      gst_queue_array_new_for_struct (sizeof (CaptionQueueItem), 0);
-  gst_queue_array_set_clear_func (self->scheduled[0],
-      (GDestroyNotify) clear_scheduled);
-  gst_queue_array_set_clear_func (self->scheduled[1],
-      (GDestroyNotify) clear_scheduled);
   self->cdp_hdr_sequence_cntr = 0;
   self->cdp_fps_entry = &null_fps_entry;
+
+  self->cc_buffer = cc_buffer_new ();
+  cc_buffer_set_max_buffer_time (self->cc_buffer, GST_CLOCK_TIME_NONE);
 }
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.h b/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.h
index 6336ab1b1e..8d370bcf00 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.h
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/gstcccombiner.h
@@ -25,6 +25,8 @@
 #include <gst/base/base.h>
 #include <gst/video/video.h>
 
+#include "ccutils.h"
+
 G_BEGIN_DECLS
 #define GST_TYPE_CCCOMBINER \
   (gst_cc_combiner_get_type())
@@ -40,15 +42,6 @@ G_BEGIN_DECLS
 typedef struct _GstCCCombiner GstCCCombiner;
 typedef struct _GstCCCombinerClass GstCCCombinerClass;
 
-struct cdp_fps_entry
-{
-  guint8 fps_idx;
-  guint fps_n, fps_d;
-  guint max_cc_count;
-  guint max_ccp_count;
-  guint max_cea608_count;
-};
-
 struct _GstCCCombiner
 {
   GstAggregator parent;
@@ -70,8 +63,9 @@ struct _GstCCCombiner
   gboolean schedule;
   guint max_scheduled;
   gboolean output_padding;
-  /* One queue per field */
-  GstQueueArray *scheduled[2];
+  guint current_scheduled;
+
+  CCBuffer *cc_buffer;
   guint16 cdp_hdr_sequence_cntr;
   const struct cdp_fps_entry *cdp_fps_entry;
 };
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.c b/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.c
index 66913ab693..14ac7c6884 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.c
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.c
@@ -28,6 +28,7 @@
 #include <gst/video/video.h>
 #include <string.h>
 
+#include "ccutils.h"
 #include "gstccconverter.h"
 
 GST_DEBUG_CATEGORY_STATIC (gst_cc_converter_debug);
@@ -79,11 +80,11 @@ static GType
 gst_cc_converter_cdp_mode_get_type (void)
 {
   static const GFlagsValue values[] = {
-    {GST_CC_CONVERTER_CDP_MODE_TIME_CODE,
+    {GST_CC_CDP_MODE_TIME_CODE,
         "Store time code information in CDP packets", "time-code"},
-    {GST_CC_CONVERTER_CDP_MODE_CC_DATA, "Store CC data in CDP packets",
+    {GST_CC_CDP_MODE_CC_DATA, "Store CC data in CDP packets",
         "cc-data"},
-    {GST_CC_CONVERTER_CDP_MODE_CC_SVC_INFO,
+    {GST_CC_CDP_MODE_CC_SVC_INFO,
         "Store CC service information in CDP packets", "cc-svc-info"},
     {0, NULL, NULL}
   };
@@ -471,49 +472,6 @@ invalid_caps:
   }
 }
 
-struct cdp_fps_entry
-{
-  guint8 fps_idx;
-  guint fps_n, fps_d;
-  guint max_cc_count;
-  guint max_ccp_count;
-  guint max_cea608_count;
-};
-
-static const struct cdp_fps_entry cdp_fps_table[] = {
-  {0x1f, 24000, 1001, 25, 22, 3 /* FIXME: alternating max cea608 count! */ },
-  {0x2f, 24, 1, 25, 22, 2},
-  {0x3f, 25, 1, 24, 22, 2},
-  {0x4f, 30000, 1001, 20, 18, 2},
-  {0x5f, 30, 1, 20, 18, 2},
-  {0x6f, 50, 1, 12, 11, 1},
-  {0x7f, 60000, 1001, 10, 9, 1},
-  {0x8f, 60, 1, 10, 9, 1},
-};
-static const struct cdp_fps_entry null_fps_entry = { 0, 0, 0, 0 };
-
-static const struct cdp_fps_entry *
-cdp_fps_entry_from_id (guint8 id)
-{
-  int i;
-  for (i = 0; i < G_N_ELEMENTS (cdp_fps_table); i++) {
-    if (cdp_fps_table[i].fps_idx == id)
-      return &cdp_fps_table[i];
-  }
-  return &null_fps_entry;
-}
-
-static const struct cdp_fps_entry *
-cdp_fps_entry_from_fps (guint fps_n, guint fps_d)
-{
-  int i;
-  for (i = 0; i < G_N_ELEMENTS (cdp_fps_table); i++) {
-    if (cdp_fps_table[i].fps_n == fps_n && cdp_fps_table[i].fps_d == fps_d)
-      return &cdp_fps_table[i];
-  }
-  return &null_fps_entry;
-}
-
 static void
 get_framerate_output_scale (GstCCConverter * self,
     const struct cdp_fps_entry *in_fps_entry, gint * scale_n, gint * scale_d)
@@ -541,7 +499,6 @@ interpolate_time_code_with_framerate (GstCCConverter * self,
   guint output_frame;
   GstVideoTimeCodeFlags flags;
 
-  g_return_val_if_fail (tc != NULL, FALSE);
   g_return_val_if_fail (out != NULL, FALSE);
   /* out_n/d can only be 0 if scale_n/d are 1/1 */
   g_return_val_if_fail ((scale_n == 1 && scale_d == 1) || (out_fps_n != 0
@@ -598,999 +555,79 @@ interpolate_time_code_with_framerate (GstCCConverter * self,
   return TRUE;
 }
 
-/* remove padding bytes from a cc_data packet. Returns the length of the new
- * data in @cc_data */
-static guint
-compact_cc_data (guint8 * cc_data, guint cc_data_len)
-{
-  gboolean started_ccp = FALSE;
-  guint out_len = 0;
-  guint i;
-
-  if (cc_data_len % 3 != 0) {
-    GST_WARNING ("Invalid cc_data buffer size");
-    cc_data_len = cc_data_len - (cc_data_len % 3);
-  }
-
-  for (i = 0; i < cc_data_len / 3; i++) {
-    gboolean cc_valid = (cc_data[i * 3] & 0x04) == 0x04;
-    guint8 cc_type = cc_data[i * 3] & 0x03;
-
-    if (!started_ccp && (cc_type == 0x00 || cc_type == 0x01)) {
-      if (cc_valid) {
-        /* copy over valid 608 data */
-        cc_data[out_len++] = cc_data[i * 3];
-        cc_data[out_len++] = cc_data[i * 3 + 1];
-        cc_data[out_len++] = cc_data[i * 3 + 2];
-      }
-      continue;
-    }
-
-    if (cc_type & 0x10)
-      started_ccp = TRUE;
-
-    if (!cc_valid)
-      continue;
-
-    if (cc_type == 0x00 || cc_type == 0x01) {
-      GST_WARNING ("Invalid cc_data.  cea608 bytes after cea708");
-      return 0;
-    }
-
-    cc_data[out_len++] = cc_data[i * 3];
-    cc_data[out_len++] = cc_data[i * 3 + 1];
-    cc_data[out_len++] = cc_data[i * 3 + 2];
-  }
-
-  GST_LOG ("compacted cc_data from %u to %u", cc_data_len, out_len);
-
-  return out_len;
-}
-
-static gint
-cc_data_extract_cea608 (guint8 * cc_data, guint cc_data_len,
-    guint8 * cea608_field1, guint * cea608_field1_len,
-    guint8 * cea608_field2, guint * cea608_field2_len)
-{
-  guint i, field_1_len = 0, field_2_len = 0;
-
-  if (cea608_field1_len) {
-    field_1_len = *cea608_field1_len;
-    *cea608_field1_len = 0;
-  }
-  if (cea608_field2_len) {
-    field_2_len = *cea608_field2_len;
-    *cea608_field2_len = 0;
-  }
-
-  if (cc_data_len % 3 != 0) {
-    GST_WARNING ("Invalid cc_data buffer size %u. Truncating to a multiple "
-        "of 3", cc_data_len);
-    cc_data_len = cc_data_len - (cc_data_len % 3);
-  }
-
-  for (i = 0; i < cc_data_len / 3; i++) {
-    guint8 byte0 = cc_data[i * 3 + 0];
-    guint8 byte1 = cc_data[i * 3 + 1];
-    guint8 byte2 = cc_data[i * 3 + 2];
-    gboolean cc_valid = (byte0 & 0x04) == 0x04;
-    guint8 cc_type = byte0 & 0x03;
-
-    GST_TRACE ("0x%02x 0x%02x 0x%02x, valid: %u, type: 0b%u%u", byte0, byte1,
-        byte2, cc_valid, (cc_type & 0x2) == 0x2, (cc_type & 0x1) == 0x1);
-
-    if (cc_type == 0x00) {
-      if (!cc_valid)
-        continue;
-
-      if (cea608_field1 && cea608_field1_len) {
-        if (*cea608_field1_len + 2 > field_1_len) {
-          GST_WARNING ("Too many cea608 input bytes %u for field 1",
-              *cea608_field1_len + 2);
-          return -1;
-        }
-
-        if (byte1 != 0x80 || byte2 != 0x80) {
-          cea608_field1[(*cea608_field1_len)++] = byte1;
-          cea608_field1[(*cea608_field1_len)++] = byte2;
-        }
-      }
-    } else if (cc_type == 0x01) {
-      if (!cc_valid)
-        continue;
-
-      if (cea608_field2 && cea608_field2_len) {
-        if (*cea608_field2_len + 2 > field_2_len) {
-          GST_WARNING ("Too many cea608 input bytes %u for field 2",
-              *cea608_field2_len + 2);
-          return -1;
-        }
-        if (byte1 != 0x80 || byte2 != 0x80) {
-          cea608_field2[(*cea608_field2_len)++] = byte1;
-          cea608_field2[(*cea608_field2_len)++] = byte2;
-        }
-      }
-    } else {
-      /* all cea608 packets must be at the beginning of a cc_data */
-      break;
-    }
-  }
-
-  g_assert_cmpint (i * 3, <=, cc_data_len);
-
-  GST_LOG ("Extracted cea608-1 of length %u and cea608-2 of length %u",
-      VAL_OR_0 (cea608_field1_len), VAL_OR_0 (cea608_field2_len));
-
-  return i * 3;
-}
-
-static void
-store_cc_data (GstCCConverter * self, const guint8 * ccp_data,
-    guint ccp_data_len, const guint8 * cea608_1, guint cea608_1_len,
-    const guint8 * cea608_2, guint cea608_2_len)
-{
-  GST_TRACE_OBJECT (self, "attempting to hold data of len ccp:%u, cea608 1:%u, "
-      "cea608 2:%u until next output buffer", ccp_data_len, cea608_1_len,
-      cea608_2_len);
-
-  if (ccp_data && ccp_data_len > 0) {
-    if (ccp_data_len > sizeof (self->scratch_ccp)) {
-      GST_ELEMENT_WARNING (self, STREAM, DECODE,
-          ("Closed Caption internal buffer overun. Dropping data"),
-          ("CCP scratch buffer requires space for %u bytes but only %"
-              G_GSIZE_FORMAT " bytes are available", ccp_data_len,
-              sizeof (self->scratch_ccp)));
-      self->scratch_ccp_len = 0;
-    } else {
-      memcpy (self->scratch_ccp, ccp_data, ccp_data_len);
-      self->scratch_ccp_len = ccp_data_len;
-    }
-  } else {
-    self->scratch_ccp_len = 0;
-  }
-  g_assert_cmpint (self->scratch_ccp_len, <=, sizeof (self->scratch_ccp));
-
-  if (cea608_1 && cea608_1_len > 0) {
-    if (cea608_1_len > sizeof (self->scratch_cea608_1)) {
-      GST_ELEMENT_WARNING (self, STREAM, DECODE,
-          ("Closed Caption internal buffer overun. Dropping data"),
-          ("CEA608 field 1 scratch buffer requires space for %u bytes but "
-              "only %" G_GSIZE_FORMAT " bytes are available", cea608_1_len,
-              sizeof (self->scratch_cea608_1_len)));
-      self->scratch_cea608_1_len = 0;
-    } else {
-      memcpy (self->scratch_cea608_1, cea608_1, cea608_1_len);
-      self->scratch_cea608_1_len = cea608_1_len;
-    }
-  } else {
-    self->scratch_cea608_1_len = 0;
-  }
-  g_assert_cmpint (self->scratch_cea608_1_len, <=,
-      sizeof (self->scratch_cea608_1));
-
-  if (cea608_2 && cea608_2_len > 0) {
-    if (cea608_2_len > sizeof (self->scratch_cea608_2)) {
-      GST_ELEMENT_WARNING (self, STREAM, DECODE,
-          ("Closed Caption internal buffer overun. Dropping data"),
-          ("CEA608 field 2 scratch buffer requires space for %u bytes but "
-              "only %" G_GSIZE_FORMAT " bytes are available", cea608_2_len,
-              sizeof (self->scratch_cea608_2_len)));
-      self->scratch_cea608_2_len = 0;
-    } else {
-      memcpy (self->scratch_cea608_2, cea608_2, cea608_2_len);
-      self->scratch_cea608_2_len = cea608_2_len;
-    }
-  } else {
-    self->scratch_cea608_2_len = 0;
-  }
-  g_assert_cmpint (self->scratch_cea608_2_len, <=,
-      sizeof (self->scratch_cea608_2));
-
-  GST_DEBUG_OBJECT (self, "holding data of len ccp:%u, cea608 1:%u, "
-      "cea608 2:%u until next output buffer", self->scratch_ccp_len,
-      self->scratch_cea608_1_len, self->scratch_cea608_2_len);
-}
-
 static gboolean
-write_cea608 (GstCCConverter * self, gboolean pad_cea608,
-    const struct cdp_fps_entry *out_fps_entry, const guint8 * cea608_1,
-    guint cea608_1_len, const guint8 * cea608_2, guint cea608_2_len,
-    guint8 * out, guint * out_size, gboolean * is_last_cea608_field1)
-{
-  guint i = 0, out_i = 0, max_size = 0, cea608_1_i = 0, cea608_2_i = 0;
-  guint cea608_output_count;
-  guint total_cea608_1_count, total_cea608_2_count;
-  gboolean write_cea608_field2_first = FALSE;
-  gboolean wrote_field1_last = FALSE;
-  gboolean wrote_first = FALSE;
-
-  g_assert (out);
-  g_assert (out_size);
-  g_assert (!cea608_1 || cea608_1_len % 2 == 0);
-  g_assert (!cea608_2 || cea608_2_len % 2 == 0);
-  g_assert (cea608_1 || cea608_2);
-
-  if (is_last_cea608_field1)
-    write_cea608_field2_first = *is_last_cea608_field1;
-
-  cea608_1_len /= 2;
-  cea608_2_len /= 2;
-#if 0
-  /* FIXME: if cea608 field 2 is generated, field 1 needs to be generated,
-   * However that is not possible for 60fps (where only one cea608 field fits)
-   * without adding previous output buffer tracking */
-  g_assert_cmpint (cea608_1_len >= cea608_2_len);
-#endif
-  g_assert_cmpint (cea608_1_len + cea608_2_len, <=,
-      out_fps_entry->max_cea608_count);
-
-#if 0
-  /* FIXME: if cea608 field 2 is generated, field 1 needs to be generated. */
-  if (cea608_1_len < cea608_2_len)
-    total_cea608_1_count += cea608_2_len - cea608_1_len;
-#endif
-
-  if (pad_cea608) {
-    max_size = out_fps_entry->max_cea608_count * 3;
-  } else {
-    max_size = (cea608_1_len + cea608_2_len) * 3;
-  }
-  if (*out_size < max_size) {
-    GST_WARNING_OBJECT (self, "Output data too small (%u < %u) for cea608 data",
-        *out_size, max_size);
-    return FALSE;
-  }
-
-  /* FIXME: interlacing, tff, rff, ensuring cea608 field1 is generated if
-   * field2 exists even across packets */
-
-  total_cea608_1_count = cea608_1_len;
-  total_cea608_2_count = cea608_2_len;
-  cea608_output_count = cea608_1_len + cea608_2_len;
-  if (pad_cea608) {
-    guint max_cea608_count = out_fps_entry->max_cea608_count;
-
-    total_cea608_1_count = max_cea608_count / 2;
-    total_cea608_2_count = max_cea608_count / 2;
-
-    if (total_cea608_1_count + total_cea608_2_count < max_cea608_count) {
-      if (write_cea608_field2_first) {
-        total_cea608_2_count++;
-      } else {
-        total_cea608_1_count++;
-      }
-    }
-
-    cea608_output_count = total_cea608_1_count + total_cea608_2_count;
-  }
-
-  GST_LOG ("writing %u cea608-1 fields and %u cea608-2 fields",
-      total_cea608_1_count, total_cea608_2_count);
-  g_assert_cmpint (total_cea608_1_count + total_cea608_2_count, <=,
-      out_fps_entry->max_cea608_count);
-
-  wrote_first = !write_cea608_field2_first;
-  while (cea608_1_i + cea608_2_i < cea608_output_count) {
-    if (wrote_first) {
-      if (cea608_1_i < cea608_1_len) {
-        out[out_i++] = 0xfc;
-        out[out_i++] = cea608_1[cea608_1_i * 2];
-        out[out_i++] = cea608_1[cea608_1_i * 2 + 1];
-        cea608_1_i++;
-        i++;
-        wrote_field1_last = TRUE;
-      } else if (cea608_1_i < total_cea608_1_count) {
-        out[out_i++] = 0xf8;
-        out[out_i++] = 0x80;
-        out[out_i++] = 0x80;
-        cea608_1_i++;
-        i++;
-        wrote_field1_last = TRUE;
-      }
-    }
-
-    if (cea608_2_i < cea608_2_len) {
-      out[out_i++] = 0xfd;
-      out[out_i++] = cea608_2[cea608_2_i * 2];
-      out[out_i++] = cea608_2[cea608_2_i * 2 + 1];
-      cea608_2_i++;
-      i++;
-      wrote_field1_last = FALSE;
-    } else if (cea608_2_i < total_cea608_2_count) {
-      out[out_i++] = 0xf9;
-      out[out_i++] = 0x80;
-      out[out_i++] = 0x80;
-      cea608_2_i++;
-      i++;
-      wrote_field1_last = FALSE;
-    }
-
-    wrote_first = TRUE;
-  }
-
-  g_assert_cmpint (out_i / 3, <=, out_fps_entry->max_cea608_count);
-
-  *out_size = out_i;
-  if (is_last_cea608_field1)
-    *is_last_cea608_field1 = wrote_field1_last;
-
-  return TRUE;
-}
-
-static gboolean
-combine_cc_data (GstCCConverter * self, gboolean pad_cea608,
-    const struct cdp_fps_entry *out_fps_entry, const guint8 * ccp_data,
-    guint ccp_data_len, const guint8 * cea608_1, guint cea608_1_len,
-    const guint8 * cea608_2, guint cea608_2_len, guint8 * out, guint * out_size,
-    gboolean * last_cea608_is_field1)
-{
-  guint out_i = 0, max_size = 0;
-  guint cea608_size = *out_size;
-
-  g_assert (out);
-  g_assert (out_size);
-  g_assert (!ccp_data || ccp_data_len % 3 == 0);
-
-  if (cea608_1 || cea608_2) {
-    if (!write_cea608 (self, pad_cea608, out_fps_entry, cea608_1, cea608_1_len,
-            cea608_2, cea608_2_len, out, &cea608_size, last_cea608_is_field1))
-      return FALSE;
-  } else {
-    cea608_size = 0;
-  }
-
-  max_size = ccp_data_len + cea608_size;
-  if (*out_size < max_size) {
-    GST_WARNING_OBJECT (self, "Output data too small (%u < %u)", *out_size,
-        max_size);
-    return FALSE;
-  }
-
-  *out_size = cea608_size;
-  out_i = cea608_size;
-  if (ccp_data) {
-    memcpy (&out[out_i], ccp_data, ccp_data_len);
-    *out_size += ccp_data_len;
-  }
-
-  g_assert_cmpint (*out_size, <, MAX_CDP_PACKET_LEN);
-
-  return TRUE;
-}
-
-/* takes cc_data cea608_1, cea608_2 and attempts to fit it into a hypothetical
- * output packet.  Any leftover data is stored for later addition.  Returns
- * whether any output can be generated. @ccp_data_len, @cea608_1_len,
- * @cea608_2_len are also updated to reflect the size of that data to add to
- * the output packet */
-static gboolean
-fit_and_scale_cc_data (GstCCConverter * self,
+can_take_buffer (GstCCConverter * self,
     const struct cdp_fps_entry *in_fps_entry,
-    const struct cdp_fps_entry *out_fps_entry, const guint8 * ccp_data,
-    guint * ccp_data_len, const guint8 * cea608_1, guint * cea608_1_len,
-    const guint8 * cea608_2, guint * cea608_2_len, const GstVideoTimeCode * tc,
-    gboolean use_cea608_field2_first)
+    const struct cdp_fps_entry *out_fps_entry,
+    const GstVideoTimeCode * in_tc, GstVideoTimeCode * out_tc)
 {
-  if (!in_fps_entry || in_fps_entry->fps_n == 0) {
-    in_fps_entry = cdp_fps_entry_from_fps (self->in_fps_n, self->in_fps_d);
-    if (!in_fps_entry || in_fps_entry->fps_n == 0)
-      g_assert_not_reached ();
-  }
-
-  /* This is slightly looser than checking for the exact framerate as the cdp
-   * spec allow for 0.1% difference between framerates to be considered equal */
-  if (in_fps_entry->max_cc_count == out_fps_entry->max_cc_count) {
-    if (tc && tc->config.fps_n != 0)
-      interpolate_time_code_with_framerate (self, tc, out_fps_entry->fps_n,
-          out_fps_entry->fps_d, 1, 1, &self->current_output_timecode);
-
-    self->scratch_ccp_len = 0;
-    self->scratch_cea608_1_len = 0;
-    self->scratch_cea608_2_len = 0;
-    self->input_frames = 0;
-    self->output_frames = 0;
-  } else {
-    int input_frame_n, input_frame_d, output_frame_n, output_frame_d;
-    int output_time_cmp, scale_n, scale_d, rate_cmp;
+  int input_frame_n, input_frame_d, output_frame_n, output_frame_d;
+  int output_time_cmp, scale_n, scale_d;
 
-    /* TODO: handle input discont */
+  /* TODO: handle input discont */
 
+  if (self->in_fps_n == 0) {
+    input_frame_n = self->input_frames;
+    input_frame_d = 1;
+  } else {
     /* compute the relative frame count for each */
     if (!gst_util_fraction_multiply (self->in_fps_d, self->in_fps_n,
             self->input_frames, 1, &input_frame_n, &input_frame_d))
       /* we should never overflow */
       g_assert_not_reached ();
+  }
 
+  if (self->in_fps_n == 0) {
+    output_frame_n = self->output_frames;
+    output_frame_d = 1;
+  } else {
     if (!gst_util_fraction_multiply (self->out_fps_d, self->out_fps_n,
             self->output_frames, 1, &output_frame_n, &output_frame_d))
       /* we should never overflow */
       g_assert_not_reached ();
+  }
 
-    output_time_cmp = gst_util_fraction_compare (input_frame_n, input_frame_d,
-        output_frame_n, output_frame_d);
-
-    /* compute the relative rates of the two framerates */
-    get_framerate_output_scale (self, in_fps_entry, &scale_n, &scale_d);
-
-    rate_cmp = gst_util_fraction_compare (scale_n, scale_d, 1, 1);
-
-    GST_TRACE_OBJECT (self, "performing framerate conversion at scale %d/%d "
-        "of cc data of with sizes, ccp:%u, cea608-1:%u, cea608-2:%u", scale_n,
-        scale_d, VAL_OR_0 (ccp_data_len), VAL_OR_0 (cea608_1_len),
-        VAL_OR_0 (cea608_2_len));
-
-    if (rate_cmp == 0) {
-      /* we are not scaling. Should never happen with current conditions
-       * above */
-      g_assert_not_reached ();
-    } else if (output_time_cmp < 0) {
-      /* we can't generate an output yet */
-      guint cd_len = ccp_data_len ? *ccp_data_len : 0;
-      guint c1_len = cea608_1_len ? *cea608_1_len : 0;
-      guint c2_len = cea608_2_len ? *cea608_2_len : 0;
-
-      store_cc_data (self, ccp_data, cd_len, cea608_1, c1_len, cea608_2,
-          c2_len);
-      if (ccp_data_len)
-        *ccp_data_len = 0;
-      if (cea608_1_len)
-        *cea608_1_len = 0;
-      if (cea608_2_len)
-        *cea608_2_len = 0;
-      return FALSE;
-    } else if (rate_cmp != 0) {
-      /* we are changing the framerate and may overflow the max output packet
-       * size. Split them where necessary. */
-      gint extra_ccp = 0, extra_cea608_1 = 0, extra_cea608_2 = 0;
-      gint ccp_off = 0, cea608_1_off = 0, cea608_2_off = 0;
-      gboolean wrote_first = FALSE;
-      gint field2_padding = 0;
-
-      if (output_time_cmp == 0) {
-        /* we have completed a cycle and can reset our counters to avoid
-         * overflow. Anything that fits into the output packet will be written */
-        GST_LOG_OBJECT (self, "cycle completed, resetting frame counters");
-        self->scratch_ccp_len = 0;
-        self->scratch_cea608_1_len = 0;
-        self->scratch_cea608_2_len = 0;
-        self->input_frames = 0;
-        self->output_frames = 0;
-      }
-
-      if (ccp_data_len) {
-        extra_ccp = *ccp_data_len - 3 * out_fps_entry->max_ccp_count;
-        extra_ccp = MAX (0, extra_ccp);
-        ccp_off = *ccp_data_len - extra_ccp;
-      }
-
-      extra_cea608_1 = VAL_OR_0 (cea608_1_len);
-      extra_cea608_2 = VAL_OR_0 (cea608_2_len);
-
-      wrote_first = !use_cea608_field2_first;
-      /* try to push data into the packets.  Anything 'extra' will be
-       * stored for later */
-      while (extra_cea608_1 > 0 || extra_cea608_2 > 0) {
-        gint avail_1, avail_2;
-
-        avail_1 = VAL_OR_0 (cea608_1_len) - extra_cea608_1;
-        avail_2 = VAL_OR_0 (cea608_2_len) - extra_cea608_2;
-        if (avail_1 + avail_2 + field2_padding >=
-            2 * out_fps_entry->max_cea608_count)
-          break;
-
-        if (wrote_first && extra_cea608_1 > 0) {
-          extra_cea608_1 -= 2;
-          g_assert_cmpint (extra_cea608_1, >=, 0);
-          cea608_1_off += 2;
-          g_assert_cmpint (cea608_1_off, <=, *cea608_1_len);
-        }
+  output_time_cmp = gst_util_fraction_compare (input_frame_n, input_frame_d,
+      output_frame_n, output_frame_d);
 
-        avail_1 = VAL_OR_0 (cea608_1_len) - extra_cea608_1;
-        avail_2 = VAL_OR_0 (cea608_2_len) - extra_cea608_2;
-        if (avail_1 + avail_2 + field2_padding >=
-            2 * out_fps_entry->max_cea608_count)
-          break;
+  in_fps_entry = cdp_fps_entry_from_fps (self->in_fps_n, self->in_fps_d);
+  if (!in_fps_entry || in_fps_entry->fps_n == 0)
+    g_assert_not_reached ();
 
-        if (extra_cea608_2 > 0) {
-          extra_cea608_2 -= 2;
-          g_assert_cmpint (extra_cea608_2, >=, 0);
-          cea608_2_off += 2;
-          g_assert_cmpint (cea608_2_off, <=, *cea608_2_len);
-        } else if (!wrote_first) {
-          /* we need to insert field 2 padding if we don't have data and are
-           * requested to start with field2 */
-          field2_padding += 2;
-        }
-        wrote_first = TRUE;
-      }
+  /* compute the relative rates of the two framerates */
+  get_framerate_output_scale (self, in_fps_entry, &scale_n, &scale_d);
 
-      GST_TRACE_OBJECT (self, "allocated sizes ccp:%u, cea608-1:%u, "
-          "cea608-2:%u", ccp_off, cea608_1_off, cea608_2_off);
-
-      if (extra_ccp > 0 || extra_cea608_1 > 0 || extra_cea608_2 > 0) {
-        /* packet would overflow, push extra bytes into the next packet */
-        GST_DEBUG_OBJECT (self, "buffer would overflow by %u ccp bytes, "
-            "%u cea608 field 1 bytes, or %u cea608 field 2 bytes", extra_ccp,
-            extra_cea608_1, extra_cea608_2);
-        store_cc_data (self, &ccp_data[ccp_off], extra_ccp,
-            &cea608_1[cea608_1_off], extra_cea608_1, &cea608_2[cea608_2_off],
-            extra_cea608_2);
-        if (ccp_data_len)
-          *ccp_data_len = MIN (*ccp_data_len, ccp_off);
-        if (cea608_1_len)
-          *cea608_1_len = MIN (*cea608_1_len, cea608_1_off);
-        if (cea608_2_len)
-          *cea608_2_len = MIN (*cea608_2_len, cea608_2_off);
-      } else {
-        GST_DEBUG_OBJECT (self, "section sizes of %u ccp bytes, "
-            "%u cea608 field 1 bytes, and %u cea608 field 2 bytes fit within "
-            "output packet", VAL_OR_0 (ccp_data_len), VAL_OR_0 (cea608_1_len),
-            VAL_OR_0 (cea608_2_len));
-        self->scratch_ccp_len = 0;
-        self->scratch_cea608_1_len = 0;
-        self->scratch_cea608_2_len = 0;
-      }
-    } else {
-      g_assert_not_reached ();
-    }
+  GST_TRACE_OBJECT (self, "performing conversion at scale %d/%d, "
+      "time comparison %i", scale_n, scale_d, output_time_cmp);
 
-    if (tc && tc->config.fps_n != 0)
-      interpolate_time_code_with_framerate (self, tc, out_fps_entry->fps_n,
-          out_fps_entry->fps_d, scale_n, scale_d,
-          &self->current_output_timecode);
+  if (output_time_cmp < 0) {
+    /* we can't generate an output yet */
+    return FALSE;
+  } else {
+    interpolate_time_code_with_framerate (self, in_tc, out_fps_entry->fps_n,
+        out_fps_entry->fps_d, scale_n, scale_d, out_tc);
+    return TRUE;
   }
-
-  g_assert_cmpint (VAL_OR_0 (ccp_data_len) + (VAL_OR_0 (cea608_1_len) +
-          VAL_OR_0 (cea608_2_len)) / 2 * 3, <=,
-      3 * out_fps_entry->max_cc_count);
-
-  GST_DEBUG_OBJECT (self, "write out packet with lengths ccp:%u, cea608-1:%u, "
-      "cea608-2:%u", VAL_OR_0 (ccp_data_len), VAL_OR_0 (cea608_1_len),
-      VAL_OR_0 (cea608_2_len));
-
-  return TRUE;
 }
 
-/* Converts raw CEA708 cc_data and an optional timecode into CDP */
 static guint
 convert_cea708_cc_data_cea708_cdp_internal (GstCCConverter * self,
     const guint8 * cc_data, guint cc_data_len, guint8 * cdp, guint cdp_len,
     const GstVideoTimeCode * tc, const struct cdp_fps_entry *fps_entry)
 {
-  GstByteWriter bw;
-  guint8 flags, checksum;
-  guint i, len;
-
-  GST_DEBUG_OBJECT (self, "writing out cdp packet from cc_data with length %u",
-      cc_data_len);
-
-  gst_byte_writer_init_with_data (&bw, cdp, cdp_len, FALSE);
-  gst_byte_writer_put_uint16_be_unchecked (&bw, 0x9669);
-  /* Write a length of 0 for now */
-  gst_byte_writer_put_uint8_unchecked (&bw, 0);
-
-  gst_byte_writer_put_uint8_unchecked (&bw, fps_entry->fps_idx);
-
-  if (cc_data_len / 3 > fps_entry->max_cc_count) {
-    GST_WARNING_OBJECT (self, "Too many cc_data triplets for framerate: %u. "
-        "Truncating to %u", cc_data_len / 3, fps_entry->max_cc_count);
-    cc_data_len = 3 * fps_entry->max_cc_count;
-  }
-
-  /* caption_service_active */
-  flags = 0x02;
-
-  /* ccdata_present */
-  if ((self->cdp_mode & GST_CC_CONVERTER_CDP_MODE_CC_DATA))
-    flags |= 0x40;
-
-  /* time_code_present */
-  if ((self->cdp_mode & GST_CC_CONVERTER_CDP_MODE_TIME_CODE) && tc
-      && tc->config.fps_n > 0)
-    flags |= 0x80;
-
-  /* reserved */
-  flags |= 0x01;
-
-  gst_byte_writer_put_uint8_unchecked (&bw, flags);
-
-  gst_byte_writer_put_uint16_be_unchecked (&bw, self->cdp_hdr_sequence_cntr);
-
-  if ((self->cdp_mode & GST_CC_CONVERTER_CDP_MODE_TIME_CODE) && tc
-      && tc->config.fps_n > 0) {
-    guint8 u8;
-
-    gst_byte_writer_put_uint8_unchecked (&bw, 0x71);
-    /* reserved 11 - 2 bits */
-    u8 = 0xc0;
-    /* tens of hours - 2 bits */
-    u8 |= ((tc->hours / 10) & 0x3) << 4;
-    /* units of hours - 4 bits */
-    u8 |= (tc->hours % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-
-    /* reserved 1 - 1 bit */
-    u8 = 0x80;
-    /* tens of minutes - 3 bits */
-    u8 |= ((tc->minutes / 10) & 0x7) << 4;
-    /* units of minutes - 4 bits */
-    u8 |= (tc->minutes % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-
-    /* field flag - 1 bit */
-    u8 = tc->field_count < 2 ? 0x00 : 0x80;
-    /* tens of seconds - 3 bits */
-    u8 |= ((tc->seconds / 10) & 0x7) << 4;
-    /* units of seconds - 4 bits */
-    u8 |= (tc->seconds % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-
-    /* drop frame flag - 1 bit */
-    u8 = (tc->config.flags & GST_VIDEO_TIME_CODE_FLAGS_DROP_FRAME) ? 0x80 :
-        0x00;
-    /* reserved0 - 1 bit */
-    /* tens of frames - 2 bits */
-    u8 |= ((tc->frames / 10) & 0x3) << 4;
-    /* units of frames 4 bits */
-    u8 |= (tc->frames % 10) & 0xf;
-    gst_byte_writer_put_uint8_unchecked (&bw, u8);
-  }
-
-  if ((self->cdp_mode & GST_CC_CONVERTER_CDP_MODE_CC_DATA)) {
-    gst_byte_writer_put_uint8_unchecked (&bw, 0x72);
-    gst_byte_writer_put_uint8_unchecked (&bw, 0xe0 | fps_entry->max_cc_count);
-    gst_byte_writer_put_data_unchecked (&bw, cc_data, cc_data_len);
-    while (fps_entry->max_cc_count > cc_data_len / 3) {
-      gst_byte_writer_put_uint8_unchecked (&bw, 0xfa);
-      gst_byte_writer_put_uint8_unchecked (&bw, 0x00);
-      gst_byte_writer_put_uint8_unchecked (&bw, 0x00);
-      cc_data_len += 3;
-    }
-  }
+  guint ret;
 
-  gst_byte_writer_put_uint8_unchecked (&bw, 0x74);
-  gst_byte_writer_put_uint16_be_unchecked (&bw, self->cdp_hdr_sequence_cntr);
+  ret = convert_cea708_cc_data_to_cdp (GST_OBJECT (self),
+      (GstCCCDPMode) self->cdp_mode, self->cdp_hdr_sequence_cntr, cc_data,
+      cc_data_len, cdp, cdp_len, tc, fps_entry);
   self->cdp_hdr_sequence_cntr++;
-  /* We calculate the checksum afterwards */
-  gst_byte_writer_put_uint8_unchecked (&bw, 0);
-
-  len = gst_byte_writer_get_pos (&bw);
-  gst_byte_writer_set_pos (&bw, 2);
-  gst_byte_writer_put_uint8_unchecked (&bw, len);
-
-  checksum = 0;
-  for (i = 0; i < len; i++) {
-    checksum += cdp[i];
-  }
-  checksum &= 0xff;
-  checksum = 256 - checksum;
-  cdp[len - 1] = checksum;
-
-  return len;
-}
-
-/* Converts CDP into raw CEA708 cc_data */
-static guint
-convert_cea708_cdp_cea708_cc_data_internal (GstCCConverter * self,
-    const guint8 * cdp, guint cdp_len, guint8 cc_data[MAX_CDP_PACKET_LEN],
-    GstVideoTimeCode * tc, const struct cdp_fps_entry **out_fps_entry)
-{
-  GstByteReader br;
-  guint16 u16;
-  guint8 u8;
-  guint8 flags;
-  guint len = 0;
-  const struct cdp_fps_entry *fps_entry;
-
-  *out_fps_entry = &null_fps_entry;
-  memset (tc, 0, sizeof (*tc));
-
-  /* Header + footer length */
-  if (cdp_len < 11) {
-    GST_WARNING_OBJECT (self, "cdp packet too short (%u). expected at "
-        "least %u", cdp_len, 11);
-    return 0;
-  }
-
-  gst_byte_reader_init (&br, cdp, cdp_len);
-  u16 = gst_byte_reader_get_uint16_be_unchecked (&br);
-  if (u16 != 0x9669) {
-    GST_WARNING_OBJECT (self, "cdp packet does not have initial magic bytes "
-        "of 0x9669");
-    return 0;
-  }
-
-  u8 = gst_byte_reader_get_uint8_unchecked (&br);
-  if (u8 != cdp_len) {
-    GST_WARNING_OBJECT (self, "cdp packet length (%u) does not match passed "
-        "in value (%u)", u8, cdp_len);
-    return 0;
-  }
-
-  u8 = gst_byte_reader_get_uint8_unchecked (&br);
-  fps_entry = cdp_fps_entry_from_id (u8);
-  if (!fps_entry || fps_entry->fps_n == 0) {
-    GST_WARNING_OBJECT (self, "cdp packet does not have a valid framerate "
-        "id (0x%02x", u8);
-    return 0;
-  }
-
-  flags = gst_byte_reader_get_uint8_unchecked (&br);
-  /* No cc_data? */
-  if ((flags & 0x40) == 0) {
-    GST_DEBUG_OBJECT (self, "cdp packet does have any cc_data");
-    return 0;
-  }
-
-  /* cdp_hdr_sequence_cntr */
-  gst_byte_reader_skip_unchecked (&br, 2);
-
-  /* time_code_present */
-  if (flags & 0x80) {
-    guint8 hours, minutes, seconds, frames, fields;
-    gboolean drop_frame;
-
-    if (gst_byte_reader_get_remaining (&br) < 5) {
-      GST_WARNING_OBJECT (self, "cdp packet does not have enough data to "
-          "contain a timecode (%u). Need at least 5 bytes",
-          gst_byte_reader_get_remaining (&br));
-      return 0;
-    }
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if (u8 != 0x71) {
-      GST_WARNING_OBJECT (self, "cdp packet does not have timecode start byte "
-          "of 0x71, found 0x%02x", u8);
-      return 0;
-    }
-
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if ((u8 & 0xc0) != 0xc0) {
-      GST_WARNING_OBJECT (self, "reserved bits are not 0xc0, found 0x%02x", u8);
-      return 0;
-    }
-
-    hours = ((u8 >> 4) & 0x3) * 10 + (u8 & 0xf);
-
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if ((u8 & 0x80) != 0x80) {
-      GST_WARNING_OBJECT (self, "reserved bit is not 0x80, found 0x%02x", u8);
-      return 0;
-    }
-    minutes = ((u8 >> 4) & 0x7) * 10 + (u8 & 0xf);
-
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if (u8 & 0x80)
-      fields = 2;
-    else
-      fields = 1;
-    seconds = ((u8 >> 4) & 0x7) * 10 + (u8 & 0xf);
-
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if (u8 & 0x40) {
-      GST_WARNING_OBJECT (self, "reserved bit is not 0x0, found 0x%02x", u8);
-      return 0;
-    }
-
-    drop_frame = ! !(u8 & 0x80);
-    frames = ((u8 >> 4) & 0x3) * 10 + (u8 & 0xf);
-
-    gst_video_time_code_init (tc, fps_entry->fps_n, fps_entry->fps_d, NULL,
-        drop_frame ? GST_VIDEO_TIME_CODE_FLAGS_DROP_FRAME :
-        GST_VIDEO_TIME_CODE_FLAGS_NONE, hours, minutes, seconds, frames,
-        fields);
-  }
-
-  /* ccdata_present */
-  if (flags & 0x40) {
-    guint8 cc_count;
-
-    if (gst_byte_reader_get_remaining (&br) < 2) {
-      GST_WARNING_OBJECT (self, "not enough data to contain valid cc_data");
-      return 0;
-    }
-    u8 = gst_byte_reader_get_uint8_unchecked (&br);
-    if (u8 != 0x72) {
-      GST_WARNING_OBJECT (self, "missing cc_data start code of 0x72, "
-          "found 0x%02x", u8);
-      return 0;
-    }
-
-    cc_count = gst_byte_reader_get_uint8_unchecked (&br);
-    if ((cc_count & 0xe0) != 0xe0) {
-      GST_WARNING_OBJECT (self, "reserved bits are not 0xe0, found 0x%02x", u8);
-      return 0;
-    }
-    cc_count &= 0x1f;
-
-    len = 3 * cc_count;
-    if (gst_byte_reader_get_remaining (&br) < len) {
-      GST_WARNING_OBJECT (self, "not enough bytes (%u) left for the number of "
-          "byte triples (%u)", gst_byte_reader_get_remaining (&br), cc_count);
-      return 0;
-    }
-
-    memcpy (cc_data, gst_byte_reader_get_data_unchecked (&br, len), len);
-  }
-
-  *out_fps_entry = fps_entry;
-
-  /* skip everything else we don't care about */
-  return len;
-}
-
-static gboolean
-copy_from_stored_data (GstCCConverter * self, guint8 * out_ccp,
-    guint * ccp_size, guint8 * cea608_1, guint * cea608_1_len,
-    guint8 * cea608_2, guint * cea608_2_len)
-{
-  guint ccp_in_size = 0, cea608_1_in_size = 0, cea608_2_in_size = 0;
-
-  g_assert ((out_ccp && ccp_size) || (!out_ccp && !ccp_size));
-  g_assert ((cea608_1 && cea608_1_len) || (!cea608_1 && !cea608_1_len));
-  g_assert ((cea608_2 && cea608_2_len) || (!cea608_2 && !cea608_2_len));
-
-  if (ccp_size) {
-    ccp_in_size = *ccp_size;
-    *ccp_size = 0;
-  }
-  if (cea608_1_len) {
-    cea608_1_in_size = *cea608_1_len;
-    *cea608_1_len = 0;
-  }
-  if (cea608_2_len) {
-    cea608_2_in_size = *cea608_2_len;
-    *cea608_2_len = 0;
-  }
-
-  if (out_ccp && self->scratch_ccp_len > 0) {
-    GST_DEBUG_OBJECT (self, "copying from previous scratch ccp buffer of "
-        "%u bytes", self->scratch_ccp_len);
-    if (ccp_in_size < *ccp_size + self->scratch_ccp_len) {
-      GST_WARNING_OBJECT (self, "output buffer too small %u < %u", ccp_in_size,
-          *ccp_size + self->scratch_ccp_len);
-      goto fail;
-    }
-    memcpy (&out_ccp[*ccp_size], self->scratch_ccp, self->scratch_ccp_len);
-    *ccp_size += self->scratch_ccp_len;
-  }
-
-  if (cea608_1 && self->scratch_cea608_1_len > 0) {
-    GST_DEBUG_OBJECT (self, "copying from previous scratch cea608 field 1 "
-        "buffer of %u bytes", self->scratch_cea608_1_len);
-    if (cea608_1_in_size < *cea608_1_len + self->scratch_cea608_1_len) {
-      GST_WARNING_OBJECT (self, "output buffer too small %u < %u",
-          cea608_1_in_size, *cea608_1_len + self->scratch_cea608_1_len);
-      goto fail;
-    }
-    memcpy (&cea608_1[*cea608_1_len], self->scratch_cea608_1,
-        self->scratch_cea608_1_len);
-    *cea608_1_len += self->scratch_cea608_1_len;
-  }
-
-  if (cea608_2 && self->scratch_cea608_2_len > 0) {
-    GST_DEBUG_OBJECT (self, "copying from previous scratch cea608 field 2 "
-        "buffer of %u bytes", self->scratch_cea608_2_len);
-    if (cea608_2_in_size < *cea608_2_len + self->scratch_cea608_2_len) {
-      GST_WARNING_OBJECT (self, "output buffer too small %u < %u",
-          cea608_2_in_size, *cea608_2_len + self->scratch_cea608_2_len);
-      goto fail;
-    }
-    memcpy (&cea608_2[*cea608_2_len], self->scratch_cea608_2,
-        self->scratch_cea608_2_len);
-    *cea608_2_len += self->scratch_cea608_2_len;
-  }
-
-  return TRUE;
-
-fail:
-  if (ccp_size)
-    *ccp_size = 0;
-  if (cea608_1_len)
-    *cea608_1_len = 0;
-  if (cea608_2_len)
-    *cea608_2_len = 0;
-  return FALSE;
-}
-
-static gboolean
-cc_data_to_cea608_ccp (GstCCConverter * self, guint8 * cc_data,
-    guint cc_data_len, guint8 * out_ccp, guint * ccp_size, guint8 * cea608_1,
-    guint * cea608_1_len, guint8 * cea608_2, guint * cea608_2_len,
-    const struct cdp_fps_entry *in_fps_entry)
-{
-  guint ccp_in_size = 0, cea608_1_in_size = 0, cea608_2_in_size = 0;
-
-  g_assert (cc_data || cc_data_len == 0);
 
-  if (ccp_size)
-    ccp_in_size = *ccp_size;
-  if (cea608_1_len)
-    cea608_1_in_size = *cea608_1_len;
-  if (cea608_2_len)
-    cea608_2_in_size = *cea608_2_len;
-
-  if (!copy_from_stored_data (self, out_ccp, ccp_size, cea608_1, cea608_1_len,
-          cea608_2, cea608_2_len))
-    goto fail;
-
-  if (cc_data) {
-    gint ccp_offset = 0;
-    guint new_cea608_1_len = 0, new_cea608_2_len = 0;
-    guint8 *new_cea608_1 = cea608_1, *new_cea608_2 = cea608_2;
-
-    if (cea608_1_len) {
-      new_cea608_1_len = cea608_1_in_size - *cea608_1_len;
-      new_cea608_1 = &cea608_1[*cea608_1_len];
-    }
-    if (cea608_2_len) {
-      new_cea608_2_len = cea608_2_in_size - *cea608_2_len;
-      new_cea608_2 = &cea608_2[*cea608_2_len];
-    }
-
-    cc_data_len = compact_cc_data (cc_data, cc_data_len);
-
-    if (cc_data_len / 3 > in_fps_entry->max_cc_count) {
-      GST_WARNING_OBJECT (self, "Too many cc_data triples in CDP packet %u. "
-          "Truncating to %u", cc_data_len / 3, in_fps_entry->max_cc_count);
-      cc_data_len = 3 * in_fps_entry->max_cc_count;
-    }
-
-    ccp_offset = cc_data_extract_cea608 (cc_data, cc_data_len, new_cea608_1,
-        &new_cea608_1_len, new_cea608_2, &new_cea608_2_len);
-    if (ccp_offset < 0) {
-      GST_WARNING_OBJECT (self, "Failed to extract cea608 from cc_data");
-      goto fail;
-    }
-
-    if ((new_cea608_1_len + new_cea608_2_len) / 2 >
-        in_fps_entry->max_cea608_count) {
-      GST_WARNING_OBJECT (self, "Too many cea608 triples in CDP packet %u. "
-          "Truncating to %u", (new_cea608_1_len + new_cea608_2_len) / 2,
-          in_fps_entry->max_cea608_count);
-      if ((new_cea608_1_len + new_cea608_2_len) / 2 >
-          in_fps_entry->max_cea608_count) {
-        new_cea608_1_len = 2 * in_fps_entry->max_cea608_count;
-        new_cea608_2_len = 0;
-      } else {
-        new_cea608_2_len =
-            2 * in_fps_entry->max_cea608_count - new_cea608_1_len;
-      }
-    }
-
-    if (cea608_1_len)
-      *cea608_1_len += new_cea608_1_len;
-    if (cea608_2_len)
-      *cea608_2_len += new_cea608_2_len;
-
-    if (out_ccp) {
-      if (ccp_in_size < *ccp_size + cc_data_len - ccp_offset) {
-        GST_WARNING_OBJECT (self, "output buffer too small %u < %u",
-            ccp_in_size, *ccp_size + cc_data_len - ccp_offset);
-        goto fail;
-      }
-      memcpy (&out_ccp[*ccp_size], &cc_data[ccp_offset],
-          cc_data_len - ccp_offset);
-      *ccp_size += cc_data_len - ccp_offset;
-    }
-  }
-
-  return TRUE;
-
-fail:
-  if (ccp_size)
-    *ccp_size = 0;
-  if (cea608_1_len)
-    *cea608_1_len = 0;
-  if (cea608_2_len)
-    *cea608_2_len = 0;
-  return FALSE;
+  return ret;
 }
 
 static gboolean
-cdp_to_cea608_cc_data (GstCCConverter * self, GstBuffer * inbuf,
-    guint8 * out_ccp, guint * ccp_size, guint8 * cea608_1, guint * cea608_1_len,
-    guint8 * cea608_2, guint * cea608_2_len, GstVideoTimeCode * out_tc,
-    const struct cdp_fps_entry **in_fps_entry)
+push_cdp_buffer (GstCCConverter * self, GstBuffer * inbuf,
+    GstVideoTimeCode * out_tc, const struct cdp_fps_entry **in_fps_entry)
 {
   guint8 cc_data[MAX_CDP_PACKET_LEN];
   guint cc_data_len = 0;
@@ -1600,16 +637,16 @@ cdp_to_cea608_cc_data (GstCCConverter * self, GstBuffer * inbuf,
     gst_buffer_map (inbuf, &in, GST_MAP_READ);
 
     cc_data_len =
-        convert_cea708_cdp_cea708_cc_data_internal (self, in.data, in.size,
+        convert_cea708_cdp_to_cc_data (GST_OBJECT (self), in.data, in.size,
         cc_data, out_tc, in_fps_entry);
 
+    cc_buffer_push_cc_data (self->cc_buffer, cc_data, cc_data_len);
+
     gst_buffer_unmap (inbuf, &in);
     self->input_frames++;
   }
 
-  return cc_data_to_cea608_ccp (self, inbuf ? cc_data : NULL, cc_data_len,
-      out_ccp, ccp_size, cea608_1, cea608_1_len, cea608_2, cea608_2_len,
-      inbuf ? *in_fps_entry : NULL);
+  return TRUE;
 }
 
 static GstFlowReturn
@@ -1701,18 +738,14 @@ convert_cea608_raw_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   GstMapInfo in, out;
   const struct cdp_fps_entry *in_fps_entry, *out_fps_entry;
   guint cc_data_len = MAX_CDP_PACKET_LEN;
-  guint cea608_1_len = MAX_CDP_PACKET_LEN;
-  guint8 cc_data[MAX_CDP_PACKET_LEN], cea608_1[MAX_CEA608_LEN];
+  guint8 cc_data[MAX_CDP_PACKET_LEN];
 
   in_fps_entry = cdp_fps_entry_from_fps (self->in_fps_n, self->in_fps_d);
   if (!in_fps_entry || in_fps_entry->fps_n == 0)
     g_assert_not_reached ();
 
-  if (!copy_from_stored_data (self, NULL, 0, cea608_1, &cea608_1_len, NULL, 0))
-    goto drop;
-
   if (inbuf) {
-    guint n = 0, i;
+    guint n = 0;
 
     n = gst_buffer_get_size (inbuf);
     if (n & 1) {
@@ -1730,14 +763,8 @@ convert_cea608_raw_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
     }
 
     gst_buffer_map (inbuf, &in, GST_MAP_READ);
-    for (i = 0; i < n; i++) {
-      guint byte1 = in.data[i * 2 + 0];
-      guint byte2 = in.data[i * 2 + 1];
-      if (byte1 != 0x80 || byte2 != 0x80) {
-        cea608_1[cea608_1_len++] = byte1;
-        cea608_1[cea608_1_len++] = byte2;
-      }
-    }
+    cc_buffer_push_separated (self->cc_buffer, in.data, in.size, NULL, 0, NULL,
+        0);
     gst_buffer_unmap (inbuf, &in);
     self->input_frames++;
   }
@@ -1746,15 +773,12 @@ convert_cea608_raw_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     g_assert_not_reached ();
 
-  if (!fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, NULL, 0,
-          cea608_1, &cea608_1_len, NULL, 0, tc_meta ? &tc_meta->tc : NULL,
-          FALSE))
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry,
+          tc_meta ? &tc_meta->tc : NULL, &self->current_output_timecode))
     goto drop;
 
-  if (!combine_cc_data (self, TRUE, out_fps_entry, NULL, 0, cea608_1,
-          cea608_1_len, NULL, 0, cc_data, &cc_data_len,
-          &self->last_cea608_written_was_field1))
-    goto drop;
+  cc_buffer_take_cc_data (self->cc_buffer, out_fps_entry, cc_data,
+      &cc_data_len);
 
   gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
   cc_data_len =
@@ -1857,7 +881,7 @@ convert_cea608_s334_1a_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   GstMapInfo in, out;
   const struct cdp_fps_entry *in_fps_entry, *out_fps_entry;
   guint cc_data_len = MAX_CDP_PACKET_LEN;
-  guint cea608_1_len = MAX_CDP_PACKET_LEN, cea608_2_len = MAX_CDP_PACKET_LEN;
+  guint cea608_1_len = 0, cea608_2_len = 0;
   guint8 cc_data[MAX_CDP_PACKET_LEN];
   guint8 cea608_1[MAX_CEA608_LEN], cea608_2[MAX_CEA608_LEN];
   guint i, n;
@@ -1866,10 +890,6 @@ convert_cea608_s334_1a_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   if (!in_fps_entry || in_fps_entry->fps_n == 0)
     g_assert_not_reached ();
 
-  if (!copy_from_stored_data (self, NULL, 0, cea608_1, &cea608_1_len,
-          cea608_2, &cea608_2_len))
-    goto drop;
-
   if (inbuf) {
     n = gst_buffer_get_size (inbuf);
     if (n % 3 != 0) {
@@ -1903,6 +923,9 @@ convert_cea608_s334_1a_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
       }
     }
     gst_buffer_unmap (inbuf, &in);
+
+    cc_buffer_push_separated (self->cc_buffer, cea608_1, cea608_1_len,
+        cea608_2, cea608_2_len, NULL, 0);
     self->input_frames++;
   }
 
@@ -1910,18 +933,12 @@ convert_cea608_s334_1a_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     g_assert_not_reached ();
 
-  if (!fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, NULL, 0,
-          cea608_1, &cea608_1_len, cea608_2, &cea608_2_len,
-          tc_meta ? &tc_meta->tc : NULL,
-          self->last_cea608_written_was_field1)) {
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry,
+          tc_meta ? &tc_meta->tc : NULL, &self->current_output_timecode))
     goto drop;
-  }
 
-  if (!combine_cc_data (self, TRUE, out_fps_entry, NULL, 0, cea608_1,
-          cea608_1_len, cea608_2, cea608_2_len, cc_data, &cc_data_len,
-          &self->last_cea608_written_was_field1)) {
-    goto drop;
-  }
+  cc_buffer_take_cc_data (self->cc_buffer, out_fps_entry, cc_data,
+      &cc_data_len);
 
   gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
   cc_data_len =
@@ -2033,10 +1050,8 @@ convert_cea708_cc_data_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   GstMapInfo in, out;
   const struct cdp_fps_entry *in_fps_entry, *out_fps_entry;
   guint in_cc_data_len;
-  guint cc_data_len = MAX_CDP_PACKET_LEN, ccp_data_len = MAX_CDP_PACKET_LEN;
-  guint cea608_1_len = MAX_CEA608_LEN, cea608_2_len = MAX_CEA608_LEN;
-  guint8 cc_data[MAX_CDP_PACKET_LEN], ccp_data[MAX_CDP_PACKET_LEN];
-  guint8 cea608_1[MAX_CEA608_LEN], cea608_2[MAX_CEA608_LEN];
+  guint cc_data_len = MAX_CDP_PACKET_LEN;
+  guint8 cc_data[MAX_CDP_PACKET_LEN];
   guint8 *in_cc_data;
 
   if (inbuf) {
@@ -2057,26 +1072,16 @@ convert_cea708_cc_data_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     g_assert_not_reached ();
 
-  if (!cc_data_to_cea608_ccp (self, in_cc_data, in_cc_data_len, ccp_data,
-          &ccp_data_len, cea608_1, &cea608_1_len, cea608_2, &cea608_2_len,
-          in_fps_entry)) {
-    if (inbuf)
-      gst_buffer_unmap (inbuf, &in);
-    goto drop;
-  }
-
+  cc_buffer_push_cc_data (self->cc_buffer, in_cc_data, in_cc_data_len);
   if (inbuf)
     gst_buffer_unmap (inbuf, &in);
 
-  if (!fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, ccp_data,
-          &ccp_data_len, cea608_1, &cea608_1_len, cea608_2, &cea608_2_len,
-          tc_meta ? &tc_meta->tc : NULL, self->last_cea608_written_was_field1))
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry,
+          tc_meta ? &tc_meta->tc : NULL, &self->current_output_timecode))
     goto drop;
 
-  if (!combine_cc_data (self, TRUE, out_fps_entry, ccp_data, ccp_data_len,
-          cea608_1, cea608_1_len, cea608_2, cea608_2_len, cc_data,
-          &cc_data_len, &self->last_cea608_written_was_field1))
-    goto drop;
+  cc_buffer_take_cc_data (self->cc_buffer, out_fps_entry, cc_data,
+      &cc_data_len);
 
   gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
   cc_data_len =
@@ -2101,13 +1106,10 @@ convert_cea708_cdp_cea608_raw (GstCCConverter * self, GstBuffer * inbuf,
 {
   GstMapInfo out;
   GstVideoTimeCode tc = GST_VIDEO_TIME_CODE_INIT;
-  guint8 cea608_1[MAX_CEA608_LEN];
-  guint cea608_1_len = MAX_CEA608_LEN;
+  guint cea608_1_len;
   const struct cdp_fps_entry *in_fps_entry = NULL, *out_fps_entry;
 
-  gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
-  if (!cdp_to_cea608_cc_data (self, inbuf, NULL, NULL, cea608_1, &cea608_1_len,
-          NULL, NULL, &tc, &in_fps_entry)) {
+  if (!push_cdp_buffer (self, inbuf, &tc, &in_fps_entry)) {
     gst_buffer_set_size (outbuf, 0);
     return GST_FLOW_OK;
   }
@@ -2116,29 +1118,16 @@ convert_cea708_cdp_cea608_raw (GstCCConverter * self, GstBuffer * inbuf,
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     out_fps_entry = in_fps_entry;
 
-  if (fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, NULL, 0,
-          cea608_1, &cea608_1_len, NULL, NULL, &tc, FALSE)) {
-    guint i, out_size = (guint) out.size;
-
-    self->output_frames++;
-    if (!write_cea608 (self, TRUE, out_fps_entry, cea608_1, cea608_1_len, NULL,
-            0, out.data, &out_size, NULL)) {
-      gst_buffer_unmap (outbuf, &out);
-      return GST_FLOW_ERROR;
-    }
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry, &tc,
+          &self->current_output_timecode))
+    goto drop;
 
-    /* remove the first byte from each cea608 packet */
-    for (i = 0; i < out_size / 3; i++) {
-      out.data[i * 2 + 0] = out.data[i * 3 + 1];
-      out.data[i * 2 + 1] = out.data[i * 3 + 2];
-    }
-    cea608_1_len = out_size / 3 * 2;
-  } else {
-    cea608_1_len = 0;
-  }
+  gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
+  cea608_1_len = out.size;
+  cc_buffer_take_separated (self->cc_buffer, out_fps_entry, out.data,
+      &cea608_1_len, NULL, 0, NULL, 0);
   gst_buffer_unmap (outbuf, &out);
-
-  gst_buffer_set_size (outbuf, cea608_1_len);
+  self->output_frames++;
 
   if (self->current_output_timecode.config.fps_n != 0 && !tc_meta) {
     gst_buffer_add_video_time_code_meta (outbuf,
@@ -2146,7 +1135,13 @@ convert_cea708_cdp_cea608_raw (GstCCConverter * self, GstBuffer * inbuf,
     gst_video_time_code_increment_frame (&self->current_output_timecode);
   }
 
+out:
+  gst_buffer_set_size (outbuf, cea608_1_len);
   return GST_FLOW_OK;
+
+drop:
+  cea608_1_len = 0;
+  goto out;
 }
 
 static GstFlowReturn
@@ -2156,34 +1151,31 @@ convert_cea708_cdp_cea608_s334_1a (GstCCConverter * self, GstBuffer * inbuf,
   GstMapInfo out;
   GstVideoTimeCode tc = GST_VIDEO_TIME_CODE_INIT;
   const struct cdp_fps_entry *in_fps_entry = NULL, *out_fps_entry;
-  guint8 cea608_1[MAX_CEA608_LEN], cea608_2[MAX_CEA608_LEN];
-  guint cea608_1_len = MAX_CEA608_LEN, cea608_2_len = MAX_CEA608_LEN;
-  guint i, cc_data_len;
+  guint cc_data_len;
+  int s334_len;
+  guint i;
 
-  if (!cdp_to_cea608_cc_data (self, inbuf, NULL, NULL, cea608_1, &cea608_1_len,
-          cea608_2, &cea608_2_len, &tc, &in_fps_entry))
+  if (!push_cdp_buffer (self, inbuf, &tc, &in_fps_entry))
     goto drop;
 
   out_fps_entry = cdp_fps_entry_from_fps (self->out_fps_n, self->out_fps_d);
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     out_fps_entry = in_fps_entry;
 
-  if (!fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, NULL, 0,
-          cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, &tc,
-          self->last_cea608_written_was_field1))
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry, &tc,
+          &self->current_output_timecode))
     goto drop;
 
-  cc_data_len = gst_buffer_get_sizes (outbuf, NULL, NULL);
-
   gst_buffer_map (outbuf, &out, GST_MAP_READWRITE);
-  if (!combine_cc_data (self, TRUE, out_fps_entry, NULL, 0, cea608_1,
-          cea608_1_len, cea608_2, cea608_2_len, out.data, &cc_data_len,
-          &self->last_cea608_written_was_field1)) {
-    gst_buffer_unmap (outbuf, &out);
+
+  cc_data_len = out.size;
+  cc_buffer_take_cc_data (self->cc_buffer, out_fps_entry, out.data,
+      &cc_data_len);
+  s334_len = drop_ccp_from_cc_data (out.data, cc_data_len);
+  if (s334_len < 0)
     goto drop;
-  }
 
-  for (i = 0; i < cc_data_len / 3; i++) {
+  for (i = 0; i < s334_len / 3; i++) {
     guint byte = out.data[i * 3];
     /* We have to assume a line offset of 0 */
     out.data[i * 3] = (byte == 0xfc || byte == 0xf8) ? 0x80 : 0x00;
@@ -2192,7 +1184,7 @@ convert_cea708_cdp_cea608_s334_1a (GstCCConverter * self, GstBuffer * inbuf,
   gst_buffer_unmap (outbuf, &out);
   self->output_frames++;
 
-  gst_buffer_set_size (outbuf, cc_data_len);
+  gst_buffer_set_size (outbuf, s334_len);
 
   if (self->current_output_timecode.config.fps_n != 0 && !tc_meta) {
     gst_buffer_add_video_time_code_meta (outbuf,
@@ -2214,34 +1206,22 @@ convert_cea708_cdp_cea708_cc_data (GstCCConverter * self, GstBuffer * inbuf,
   GstMapInfo out;
   GstVideoTimeCode tc = GST_VIDEO_TIME_CODE_INIT;
   const struct cdp_fps_entry *in_fps_entry = NULL, *out_fps_entry;
-  guint8 cea608_1[MAX_CEA608_LEN], cea608_2[MAX_CEA608_LEN];
-  guint8 ccp_data[MAX_CDP_PACKET_LEN];
-  guint cea608_1_len = MAX_CEA608_LEN, cea608_2_len = MAX_CEA608_LEN;
-  guint ccp_data_len = MAX_CDP_PACKET_LEN;
   guint out_len = 0;
 
-  if (!cdp_to_cea608_cc_data (self, inbuf, ccp_data, &ccp_data_len,
-          cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, &tc, &in_fps_entry))
+  if (!push_cdp_buffer (self, inbuf, &tc, &in_fps_entry))
     goto out;
 
   out_fps_entry = cdp_fps_entry_from_fps (self->out_fps_n, self->out_fps_d);
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     out_fps_entry = in_fps_entry;
 
-  if (!fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, ccp_data,
-          &ccp_data_len, cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, &tc,
-          self->last_cea608_written_was_field1))
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry, &tc,
+          &self->current_output_timecode))
     goto out;
 
   gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
   out_len = (guint) out.size;
-  if (!combine_cc_data (self, TRUE, out_fps_entry, ccp_data, ccp_data_len,
-          cea608_1, cea608_1_len, cea608_2, cea608_2_len, out.data, &out_len,
-          &self->last_cea608_written_was_field1)) {
-    gst_buffer_unmap (outbuf, &out);
-    out_len = 0;
-    goto out;
-  }
+  cc_buffer_take_cc_data (self->cc_buffer, out_fps_entry, out.data, &out_len);
 
   gst_buffer_unmap (outbuf, &out);
   self->output_frames++;
@@ -2265,30 +1245,23 @@ convert_cea708_cdp_cea708_cdp (GstCCConverter * self, GstBuffer * inbuf,
   GstMapInfo out;
   GstVideoTimeCode tc = GST_VIDEO_TIME_CODE_INIT;
   const struct cdp_fps_entry *in_fps_entry = NULL, *out_fps_entry;
-  guint8 cea608_1[MAX_CEA608_LEN], cea608_2[MAX_CEA608_LEN];
-  guint8 ccp_data[MAX_CDP_PACKET_LEN], cc_data[MAX_CDP_PACKET_LEN];
-  guint cea608_1_len = MAX_CEA608_LEN, cea608_2_len = MAX_CEA608_LEN;
-  guint ccp_data_len = MAX_CDP_PACKET_LEN, cc_data_len = MAX_CDP_PACKET_LEN;
+  guint8 cc_data[MAX_CDP_PACKET_LEN];
+  guint cc_data_len = MAX_CDP_PACKET_LEN;
   guint out_len = 0;
 
-  if (!cdp_to_cea608_cc_data (self, inbuf, ccp_data, &ccp_data_len,
-          cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, &tc, &in_fps_entry))
+  if (!push_cdp_buffer (self, inbuf, &tc, &in_fps_entry))
     goto out;
 
   out_fps_entry = cdp_fps_entry_from_fps (self->out_fps_n, self->out_fps_d);
   if (!out_fps_entry || out_fps_entry->fps_n == 0)
     out_fps_entry = in_fps_entry;
 
-  if (!fit_and_scale_cc_data (self, in_fps_entry, out_fps_entry, ccp_data,
-          &ccp_data_len, cea608_1, &cea608_1_len, cea608_2, &cea608_2_len, &tc,
-          self->last_cea608_written_was_field1))
+  if (!can_take_buffer (self, in_fps_entry, out_fps_entry, &tc,
+          &self->current_output_timecode))
     goto out;
 
-  if (!combine_cc_data (self, TRUE, out_fps_entry, ccp_data, ccp_data_len,
-          cea608_1, cea608_1_len, cea608_2, cea608_2_len, cc_data,
-          &cc_data_len, &self->last_cea608_written_was_field1)) {
-    goto out;
-  }
+  cc_buffer_take_cc_data (self->cc_buffer, out_fps_entry, cc_data,
+      &cc_data_len);
 
   gst_buffer_map (outbuf, &out, GST_MAP_WRITE);
   out_len =
@@ -2491,14 +1464,11 @@ can_generate_output (GstCCConverter * self)
 static void
 reset_counters (GstCCConverter * self)
 {
-  self->scratch_ccp_len = 0;
-  self->scratch_cea608_1_len = 0;
-  self->scratch_cea608_2_len = 0;
   self->input_frames = 0;
   self->output_frames = 1;
   gst_video_time_code_clear (&self->current_output_timecode);
   gst_clear_buffer (&self->previous_buffer);
-  self->last_cea608_written_was_field1 = FALSE;
+  cc_buffer_discard (self->cc_buffer);
 }
 
 static GstFlowReturn
@@ -2507,9 +1477,13 @@ drain_input (GstCCConverter * self)
   GstBaseTransformClass *bclass = GST_BASE_TRANSFORM_GET_CLASS (self);
   GstBaseTransform *trans = GST_BASE_TRANSFORM (self);
   GstFlowReturn ret = GST_FLOW_OK;
+  guint cea608_1_len, cea608_2_len, ccp_len;
 
-  while (self->scratch_ccp_len > 0 || self->scratch_cea608_1_len > 0
-      || self->scratch_cea608_2_len > 0 || can_generate_output (self)) {
+  cc_buffer_get_stored_size (self->cc_buffer, &cea608_1_len, &cea608_2_len,
+      &ccp_len);
+
+  while (ccp_len > 0 || cea608_1_len > 0 || cea608_2_len > 0
+      || can_generate_output (self)) {
     GstBuffer *outbuf;
 
     if (!self->previous_buffer) {
@@ -2529,6 +1503,8 @@ drain_input (GstCCConverter * self)
     }
 
     ret = gst_cc_converter_transform (self, NULL, outbuf);
+    cc_buffer_get_stored_size (self->cc_buffer, &cea608_1_len, &cea608_2_len,
+        &ccp_len);
     if (gst_buffer_get_size (outbuf) <= 0) {
       /* try to move the output along */
       self->input_frames++;
@@ -2689,6 +1665,16 @@ gst_cc_converter_get_property (GObject * object, guint prop_id, GValue * value,
   }
 }
 
+static void
+gst_cc_converter_finalize (GObject * object)
+{
+  GstCCConverter *self = GST_CCCONVERTER (object);
+
+  gst_clear_object (&self->cc_buffer);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
 static void
 gst_cc_converter_class_init (GstCCConverterClass * klass)
 {
@@ -2702,6 +1688,7 @@ gst_cc_converter_class_init (GstCCConverterClass * klass)
 
   gobject_class->set_property = gst_cc_converter_set_property;
   gobject_class->get_property = gst_cc_converter_get_property;
+  gobject_class->finalize = gst_cc_converter_finalize;
 
   /**
    * GstCCConverter:cdp-mode
@@ -2756,4 +1743,5 @@ static void
 gst_cc_converter_init (GstCCConverter * self)
 {
   self->cdp_mode = DEFAULT_CDP_MODE;
+  self->cc_buffer = cc_buffer_new ();
 }
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.h b/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.h
index 420255007e..6792c762a4 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.h
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/gstccconverter.h
@@ -25,6 +25,8 @@
 #include <gst/base/base.h>
 #include <gst/video/video.h>
 
+#include "ccutils.h"
+
 G_BEGIN_DECLS
 #define GST_TYPE_CCCONVERTER \
   (gst_cc_converter_get_type())
@@ -40,9 +42,6 @@ G_BEGIN_DECLS
 typedef struct _GstCCConverter GstCCConverter;
 typedef struct _GstCCConverterClass GstCCConverterClass;
 
-#define MAX_CDP_PACKET_LEN 256
-#define MAX_CEA608_LEN 32
-
 typedef enum {
   GST_CC_CONVERTER_CDP_MODE_TIME_CODE   = (1<<0),
   GST_CC_CONVERTER_CDP_MODE_CC_DATA     = (1<<1),
@@ -67,21 +66,13 @@ struct _GstCCConverter
   /* for framerate differences, we need to keep previous/next frames in order
    * to split/merge data across multiple input or output buffers.  The data is
    * stored as cc_data */
-  guint8    scratch_cea608_1[MAX_CEA608_LEN];
-  guint     scratch_cea608_1_len;
-  guint8    scratch_cea608_2[MAX_CEA608_LEN];
-  guint     scratch_cea608_2_len;
-  guint8    scratch_ccp[MAX_CDP_PACKET_LEN];
-  guint     scratch_ccp_len;
+  CCBuffer *cc_buffer;
 
   guint     input_frames;
   guint     output_frames;
   GstVideoTimeCode current_output_timecode;
   /* previous buffer for copying metas onto */
   GstBuffer *previous_buffer;
-
-  /* used for tracking which field to write across output buffer boundaries */
-  gboolean last_cea608_written_was_field1;
 };
 
 struct _GstCCConverterClass
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/gstclosedcaption.c b/subprojects/gst-plugins-bad/ext/closedcaption/gstclosedcaption.c
index 05910ac736..8668a8496d 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/gstclosedcaption.c
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/gstclosedcaption.c
@@ -31,12 +31,16 @@
 #include "gstline21dec.h"
 #include "gstceaccoverlay.h"
 #include "gstline21enc.h"
+#include "ccutils.h"
 
 static gboolean
 closedcaption_init (GstPlugin * plugin)
 {
   gboolean ret = FALSE;
 
+  GST_DEBUG_CATEGORY_INIT (ccutils_debug_cat, "ccutils", 0,
+      "Closed caption utilities");
+
   ret |= GST_ELEMENT_REGISTER (cccombiner, plugin);
   ret |= GST_ELEMENT_REGISTER (ccconverter, plugin);
   ret |= GST_ELEMENT_REGISTER (ccextractor, plugin);
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/meson.build b/subprojects/gst-plugins-bad/ext/closedcaption/meson.build
index 568d51fa55..ab8358254c 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/meson.build
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/meson.build
@@ -12,7 +12,7 @@ zvbi_sources = [
 if closedcaption_dep.found()
   gstclosedcaption = library('gstclosedcaption',
     'gstcccombiner.c', 'gstccextractor.c', 'gstccconverter.c', 'gstclosedcaption.c',
-    'gstline21dec.c', 'gstcea708decoder.c', 'gstceaccoverlay.c', 'gstline21enc.c',
+    'gstline21dec.c', 'gstcea708decoder.c', 'gstceaccoverlay.c', 'gstline21enc.c', 'ccutils.c',
     zvbi_sources,
     c_args : gst_plugins_bad_args,
     link_args : noseh_link_args,
diff --git a/subprojects/gst-plugins-bad/ext/dash/gstmpdclient.c b/subprojects/gst-plugins-bad/ext/dash/gstmpdclient.c
index 8938ce771e..60a523c201 100644
--- a/subprojects/gst-plugins-bad/ext/dash/gstmpdclient.c
+++ b/subprojects/gst-plugins-bad/ext/dash/gstmpdclient.c
@@ -2041,9 +2041,7 @@ gst_mpd_client_get_next_fragment (GstMPDClient * client,
 
     GST_DEBUG ("currentChunk->SegmentURL = %p", currentChunk->SegmentURL);
     if (currentChunk->SegmentURL != NULL) {
-      mediaURL =
-          g_strdup (gst_mpdparser_get_mediaURL (stream,
-              currentChunk->SegmentURL));
+      mediaURL = gst_mpdparser_get_mediaURL (stream, currentChunk->SegmentURL);
       indexURL = g_strdup (currentChunk->SegmentURL->index);
     } else if (stream->cur_seg_template != NULL) {
       mediaURL =
@@ -2315,9 +2313,8 @@ gst_mpd_client_get_next_header (GstMPDClient * client, gchar ** uri,
   *uri = NULL;
   if (stream->cur_segment_base) {
     if (stream->cur_segment_base->Initialization) {
-      *uri =
-          g_strdup (gst_mpdparser_get_initializationURL (stream,
-              stream->cur_segment_base->Initialization));
+      *uri = gst_mpdparser_get_initializationURL (stream,
+          stream->cur_segment_base->Initialization);
       if (stream->cur_segment_base->Initialization->range) {
         *range_start =
             stream->cur_segment_base->Initialization->range->first_byte_pos;
@@ -2325,9 +2322,8 @@ gst_mpd_client_get_next_header (GstMPDClient * client, gchar ** uri,
             stream->cur_segment_base->Initialization->range->last_byte_pos;
       }
     } else if (stream->cur_segment_base->indexRange) {
-      *uri =
-          g_strdup (gst_mpdparser_get_initializationURL (stream,
-              stream->cur_segment_base->Initialization));
+      *uri = gst_mpdparser_get_initializationURL (stream,
+          stream->cur_segment_base->Initialization);
       *range_start = 0;
       *range_end = stream->cur_segment_base->indexRange->first_byte_pos - 1;
     }
@@ -2362,9 +2358,8 @@ gst_mpd_client_get_next_header_index (GstMPDClient * client, gchar ** uri,
   GST_DEBUG ("Looking for current representation index");
   *uri = NULL;
   if (stream->cur_segment_base && stream->cur_segment_base->indexRange) {
-    *uri =
-        g_strdup (gst_mpdparser_get_initializationURL (stream,
-            stream->cur_segment_base->RepresentationIndex));
+    *uri = gst_mpdparser_get_initializationURL (stream,
+        stream->cur_segment_base->RepresentationIndex);
     *range_start = stream->cur_segment_base->indexRange->first_byte_pos;
     *range_end = stream->cur_segment_base->indexRange->last_byte_pos;
   } else if (stream->cur_seg_template && stream->cur_seg_template->index) {
diff --git a/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.c b/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.c
index f88bb6c807..c36f2acb5b 100644
--- a/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.c
+++ b/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.c
@@ -1366,34 +1366,56 @@ gst_mpdparser_free_active_stream (GstActiveStream * active_stream)
   }
 }
 
-const gchar *
+static gchar *
+get_base_url_with_query (GstActiveStream * stream)
+{
+  GstUri *uri;
+  gchar *uri_str;
+
+  if (!stream->queryURL)
+    return g_strdup (stream->baseURL);
+
+  uri = gst_uri_from_string (stream->baseURL);
+  gst_uri_set_query_string (uri, stream->queryURL);
+  uri_str = gst_uri_to_string (uri);
+
+  gst_uri_unref (uri);
+  return uri_str;
+}
+
+/*
+ * gst_mpdparser_get_initializationURL:
+ *
+ * Returns: (transfer full): stream initializationURL if available,
+ *   baseURL combined with queryURL otherwise.
+ */
+gchar *
 gst_mpdparser_get_initializationURL (GstActiveStream * stream,
     GstMPDURLTypeNode * InitializationURL)
 {
-  const gchar *url_prefix;
-
   g_return_val_if_fail (stream != NULL, NULL);
 
-  url_prefix = (InitializationURL
-      && InitializationURL->sourceURL) ? InitializationURL->sourceURL : stream->
-      baseURL;
-
-  return url_prefix;
+  return (InitializationURL && InitializationURL->sourceURL)
+      ? g_strdup (InitializationURL->sourceURL)
+      : get_base_url_with_query (stream);
 }
 
+/*
+ * gst_mpdparser_get_mediaURL:
+ *
+ * Returns: (transfer full): stream mediaURL if available,
+ *   baseURL combined with queryURL otherwise.
+ */
 gchar *
 gst_mpdparser_get_mediaURL (GstActiveStream * stream,
     GstMPDSegmentURLNode * segmentURL)
 {
-  const gchar *url_prefix;
-
   g_return_val_if_fail (stream != NULL, NULL);
   g_return_val_if_fail (segmentURL != NULL, NULL);
 
-  url_prefix = segmentURL->media ? segmentURL->media : stream->baseURL;
-  g_return_val_if_fail (url_prefix != NULL, NULL);
-
-  return segmentURL->media;
+  return (segmentURL->media)
+      ? g_strdup (segmentURL->media)
+      : get_base_url_with_query (stream);
 }
 
 /* navigation functions */
diff --git a/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.h b/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.h
index f51b962bf1..c0930a45e0 100644
--- a/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.h
+++ b/subprojects/gst-plugins-bad/ext/dash/gstmpdparser.h
@@ -162,7 +162,7 @@ void gst_mpdparser_media_fragment_info_clear (GstMediaFragmentInfo * fragment);
 /* Active stream methods*/
 void gst_mpdparser_init_active_stream_segments (GstActiveStream * stream);
 gchar *gst_mpdparser_get_mediaURL (GstActiveStream * stream, GstMPDSegmentURLNode * segmentURL);
-const gchar *gst_mpdparser_get_initializationURL (GstActiveStream * stream, GstMPDURLTypeNode * InitializationURL);
+gchar *gst_mpdparser_get_initializationURL (GstActiveStream * stream, GstMPDURLTypeNode * InitializationURL);
 gchar *gst_mpdparser_build_URL_from_template (const gchar * url_template, const gchar * id, guint number, guint bandwidth, guint64 time);
 
 G_END_DECLS
diff --git a/subprojects/gst-plugins-bad/ext/gs/gstgssink.cpp b/subprojects/gst-plugins-bad/ext/gs/gstgssink.cpp
index 4c3d740b10..0aa71db0cb 100644
--- a/subprojects/gst-plugins-bad/ext/gs/gstgssink.cpp
+++ b/subprojects/gst-plugins-bad/ext/gs/gstgssink.cpp
@@ -112,6 +112,7 @@ enum {
   PROP_START_DATE,
   PROP_SERVICE_ACCOUNT_CREDENTIALS,
   PROP_METADATA,
+  PROP_CONTENT_TYPE,
 };
 
 class GSWriteStream;
@@ -131,6 +132,7 @@ struct _GstGsSink {
   gboolean post_messages;
   GstGsSinkNext next_file;
   const gchar* content_type;
+  gchar* content_type_prop;
   size_t nb_percent_format;
   gboolean percent_s_is_first;
   GstStructure* metadata;
@@ -333,6 +335,23 @@ static void gst_gs_sink_class_init(GstGsSinkClass* klass) {
           (GParamFlags)(G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS |
                         GST_PARAM_MUTABLE_READY)));
 
+  /**
+   * GstGsSink:content-type:
+   *
+   * The Content-Type of the object.
+   * If not set we use the name of the input caps.
+   *
+   * Since: 1.22
+   */
+  g_object_class_install_property(
+      gobject_class, PROP_CONTENT_TYPE,
+      g_param_spec_string(
+          "content-type", "Content-Type",
+          "The Content-Type of the object",
+          NULL,
+          (GParamFlags)(G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS |
+                        GST_PARAM_MUTABLE_READY)));
+
   gobject_class->finalize = gst_gs_sink_finalize;
 
   gstbasesink_class->start = GST_DEBUG_FUNCPTR(gst_gs_sink_start);
@@ -365,6 +384,7 @@ static void gst_gs_sink_init(GstGsSink* sink) {
   sink->start_date = NULL;
   sink->next_file = DEFAULT_NEXT_FILE;
   sink->content_type = NULL;
+  sink->content_type_prop = NULL;
   sink->nb_percent_format = 0;
   sink->percent_s_is_first = FALSE;
 
@@ -391,6 +411,7 @@ static void gst_gs_sink_finalize(GObject* object) {
     sink->start_date = NULL;
   }
   sink->content_type = NULL;
+  g_clear_pointer(&sink->content_type_prop, g_free);
   g_clear_pointer(&sink->metadata, gst_structure_free);
 
   G_OBJECT_CLASS(parent_class)->finalize(object);
@@ -489,6 +510,10 @@ static void gst_gs_sink_set_property(GObject* object,
       g_clear_pointer(&sink->metadata, gst_structure_free);
       sink->metadata = (GstStructure*)g_value_dup_boxed(value);
       break;
+    case PROP_CONTENT_TYPE:
+      g_clear_pointer(&sink->content_type_prop, g_free);
+      sink->content_type_prop = g_value_dup_string(value);
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);
       break;
@@ -529,6 +554,9 @@ static void gst_gs_sink_get_property(GObject* object,
     case PROP_METADATA:
       g_value_set_boxed(value, sink->metadata);
       break;
+    case PROP_CONTENT_TYPE:
+      g_value_set_string(value, sink->content_type_prop);
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);
       break;
@@ -691,12 +719,18 @@ static GstFlowReturn gst_gs_sink_write_buffer(GstGsSink* sink,
   GstMapInfo map = {0};
   gchar* object_name = NULL;
   gchar* buffer_date = NULL;
+  const gchar* content_type;
 
   if (!gst_buffer_map(buffer, &map, GST_MAP_READ))
     return GST_FLOW_ERROR;
 
+  if (sink->content_type_prop)
+    content_type = sink->content_type_prop;
+  else
+    content_type = sink->content_type;
+
   gcs::ObjectMetadata metadata =
-      gcs::ObjectMetadata().set_content_type(sink->content_type);
+      gcs::ObjectMetadata().set_content_type(content_type);
 
   if (sink->metadata) {
     struct AddMetadataIter it = {sink, &metadata};
@@ -861,7 +895,9 @@ static gboolean gst_gs_sink_set_caps(GstBaseSink* bsink, GstCaps* caps) {
 
   sink->content_type = gst_structure_get_name(s);
 
-  GST_INFO_OBJECT(sink, "Content type: %s", sink->content_type);
+  /* TODO: we could automatically convert some caps such as 'video/quicktime,variant=iso' to 'video/mp4' */
+
+  GST_INFO_OBJECT(sink, "Content-Type: caps: %s property: %s", sink->content_type, sink->content_type_prop);
 
   return TRUE;
 }
diff --git a/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.c b/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.c
index 8cf6c2acc6..305406e476 100644
--- a/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.c
+++ b/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.c
@@ -1166,6 +1166,13 @@ gst_hls_demux_data_received (GstAdaptiveDemux * demux,
     buffer = tmp_buffer;
   }
 
+  if (hlsdemux->prog_dt) {
+    gst_adaptive_demux_stream_set_tags (stream,
+        gst_tag_list_new (GST_TAG_DATE_TIME, hlsdemux->prog_dt, NULL));
+    gst_date_time_unref (hlsdemux->prog_dt);
+    hlsdemux->prog_dt = NULL;
+  }
+
   return gst_hls_demux_handle_buffer (demux, stream, buffer, FALSE);
 }
 
@@ -1247,7 +1254,9 @@ gst_hls_demux_update_fragment_info (GstAdaptiveDemuxStream * stream)
   m3u8 = gst_hls_demux_stream_get_m3u8 (hlsdemux_stream);
 
   forward = (stream->demux->segment.rate > 0);
-  file = gst_m3u8_get_next_fragment (m3u8, forward, &sequence_pos, &discont);
+  file =
+      gst_m3u8_get_next_fragment (m3u8, forward, &sequence_pos,
+      &hlsdemux->prog_dt, &discont);
 
   if (file == NULL) {
     GST_INFO_OBJECT (hlsdemux, "This playlist doesn't contain more fragments");
@@ -1359,6 +1368,12 @@ gst_hls_demux_reset (GstAdaptiveDemux * ademux)
   GST_DEBUG_OBJECT (demux, "Streams aware : %d", demux->streams_aware);
 
   gst_hls_demux_clear_all_pending_data (demux);
+
+  if (demux->prog_dt) {
+    gst_date_time_unref (demux->prog_dt);
+    demux->prog_dt = NULL;
+  }
+
   GST_M3U8_CLIENT_UNLOCK (hlsdemux->client);
 }
 
diff --git a/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.h b/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.h
index 98d6099cbf..846026eac3 100644
--- a/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.h
+++ b/subprojects/gst-plugins-bad/ext/hls/gsthlsdemux.h
@@ -141,6 +141,8 @@ struct _GstHLSDemux
   GHashTable *keys;
   GMutex      keys_lock;
 
+  GstDateTime *prog_dt;
+
   /* FIXME: check locking, protected automatically by manifest_lock already? */
   /* The master playlist with the available variant streams */
   GstHLSMasterPlaylist *master;
diff --git a/subprojects/gst-plugins-bad/ext/hls/m3u8.c b/subprojects/gst-plugins-bad/ext/hls/m3u8.c
index d20e352c3f..4f3595e5eb 100644
--- a/subprojects/gst-plugins-bad/ext/hls/m3u8.c
+++ b/subprojects/gst-plugins-bad/ext/hls/m3u8.c
@@ -32,7 +32,8 @@
 #define GST_CAT_DEFAULT hls_debug
 
 static GstM3U8MediaFile *gst_m3u8_media_file_new (gchar * uri,
-    gchar * title, GstClockTime duration, guint sequence);
+    gchar * title, GstClockTime duration, guint sequence,
+    GstDateTime * program_dt);
 static void gst_m3u8_init_file_unref (GstM3U8InitFile * self);
 static gchar *uri_join (const gchar * uri, const gchar * path);
 
@@ -116,7 +117,7 @@ gst_m3u8_unref (GstM3U8 * self)
 
 static GstM3U8MediaFile *
 gst_m3u8_media_file_new (gchar * uri, gchar * title, GstClockTime duration,
-    guint sequence)
+    guint sequence, GstDateTime * program_dt)
 {
   GstM3U8MediaFile *file;
 
@@ -126,6 +127,7 @@ gst_m3u8_media_file_new (gchar * uri, gchar * title, GstClockTime duration,
   file->duration = duration;
   file->sequence = sequence;
   file->ref_count = 1;
+  file->program_dt = program_dt;
 
   return file;
 }
@@ -150,6 +152,8 @@ gst_m3u8_media_file_unref (GstM3U8MediaFile * self)
     g_free (self->title);
     g_free (self->uri);
     g_free (self->key);
+    if (self->program_dt)
+      gst_date_time_unref (self->program_dt);
     g_free (self);
   }
 }
@@ -483,6 +487,7 @@ gboolean
 gst_m3u8_update (GstM3U8 * self, gchar * data)
 {
   gint val;
+  GstDateTime *program_dt = NULL;
   GstClockTime duration;
   gchar *title, *end;
   gboolean discontinuity = FALSE;
@@ -558,7 +563,10 @@ gst_m3u8_update (GstM3U8 * self, gchar * data)
       data = uri_join (self->base_uri ? self->base_uri : self->uri, data);
       if (data != NULL) {
         GstM3U8MediaFile *file;
-        file = gst_m3u8_media_file_new (data, title, duration, mediasequence++);
+        file =
+            gst_m3u8_media_file_new (data, title, duration,
+            mediasequence++, program_dt);
+        program_dt = NULL;
 
         /* set encryption params */
         file->key = current_key ? g_strdup (current_key) : NULL;
@@ -647,8 +655,12 @@ gst_m3u8_update (GstM3U8 * self, gchar * data)
         self->discont_sequence++;
         discontinuity = TRUE;
       } else if (g_str_has_prefix (data_ext_x, "PROGRAM-DATE-TIME:")) {
-        /* <YYYY-MM-DDThh:mm:ssZ> */
-        GST_DEBUG ("FIXME parse date");
+        if (program_dt)
+          gst_date_time_unref (program_dt);
+        program_dt = gst_date_time_new_from_iso8601_string (data + 25);
+        if (!program_dt) {
+          GST_WARNING ("Could not parse program date/time");
+        }
       } else if (g_str_has_prefix (data_ext_x, "ALLOW-CACHE:")) {
         self->allowcache = g_ascii_strcasecmp (data + 19, "YES") == 0;
       } else if (g_str_has_prefix (data_ext_x, "KEY:")) {
@@ -767,6 +779,11 @@ gst_m3u8_update (GstM3U8 * self, gchar * data)
   g_free (current_key);
   current_key = NULL;
 
+  if (program_dt) {
+    gst_date_time_unref (program_dt);
+    program_dt = NULL;
+  }
+
   self->files = g_list_reverse (self->files);
 
   if (last_init_file)
@@ -919,7 +936,8 @@ m3u8_find_next_fragment (GstM3U8 * m3u8, gboolean forward)
 
 GstM3U8MediaFile *
 gst_m3u8_get_next_fragment (GstM3U8 * m3u8, gboolean forward,
-    GstClockTime * sequence_position, gboolean * discont)
+    GstClockTime * sequence_position, GstDateTime ** program_dt,
+    gboolean * discont)
 {
   GstM3U8MediaFile *file = NULL;
 
@@ -945,6 +963,11 @@ gst_m3u8_get_next_fragment (GstM3U8 * m3u8, gboolean forward,
 
   if (sequence_position)
     *sequence_position = m3u8->sequence_position;
+
+  if (program_dt)
+    *program_dt =
+        file->program_dt ? gst_date_time_ref (file->program_dt) : NULL;
+
   if (discont)
     *discont = file->discont || (m3u8->sequence != file->sequence);
 
diff --git a/subprojects/gst-plugins-bad/ext/hls/m3u8.h b/subprojects/gst-plugins-bad/ext/hls/m3u8.h
index aa511360d1..4a8d926673 100644
--- a/subprojects/gst-plugins-bad/ext/hls/m3u8.h
+++ b/subprojects/gst-plugins-bad/ext/hls/m3u8.h
@@ -99,6 +99,7 @@ struct _GstM3U8MediaFile
   gchar *key;
   guint8 iv[16];
   gint64 offset, size;
+  GstDateTime *program_dt;      /* program date time */
   gint ref_count;               /* ATOMIC */
   GstM3U8InitFile *init_file;   /* Media Initialization (hold ref) */
 };
@@ -127,6 +128,7 @@ void               gst_m3u8_set_uri              (GstM3U8      * m3u8,
 GstM3U8MediaFile * gst_m3u8_get_next_fragment    (GstM3U8      * m3u8,
                                                   gboolean       forward,
                                                   GstClockTime * sequence_position,
+                                                  GstDateTime ** program_dt,
                                                   gboolean     * discont);
 
 gboolean           gst_m3u8_has_next_fragment    (GstM3U8 * m3u8,
diff --git a/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.cpp b/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.cpp
index f47abf1c92..a8600d2052 100644
--- a/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.cpp
+++ b/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.cpp
@@ -73,6 +73,7 @@ GstOnnxClient::GstOnnxClient ():session (nullptr),
 
 GstOnnxClient::~GstOnnxClient ()
 {
+    outputNames.clear();
     delete session;
     delete[]dest;
 }
@@ -115,6 +116,10 @@ std::string GstOnnxClient::getOutputNodeName (GstMlOutputNodeFunction nodeType)
       case GST_ML_OUTPUT_NODE_FUNCTION_CLASS:
         return "label";
         break;
+      case GST_ML_OUTPUT_NODE_NUMBER_OF:
+        g_assert_not_reached();
+        GST_WARNING("Invalid parameter");
+        break;
     };
 
     return "";
@@ -130,9 +135,16 @@ GstMlModelInputImageFormat GstOnnxClient::getInputImageFormat (void)
     return inputImageFormat;
 }
 
-std::vector < const char *>GstOnnxClient::getOutputNodeNames (void)
+std::vector< const char *> GstOnnxClient::getOutputNodeNames (void)
 {
-    return outputNames;
+    if (!outputNames.empty() && outputNamesRaw.size() != outputNames.size()) {
+        outputNamesRaw.resize(outputNames.size());
+        for (size_t i = 0; i < outputNamesRaw.size(); i++) {
+          outputNamesRaw[i] = outputNames[i].get();
+        }
+    }
+
+    return outputNamesRaw;
 }
 
 void GstOnnxClient::setOutputNodeIndex (GstMlOutputNodeFunction node,
@@ -227,11 +239,13 @@ bool GstOnnxClient::createSession (std::string modelFile,
     GST_DEBUG ("Number of Output Nodes: %d", (gint) session->GetOutputCount ());
 
     Ort::AllocatorWithDefaultOptions allocator;
-    GST_DEBUG ("Input name: %s", session->GetInputName (0, allocator));
+    auto input_name = session->GetInputNameAllocated (0, allocator);
+    GST_DEBUG ("Input name: %s", input_name.get());
 
     for (size_t i = 0; i < session->GetOutputCount (); ++i) {
-      auto output_name = session->GetOutputName (i, allocator);
-      outputNames.push_back (output_name);
+      auto output_name = session->GetOutputNameAllocated (i, allocator);
+      GST_DEBUG("Output name %lu:%s", i, output_name.get());
+      outputNames.push_back (std::move(output_name));
       auto type_info = session->GetOutputTypeInfo (i);
       auto tensor_info = type_info.GetTensorTypeAndShapeInfo ();
 
@@ -278,7 +292,7 @@ template < typename T > std::vector < GstMlBoundingBox >
     parseDimensions (vmeta);
 
     Ort::AllocatorWithDefaultOptions allocator;
-    auto inputName = session->GetInputName (0, allocator);
+    auto inputName = session->GetInputNameAllocated (0, allocator);
     auto inputTypeInfo = session->GetInputTypeInfo (0);
     std::vector < int64_t > inputDims =
         inputTypeInfo.GetTensorTypeAndShapeInfo ().GetShape ();
@@ -366,11 +380,11 @@ template < typename T > std::vector < GstMlBoundingBox >
     std::vector < Ort::Value > inputTensors;
     inputTensors.push_back (Ort::Value::CreateTensor < uint8_t > (memoryInfo,
             dest, inputTensorSize, inputDims.data (), inputDims.size ()));
-    std::vector < const char *>inputNames { inputName };
+    std::vector < const char *>inputNames { inputName.get () };
 
     std::vector < Ort::Value > modelOutput = session->Run (Ort::RunOptions { nullptr},
         inputNames.data (),
-        inputTensors.data (), 1, outputNames.data (), outputNames.size ());
+        inputTensors.data (), 1, outputNamesRaw.data (), outputNamesRaw.size ());
 
     auto numDetections =
         modelOutput[getOutputNodeIndex
diff --git a/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.h b/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.h
index 769cd11550..edbc2f4655 100644
--- a/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.h
+++ b/subprojects/gst-plugins-bad/ext/onnx/gstonnxclient.h
@@ -108,7 +108,8 @@ namespace GstOnnxNamespace {
     GstMlOutputNodeInfo outputNodeInfo[GST_ML_OUTPUT_NODE_NUMBER_OF];
     // !! indexed by array index
 	size_t outputNodeIndexToFunction[GST_ML_OUTPUT_NODE_NUMBER_OF];
-    std::vector < const char *>outputNames;
+    std::vector < const char *> outputNamesRaw;
+    std::vector < Ort::AllocatedStringPtr > outputNames;
     GstMlModelInputImageFormat inputImageFormat;
     bool fixedInputImageSize;
   };
diff --git a/subprojects/gst-plugins-bad/ext/onnx/gstonnxobjectdetector.cpp b/subprojects/gst-plugins-bad/ext/onnx/gstonnxobjectdetector.cpp
index 28f4cf2fa0..680b02f3f8 100644
--- a/subprojects/gst-plugins-bad/ext/onnx/gstonnxobjectdetector.cpp
+++ b/subprojects/gst-plugins-bad/ext/onnx/gstonnxobjectdetector.cpp
@@ -55,16 +55,24 @@
  *
  * ## Example launch command:
  *
- * (note: an object detection model has 3 or 4 output nodes, but there is no naming convention
- * to indicate which node outputs the bounding box, which node outputs the label, etc.
- * So, the `onnxobjectdetector` element has properties to map each node's functionality to its
- * respective node index in the specified model )
+ * (note: an object detection model has 3 or 4 output nodes, but there is no
+ * naming convention to indicate which node outputs the bounding box, which
+ * node outputs the label, etc. So, the `onnxobjectdetector` element has
+ * properties to map each node's functionality to its respective node index in
+ * the specified model. Image resolution also need to be adapted to the model.
+ * The videoscale in the pipeline below will scale the image, using padding if
+ * required, to 640x383 resolution required by the model.)
+ *
+ * model.onnx can be found here:
+ * https://github.com/zoq/onnx-runtime-examples/raw/main/data/models/model.onnx
  *
  * ```
  * GST_DEBUG=objectdetector:5 gst-launch-1.0 multifilesrc \
  * location=000000088462.jpg caps=image/jpeg,framerate=\(fraction\)30/1 ! jpegdec ! \
  * videoconvert ! \
- * onnxobjectdetector \
+ * videoscale ! \
+ * 'video/x-raw,width=640,height=383' ! \
+ * onnxobjectdetector ! \
  * box-node-index=0 \
  * class-node-index=1 \
  * score-node-index=2 \
diff --git a/subprojects/gst-plugins-bad/ext/onnx/meson.build b/subprojects/gst-plugins-bad/ext/onnx/meson.build
index ff91739746..e66d649e03 100644
--- a/subprojects/gst-plugins-bad/ext/onnx/meson.build
+++ b/subprojects/gst-plugins-bad/ext/onnx/meson.build
@@ -3,7 +3,7 @@ if get_option('onnx').disabled()
 endif
 
 
-onnxrt_dep = dependency('libonnxruntime',required : get_option('onnx'))
+onnxrt_dep = dependency('libonnxruntime', version : '>= 1.13.1', required : get_option('onnx'))
 
 if onnxrt_dep.found()
 	onnxrt_include_root = onnxrt_dep.get_variable('includedir')
diff --git a/subprojects/gst-plugins-bad/ext/sctp/gstsctpdec.c b/subprojects/gst-plugins-bad/ext/sctp/gstsctpdec.c
index 097b629b9e..a90f89428f 100644
--- a/subprojects/gst-plugins-bad/ext/sctp/gstsctpdec.c
+++ b/subprojects/gst-plugins-bad/ext/sctp/gstsctpdec.c
@@ -629,8 +629,14 @@ on_gst_sctp_association_stream_reset (GstSctpAssociation * gst_sctp_association,
   srcpad = gst_element_get_static_pad (GST_ELEMENT (self), pad_name);
   g_free (pad_name);
   if (!srcpad) {
-    GST_WARNING_OBJECT (self, "Reset called on stream without a srcpad");
-    return;
+    /* This can happen if a stream is created but the peer never sends any data.
+     * We still need to signal the reset by removing the relevant pad.  To do
+     * that, we need to add the relevant pad first. */
+    srcpad = get_pad_for_stream_id (self, stream_id);
+    if (!srcpad) {
+      GST_WARNING_OBJECT (self, "Reset called on stream without a srcpad");
+      return;
+    }
   }
   remove_pad (self, srcpad);
   gst_object_unref (srcpad);
diff --git a/subprojects/gst-plugins-bad/ext/webrtc/gstwebrtcbin.c b/subprojects/gst-plugins-bad/ext/webrtc/gstwebrtcbin.c
index dd16885238..2401fd4762 100644
--- a/subprojects/gst-plugins-bad/ext/webrtc/gstwebrtcbin.c
+++ b/subprojects/gst-plugins-bad/ext/webrtc/gstwebrtcbin.c
@@ -533,6 +533,7 @@ enum
   PROP_ICE_AGENT,
   PROP_LATENCY,
   PROP_SCTP_TRANSPORT,
+  PROP_HTTP_PROXY
 };
 
 static guint gst_webrtc_bin_signals[LAST_SIGNAL] = { 0 };
@@ -2407,11 +2408,11 @@ _on_sctpdec_pad_added (GstElement * sctpdec, GstPad * pad,
     g_signal_emit (webrtc, gst_webrtc_bin_signals[PREPARE_DATA_CHANNEL_SIGNAL],
         0, channel, FALSE);
 
-    gst_bin_add (GST_BIN (webrtc), channel->appsrc);
-    gst_bin_add (GST_BIN (webrtc), channel->appsink);
+    gst_bin_add (GST_BIN (webrtc), channel->src_bin);
+    gst_bin_add (GST_BIN (webrtc), channel->sink_bin);
 
-    gst_element_sync_state_with_parent (channel->appsrc);
-    gst_element_sync_state_with_parent (channel->appsink);
+    gst_element_sync_state_with_parent (channel->src_bin);
+    gst_element_sync_state_with_parent (channel->sink_bin);
 
     webrtc_data_channel_link_to_sctp (channel, webrtc->priv->sctp_transport);
 
@@ -2422,7 +2423,7 @@ _on_sctpdec_pad_added (GstElement * sctpdec, GstPad * pad,
   g_signal_connect (channel, "notify::ready-state",
       G_CALLBACK (_on_data_channel_ready_state), webrtc);
 
-  sink_pad = gst_element_get_static_pad (channel->appsink, "sink");
+  sink_pad = gst_element_get_static_pad (channel->sink_bin, "sink");
   if (gst_pad_link (pad, sink_pad) != GST_PAD_LINK_OK)
     GST_WARNING_OBJECT (channel, "Failed to link sctp pad %s with channel %"
         GST_PTR_FORMAT, GST_PAD_NAME (pad), channel);
@@ -4923,7 +4924,7 @@ _set_internal_rtpbin_element_props_from_stream (GstWebRTCBin * webrtc,
         g_value_unset (&ptval);
       }
 
-      GST_DEBUG_OBJECT (webrtc, "stream %" GST_PTR_FORMAT " transceiever %"
+      GST_DEBUG_OBJECT (webrtc, "stream %" GST_PTR_FORMAT " transceiver %"
           GST_PTR_FORMAT " has FEC payload %d and RED payload %d", stream,
           trans, ulpfec_pt, red_pt);
 
@@ -5781,10 +5782,9 @@ static void
 _connect_rtpfunnel (GstWebRTCBin * webrtc, guint session_id)
 {
   gchar *pad_name;
-  GstPad *queue_srcpad;
+  GstPad *srcpad;
   GstPad *rtp_sink;
   TransportStream *stream = _find_transport_for_session (webrtc, session_id);
-  GstElement *queue;
 
   g_assert (stream);
 
@@ -5795,19 +5795,14 @@ _connect_rtpfunnel (GstWebRTCBin * webrtc, guint session_id)
   gst_bin_add (GST_BIN (webrtc), webrtc->rtpfunnel);
   gst_element_sync_state_with_parent (webrtc->rtpfunnel);
 
-  queue = gst_element_factory_make ("queue", NULL);
-  gst_bin_add (GST_BIN (webrtc), queue);
-  gst_element_sync_state_with_parent (queue);
-
-  gst_element_link (webrtc->rtpfunnel, queue);
-
-  queue_srcpad = gst_element_get_static_pad (queue, "src");
+  srcpad = gst_element_get_static_pad (webrtc->rtpfunnel, "src");
 
   pad_name = g_strdup_printf ("send_rtp_sink_%d", session_id);
   rtp_sink = gst_element_request_pad_simple (webrtc->rtpbin, pad_name);
   g_free (pad_name);
-  gst_pad_link (queue_srcpad, rtp_sink);
-  gst_object_unref (queue_srcpad);
+
+  gst_pad_link (srcpad, rtp_sink);
+  gst_object_unref (srcpad);
   gst_object_unref (rtp_sink);
 
   pad_name = g_strdup_printf ("send_rtp_src_%d", session_id);
@@ -6968,11 +6963,11 @@ gst_webrtc_bin_create_data_channel (GstWebRTCBin * webrtc, const gchar * label,
   g_signal_emit (webrtc, gst_webrtc_bin_signals[PREPARE_DATA_CHANNEL_SIGNAL], 0,
       ret, TRUE);
 
-  gst_bin_add (GST_BIN (webrtc), ret->appsrc);
-  gst_bin_add (GST_BIN (webrtc), ret->appsink);
+  gst_bin_add (GST_BIN (webrtc), ret->src_bin);
+  gst_bin_add (GST_BIN (webrtc), ret->sink_bin);
 
-  gst_element_sync_state_with_parent (ret->appsrc);
-  gst_element_sync_state_with_parent (ret->appsink);
+  gst_element_sync_state_with_parent (ret->src_bin);
+  gst_element_sync_state_with_parent (ret->sink_bin);
 
   ret = gst_object_ref (ret);
   ret->webrtcbin = webrtc;
@@ -8058,6 +8053,10 @@ gst_webrtc_bin_set_property (GObject * object, guint prop_id,
     case PROP_ICE_AGENT:
       webrtc->priv->ice = g_value_get_object (value);
       break;
+    case PROP_HTTP_PROXY:
+      gst_webrtc_ice_set_http_proxy (webrtc->priv->ice,
+          g_value_get_string (value));
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -8135,6 +8134,10 @@ gst_webrtc_bin_get_property (GObject * object, guint prop_id,
     case PROP_SCTP_TRANSPORT:
       g_value_set_object (value, webrtc->priv->sctp_transport);
       break;
+    case PROP_HTTP_PROXY:
+      g_value_take_string (value,
+          gst_webrtc_ice_get_http_proxy (webrtc->priv->ice));
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -8419,6 +8422,21 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
           0, G_MAXUINT, DEFAULT_JB_LATENCY,
           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 
+  /**
+   * GstWebRTCBin:http-proxy:
+   *
+   * A HTTP proxy for use with TURN/TCP of the form
+   * http://[username:password@]hostname[:port]
+   *
+   * Since: 1.22
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_HTTP_PROXY,
+      g_param_spec_string ("http-proxy", "HTTP Proxy",
+          "A HTTP proxy for use with TURN/TCP of the form "
+          "http://[username:password@]hostname[:port]",
+          NULL, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
   /**
    * GstWebRTCBin:sctp-transport:
    *
diff --git a/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.c b/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.c
index bb2b023618..0260c61721 100644
--- a/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.c
+++ b/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.c
@@ -44,6 +44,141 @@
 #define GST_CAT_DEFAULT webrtc_data_channel_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
+static void _close_procedure (WebRTCDataChannel * channel, gpointer user_data);
+
+typedef void (*ChannelTask) (GstWebRTCDataChannel * channel,
+    gpointer user_data);
+
+struct task
+{
+  GstWebRTCDataChannel *channel;
+  ChannelTask func;
+  gpointer user_data;
+  GDestroyNotify notify;
+};
+
+static GstStructure *
+_execute_task (GstWebRTCBin * webrtc, struct task *task)
+{
+  if (task->func)
+    task->func (task->channel, task->user_data);
+
+  return NULL;
+}
+
+static void
+_free_task (struct task *task)
+{
+  gst_object_unref (task->channel);
+
+  if (task->notify)
+    task->notify (task->user_data);
+  g_free (task);
+}
+
+static void
+_channel_enqueue_task (WebRTCDataChannel * channel, ChannelTask func,
+    gpointer user_data, GDestroyNotify notify)
+{
+  struct task *task = g_new0 (struct task, 1);
+
+  task->channel = gst_object_ref (channel);
+  task->func = func;
+  task->user_data = user_data;
+  task->notify = notify;
+
+  gst_webrtc_bin_enqueue_task (channel->webrtcbin,
+      (GstWebRTCBinFunc) _execute_task, task, (GDestroyNotify) _free_task,
+      NULL);
+}
+
+static void
+_channel_store_error (WebRTCDataChannel * channel, GError * error)
+{
+  GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
+  if (error) {
+    GST_WARNING_OBJECT (channel, "Error: %s",
+        error ? error->message : "Unknown");
+    if (!channel->stored_error)
+      channel->stored_error = error;
+    else
+      g_clear_error (&error);
+  }
+  GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+}
+
+struct _WebRTCErrorIgnoreBin
+{
+  GstBin bin;
+
+  WebRTCDataChannel *data_channel;
+};
+
+G_DEFINE_TYPE (WebRTCErrorIgnoreBin, webrtc_error_ignore_bin, GST_TYPE_BIN);
+
+static void
+webrtc_error_ignore_bin_handle_message (GstBin * bin, GstMessage * message)
+{
+  WebRTCErrorIgnoreBin *self = WEBRTC_ERROR_IGNORE_BIN (bin);
+
+  switch (GST_MESSAGE_TYPE (message)) {
+    case GST_MESSAGE_ERROR:{
+      GError *error = NULL;
+      gst_message_parse_error (message, &error, NULL);
+      GST_DEBUG_OBJECT (bin, "handling error message from internal element");
+      _channel_store_error (self->data_channel, error);
+      _channel_enqueue_task (self->data_channel, (ChannelTask) _close_procedure,
+          NULL, NULL);
+      break;
+    }
+    default:
+      GST_BIN_CLASS (webrtc_error_ignore_bin_parent_class)->handle_message (bin,
+          message);
+      break;
+  }
+}
+
+static void
+webrtc_error_ignore_bin_class_init (WebRTCErrorIgnoreBinClass * klass)
+{
+  GstBinClass *bin_class = (GstBinClass *) klass;
+
+  bin_class->handle_message = webrtc_error_ignore_bin_handle_message;
+}
+
+static void
+webrtc_error_ignore_bin_init (WebRTCErrorIgnoreBin * bin)
+{
+}
+
+static GstElement *
+webrtc_error_ignore_bin_new (WebRTCDataChannel * data_channel,
+    GstElement * other)
+{
+  WebRTCErrorIgnoreBin *self;
+  GstPad *pad;
+
+  self = g_object_new (webrtc_error_ignore_bin_get_type (), NULL);
+  self->data_channel = data_channel;
+
+  gst_bin_add (GST_BIN (self), other);
+
+  pad = gst_element_get_static_pad (other, "src");
+  if (pad) {
+    GstPad *ghost_pad = gst_ghost_pad_new ("src", pad);
+    gst_element_add_pad (GST_ELEMENT (self), ghost_pad);
+    gst_clear_object (&pad);
+  }
+  pad = gst_element_get_static_pad (other, "sink");
+  if (pad) {
+    GstPad *ghost_pad = gst_ghost_pad_new ("sink", pad);
+    gst_element_add_pad (GST_ELEMENT (self), ghost_pad);
+    gst_clear_object (&pad);
+  }
+
+  return (GstElement *) self;
+}
+
 #define webrtc_data_channel_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (WebRTCDataChannel, webrtc_data_channel,
     GST_TYPE_WEBRTC_DATA_CHANNEL,
@@ -213,67 +348,6 @@ construct_ack_packet (WebRTCDataChannel * channel)
   return buf;
 }
 
-typedef void (*ChannelTask) (GstWebRTCDataChannel * channel,
-    gpointer user_data);
-
-struct task
-{
-  GstWebRTCDataChannel *channel;
-  ChannelTask func;
-  gpointer user_data;
-  GDestroyNotify notify;
-};
-
-static GstStructure *
-_execute_task (GstWebRTCBin * webrtc, struct task *task)
-{
-  if (task->func)
-    task->func (task->channel, task->user_data);
-
-  return NULL;
-}
-
-static void
-_free_task (struct task *task)
-{
-  gst_object_unref (task->channel);
-
-  if (task->notify)
-    task->notify (task->user_data);
-  g_free (task);
-}
-
-static void
-_channel_enqueue_task (WebRTCDataChannel * channel, ChannelTask func,
-    gpointer user_data, GDestroyNotify notify)
-{
-  struct task *task = g_new0 (struct task, 1);
-
-  task->channel = gst_object_ref (channel);
-  task->func = func;
-  task->user_data = user_data;
-  task->notify = notify;
-
-  gst_webrtc_bin_enqueue_task (channel->webrtcbin,
-      (GstWebRTCBinFunc) _execute_task, task, (GDestroyNotify) _free_task,
-      NULL);
-}
-
-static void
-_channel_store_error (WebRTCDataChannel * channel, GError * error)
-{
-  GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
-  if (error) {
-    GST_WARNING_OBJECT (channel, "Error: %s",
-        error ? error->message : "Unknown");
-    if (!channel->stored_error)
-      channel->stored_error = error;
-    else
-      g_clear_error (&error);
-  }
-  GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
-}
-
 static void
 _emit_on_open (WebRTCDataChannel * channel, gpointer user_data)
 {
@@ -290,6 +364,10 @@ _transport_closed (WebRTCDataChannel * channel)
   error = channel->stored_error;
   channel->stored_error = NULL;
 
+  GST_TRACE_OBJECT (channel, "transport closed, peer closed %u error %p "
+      "buffered %" G_GUINT64_FORMAT, channel->peer_closed, error,
+      channel->parent.buffered_amount);
+
   both_sides_closed =
       channel->peer_closed && channel->parent.buffered_amount <= 0;
   if (both_sides_closed || error) {
@@ -314,7 +392,7 @@ _close_sctp_stream (WebRTCDataChannel * channel, gpointer user_data)
   GST_INFO_OBJECT (channel, "Closing outgoing SCTP stream %i label \"%s\"",
       channel->parent.id, channel->parent.label);
 
-  pad = gst_element_get_static_pad (channel->appsrc, "src");
+  pad = gst_element_get_static_pad (channel->src_bin, "src");
   peer = gst_pad_get_peer (pad);
   gst_object_unref (pad);
 
@@ -322,6 +400,7 @@ _close_sctp_stream (WebRTCDataChannel * channel, gpointer user_data)
     GstElement *sctpenc = gst_pad_get_parent_element (peer);
 
     if (sctpenc) {
+      GST_TRACE_OBJECT (channel, "removing sctpenc pad %" GST_PTR_FORMAT, peer);
       gst_element_release_request_pad (sctpenc, peer);
       gst_object_unref (sctpenc);
     }
@@ -484,6 +563,8 @@ _parse_control_packet (WebRTCDataChannel * channel, guint8 * data,
     if (ret != GST_FLOW_OK) {
       g_set_error (error, GST_WEBRTC_ERROR,
           GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "Could not send ack packet");
+      GST_WARNING_OBJECT (channel, "push returned %i, %s", ret,
+          gst_flow_get_name (ret));
       return ret;
     }
 
@@ -800,6 +881,8 @@ webrtc_data_channel_send_data (GstWebRTCDataChannel * base_channel,
   } else {
     g_set_error (error, GST_WEBRTC_ERROR,
         GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "Failed to send data");
+    GST_WARNING_OBJECT (channel, "push returned %i, %s", ret,
+        gst_flow_get_name (ret));
 
     GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
     channel->parent.buffered_amount -= size;
@@ -1001,6 +1084,8 @@ gst_webrtc_data_channel_constructed (GObject * object)
   channel->src_probe = gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_DATA_BOTH,
       (GstPadProbeCallback) on_appsrc_data, channel, NULL);
 
+  channel->src_bin = webrtc_error_ignore_bin_new (channel, channel->appsrc);
+
   channel->appsink = gst_element_factory_make ("appsink", NULL);
   gst_object_ref_sink (channel->appsink);
   g_object_set (channel->appsink, "sync", FALSE, "async", FALSE, "caps", caps,
@@ -1008,6 +1093,8 @@ gst_webrtc_data_channel_constructed (GObject * object)
   gst_app_sink_set_callbacks (GST_APP_SINK (channel->appsink), &sink_callbacks,
       channel, NULL);
 
+  channel->sink_bin = webrtc_error_ignore_bin_new (channel, channel->appsink);
+
   gst_object_unref (pad);
   gst_caps_unref (caps);
 }
@@ -1078,7 +1165,7 @@ _data_channel_set_sctp_transport (WebRTCDataChannel * channel,
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
   if (channel->sctp_transport)
     g_signal_handlers_disconnect_by_data (channel->sctp_transport, channel);
-  GST_TRACE ("%p set sctp %p", channel, sctp);
+  GST_TRACE_OBJECT (channel, "set sctp %p", sctp);
 
   gst_object_replace ((GstObject **) & channel->sctp_transport,
       GST_OBJECT (sctp));
@@ -1106,7 +1193,7 @@ webrtc_data_channel_link_to_sctp (WebRTCDataChannel * channel,
 
       _data_channel_set_sctp_transport (channel, sctp_transport);
       pad_name = g_strdup_printf ("sink_%u", id);
-      if (!gst_element_link_pads (channel->appsrc, "src",
+      if (!gst_element_link_pads (channel->src_bin, "src",
               channel->sctp_transport->sctpenc, pad_name))
         g_warn_if_reached ();
       g_free (pad_name);
diff --git a/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.h b/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.h
index a0b38a7ad2..dd65a66ae3 100644
--- a/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.h
+++ b/subprojects/gst-plugins-bad/ext/webrtc/webrtcdatachannel.h
@@ -46,7 +46,9 @@ struct _WebRTCDataChannel
   GstWebRTCDataChannel              parent;
 
   WebRTCSCTPTransport              *sctp_transport;
+  GstElement                       *src_bin;
   GstElement                       *appsrc;
+  GstElement                       *sink_bin;
   GstElement                       *appsink;
 
   GstWebRTCBin                     *webrtcbin;
@@ -70,6 +72,8 @@ G_GNUC_INTERNAL
 void    webrtc_data_channel_link_to_sctp (WebRTCDataChannel                 *channel,
                                           WebRTCSCTPTransport               *sctp_transport);
 
+G_DECLARE_FINAL_TYPE (WebRTCErrorIgnoreBin, webrtc_error_ignore_bin, WEBRTC, ERROR_IGNORE_BIN, GstBin);
+
 G_END_DECLS
 
 #endif /* __WEBRTC_DATA_CHANNEL_H__ */
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gstav1parser.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gstav1parser.c
index e2876db01f..3e80380976 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gstav1parser.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gstav1parser.c
@@ -799,8 +799,7 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
 
     if (obu_length == 0) {
       /* An empty obu? let continue to the next */
-      ret = GST_AV1_PARSER_DROP;
-      goto error;
+      return GST_AV1_PARSER_DROP;
     }
   }
 
@@ -881,8 +880,7 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
         (parser->state.operating_point_idc >> (obu->header.obu_spatial_id +
             8)) & 1;
     if (!inTemporalLayer || !inSpatialLayer) {
-      ret = GST_AV1_PARSER_DROP;
-      goto error;
+      return GST_AV1_PARSER_DROP;
     }
   }
 
@@ -1449,9 +1447,7 @@ gst_av1_parser_parse_sequence_header_obu (GstAV1Parser * parser,
   gst_av1_parse_reset_state (parser, FALSE);
 
   /* choose_operating_point() set the operating_point */
-  if (parser->state.operating_point < 0 ||
-      parser->state.operating_point >
-      seq_header->operating_points_cnt_minus_1) {
+  if (parser->state.operating_point > seq_header->operating_points_cnt_minus_1) {
     GST_WARNING ("Invalid operating_point %d set by user, just use 0",
         parser->state.operating_point);
     parser->state.operating_point_idc = seq_header->operating_points[0].idc;
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c
index 25427adc0d..349d6d23b3 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c
@@ -795,7 +795,7 @@ gst_h264_slice_parse_pred_weight_table (GstH264SliceHdr * slice,
       p->chroma_weight_l0[i][1] = default_chroma_weight;
     }
     if (GST_H264_IS_B_SLICE (slice)) {
-      for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++) {
+      for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++) {
         p->chroma_weight_l1[i][0] = default_chroma_weight;
         p->chroma_weight_l1[i][1] = default_chroma_weight;
       }
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1decoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1decoder.c
index 7208821dfd..019437e7d8 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1decoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1decoder.c
@@ -48,6 +48,8 @@ struct _GstAV1DecoderPrivate
   guint preferred_output_delay;
   GstQueueArray *output_queue;
   gboolean is_live;
+
+  gboolean input_state_changed;
 };
 
 typedef struct
@@ -83,6 +85,7 @@ static gboolean gst_av1_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_av1_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_av1_decoder_set_format (GstVideoDecoder * decoder,
     GstVideoCodecState * state);
+static gboolean gst_av1_decoder_negotiate (GstVideoDecoder * decoder);
 static GstFlowReturn gst_av1_decoder_finish (GstVideoDecoder * decoder);
 static gboolean gst_av1_decoder_flush (GstVideoDecoder * decoder);
 static GstFlowReturn gst_av1_decoder_drain (GstVideoDecoder * decoder);
@@ -102,6 +105,7 @@ gst_av1_decoder_class_init (GstAV1DecoderClass * klass)
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_av1_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_av1_decoder_stop);
   decoder_class->set_format = GST_DEBUG_FUNCPTR (gst_av1_decoder_set_format);
+  decoder_class->negotiate = GST_DEBUG_FUNCPTR (gst_av1_decoder_negotiate);
   decoder_class->finish = GST_DEBUG_FUNCPTR (gst_av1_decoder_finish);
   decoder_class->flush = GST_DEBUG_FUNCPTR (gst_av1_decoder_flush);
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_av1_decoder_drain);
@@ -210,6 +214,8 @@ gst_av1_decoder_set_format (GstVideoDecoder * decoder,
 
   GST_DEBUG_OBJECT (decoder, "Set format");
 
+  priv->input_state_changed = TRUE;
+
   if (self->input_state)
     gst_video_codec_state_unref (self->input_state);
 
@@ -227,6 +233,17 @@ gst_av1_decoder_set_format (GstVideoDecoder * decoder,
   return TRUE;
 }
 
+static gboolean
+gst_av1_decoder_negotiate (GstVideoDecoder * decoder)
+{
+  GstAV1Decoder *self = GST_AV1_DECODER (decoder);
+
+  /* output state must be updated by subclass using new input state already */
+  self->priv->input_state_changed = FALSE;
+
+  return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
+}
+
 static void
 gst_av1_decoder_drain_output_queue (GstAV1Decoder * self,
     guint num, GstFlowReturn * ret)
@@ -386,6 +403,8 @@ gst_av1_decoder_process_sequence (GstAV1Decoder * self, GstAV1OBU * obu)
         _floor_log2 (priv->parser->state.operating_point_idc >> 8);
     GST_INFO_OBJECT (self, "set highest spatial layer to %d",
         self->highest_spatial_layer);
+  } else {
+    self->highest_spatial_layer = 0;
   }
 
   ret = klass->new_sequence (self, &seq_header,
@@ -676,6 +695,11 @@ gst_av1_decoder_handle_frame (GstVideoDecoder * decoder,
   while (total_consumed < map.size) {
     res = gst_av1_parser_identify_one_obu (priv->parser,
         map.data + total_consumed, map.size, &obu, &consumed);
+    if (res == GST_AV1_PARSER_DROP) {
+      total_consumed += consumed;
+      continue;
+    }
+
     if (res != GST_AV1_PARSER_OK) {
       ret = GST_FLOW_ERROR;
       goto out;
@@ -695,11 +719,11 @@ gst_av1_decoder_handle_frame (GstVideoDecoder * decoder,
     goto out;
   }
 
-  if (priv->current_picture->temporal_id > self->highest_spatial_layer) {
+  if (priv->current_picture->spatial_id > self->highest_spatial_layer) {
     ret = GST_FLOW_ERROR;
     GST_VIDEO_DECODER_ERROR (self, 1, STREAM, DECODE,
-        ("current picture temporal_id %d should not be higher than "
-            "highest spatial layer %d", priv->current_picture->temporal_id,
+        ("current picture spatial_id %d should not be higher than "
+            "highest spatial layer %d", priv->current_picture->spatial_id,
             self->highest_spatial_layer), (NULL), ret);
     goto out;
   }
@@ -731,6 +755,14 @@ out:
       } else {
         GstAV1DecoderOutputFrame output_frame;
 
+        /* If subclass didn't update output state at this point,
+         * marking this picture as a discont and stores current input state */
+        if (priv->input_state_changed) {
+          priv->current_picture->discont_state =
+              gst_video_codec_state_ref (self->input_state);
+          priv->input_state_changed = FALSE;
+        }
+
         output_frame.frame = frame;
         output_frame.picture = priv->current_picture;
         output_frame.self = self;
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.c
index 733522feec..10ea59449c 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.c
@@ -36,6 +36,9 @@ _gst_av1_picture_free (GstAV1Picture * picture)
   if (picture->notify)
     picture->notify (picture->user_data);
 
+  if (picture->discont_state)
+    gst_video_codec_state_unref (picture->discont_state);
+
   g_free (picture);
 }
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.h b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.h
index f0d8a706d0..25ae05908c 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstav1picture.h
@@ -22,6 +22,7 @@
 
 #include <gst/codecs/codecs-prelude.h>
 #include <gst/codecparsers/gstav1parser.h>
+#include <gst/video/video.h>
 
 G_BEGIN_DECLS
 
@@ -84,6 +85,9 @@ struct _GstAV1Picture
   gboolean showable_frame;
   gboolean apply_grain;
 
+  /* decoder input state if this picture is discont point */
+  GstVideoCodecState *discont_state;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264decoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264decoder.c
index 7afe50b908..d62cdca299 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264decoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264decoder.c
@@ -150,6 +150,8 @@ struct _GstH264DecoderPrivate
 
   /* For delayed output */
   GstQueueArray *output_queue;
+
+  gboolean input_state_changed;
 };
 
 typedef struct
@@ -179,6 +181,7 @@ static gboolean gst_h264_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_h264_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_h264_decoder_set_format (GstVideoDecoder * decoder,
     GstVideoCodecState * state);
+static gboolean gst_h264_decoder_negotiate (GstVideoDecoder * decoder);
 static GstFlowReturn gst_h264_decoder_finish (GstVideoDecoder * decoder);
 static gboolean gst_h264_decoder_flush (GstVideoDecoder * decoder);
 static GstFlowReturn gst_h264_decoder_drain (GstVideoDecoder * decoder);
@@ -307,6 +310,7 @@ gst_h264_decoder_class_init (GstH264DecoderClass * klass)
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_h264_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_h264_decoder_stop);
   decoder_class->set_format = GST_DEBUG_FUNCPTR (gst_h264_decoder_set_format);
+  decoder_class->negotiate = GST_DEBUG_FUNCPTR (gst_h264_decoder_negotiate);
   decoder_class->finish = GST_DEBUG_FUNCPTR (gst_h264_decoder_finish);
   decoder_class->flush = GST_DEBUG_FUNCPTR (gst_h264_decoder_flush);
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_h264_decoder_drain);
@@ -1023,6 +1027,14 @@ gst_h264_decoder_start_current_picture (GstH264Decoder * self)
   g_assert (priv->active_sps != NULL);
   g_assert (priv->active_pps != NULL);
 
+  /* If subclass didn't update output state at this point,
+   * marking this picture as a discont and stores current input state */
+  if (priv->input_state_changed) {
+    priv->current_picture->discont_state =
+        gst_video_codec_state_ref (self->input_state);
+    priv->input_state_changed = FALSE;
+  }
+
   sps = priv->active_sps;
 
   priv->max_frame_num = sps->max_frame_num;
@@ -1369,6 +1381,8 @@ gst_h264_decoder_set_format (GstVideoDecoder * decoder,
 
   GST_DEBUG_OBJECT (decoder, "Set format");
 
+  priv->input_state_changed = TRUE;
+
   if (self->input_state)
     gst_video_codec_state_unref (self->input_state);
 
@@ -1441,6 +1455,17 @@ gst_h264_decoder_set_format (GstVideoDecoder * decoder,
   return TRUE;
 }
 
+static gboolean
+gst_h264_decoder_negotiate (GstVideoDecoder * decoder)
+{
+  GstH264Decoder *self = GST_H264_DECODER (decoder);
+
+  /* output state must be updated by subclass using new input state already */
+  self->priv->input_state_changed = FALSE;
+
+  return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
+}
+
 static gboolean
 gst_h264_decoder_fill_picture_from_slice (GstH264Decoder * self,
     const GstH264Slice * slice, GstH264Picture * picture)
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.c
index abb4bfb202..f3ba1ba672 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.c
@@ -35,6 +35,9 @@ _gst_h264_picture_free (GstH264Picture * picture)
   if (picture->notify)
     picture->notify (picture->user_data);
 
+  if (picture->discont_state)
+    gst_video_codec_state_unref (picture->discont_state);
+
   g_free (picture);
 }
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.h b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.h
index 3893381fb6..19f865d6c3 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth264picture.h
@@ -161,6 +161,9 @@ struct _GstH264Picture
 
   GstVideoBufferFlags buffer_flags;
 
+  /* decoder input state if this picture is discont point */
+  GstVideoCodecState *discont_state;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265decoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265decoder.c
index 3b7757cafb..31265171f4 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265decoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265decoder.c
@@ -134,6 +134,8 @@ struct _GstH265DecoderPrivate
   guint preferred_output_delay;
   gboolean is_live;
   GstQueueArray *output_queue;
+
+  gboolean input_state_changed;
 };
 
 typedef struct
@@ -173,6 +175,7 @@ static gboolean gst_h265_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_h265_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_h265_decoder_set_format (GstVideoDecoder * decoder,
     GstVideoCodecState * state);
+static gboolean gst_h265_decoder_negotiate (GstVideoDecoder * decoder);
 static GstFlowReturn gst_h265_decoder_finish (GstVideoDecoder * decoder);
 static gboolean gst_h265_decoder_flush (GstVideoDecoder * decoder);
 static GstFlowReturn gst_h265_decoder_drain (GstVideoDecoder * decoder);
@@ -201,6 +204,7 @@ gst_h265_decoder_class_init (GstH265DecoderClass * klass)
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_h265_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_h265_decoder_stop);
   decoder_class->set_format = GST_DEBUG_FUNCPTR (gst_h265_decoder_set_format);
+  decoder_class->negotiate = GST_DEBUG_FUNCPTR (gst_h265_decoder_negotiate);
   decoder_class->finish = GST_DEBUG_FUNCPTR (gst_h265_decoder_finish);
   decoder_class->flush = GST_DEBUG_FUNCPTR (gst_h265_decoder_flush);
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_h265_decoder_drain);
@@ -1083,6 +1087,8 @@ gst_h265_decoder_set_format (GstVideoDecoder * decoder,
 
   GST_DEBUG_OBJECT (decoder, "Set format");
 
+  priv->input_state_changed = TRUE;
+
   if (self->input_state)
     gst_video_codec_state_unref (self->input_state);
 
@@ -1151,6 +1157,17 @@ gst_h265_decoder_set_format (GstVideoDecoder * decoder,
   return TRUE;
 }
 
+static gboolean
+gst_h265_decoder_negotiate (GstVideoDecoder * decoder)
+{
+  GstH265Decoder *self = GST_H265_DECODER (decoder);
+
+  /* output state must be updated by subclass using new input state already */
+  self->priv->input_state_changed = FALSE;
+
+  return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
+}
+
 static gboolean
 gst_h265_decoder_flush (GstVideoDecoder * decoder)
 {
@@ -1785,6 +1802,14 @@ gst_h265_decoder_start_current_picture (GstH265Decoder * self)
     return GST_FLOW_OK;
   }
 
+  /* If subclass didn't update output state at this point,
+   * marking this picture as a discont and stores current input state */
+  if (priv->input_state_changed) {
+    priv->current_picture->discont_state =
+        gst_video_codec_state_ref (self->input_state);
+    priv->input_state_changed = FALSE;
+  }
+
   gst_h265_decoder_prepare_rps (self, &priv->current_slice,
       priv->current_picture);
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.c
index 995e4f93a2..dc0aa61207 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.c
@@ -34,6 +34,9 @@ _gst_h265_picture_free (GstH265Picture * picture)
   if (picture->notify)
     picture->notify (picture->user_data);
 
+  if (picture->discont_state)
+    gst_video_codec_state_unref (picture->discont_state);
+
   g_free (picture);
 }
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.h b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.h
index a96a1629c9..ac2e3fd58a 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gsth265picture.h
@@ -90,6 +90,9 @@ struct _GstH265Picture
 
   GstVideoBufferFlags buffer_flags;
 
+  /* decoder input state if this picture is discont point */
+  GstVideoCodecState *discont_state;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2decoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2decoder.c
index 988eb7cc36..7a45be6b91 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2decoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2decoder.c
@@ -267,6 +267,8 @@ struct _GstMpeg2DecoderPrivate
   GstQueueArray *output_queue;
   /* used for low-latency vs. high throughput mode decision */
   gboolean is_live;
+
+  gboolean input_state_changed;
 };
 
 #define UPDATE_FLOW_RETURN(ret,new_ret) G_STMT_START { \
@@ -293,6 +295,7 @@ static gboolean gst_mpeg2_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_mpeg2_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_mpeg2_decoder_set_format (GstVideoDecoder * decoder,
     GstVideoCodecState * state);
+static gboolean gst_mpeg2_decoder_negotiate (GstVideoDecoder * decoder);
 static GstFlowReturn gst_mpeg2_decoder_finish (GstVideoDecoder * decoder);
 static gboolean gst_mpeg2_decoder_flush (GstVideoDecoder * decoder);
 static GstFlowReturn gst_mpeg2_decoder_drain (GstVideoDecoder * decoder);
@@ -314,6 +317,7 @@ gst_mpeg2_decoder_class_init (GstMpeg2DecoderClass * klass)
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_stop);
   decoder_class->set_format = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_set_format);
+  decoder_class->negotiate = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_negotiate);
   decoder_class->finish = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_finish);
   decoder_class->flush = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_flush);
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_mpeg2_decoder_drain);
@@ -379,6 +383,8 @@ gst_mpeg2_decoder_set_format (GstVideoDecoder * decoder,
 
   GST_DEBUG_OBJECT (decoder, "Set format");
 
+  priv->input_state_changed = TRUE;
+
   if (self->input_state)
     gst_video_codec_state_unref (self->input_state);
 
@@ -395,6 +401,17 @@ gst_mpeg2_decoder_set_format (GstVideoDecoder * decoder,
   return TRUE;
 }
 
+static gboolean
+gst_mpeg2_decoder_negotiate (GstVideoDecoder * decoder)
+{
+  GstMpeg2Decoder *self = GST_MPEG2_DECODER (decoder);
+
+  /* output state must be updated by subclass using new input state already */
+  self->priv->input_state_changed = FALSE;
+
+  return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
+}
+
 static GstFlowReturn
 gst_mpeg2_decoder_drain (GstVideoDecoder * decoder)
 {
@@ -817,6 +834,14 @@ gst_mpeg2_decoder_start_current_picture (GstMpeg2Decoder * decoder,
   GstMpeg2Picture *prev_picture, *next_picture;
   GstFlowReturn ret;
 
+  /* If subclass didn't update output state at this point,
+   * marking this picture as a discont and stores current input state */
+  if (priv->input_state_changed) {
+    priv->current_picture->discont_state =
+        gst_video_codec_state_ref (decoder->input_state);
+    priv->input_state_changed = FALSE;
+  }
+
   if (!klass->start_picture)
     return GST_FLOW_OK;
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.c
index 7a72cab8e3..fd87ab39f1 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.c
@@ -40,6 +40,9 @@ _gst_mpeg2_picture_free (GstMpeg2Picture * picture)
   if (picture->notify)
     picture->notify (picture->user_data);
 
+  if (picture->discont_state)
+    gst_video_codec_state_unref (picture->discont_state);
+
   g_free (picture);
 }
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.h b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.h
index bd5ac3794e..c9614895b3 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstmpeg2picture.h
@@ -94,6 +94,9 @@ struct _GstMpeg2Picture
   GstMpegVideoPictureStructure structure;
   GstMpegVideoPictureType type;
 
+  /* decoder input state if this picture is discont point */
+  GstVideoCodecState *discont_state;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8decoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8decoder.c
index 9afb8d833c..97d72fa03d 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8decoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8decoder.c
@@ -47,6 +47,8 @@ struct _GstVp8DecoderPrivate
   /* for delayed output */
   GstQueueArray *output_queue;
   gboolean is_live;
+
+  gboolean input_state_changed;
 };
 
 typedef struct
@@ -67,6 +69,7 @@ static gboolean gst_vp8_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_vp8_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_vp8_decoder_set_format (GstVideoDecoder * decoder,
     GstVideoCodecState * state);
+static gboolean gst_vp8_decoder_negotiate (GstVideoDecoder * decoder);
 static GstFlowReturn gst_vp8_decoder_finish (GstVideoDecoder * decoder);
 static gboolean gst_vp8_decoder_flush (GstVideoDecoder * decoder);
 static GstFlowReturn gst_vp8_decoder_drain (GstVideoDecoder * decoder);
@@ -87,6 +90,7 @@ gst_vp8_decoder_class_init (GstVp8DecoderClass * klass)
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_vp8_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_vp8_decoder_stop);
   decoder_class->set_format = GST_DEBUG_FUNCPTR (gst_vp8_decoder_set_format);
+  decoder_class->negotiate = GST_DEBUG_FUNCPTR (gst_vp8_decoder_negotiate);
   decoder_class->finish = GST_DEBUG_FUNCPTR (gst_vp8_decoder_finish);
   decoder_class->flush = GST_DEBUG_FUNCPTR (gst_vp8_decoder_flush);
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_vp8_decoder_drain);
@@ -205,6 +209,8 @@ gst_vp8_decoder_set_format (GstVideoDecoder * decoder,
 
   GST_DEBUG_OBJECT (decoder, "Set format");
 
+  priv->input_state_changed = TRUE;
+
   if (self->input_state)
     gst_video_codec_state_unref (self->input_state);
 
@@ -221,6 +227,17 @@ gst_vp8_decoder_set_format (GstVideoDecoder * decoder,
   return TRUE;
 }
 
+static gboolean
+gst_vp8_decoder_negotiate (GstVideoDecoder * decoder)
+{
+  GstVp8Decoder *self = GST_VP8_DECODER (decoder);
+
+  /* output state must be updated by subclass using new input state already */
+  self->priv->input_state_changed = FALSE;
+
+  return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
+}
+
 static gboolean
 gst_vp8_decoder_update_reference (GstVp8Decoder * self, GstVp8Picture * picture)
 {
@@ -452,6 +469,13 @@ gst_vp8_decoder_handle_frame (GstVideoDecoder * decoder,
 
     ret = gst_video_decoder_finish_frame (GST_VIDEO_DECODER (self), frame);
   } else {
+    /* If subclass didn't update output state at this point,
+     * marking this picture as a discont and stores current input state */
+    if (priv->input_state_changed) {
+      picture->discont_state = gst_video_codec_state_ref (self->input_state);
+      priv->input_state_changed = FALSE;
+    }
+
     output_frame.frame = frame;
     output_frame.picture = picture;
     output_frame.self = self;
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.c
index b40e207c2e..4a56605ef3 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.c
@@ -36,6 +36,9 @@ _gst_vp8_picture_free (GstVp8Picture * picture)
   if (picture->notify)
     picture->notify (picture->user_data);
 
+  if (picture->discont_state)
+    gst_video_codec_state_unref (picture->discont_state);
+
   g_free (picture);
 }
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.h b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.h
index abfc07adb9..9fc3f65f53 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp8picture.h
@@ -22,6 +22,7 @@
 
 #include <gst/codecs/codecs-prelude.h>
 #include <gst/codecparsers/gstvp8parser.h>
+#include <gst/video/video.h>
 
 G_BEGIN_DECLS
 
@@ -34,6 +35,7 @@ typedef struct _GstVp8Picture GstVp8Picture;
 
 struct _GstVp8Picture
 {
+  /*< private >*/
   GstMiniObject parent;
 
   GstClockTime pts;
@@ -46,6 +48,9 @@ struct _GstVp8Picture
   const guint8 * data;
   gsize size;
 
+  /* decoder input state if this picture is discont point */
+  GstVideoCodecState *discont_state;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9decoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9decoder.c
index f5ad4d2e06..1740e75595 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9decoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9decoder.c
@@ -84,6 +84,8 @@ struct _GstVp9DecoderPrivate
   guint preferred_output_delay;
   GstQueueArray *output_queue;
   gboolean is_live;
+
+  gboolean input_state_changed;
 };
 
 typedef struct
@@ -104,6 +106,7 @@ static gboolean gst_vp9_decoder_start (GstVideoDecoder * decoder);
 static gboolean gst_vp9_decoder_stop (GstVideoDecoder * decoder);
 static gboolean gst_vp9_decoder_set_format (GstVideoDecoder * decoder,
     GstVideoCodecState * state);
+static gboolean gst_vp9_decoder_negotiate (GstVideoDecoder * decoder);
 static GstFlowReturn gst_vp9_decoder_finish (GstVideoDecoder * decoder);
 static gboolean gst_vp9_decoder_flush (GstVideoDecoder * decoder);
 static GstFlowReturn gst_vp9_decoder_drain (GstVideoDecoder * decoder);
@@ -125,6 +128,7 @@ gst_vp9_decoder_class_init (GstVp9DecoderClass * klass)
   decoder_class->start = GST_DEBUG_FUNCPTR (gst_vp9_decoder_start);
   decoder_class->stop = GST_DEBUG_FUNCPTR (gst_vp9_decoder_stop);
   decoder_class->set_format = GST_DEBUG_FUNCPTR (gst_vp9_decoder_set_format);
+  decoder_class->negotiate = GST_DEBUG_FUNCPTR (gst_vp9_decoder_negotiate);
   decoder_class->finish = GST_DEBUG_FUNCPTR (gst_vp9_decoder_finish);
   decoder_class->flush = GST_DEBUG_FUNCPTR (gst_vp9_decoder_flush);
   decoder_class->drain = GST_DEBUG_FUNCPTR (gst_vp9_decoder_drain);
@@ -264,6 +268,8 @@ gst_vp9_decoder_set_format (GstVideoDecoder * decoder,
 
   GST_DEBUG_OBJECT (decoder, "Set format");
 
+  priv->input_state_changed = TRUE;
+
   if (self->input_state)
     gst_video_codec_state_unref (self->input_state);
 
@@ -277,6 +283,17 @@ gst_vp9_decoder_set_format (GstVideoDecoder * decoder,
   return TRUE;
 }
 
+static gboolean
+gst_vp9_decoder_negotiate (GstVideoDecoder * decoder)
+{
+  GstVp9Decoder *self = GST_VP9_DECODER (decoder);
+
+  /* output state must be updated by subclass using new input state already */
+  self->priv->input_state_changed = FALSE;
+
+  return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
+}
+
 static void
 gst_vp9_decoder_reset (GstVp9Decoder * self)
 {
@@ -529,6 +546,13 @@ gst_vp9_decoder_handle_frame (GstVideoDecoder * decoder,
 
     ret = gst_video_decoder_finish_frame (GST_VIDEO_DECODER (self), frame);
   } else {
+    /* If subclass didn't update output state at this point,
+     * marking this picture as a discont and stores current input state */
+    if (priv->input_state_changed) {
+      picture->discont_state = gst_video_codec_state_ref (self->input_state);
+      priv->input_state_changed = FALSE;
+    }
+
     output_frame.frame = frame;
     output_frame.picture = picture;
     output_frame.self = self;
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.c
index 64b5a18b67..e3e09c33f7 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.c
@@ -36,6 +36,9 @@ _gst_vp9_picture_free (GstVp9Picture * picture)
   if (picture->notify)
     picture->notify (picture->user_data);
 
+  if (picture->discont_state)
+    gst_video_codec_state_unref (picture->discont_state);
+
   g_free (picture);
 }
 
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.h b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.h
index 6caf18bd2b..4c60491872 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecs/gstvp9picture.h
@@ -22,6 +22,7 @@
 
 #include <gst/codecs/codecs-prelude.h>
 #include <gst/codecs/gstvp9statefulparser.h>
+#include <gst/video/video.h>
 
 G_BEGIN_DECLS
 
@@ -46,6 +47,9 @@ struct _GstVp9Picture
   const guint8 * data;
   gsize size;
 
+  /* decoder input state if this picture is discont point */
+  GstVideoCodecState *discont_state;
+
   gpointer user_data;
   GDestroyNotify notify;
 };
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudacontext.c b/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudacontext.c
index 9b721736ca..05bfb7b102 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudacontext.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudacontext.c
@@ -554,6 +554,7 @@ gst_cuda_context_new_wrapped (CUcontext handler, CUdevice device)
   self = g_object_new (GST_TYPE_CUDA_CONTEXT, "cuda-device-id", device, NULL);
   self->priv->context = handler;
   self->priv->device = device;
+  self->priv->tex_align = tex_align;
   gst_object_ref_sink (self);
 
 #ifdef GST_CUDA_HAS_D3D
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudamemory.c b/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudamemory.c
index 78188275e9..50ff67bfa5 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudamemory.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/cuda/gstcudamemory.c
@@ -168,6 +168,9 @@ gst_cuda_allocator_alloc_internal (GstCudaAllocator * self,
       break;
     case GST_VIDEO_FORMAT_Y444:
     case GST_VIDEO_FORMAT_Y444_16LE:
+    case GST_VIDEO_FORMAT_RGBP:
+    case GST_VIDEO_FORMAT_BGRP:
+    case GST_VIDEO_FORMAT_GBR:
       alloc_info->stride[0] = pitch;
       alloc_info->stride[1] = pitch;
       alloc_info->stride[2] = pitch;
@@ -175,6 +178,16 @@ gst_cuda_allocator_alloc_internal (GstCudaAllocator * self,
       alloc_info->offset[1] = alloc_info->stride[0] * height;
       alloc_info->offset[2] = alloc_info->offset[1] * 2;
       break;
+    case GST_VIDEO_FORMAT_GBRA:
+      alloc_info->stride[0] = pitch;
+      alloc_info->stride[1] = pitch;
+      alloc_info->stride[2] = pitch;
+      alloc_info->stride[3] = pitch;
+      alloc_info->offset[0] = 0;
+      alloc_info->offset[1] = alloc_info->stride[0] * height;
+      alloc_info->offset[2] = alloc_info->offset[1] * 2;
+      alloc_info->offset[3] = alloc_info->offset[1] * 3;
+      break;
     case GST_VIDEO_FORMAT_BGRA:
     case GST_VIDEO_FORMAT_RGBA:
     case GST_VIDEO_FORMAT_RGBx:
@@ -516,8 +529,14 @@ gst_cuda_allocator_alloc (GstCudaAllocator * allocator,
     case GST_VIDEO_FORMAT_I422_12LE:
     case GST_VIDEO_FORMAT_Y444:
     case GST_VIDEO_FORMAT_Y444_16LE:
+    case GST_VIDEO_FORMAT_RGBP:
+    case GST_VIDEO_FORMAT_BGRP:
+    case GST_VIDEO_FORMAT_GBR:
       alloc_height *= 3;
       break;
+    case GST_VIDEO_FORMAT_GBRA:
+      alloc_height *= 4;
+      break;
     default:
       break;
   }
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11-private.h b/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11-private.h
index 8529e824f3..35182500e9 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11-private.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11-private.h
@@ -33,7 +33,8 @@ G_BEGIN_DECLS
     "RGBA64_LE, RGB10A2_LE, BGRA, RGBA, BGRx, RGBx, VUYA, NV12, NV21, " \
     "P010_10LE, P012_LE, P016_LE, I420, YV12, I420_10LE, I420_12LE, " \
     "Y42B, I422_10LE, I422_12LE, Y444, Y444_10LE, Y444_12LE, Y444_16LE, " \
-    "GRAY8, GRAY16_LE, AYUV, AYUV64"
+    "GRAY8, GRAY16_LE, AYUV, AYUV64, RGBP, BGRP, GBR, GBR_10LE, GBR_12LE, " \
+    "GBRA, GBRA_10LE, GBRA_12LE"
 
 #define GST_D3D11_EXTRA_IN_FORMATS \
     "Y410, YUY2"
@@ -86,6 +87,12 @@ void  gst_d3d11_device_dxgi_debug  (GstD3D11Device * device,
     { DXGI_FORMAT_ ##d, DXGI_FORMAT_UNKNOWN, DXGI_FORMAT_UNKNOWN, DXGI_FORMAT_UNKNOWN }, \
     (D3D11_FORMAT_SUPPORT) (D3D11_FORMAT_SUPPORT_RENDER_TARGET | D3D11_FORMAT_SUPPORT_SHADER_SAMPLE) }
 
+#define MAKE_FORMAT_MAP_RGBP(g,d,a) \
+  { GST_VIDEO_FORMAT_ ##g, DXGI_FORMAT_UNKNOWN, \
+    { DXGI_FORMAT_ ##d, DXGI_FORMAT_ ##d, DXGI_FORMAT_ ##d, DXGI_FORMAT_ ##a }, \
+    { DXGI_FORMAT_ ##d, DXGI_FORMAT_ ##d, DXGI_FORMAT_ ##d, DXGI_FORMAT_ ##a }, \
+    (D3D11_FORMAT_SUPPORT) (D3D11_FORMAT_SUPPORT_RENDER_TARGET | D3D11_FORMAT_SUPPORT_SHADER_SAMPLE) }
+
 static const GstD3D11Format _gst_d3d11_default_format_map[] = {
   MAKE_FORMAT_MAP_RGB (BGRA, B8G8R8A8_UNORM),
   MAKE_FORMAT_MAP_RGB (RGBA, R8G8B8A8_UNORM),
@@ -123,6 +130,14 @@ static const GstD3D11Format _gst_d3d11_default_format_map[] = {
       D3D11_FORMAT_SUPPORT_SHADER_SAMPLE),
   MAKE_FORMAT_MAP_YUV_FULL (YUY2, YUY2, R8G8B8A8_UNORM, UNKNOWN, UNKNOWN, UNKNOWN,
       D3D11_FORMAT_SUPPORT_SHADER_SAMPLE),
+  MAKE_FORMAT_MAP_RGBP (RGBP, R8_UNORM, UNKNOWN),
+  MAKE_FORMAT_MAP_RGBP (BGRP, R8_UNORM, UNKNOWN),
+  MAKE_FORMAT_MAP_RGBP (GBR, R8_UNORM, UNKNOWN),
+  MAKE_FORMAT_MAP_RGBP (GBR_10LE, R16_UNORM, UNKNOWN),
+  MAKE_FORMAT_MAP_RGBP (GBR_12LE, R16_UNORM, UNKNOWN),
+  MAKE_FORMAT_MAP_RGBP (GBRA, R8_UNORM, R8_UNORM),
+  MAKE_FORMAT_MAP_RGBP (GBRA_10LE, R16_UNORM, R16_UNORM),
+  MAKE_FORMAT_MAP_RGBP (GBRA_12LE, R16_UNORM, R16_UNORM),
 };
 
 #undef MAKE_FORMAT_MAP_YUV
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11converter.cpp b/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11converter.cpp
index 7bcaf5d985..cb7584dbfb 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11converter.cpp
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11converter.cpp
@@ -140,6 +140,15 @@ static const gchar templ_OUTPUT_THREE_PLANES[] =
     "  float4 Plane_2: SV_TARGET2;\n"
     "};";
 
+static const gchar templ_OUTPUT_FOUR_PLANES[] =
+    "struct PS_OUTPUT\n"
+    "{\n"
+    "  float4 Plane_0: SV_TARGET0;\n"
+    "  float4 Plane_1: SV_TARGET1;\n"
+    "  float4 Plane_2: SV_TARGET2;\n"
+    "  float4 Plane_3: SV_TARGET3;\n"
+    "};";
+
 typedef struct
 {
   const gchar *output_template;
@@ -151,12 +160,14 @@ enum
   OUTPUT_SINGLE_PLANE = 0,
   OUTPUT_TWO_PLANES,
   OUTPUT_THREE_PLANES,
+  OUTPUT_FOUR_PLANES,
 };
 
 static const PSOutputType output_types[] = {
   {templ_OUTPUT_SINGLE_PLANE, 1},
   {templ_OUTPUT_TWO_PLANES, 2},
   {templ_OUTPUT_THREE_PLANES, 3},
+  {templ_OUTPUT_FOUR_PLANES, 4},
 };
 
 /* colorspace conversion */
@@ -266,12 +277,23 @@ static const gchar templ_SAMPLE_PLANAR[] =
     "float4 sample_texture (float2 uv)\n"
     "{\n"
     "  float3 sample;\n"
-    "  sample.x = shaderTexture[0].Sample(samplerState, uv).x;\n"
+    "  sample.%c = shaderTexture[0].Sample(samplerState, uv).x;\n"
     "  sample.%c = shaderTexture[1].Sample(samplerState, uv).x;\n"
     "  sample.%c = shaderTexture[2].Sample(samplerState, uv).x;\n"
     "  return float4 (saturate(sample * %d), 1.0);\n"
     "}";
 
+static const gchar templ_SAMPLE_PLANAR_4[] =
+    "float4 sample_texture (float2 uv)\n"
+    "{\n"
+    "  float4 sample;\n"
+    "  sample.%c = shaderTexture[0].Sample(samplerState, uv).x;\n"
+    "  sample.%c = shaderTexture[1].Sample(samplerState, uv).x;\n"
+    "  sample.%c = shaderTexture[2].Sample(samplerState, uv).x;\n"
+    "  sample.%c = shaderTexture[3].Sample(samplerState, uv).x;\n"
+    "  return saturate(sample * %d);\n"
+    "}";
+
 static const gchar templ_SAMPLE_PLANAR_CHROMA[] =
     "float4 sample_texture (float2 uv)\n"
     "{\n"
@@ -370,24 +392,47 @@ static const gchar templ_OUTPUT_CHROMA_PLANAR_SCALED[] =
     "  return output;\n"
     "}";
 
-static const gchar templ_OUTPUT_Y444[] =
+static const gchar templ_OUTPUT_PLANAR[] =
     "PS_OUTPUT build_output (float4 sample)\n"
     "{\n"
     "  PS_OUTPUT output;\n"
-    "  output.Plane_0 = float4 (sample.x, 0.0, 0.0, 1.0);\n"
-    "  output.Plane_1 = float4 (sample.y, 0.0, 0.0, 1.0);\n"
-    "  output.Plane_2 = float4 (sample.z, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_0 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_1 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_2 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
     "  return output;\n"
     "}";
 
-static const gchar templ_OUTPUT_Y444_SCALED[] =
+static const gchar templ_OUTPUT_PLANAR_SCALED[] =
     "PS_OUTPUT build_output (float4 sample)\n"
     "{\n"
     "  PS_OUTPUT output;\n"
     "  float3 scaled = sample.xyz / %d;\n"
-    "  output.Plane_0 = float4 (scaled.x, 0.0, 0.0, 1.0);\n"
-    "  output.Plane_1 = float4 (scaled.y, 0.0, 0.0, 1.0);\n"
-    "  output.Plane_2 = float4 (scaled.z, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_0 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_1 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_2 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
+    "  return output;\n"
+    "}";
+
+static const gchar templ_OUTPUT_PLANAR_4[] =
+    "PS_OUTPUT build_output (float4 sample)\n"
+    "{\n"
+    "  PS_OUTPUT output;\n"
+    "  output.Plane_0 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_1 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_2 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_3 = float4 (sample.%c, 0.0, 0.0, 1.0);\n"
+    "  return output;\n"
+    "}";
+
+static const gchar templ_OUTPUT_PLANAR_4_SCALED[] =
+    "PS_OUTPUT build_output (float4 sample)\n"
+    "{\n"
+    "  PS_OUTPUT output;\n"
+    "  float4 scaled = sample / %d;\n"
+    "  output.Plane_0 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_1 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_2 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
+    "  output.Plane_3 = float4 (scaled.%c, 0.0, 0.0, 1.0);\n"
     "  return output;\n"
     "}";
 
@@ -634,9 +679,14 @@ struct _GstD3D11ConverterPrivate
   gchar *in_cll_str;
   gchar *out_cll_str;
 
+  /* Fallback buffer and info, for shader */
   GstVideoInfo fallback_info;
   GstBuffer *fallback_inbuf;
 
+  /* Fallback buffer used for processor */
+  GstVideoInfo piv_info;
+  GstBuffer *piv_inbuf;
+
   GstVideoOrientationMethod video_direction;
 
   SRWLOCK prop_lock;
@@ -804,6 +854,7 @@ gst_d3d11_converter_dispose (GObject * object)
     GST_D3D11_CLEAR_COM (priv->ps[i]);
 
   gst_clear_buffer (&priv->fallback_inbuf);
+  gst_clear_buffer (&priv->piv_inbuf);
   gst_clear_object (&self->device);
 
   G_OBJECT_CLASS (parent_class)->dispose (object);
@@ -1089,18 +1140,22 @@ get_packed_yuv_components (GstVideoFormat format, gchar * y, gchar * u,
 }
 
 static void
-get_planar_component (GstVideoFormat format, gchar * u, gchar * v,
-    guint * scale)
+get_planar_component (GstVideoFormat format, gchar * x, gchar * y, gchar * z,
+    gchar * w, guint * scale)
 {
   switch (format) {
     case GST_VIDEO_FORMAT_I420_10LE:
     case GST_VIDEO_FORMAT_I422_10LE:
     case GST_VIDEO_FORMAT_Y444_10LE:
+    case GST_VIDEO_FORMAT_GBR_10LE:
+    case GST_VIDEO_FORMAT_GBRA_10LE:
       *scale = (1 << 6);
       break;
     case GST_VIDEO_FORMAT_I420_12LE:
     case GST_VIDEO_FORMAT_I422_12LE:
     case GST_VIDEO_FORMAT_Y444_12LE:
+    case GST_VIDEO_FORMAT_GBR_12LE:
+    case GST_VIDEO_FORMAT_GBRA_12LE:
       *scale = (1 << 4);
       break;
     default:
@@ -1108,12 +1163,42 @@ get_planar_component (GstVideoFormat format, gchar * u, gchar * v,
       break;
   }
 
-  if (format == GST_VIDEO_FORMAT_YV12) {
-    *u = 'z';
-    *v = 'y';
-  } else {
-    *u = 'y';
-    *v = 'z';
+  switch (format) {
+    case GST_VIDEO_FORMAT_RGBP:
+      *x = 'x';
+      *y = 'y';
+      *z = 'z';
+      break;
+    case GST_VIDEO_FORMAT_BGRP:
+      *x = 'z';
+      *y = 'y';
+      *z = 'x';
+      break;
+    case GST_VIDEO_FORMAT_GBR:
+    case GST_VIDEO_FORMAT_GBR_10LE:
+    case GST_VIDEO_FORMAT_GBR_12LE:
+      *x = 'y';
+      *y = 'z';
+      *z = 'x';
+      break;
+    case GST_VIDEO_FORMAT_GBRA:
+    case GST_VIDEO_FORMAT_GBRA_10LE:
+    case GST_VIDEO_FORMAT_GBRA_12LE:
+      *x = 'y';
+      *y = 'z';
+      *z = 'x';
+      *w = 'w';
+      break;
+    case GST_VIDEO_FORMAT_YV12:
+      *x = 'x';
+      *y = 'z';
+      *z = 'y';
+      break;
+    default:
+      *x = 'x';
+      *y = 'y';
+      *z = 'z';
+      break;
   }
 }
 
@@ -1562,6 +1647,9 @@ gst_d3d11_converter_update_src_rect (GstD3D11Converter * self)
   gint texture_width = priv->input_texture_width;
   gint texture_height = priv->input_texture_height;
 
+  if (!priv->update_src_rect)
+    return TRUE;
+
   priv->update_src_rect = FALSE;
 
   priv->src_rect.left = priv->src_x;
@@ -1709,6 +1797,9 @@ gst_d3d11_converter_update_dest_rect (GstD3D11Converter * self)
   GstD3D11ConverterPrivate *priv = self->priv;
   const GstVideoInfo *out_info = &priv->out_info;
 
+  if (!priv->update_dest_rect)
+    return TRUE;
+
   priv->viewport[0].TopLeftX = priv->dest_x;
   priv->viewport[0].TopLeftY = priv->dest_y;
   priv->viewport[0].Width = priv->dest_width;
@@ -1768,6 +1859,14 @@ gst_d3d11_converter_update_dest_rect (GstD3D11Converter * self)
     case GST_VIDEO_FORMAT_Y444_10LE:
     case GST_VIDEO_FORMAT_Y444_12LE:
     case GST_VIDEO_FORMAT_Y444_16LE:
+    case GST_VIDEO_FORMAT_RGBP:
+    case GST_VIDEO_FORMAT_BGRP:
+    case GST_VIDEO_FORMAT_GBR:
+    case GST_VIDEO_FORMAT_GBR_10LE:
+    case GST_VIDEO_FORMAT_GBR_12LE:
+    case GST_VIDEO_FORMAT_GBRA:
+    case GST_VIDEO_FORMAT_GBRA_10LE:
+    case GST_VIDEO_FORMAT_GBRA_12LE:
       for (guint i = 1; i < GST_VIDEO_INFO_N_PLANES (&priv->out_info); i++)
         priv->viewport[i] = priv->viewport[0];
       break;
@@ -1840,10 +1939,10 @@ gst_d3d11_converter_prepare_output (GstD3D11Converter * self,
     case GST_VIDEO_FORMAT_Y42B:
     case GST_VIDEO_FORMAT_I422_10LE:
     case GST_VIDEO_FORMAT_I422_12LE:{
-      gchar u, v;
+      gchar y, u, v, w;
       guint scale;
 
-      get_planar_component (format, &u, &v, &scale);
+      get_planar_component (format, &y, &u, &v, &w, &scale);
 
       cinfo->ps_output[0] = &output_types[OUTPUT_SINGLE_PLANE];
       cinfo->ps_output[1] = &output_types[OUTPUT_TWO_PLANES];
@@ -1864,18 +1963,44 @@ gst_d3d11_converter_prepare_output (GstD3D11Converter * self,
     case GST_VIDEO_FORMAT_Y444:
     case GST_VIDEO_FORMAT_Y444_10LE:
     case GST_VIDEO_FORMAT_Y444_12LE:
-    case GST_VIDEO_FORMAT_Y444_16LE:{
-      gchar u, v;
+    case GST_VIDEO_FORMAT_Y444_16LE:
+    case GST_VIDEO_FORMAT_RGBP:
+    case GST_VIDEO_FORMAT_BGRP:
+    case GST_VIDEO_FORMAT_GBR:
+    case GST_VIDEO_FORMAT_GBR_10LE:
+    case GST_VIDEO_FORMAT_GBR_12LE:
+    {
+      gchar x, y, z, w;
       guint scale;
 
-      get_planar_component (format, &u, &v, &scale);
+      get_planar_component (format, &x, &y, &z, &w, &scale);
 
       cinfo->ps_output[0] = &output_types[OUTPUT_THREE_PLANES];
       if (info->finfo->depth[0] == 8) {
-        cinfo->build_output_func[0] = g_strdup (templ_OUTPUT_Y444);
+        cinfo->build_output_func[0] = g_strdup_printf (templ_OUTPUT_PLANAR,
+            x, y, z);
       } else {
-        cinfo->build_output_func[0] = g_strdup_printf (templ_OUTPUT_Y444_SCALED,
-            scale);
+        cinfo->build_output_func[0] =
+            g_strdup_printf (templ_OUTPUT_PLANAR_SCALED, scale, x, y, z);
+      }
+      break;
+    }
+    case GST_VIDEO_FORMAT_GBRA:
+    case GST_VIDEO_FORMAT_GBRA_10LE:
+    case GST_VIDEO_FORMAT_GBRA_12LE:
+    {
+      gchar x, y, z, w;
+      guint scale;
+
+      get_planar_component (format, &x, &y, &z, &w, &scale);
+
+      cinfo->ps_output[0] = &output_types[OUTPUT_FOUR_PLANES];
+      if (info->finfo->depth[0] == 8) {
+        cinfo->build_output_func[0] = g_strdup_printf (templ_OUTPUT_PLANAR_4,
+            x, y, z, w);
+      } else {
+        cinfo->build_output_func[0] =
+            g_strdup_printf (templ_OUTPUT_PLANAR_4_SCALED, scale, x, y, z, w);
       }
       break;
     }
@@ -1980,14 +2105,15 @@ gst_d3d11_converter_prepare_sample_texture (GstD3D11Converter * self,
     case GST_VIDEO_FORMAT_Y444:
     case GST_VIDEO_FORMAT_Y444_10LE:
     case GST_VIDEO_FORMAT_Y444_12LE:
-    case GST_VIDEO_FORMAT_Y444_16LE:{
-      gchar u, v;
+    case GST_VIDEO_FORMAT_Y444_16LE:
+    {
+      gchar x, y, z, w;
       guint scale;
 
-      get_planar_component (format, &u, &v, &scale);
+      get_planar_component (format, &x, &y, &z, &w, &scale);
       if (out_rgb) {
         cinfo->sample_texture_func[0] = g_strdup_printf (templ_SAMPLE_PLANAR,
-            u, v, scale);
+            x, y, z, scale);
       } else if (out_gray) {
         cinfo->sample_texture_func[0] =
             g_strdup_printf (templ_SAMPLE_YUV_LUMA_SCALED, scale);
@@ -1996,16 +2122,16 @@ gst_d3d11_converter_prepare_sample_texture (GstD3D11Converter * self,
             cinfo->ps_output[0] == &output_types[OUTPUT_THREE_PLANES]) {
           /* YUV packed or Y444 */
           cinfo->sample_texture_func[0] = g_strdup_printf (templ_SAMPLE_PLANAR,
-              u, v, scale);
+              x, y, z, scale);
         } else {
           if (priv->fast_path) {
             cinfo->sample_texture_func[0] =
                 g_strdup_printf (templ_SAMPLE_YUV_LUMA_SCALED, scale);
             cinfo->sample_texture_func[1] =
-                g_strdup_printf (templ_SAMPLE_PLANAR_CHROMA, u, v, scale);
+                g_strdup_printf (templ_SAMPLE_PLANAR_CHROMA, y, z, scale);
           } else {
             cinfo->sample_texture_func[0] =
-                g_strdup_printf (templ_SAMPLE_PLANAR, u, v, scale);
+                g_strdup_printf (templ_SAMPLE_PLANAR, x, y, z, scale);
             cinfo->sample_texture_func[1] =
                 g_strdup (cinfo->sample_texture_func[0]);
           }
@@ -2015,6 +2141,35 @@ gst_d3d11_converter_prepare_sample_texture (GstD3D11Converter * self,
         return FALSE;
       }
       break;
+    }
+      /* RGB planar */
+    case GST_VIDEO_FORMAT_RGBP:
+    case GST_VIDEO_FORMAT_BGRP:
+    case GST_VIDEO_FORMAT_GBR:
+    case GST_VIDEO_FORMAT_GBR_10LE:
+    case GST_VIDEO_FORMAT_GBR_12LE:
+    case GST_VIDEO_FORMAT_GBRA:
+    case GST_VIDEO_FORMAT_GBRA_10LE:
+    case GST_VIDEO_FORMAT_GBRA_12LE:
+    {
+      gchar x, y, z, w;
+      guint scale;
+
+      get_planar_component (format, &x, &y, &z, &w, &scale);
+
+      if (GST_VIDEO_INFO_N_PLANES (in_info) == 4) {
+        cinfo->sample_texture_func[0] = g_strdup_printf (templ_SAMPLE_PLANAR_4,
+            x, y, z, w, scale);
+      } else {
+        cinfo->sample_texture_func[0] = g_strdup_printf (templ_SAMPLE_PLANAR,
+            x, y, z, scale);
+      }
+
+      if (cinfo->ps_output[1]) {
+        cinfo->sample_texture_func[1] =
+            g_strdup (cinfo->sample_texture_func[0]);
+      }
+      break;
     }
       /* yuv packed */
     case GST_VIDEO_FORMAT_Y410:{
@@ -2634,23 +2789,45 @@ gst_d3d11_converter_calculate_border_color (GstD3D11Converter * self)
   GST_DEBUG_OBJECT (self, "Calculated background color ARGB: %f, %f, %f, %f",
       a, converted[0], converted[1], converted[2]);
 
-  if (GST_VIDEO_INFO_IS_RGB (out_info) || GST_VIDEO_INFO_IS_GRAY (out_info)) {
-    /* background color for video processor */
-    priv->background_color.RGBA.R = converted[0];
-    priv->background_color.RGBA.G = converted[1];
-    priv->background_color.RGBA.B = converted[2];
-    priv->background_color.RGBA.A = a;
+  /* background color for video processor */
+  priv->background_color.RGBA.R = converted[0];
+  priv->background_color.RGBA.G = converted[1];
+  priv->background_color.RGBA.B = converted[2];
+  priv->background_color.RGBA.A = a;
+
+  /* scale down if output is planar high bitdepth format */
+  switch (format) {
+    case GST_VIDEO_FORMAT_I420_10LE:
+    case GST_VIDEO_FORMAT_I422_10LE:
+    case GST_VIDEO_FORMAT_Y444_10LE:
+    case GST_VIDEO_FORMAT_GBR_10LE:
+    case GST_VIDEO_FORMAT_GBRA_10LE:
+      for (guint i = 0; i < 3; i++) {
+        converted[i] /= 64.0;
+      }
+      a /= 64.0;
+      break;
+    case GST_VIDEO_FORMAT_I420_12LE:
+    case GST_VIDEO_FORMAT_I422_12LE:
+    case GST_VIDEO_FORMAT_Y444_12LE:
+    case GST_VIDEO_FORMAT_GBR_12LE:
+    case GST_VIDEO_FORMAT_GBRA_12LE:
+      for (guint i = 0; i < 3; i++) {
+        converted[i] /= 16.0;
+      }
+      a /= 16.0;
+      break;
+    default:
+      break;
+  }
 
+  if ((GST_VIDEO_INFO_IS_RGB (out_info) &&
+          GST_VIDEO_INFO_N_PLANES (out_info) == 1) ||
+      GST_VIDEO_INFO_IS_GRAY (out_info)) {
     for (guint i = 0; i < 3; i++)
       priv->clear_color[0][i] = converted[i];
     priv->clear_color[0][3] = a;
   } else {
-    /* background color for video processor */
-    priv->background_color.YCbCr.Y = converted[0];
-    priv->background_color.YCbCr.Cb = converted[1];
-    priv->background_color.YCbCr.Cr = converted[2];
-    priv->background_color.YCbCr.A = a;
-
     switch (format) {
       case GST_VIDEO_FORMAT_VUYA:
         priv->clear_color[0][0] = converted[2];
@@ -2713,6 +2890,31 @@ gst_d3d11_converter_calculate_border_color (GstD3D11Converter * self)
         priv->clear_color[2][2] = 0;
         priv->clear_color[2][3] = 1.0;
         break;
+      case GST_VIDEO_FORMAT_RGBP:
+        priv->clear_color[0][0] = converted[0];
+        priv->clear_color[1][0] = converted[1];
+        priv->clear_color[2][0] = converted[2];
+        break;
+      case GST_VIDEO_FORMAT_BGRP:
+        priv->clear_color[0][0] = converted[2];
+        priv->clear_color[1][0] = converted[1];
+        priv->clear_color[2][0] = converted[0];
+        break;
+      case GST_VIDEO_FORMAT_GBR:
+      case GST_VIDEO_FORMAT_GBR_10LE:
+      case GST_VIDEO_FORMAT_GBR_12LE:
+        priv->clear_color[0][0] = converted[1];
+        priv->clear_color[1][0] = converted[2];
+        priv->clear_color[2][0] = converted[0];
+        break;
+      case GST_VIDEO_FORMAT_GBRA:
+      case GST_VIDEO_FORMAT_GBRA_10LE:
+      case GST_VIDEO_FORMAT_GBRA_12LE:
+        priv->clear_color[0][0] = converted[1];
+        priv->clear_color[1][0] = converted[2];
+        priv->clear_color[2][0] = converted[0];
+        priv->clear_color[3][0] = a;
+        break;
       default:
         g_assert_not_reached ();
         break;
@@ -2974,6 +3176,7 @@ gst_d3d11_converter_new (GstD3D11Device * device, const GstVideoInfo * in_info,
   priv->const_data.alpha = 1.0;
   priv->in_info = *in_info;
   priv->fallback_info = *in_info;
+  priv->piv_info = *in_info;
   priv->out_info = *out_info;
   priv->in_d3d11_format = in_d3d11_format;
   priv->out_d3d11_format = out_d3d11_format;
@@ -3019,12 +3222,6 @@ gst_d3d11_converter_new (GstD3D11Device * device, const GstVideoInfo * in_info,
       GST_DEBUG_OBJECT (self, "Video processor is available");
       priv->supported_backend |= GST_D3D11_CONVERTER_BACKEND_VIDEO_PROCESSOR;
     }
-
-    /* Always use converter */
-    if (GST_VIDEO_INFO_FORMAT (in_info) == GST_VIDEO_FORMAT_YUY2) {
-      GST_DEBUG_OBJECT (self, "Use video processor only");
-      goto out;
-    }
   }
 
   if ((wanted_backend & GST_D3D11_CONVERTER_BACKEND_SHADER) == 0)
@@ -3085,6 +3282,11 @@ gst_d3d11_converter_new (GstD3D11Device * device, const GstVideoInfo * in_info,
 
     priv->unpack_convert =
         gst_video_converter_new (in_info, &tmp_info, nullptr);
+    if (!priv->unpack_convert) {
+      GST_ERROR_OBJECT (self, "Couldn't create unpack convert");
+      priv->supported_backend = (GstD3D11ConverterBackend) 0;
+      goto out;
+    }
 
     priv->fallback_info = tmp_info;
     in_info = &priv->fallback_info;
@@ -3145,19 +3347,14 @@ gst_d3d11_converter_convert_internal (GstD3D11Converter * self,
   resource.As (&texture);
   texture->GetDesc (&desc);
 
-  if (priv->update_dest_rect && !gst_d3d11_converter_update_dest_rect (self)) {
-    GST_ERROR_OBJECT (self, "Failed to update dest rect");
-    return FALSE;
-  }
-
-  if (priv->update_src_rect ||
-      desc.Width != (guint) priv->input_texture_width ||
+  if (desc.Width != (guint) priv->input_texture_width ||
       desc.Height != (guint) priv->input_texture_height) {
     GST_DEBUG_OBJECT (self, "Update vertext buffer, texture resolution: %dx%d",
         desc.Width, desc.Height);
 
     priv->input_texture_width = desc.Width;
     priv->input_texture_height = desc.Height;
+    priv->update_src_rect = TRUE;
 
     if (!gst_d3d11_converter_update_src_rect (self)) {
       GST_ERROR_OBJECT (self, "Cannot update src rect");
@@ -3251,7 +3448,7 @@ gst_d3d11_converter_check_bind_flags_for_piv (guint bind_flags)
 }
 
 static gboolean
-gst_d3d11_converter_ensure_d3d11_buffer (GstD3D11Converter * self,
+gst_d3d11_converter_is_d3d11_buffer (GstD3D11Converter * self,
     GstBuffer * buffer)
 {
   if (gst_buffer_n_memory (buffer) == 0) {
@@ -3290,9 +3487,6 @@ gst_d3d11_converter_create_fallback_buffer (GstD3D11Converter * self)
 
   gst_clear_buffer (&priv->fallback_inbuf);
 
-  if (priv->processor)
-    bind_flags |= D3D11_BIND_RENDER_TARGET;
-
   params = gst_d3d11_allocation_params_new (self->device, &priv->fallback_info,
       GST_D3D11_ALLOCATION_FLAG_DEFAULT, bind_flags, 0);
 
@@ -3331,7 +3525,8 @@ gst_d3d11_converter_create_fallback_buffer (GstD3D11Converter * self)
 }
 
 static gboolean
-gst_d3d11_converter_copy_buffer (GstD3D11Converter * self, GstBuffer * in_buf)
+gst_d3d11_converter_upload_for_shader (GstD3D11Converter * self,
+    GstBuffer * in_buf)
 {
   GstD3D11ConverterPrivate *priv = self->priv;
   GstVideoFrame frame, fallback_frame;
@@ -3639,230 +3834,350 @@ gst_d3d11_converter_update_hdr10_meta (GstD3D11Converter * self)
 }
 
 static gboolean
-gst_d3d11_converter_convert_buffer_internal (GstD3D11Converter * self,
-    GstBuffer * in_buf, GstBuffer * out_buf)
+gst_d3d11_converter_need_blend (GstD3D11Converter * self)
 {
   GstD3D11ConverterPrivate *priv = self->priv;
-  ID3D11ShaderResourceView *srv[GST_VIDEO_MAX_PLANES] = { nullptr, };
-  ID3D11RenderTargetView *rtv[GST_VIDEO_MAX_PLANES] = { nullptr, };
-  ID3D11VideoProcessorInputView *piv = nullptr;
-  ID3D11VideoProcessorOutputView *pov = nullptr;
-  gboolean use_processor = FALSE;
-  GstD3D11Memory *in_dmem;
-  GstD3D11Memory *out_dmem;
-  GstMapInfo in_info[GST_VIDEO_MAX_PLANES];
-  GstMapInfo out_info[GST_VIDEO_MAX_PLANES];
-  D3D11_TEXTURE2D_DESC in_desc, out_desc;
-  guint num_srv, num_rtv;
-  gboolean ret = FALSE;
-  gboolean need_blend = FALSE;
 
-  /* Output buffer must be valid D3D11 buffer */
-  if (!gst_d3d11_converter_ensure_d3d11_buffer (self, out_buf)) {
-    GST_ERROR_OBJECT (self, "Output is not d3d11 buffer");
+  if (priv->blend && priv->blend_desc.RenderTarget[0].BlendEnable) {
+    if (priv->alpha != 1.0) {
+      return TRUE;
+    } else if ((priv->blend_desc.RenderTarget[0].SrcBlend ==
+            D3D11_BLEND_BLEND_FACTOR
+            || priv->blend_desc.RenderTarget[0].SrcBlend ==
+            D3D11_BLEND_INV_BLEND_FACTOR)
+        && (priv->blend_factor[0] != 1.0 || priv->blend_factor[1] != 1.0
+            || priv->blend_factor[2] != 1.0 || priv->blend_factor[3] != 1.0)) {
+      return TRUE;
+    }
+  }
+
+  return FALSE;
+}
+
+static gboolean
+gst_d3d11_converter_processor_available (GstD3D11Converter * self)
+{
+  GstD3D11ConverterPrivate *priv = self->priv;
+
+  if ((priv->supported_backend &
+          GST_D3D11_CONVERTER_BACKEND_VIDEO_PROCESSOR) == 0)
+    return FALSE;
+
+  /* TODO: processor may be able to blend textures */
+  if (gst_d3d11_converter_need_blend (self))
+    return FALSE;
+
+  /* flip/rotate is not supported by processor */
+  if (priv->processor_direction_not_supported)
+    return FALSE;
+
+  return TRUE;
+}
+
+static gboolean
+gst_d3d11_converter_piv_available (GstD3D11Converter * self, GstBuffer * in_buf)
+{
+  GstD3D11Memory *mem;
+  D3D11_TEXTURE2D_DESC desc;
+
+  mem = (GstD3D11Memory *) gst_buffer_peek_memory (in_buf, 0);
+  gst_d3d11_memory_get_texture_desc (mem, &desc);
+  return gst_d3d11_converter_check_bind_flags_for_piv (desc.BindFlags);
+}
+
+static gboolean
+gst_d3d11_converter_create_piv_buffer (GstD3D11Converter * self)
+{
+  GstD3D11ConverterPrivate *priv = self->priv;
+  GstD3D11AllocationParams *params;
+  GstBufferPool *pool;
+  GstCaps *caps;
+  GstStructure *config;
+
+  gst_clear_buffer (&priv->piv_inbuf);
+
+  params = gst_d3d11_allocation_params_new (self->device, &priv->piv_info,
+      GST_D3D11_ALLOCATION_FLAG_DEFAULT, 0, 0);
+
+  caps = gst_video_info_to_caps (&priv->piv_info);
+  pool = gst_d3d11_buffer_pool_new (self->device);
+
+  config = gst_buffer_pool_get_config (pool);
+  gst_buffer_pool_config_set_params (config, caps, priv->piv_info.size, 0, 0);
+  gst_buffer_pool_config_set_d3d11_allocation_params (config, params);
+  gst_caps_unref (caps);
+  gst_d3d11_allocation_params_free (params);
+
+  if (!gst_buffer_pool_set_config (pool, config)) {
+    GST_ERROR_OBJECT (self, "Failed to set pool config");
+    gst_object_unref (pool);
     return FALSE;
   }
 
-  if (gst_buffer_n_memory (in_buf) == 0) {
-    GST_ERROR_OBJECT (self, "Empty buffer");
+  if (!gst_buffer_pool_set_active (pool, TRUE)) {
+    GST_ERROR_OBJECT (self, "Failed to set active");
+    gst_object_unref (pool);
     return FALSE;
   }
 
-  /* But allows input copying */
-  if (!gst_d3d11_converter_ensure_d3d11_buffer (self, in_buf) ||
-      (GST_VIDEO_INFO_FORMAT (&priv->in_info) == GST_VIDEO_FORMAT_YUY2 &&
-          priv->unpack_convert)) {
-    if (!gst_d3d11_converter_copy_buffer (self, in_buf)) {
-      GST_ERROR_OBJECT (self, "Couldn't copy into fallback buffer");
-      return FALSE;
-    }
+  gst_buffer_pool_acquire_buffer (pool, &priv->piv_inbuf, nullptr);
+  gst_buffer_pool_set_active (pool, FALSE);
+  gst_object_unref (pool);
 
-    in_buf = priv->fallback_inbuf;
+  if (!priv->piv_inbuf) {
+    GST_ERROR_OBJECT (self, "Failed to create PIV buffer");
+    return FALSE;
   }
 
-  in_dmem = (GstD3D11Memory *) gst_buffer_peek_memory (in_buf, 0);
-  out_dmem = (GstD3D11Memory *) gst_buffer_peek_memory (out_buf, 0);
+  return TRUE;
+}
 
-  if (!gst_d3d11_memory_get_texture_desc (in_dmem, &in_desc)) {
-    GST_ERROR_OBJECT (self, "Failed to get input desc");
+static gboolean
+gst_d3d11_converter_upload_for_processor (GstD3D11Converter * self,
+    GstBuffer * in_buf)
+{
+  GstD3D11ConverterPrivate *priv = self->priv;
+  GstVideoFrame frame, fallback_frame;
+  GstVideoInfo *piv_info = &priv->piv_info;
+  gboolean ret = TRUE;
+
+  if (!gst_video_frame_map (&frame, &priv->in_info, in_buf, GST_MAP_READ)) {
+    GST_ERROR_OBJECT (self, "Failed to map input buffer");
     return FALSE;
   }
 
-  if (!gst_d3d11_memory_get_texture_desc (out_dmem, &out_desc)) {
-    GST_ERROR_OBJECT (self, "Failed to get output desc");
-    return FALSE;
+  /* Probably cropped buffer */
+  if (piv_info->width != GST_VIDEO_FRAME_WIDTH (&frame) ||
+      piv_info->height != GST_VIDEO_FRAME_HEIGHT (&frame)) {
+    gst_clear_buffer (&priv->piv_inbuf);
+
+    *piv_info = frame.info;
   }
 
-  if ((out_desc.BindFlags & D3D11_BIND_RENDER_TARGET) == 0) {
-    GST_ERROR_OBJECT (self, "Output is not bound to render target");
-    return FALSE;
+  if (!priv->piv_inbuf && !gst_d3d11_converter_create_piv_buffer (self)) {
+    goto error;
   }
 
-  if (!gst_d3d11_converter_map_buffer (self, in_buf, in_info,
+  if (!gst_video_frame_map (&fallback_frame,
+          &priv->piv_info, priv->piv_inbuf, GST_MAP_WRITE)) {
+    GST_ERROR_OBJECT (self, "Couldn't map fallback buffer");
+    goto error;
+  }
+
+  ret = gst_video_frame_copy (&fallback_frame, &frame);
+  gst_video_frame_unmap (&fallback_frame);
+  gst_video_frame_unmap (&frame);
+
+  return ret;
+
+error:
+  gst_video_frame_unmap (&frame);
+  return FALSE;
+}
+
+static gboolean
+gst_d3d11_converter_do_processor_blt (GstD3D11Converter * self,
+    GstBuffer * in_buf, GstBuffer * out_buf)
+{
+  GstD3D11ConverterPrivate *priv = self->priv;
+  ID3D11VideoProcessorInputView *piv = nullptr;
+  ID3D11VideoProcessorOutputView *pov = nullptr;
+  ID3D11VideoContext1 *video_ctx = priv->video_context;
+  ID3D11VideoProcessor *proc = priv->processor;
+  D3D11_VIDEO_PROCESSOR_STREAM stream = { 0, };
+  HRESULT hr;
+  GstMemory *in_mem, *out_mem;
+  GstD3D11Memory *in_dmem;
+  GstD3D11Memory *out_dmem;
+  GstMapInfo in_info, out_info;
+  gboolean ret = FALSE;
+
+  g_assert (gst_buffer_n_memory (in_buf) == 1);
+  g_assert (gst_buffer_n_memory (out_buf) == 1);
+
+  in_mem = gst_buffer_peek_memory (in_buf, 0);
+  out_mem = gst_buffer_peek_memory (out_buf, 0);
+
+  if (!gst_memory_map (in_mem, &in_info,
           (GstMapFlags) (GST_MAP_READ | GST_MAP_D3D11))) {
     GST_ERROR_OBJECT (self, "Couldn't map input buffer");
     return FALSE;
   }
 
-  if (!gst_d3d11_converter_map_buffer (self, out_buf, out_info,
+  if (!gst_memory_map (out_mem, &out_info,
           (GstMapFlags) (GST_MAP_WRITE | GST_MAP_D3D11))) {
     GST_ERROR_OBJECT (self, "Couldn't map output buffer");
-    gst_d3d11_converter_unmap_buffer (self, in_buf, in_info);
+    gst_memory_unmap (in_mem, &in_info);
     return FALSE;
   }
 
-  GstD3D11SRWLockGuard (&priv->prop_lock);
-  gst_d3d11_converter_update_hdr10_meta (self);
+  in_dmem = GST_D3D11_MEMORY_CAST (in_mem);
+  out_dmem = GST_D3D11_MEMORY_CAST (out_mem);
 
-  if (priv->blend && priv->blend_desc.RenderTarget[0].BlendEnable) {
-    if (priv->alpha != 1.0) {
-      need_blend = TRUE;
-    } else if ((priv->blend_desc.RenderTarget[0].SrcBlend ==
-            D3D11_BLEND_BLEND_FACTOR
-            || priv->blend_desc.RenderTarget[0].SrcBlend ==
-            D3D11_BLEND_INV_BLEND_FACTOR)
-        && (priv->blend_factor[0] != 1.0 || priv->blend_factor[1] != 1.0
-            || priv->blend_factor[2] != 1.0 || priv->blend_factor[3] != 1.0)) {
-      need_blend = TRUE;
-    }
+  piv = gst_d3d11_memory_get_processor_input_view (in_dmem,
+      priv->video_device, priv->enumerator);
+  if (!piv) {
+    GST_ERROR_OBJECT (self, "PIV is unavailable");
+    goto out;
   }
 
-  if (priv->supported_backend == GST_D3D11_CONVERTER_BACKEND_VIDEO_PROCESSOR) {
-    piv =
-        gst_d3d11_memory_get_processor_input_view (in_dmem,
-        priv->video_device, priv->enumerator);
-    pov =
-        gst_d3d11_memory_get_processor_output_view (out_dmem,
-        priv->video_device, priv->enumerator);
-
-    use_processor = TRUE;
-  } else if ((priv->supported_backend &
-          GST_D3D11_CONVERTER_BACKEND_VIDEO_PROCESSOR) != 0 && !need_blend
-      && gst_d3d11_converter_check_bind_flags_for_piv (in_desc.BindFlags)) {
-    /* TODO: processor supports alpha blending */
-
-    /* Try processor when:
-     * - We were using processor already
-     * - or SRV is unavailable (likely from decoder output)
-     * - or HDR10, as we don't support tone-mapping via shader yet
-     */
-    if (priv->processor_in_use ||
-        (in_desc.BindFlags & D3D11_BIND_SHADER_RESOURCE) == 0 ||
-        (priv->video_context2 && (priv->have_in_hdr10
-                || priv->have_out_hdr10))) {
-      piv =
-          gst_d3d11_memory_get_processor_input_view (in_dmem,
-          priv->video_device, priv->enumerator);
-      pov =
-          gst_d3d11_memory_get_processor_output_view (out_dmem,
-          priv->video_device, priv->enumerator);
-    }
+  pov = gst_d3d11_memory_get_processor_output_view (out_dmem,
+      priv->video_device, priv->enumerator);
+  if (!pov) {
+    GST_ERROR_OBJECT (self, "POV is unavailable");
+    goto out;
+  }
 
-    if (piv != nullptr && pov != nullptr)
-      use_processor = TRUE;
+  video_ctx->VideoProcessorSetStreamSourceRect (proc, 0, TRUE, &priv->src_rect);
+  video_ctx->VideoProcessorSetStreamDestRect (proc, 0, TRUE, &priv->dest_rect);
+
+  if (priv->clear_background) {
+    video_ctx->VideoProcessorSetOutputTargetRect (proc,
+        TRUE, &priv->dest_full_rect);
+    video_ctx->VideoProcessorSetOutputBackgroundColor (proc,
+        GST_VIDEO_INFO_IS_YUV (&priv->out_info), &priv->background_color);
+  } else {
+    video_ctx->VideoProcessorSetOutputTargetRect (proc, TRUE, &priv->dest_rect);
   }
 
-  if (use_processor) {
-    if (!pov) {
-      GST_ERROR_OBJECT (self, "POV is unavailable");
-      goto out;
+  if (priv->video_context2 &&
+      (priv->processor_caps.FeatureCaps & FEATURE_CAPS_METADATA_HDR10) != 0) {
+    if (priv->have_in_hdr10) {
+      priv->video_context2->VideoProcessorSetStreamHDRMetaData (proc, 0,
+          DXGI_HDR_METADATA_TYPE_HDR10, sizeof (DXGI_HDR_METADATA_HDR10),
+          &priv->in_hdr10_meta);
+    } else {
+      priv->video_context2->VideoProcessorSetStreamHDRMetaData (proc, 0,
+          DXGI_HDR_METADATA_TYPE_NONE, 0, nullptr);
     }
 
-    if (!piv) {
-      if (!gst_d3d11_converter_ensure_fallback_inbuf (self, in_buf, in_info)) {
-        GST_ERROR_OBJECT (self, "Couldn't copy into fallback texture");
-        goto out;
-      }
+    if (priv->have_out_hdr10) {
+      priv->video_context2->VideoProcessorSetOutputHDRMetaData (proc,
+          DXGI_HDR_METADATA_TYPE_HDR10, sizeof (DXGI_HDR_METADATA_HDR10),
+          &priv->in_hdr10_meta);
+    }
+  }
 
-      gst_d3d11_converter_unmap_buffer (self, in_buf, in_info);
-      in_buf = priv->fallback_inbuf;
+  if ((priv->processor_caps.FeatureCaps & FEATURE_CAPS_ROTATION) != 0) {
+    video_ctx->VideoProcessorSetStreamRotation (proc, 0,
+        priv->enable_rotation, priv->rotation);
+  }
 
-      if (!gst_d3d11_converter_map_buffer (self,
-              in_buf, in_info, (GstMapFlags) (GST_MAP_READ | GST_MAP_D3D11))) {
-        GST_ERROR_OBJECT (self, "Couldn't map fallback buffer");
-        in_buf = nullptr;
-        goto out;
-      }
+  if ((priv->processor_caps.FeatureCaps & PROCESSOR_FEATURE_CAPS_MIRROR) != 0) {
+    video_ctx->VideoProcessorSetStreamMirror (proc, 0, priv->enable_mirror,
+        priv->flip_h, priv->flip_v);
+  }
 
-      in_dmem = (GstD3D11Memory *) gst_buffer_peek_memory (in_buf, 0);
-      piv = gst_d3d11_memory_get_processor_input_view (in_dmem,
-          priv->video_device, priv->enumerator);
-      if (!piv) {
-        GST_ERROR_OBJECT (self, "Couldn't get POV from fallback buffer");
-        goto out;
-      }
-    }
+  stream.Enable = TRUE;
+  stream.pInputSurface = piv;
+
+  GST_TRACE_OBJECT (self, "Converting using processor");
+
+  hr = video_ctx->VideoProcessorBlt (proc, pov, 0, 1, &stream);
+  ret = gst_d3d11_result (hr, self->device);
+
+  priv->processor_in_use = ret;
+
+out:
+  gst_memory_unmap (out_mem, &out_info);
+  gst_memory_unmap (in_mem, &in_info);
+
+  return ret;
+}
+
+static gboolean
+gst_d3d11_converter_convert_buffer_internal (GstD3D11Converter * self,
+    GstBuffer * in_buf, GstBuffer * out_buf)
+{
+  GstD3D11ConverterPrivate *priv = self->priv;
+  ID3D11ShaderResourceView *srv[GST_VIDEO_MAX_PLANES] = { nullptr, };
+  ID3D11RenderTargetView *rtv[GST_VIDEO_MAX_PLANES] = { nullptr, };
+  GstD3D11Memory *in_dmem;
+  GstD3D11Memory *out_dmem;
+  GstMapInfo in_info[GST_VIDEO_MAX_PLANES];
+  GstMapInfo out_info[GST_VIDEO_MAX_PLANES];
+  D3D11_TEXTURE2D_DESC desc;
+  guint num_srv, num_rtv;
+  gboolean ret = FALSE;
+  gboolean in_d3d11;
+
+  GstD3D11SRWLockGuard (&priv->prop_lock);
+
+  /* Output buffer must be valid D3D11 buffer */
+  if (!gst_d3d11_converter_is_d3d11_buffer (self, out_buf)) {
+    GST_ERROR_OBJECT (self, "Output is not d3d11 buffer");
+    return FALSE;
   }
 
-  priv->processor_in_use = use_processor;
-  if (use_processor && !priv->processor_direction_not_supported) {
-    ID3D11VideoContext1 *video_ctx = priv->video_context;
-    ID3D11VideoProcessor *proc = priv->processor;
-    D3D11_VIDEO_PROCESSOR_STREAM stream = { 0, };
-    HRESULT hr;
+  if (gst_buffer_n_memory (in_buf) == 0) {
+    GST_ERROR_OBJECT (self, "Empty input buffer");
+    return FALSE;
+  }
 
-    if (priv->update_dest_rect && !gst_d3d11_converter_update_dest_rect (self)) {
-      GST_ERROR_OBJECT (self, "Failed to update dest rect");
-      goto out;
-    }
+  out_dmem = (GstD3D11Memory *) gst_buffer_peek_memory (out_buf, 0);
+  if (!gst_d3d11_memory_get_texture_desc (out_dmem, &desc)) {
+    GST_ERROR_OBJECT (self, "Failed to get output desc");
+    return FALSE;
+  }
 
-    if (priv->update_src_rect && !gst_d3d11_converter_update_src_rect (self)) {
-      GST_ERROR_OBJECT (self, "Cannot update src rect");
-      goto out;
-    }
+  if ((desc.BindFlags & D3D11_BIND_RENDER_TARGET) == 0) {
+    GST_ERROR_OBJECT (self, "Output is not bound to render target");
+    return FALSE;
+  }
 
-    video_ctx->VideoProcessorSetStreamSourceRect (proc,
-        0, TRUE, &priv->src_rect);
-    video_ctx->VideoProcessorSetStreamDestRect (proc,
-        0, TRUE, &priv->dest_rect);
+  gst_d3d11_converter_update_hdr10_meta (self);
+  /* Update in/out rect */
+  if (!gst_d3d11_converter_update_dest_rect (self)) {
+    GST_ERROR_OBJECT (self, "Failed to update dest rect");
+    return FALSE;
+  }
 
-    if (priv->clear_background) {
-      video_ctx->VideoProcessorSetOutputTargetRect (proc,
-          TRUE, &priv->dest_full_rect);
-      video_ctx->VideoProcessorSetOutputBackgroundColor (proc,
-          GST_VIDEO_INFO_IS_YUV (&priv->out_info), &priv->background_color);
-    } else {
-      video_ctx->VideoProcessorSetOutputTargetRect (proc, TRUE,
-          &priv->dest_rect);
-    }
+  if (!gst_d3d11_converter_update_src_rect (self)) {
+    GST_ERROR_OBJECT (self, "Failed to update src rect");
+    return FALSE;
+  }
 
-    if (priv->video_context2 &&
-        (priv->processor_caps.FeatureCaps & FEATURE_CAPS_METADATA_HDR10) != 0) {
-      if (priv->have_in_hdr10) {
-        priv->video_context2->VideoProcessorSetStreamHDRMetaData (proc, 0,
-            DXGI_HDR_METADATA_TYPE_HDR10, sizeof (DXGI_HDR_METADATA_HDR10),
-            &priv->in_hdr10_meta);
-      } else {
-        priv->video_context2->VideoProcessorSetStreamHDRMetaData (proc, 0,
-            DXGI_HDR_METADATA_TYPE_NONE, 0, nullptr);
-      }
+  in_d3d11 = gst_d3d11_converter_is_d3d11_buffer (self, in_buf);
+  if (gst_d3d11_converter_processor_available (self)) {
+    gboolean use_processor = FALSE;
+    gboolean piv_available = FALSE;
 
-      if (priv->have_out_hdr10) {
-        priv->video_context2->VideoProcessorSetOutputHDRMetaData (proc,
-            DXGI_HDR_METADATA_TYPE_HDR10, sizeof (DXGI_HDR_METADATA_HDR10),
-            &priv->in_hdr10_meta);
-      }
-    }
+    if (in_d3d11)
+      piv_available = gst_d3d11_converter_piv_available (self, in_buf);
 
-    if ((priv->processor_caps.FeatureCaps & FEATURE_CAPS_ROTATION) != 0) {
-      video_ctx->VideoProcessorSetStreamRotation (proc, 0,
-          priv->enable_rotation, priv->rotation);
-    }
+    if ((priv->supported_backend & GST_D3D11_CONVERTER_BACKEND_SHADER) != 0) {
+      /* processor only */
+      use_processor = TRUE;
+    } else if (piv_available) {
+      in_dmem = (GstD3D11Memory *) gst_buffer_peek_memory (in_buf, 0);
 
-    if ((priv->processor_caps.FeatureCaps & PROCESSOR_FEATURE_CAPS_MIRROR) != 0) {
-      video_ctx->VideoProcessorSetStreamMirror (proc, 0, priv->enable_mirror,
-          priv->flip_h, priv->flip_v);
+      if (GST_VIDEO_INFO_FORMAT (&priv->in_info) == GST_VIDEO_FORMAT_YUY2) {
+        /* Always use processor for packed YUV */
+        use_processor = TRUE;
+      } else if (!gst_d3d11_memory_get_shader_resource_view_size (in_dmem)) {
+        /* SRV is unavailable, use processor */
+        use_processor = TRUE;
+      } else if (priv->video_context2 &&
+          (priv->have_in_hdr10 || priv->have_out_hdr10)) {
+        /* HDR10 tonemap is needed */
+        use_processor = TRUE;
+      } else if (priv->processor_in_use) {
+        use_processor = TRUE;
+      }
     }
 
-    stream.Enable = TRUE;
-    stream.pInputSurface = piv;
-
-    GST_TRACE_OBJECT (self, "Converting using processor");
+    if (use_processor) {
+      if (!piv_available) {
+        if (!gst_d3d11_converter_upload_for_processor (self, in_buf)) {
+          GST_ERROR_OBJECT (self, "Couldn't upload buffer");
+          return FALSE;
+        }
 
-    hr = video_ctx->VideoProcessorBlt (proc, pov, 0, 1, &stream);
+        in_buf = priv->piv_inbuf;
+      }
 
-    ret = gst_d3d11_result (hr, self->device);
-    goto out;
+      return gst_d3d11_converter_do_processor_blt (self, in_buf, out_buf);
+    }
   }
 
   if ((priv->supported_backend & GST_D3D11_CONVERTER_BACKEND_SHADER) == 0) {
@@ -3870,6 +4185,29 @@ gst_d3d11_converter_convert_buffer_internal (GstD3D11Converter * self,
     goto out;
   }
 
+  if (!in_d3d11 ||
+      GST_VIDEO_INFO_FORMAT (&priv->in_info) == GST_VIDEO_FORMAT_YUY2) {
+    if (!gst_d3d11_converter_upload_for_shader (self, in_buf)) {
+      GST_ERROR_OBJECT (self, "Couldn't copy into fallback buffer");
+      return FALSE;
+    }
+
+    in_buf = priv->fallback_inbuf;
+  }
+
+  if (!gst_d3d11_converter_map_buffer (self, in_buf, in_info,
+          (GstMapFlags) (GST_MAP_READ | GST_MAP_D3D11))) {
+    GST_ERROR_OBJECT (self, "Couldn't map input buffer");
+    return FALSE;
+  }
+
+  if (!gst_d3d11_converter_map_buffer (self, out_buf, out_info,
+          (GstMapFlags) (GST_MAP_WRITE | GST_MAP_D3D11))) {
+    GST_ERROR_OBJECT (self, "Couldn't map output buffer");
+    gst_d3d11_converter_unmap_buffer (self, in_buf, in_info);
+    return FALSE;
+  }
+
   num_rtv = gst_d3d11_converter_get_rtv (self, out_buf, rtv);
   if (!num_rtv) {
     GST_ERROR_OBJECT (self, "RTV is unavailable");
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11device.cpp b/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11device.cpp
index 2fb8f00ad9..a97643a635 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11device.cpp
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/d3d11/gstd3d11device.cpp
@@ -543,7 +543,7 @@ gst_d3d11_device_setup_format_table (GstD3D11Device * self)
         }
         break;
       }
-        /* YUV non-DXGI native formats */
+        /* non-DXGI native formats */
       case GST_VIDEO_FORMAT_NV21:
       case GST_VIDEO_FORMAT_I420:
       case GST_VIDEO_FORMAT_YV12:
@@ -557,7 +557,17 @@ gst_d3d11_device_setup_format_table (GstD3D11Device * self)
       case GST_VIDEO_FORMAT_Y444_12LE:
       case GST_VIDEO_FORMAT_Y444_16LE:
       case GST_VIDEO_FORMAT_AYUV:
-      case GST_VIDEO_FORMAT_AYUV64:{
+      case GST_VIDEO_FORMAT_AYUV64:
+        /* RGB planar formats */
+      case GST_VIDEO_FORMAT_RGBP:
+      case GST_VIDEO_FORMAT_BGRP:
+      case GST_VIDEO_FORMAT_GBR:
+      case GST_VIDEO_FORMAT_GBR_10LE:
+      case GST_VIDEO_FORMAT_GBR_12LE:
+      case GST_VIDEO_FORMAT_GBRA:
+      case GST_VIDEO_FORMAT_GBRA_10LE:
+      case GST_VIDEO_FORMAT_GBRA_12LE:
+      {
         gboolean supported = TRUE;
 
         native = FALSE;
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/play/gstplay.c b/subprojects/gst-plugins-bad/gst-libs/gst/play/gstplay.c
index 950be08a5d..f99bbe1bcd 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/play/gstplay.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/play/gstplay.c
@@ -1061,9 +1061,15 @@ warning_cb (G_GNUC_UNUSED GstBus * bus, GstMessage * msg, gpointer user_data)
   GST_WARNING_OBJECT (self, "Warning: %s (%s, %d)", err->message,
       g_quark_to_string (err->domain), err->code);
 
-  api_bus_post_message (self, GST_PLAY_MESSAGE_WARNING,
-      GST_PLAY_MESSAGE_DATA_WARNING, G_TYPE_ERROR, play_err,
-      GST_PLAY_MESSAGE_DATA_WARNING_DETAILS, GST_TYPE_STRUCTURE, details, NULL);
+  if (details != NULL) {
+    api_bus_post_message (self, GST_PLAY_MESSAGE_WARNING,
+        GST_PLAY_MESSAGE_DATA_WARNING, G_TYPE_ERROR, play_err,
+        GST_PLAY_MESSAGE_DATA_WARNING_DETAILS, GST_TYPE_STRUCTURE, details,
+        NULL);
+  } else {
+    api_bus_post_message (self, GST_PLAY_MESSAGE_WARNING,
+        GST_PLAY_MESSAGE_DATA_WARNING, G_TYPE_ERROR, play_err, NULL);
+  }
 
   g_clear_error (&play_err);
   g_clear_error (&err);
@@ -1756,7 +1762,7 @@ gst_play_subtitle_info_update (GstPlay * self, GstPlayStreamInfo * stream_info)
 
       g_object_get (G_OBJECT (self->playbin), "current-suburi", &suburi, NULL);
       if (suburi) {
-        if (self->use_playbin3) {
+        if (self->use_playbin3 && self->subtitle_sid) {
           if (g_str_equal (self->subtitle_sid, stream_info->stream_id))
             info->language = g_path_get_basename (suburi);
         } else {
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/transcoder/gsttranscoder.c b/subprojects/gst-plugins-bad/gst-libs/gst/transcoder/gsttranscoder.c
index b311ad4fbc..75e27c2e7f 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/transcoder/gsttranscoder.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/transcoder/gsttranscoder.c
@@ -262,6 +262,7 @@ gst_transcoder_finalize (GObject * object)
   g_free (self->source_uri);
   g_free (self->dest_uri);
   g_cond_clear (&self->cond);
+  gst_object_unref (self->api_bus);
 
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
@@ -942,6 +943,7 @@ _error_cb (RunSyncData * data, GError * error, GstStructure * details)
 
   if (data->loop) {
     g_main_loop_quit (data->loop);
+    g_main_loop_unref (data->loop);
     data->loop = NULL;
   }
 }
@@ -951,6 +953,7 @@ _done_cb (RunSyncData * data)
 {
   if (data->loop) {
     g_main_loop_quit (data->loop);
+    g_main_loop_unref (data->loop);
     data->loop = NULL;
   }
 }
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.c b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.c
index f9ae663825..2328d0b82d 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.c
@@ -452,6 +452,45 @@ gst_webrtc_ice_get_turn_server (GstWebRTCICE * ice)
   return GST_WEBRTC_ICE_GET_CLASS (ice)->get_turn_server (ice);
 }
 
+/**
+ * gst_webrtc_ice_set_http_proxy:
+ * @ice: The #GstWebRTCICE
+ * @uri: (transfer none): URI of the HTTP proxy of the form
+ *   http://[username:password@]hostname[:port]
+ *
+ * Set HTTP Proxy to be used when connecting to TURN server.
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_http_proxy (GstWebRTCICE * ice, const gchar * uri_s)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_http_proxy);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_http_proxy (ice, uri_s);
+}
+
+/**
+ * gst_webrtc_ice_get_http_proxy:
+ * @ice: The #GstWebRTCICE
+ *
+ * Returns: (transfer full): URI of the HTTP proxy of the form
+ *   http://[username:password@]hostname[:port]
+ *
+ * Get HTTP Proxy to be used when connecting to TURN server.
+ *
+ * Since: 1.22
+ */
+gchar *
+gst_webrtc_ice_get_http_proxy (GstWebRTCICE * ice)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_http_proxy);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_http_proxy (ice);
+}
+
 
 static void
 gst_webrtc_ice_set_property (GObject * object, guint prop_id,
@@ -516,6 +555,8 @@ gst_webrtc_ice_class_init (GstWebRTCICEClass * klass)
   klass->get_stun_server = NULL;
   klass->set_turn_server = NULL;
   klass->get_turn_server = NULL;
+  klass->get_http_proxy = NULL;
+  klass->set_http_proxy = NULL;
   klass->set_tos = NULL;
   klass->set_on_ice_candidate = NULL;
   klass->get_local_candidates = NULL;
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.h b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.h
index 38e8bf6ab6..f67889b1f4 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/ice.h
@@ -106,6 +106,33 @@ struct _GstWebRTCICEClass {
   void (*set_turn_server)                              (GstWebRTCICE * ice,
                                                         const gchar * uri);
   gchar * (*get_turn_server)                           (GstWebRTCICE * ice);
+
+  /**
+   * GstWebRTCICEClass::set_http_proxy:
+   * @ice: a #GstWebRTCICE
+   * @uri: (transfer none): URI of the HTTP proxy of the form
+   *   http://[username:password@]hostname[:port]
+   *
+   * Set HTTP Proxy to be used when connecting to TURN server.
+   *
+   * Since: 1.22
+   */
+  void (*set_http_proxy)                               (GstWebRTCICE * ice,
+                                                        const gchar * uri);
+
+  /**
+   * GstWebRTCICEClass::get_http_proxy:
+   * @ice: a #GstWebRTCICE
+   *
+   * Get HTTP Proxy to be used when connecting to TURN server.
+   *
+   * Returns: (transfer full): URI of the HTTP proxy of the form
+   *   http://[username:password@]hostname[:port]
+   *
+   * Since: 1.22
+   */
+  gchar * (*get_http_proxy)                            (GstWebRTCICE * ice);
+
   void (*set_tos)                                      (GstWebRTCICE * ice,
                                                         GstWebRTCICEStream * stream,
                                                         guint tos);
@@ -186,6 +213,13 @@ void                        gst_webrtc_ice_set_turn_server          (GstWebRTCIC
 GST_WEBRTC_API
 gchar *                     gst_webrtc_ice_get_turn_server          (GstWebRTCICE * ice);
 
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_http_proxy           (GstWebRTCICE * ice,
+                                                                     const gchar * uri);
+
+GST_WEBRTC_API
+gchar *                     gst_webrtc_ice_get_http_proxy           (GstWebRTCICE * ice);
+
 GST_WEBRTC_API
 void                        gst_webrtc_ice_set_on_ice_candidate     (GstWebRTCICE * ice,
                                                                      GstWebRTCICEOnCandidateFunc func,
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/nice/nice.c b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/nice/nice.c
index ce1e430536..defc97cf82 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/nice/nice.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/nice/nice.c
@@ -34,6 +34,8 @@
     NICE_VERSION_MICRO >= (micro)))
 #endif
 
+#define HTTP_PROXY_PORT_DEFAULT 3128
+
 /* XXX:
  *
  * - are locally generated remote candidates meant to be readded to libnice?
@@ -74,6 +76,8 @@ struct _GstWebRTCNicePrivate
   GstUri *turn_server;
 
   GHashTable *turn_servers;
+
+  GstUri *http_proxy;
 };
 
 #define gst_webrtc_nice_parent_class parent_class
@@ -1390,6 +1394,106 @@ out:
   return NULL;
 }
 
+static void
+on_http_proxy_resolved (GstWebRTCICE * ice, GAsyncResult * res,
+    gpointer user_data)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GstUri *uri = user_data;
+  GList *addresses;
+  GError *error = NULL;
+  const gchar *userinfo;
+  gchar *user = NULL;
+  gchar *pass = NULL;
+  gchar *ip = NULL;
+  guint port = GST_URI_NO_PORT;
+
+  if (!(addresses = resolve_host_finish (nice, res, &error))) {
+    GST_WARNING_OBJECT (ice, "Failed to resolve http proxy: %s",
+        error->message);
+    g_clear_error (&error);
+    return;
+  }
+
+  /* XXX: only the first IP is used */
+  ip = g_inet_address_to_string (addresses->data);
+
+  if (!ip) {
+    GST_ERROR_OBJECT (ice, "failed to resolve host for proxy");
+    gst_uri_unref (uri);
+    return;
+  }
+
+  port = gst_uri_get_port (uri);
+  if (port == GST_URI_NO_PORT) {
+    port = HTTP_PROXY_PORT_DEFAULT;
+    GST_DEBUG_OBJECT (ice, "Proxy server has no port, assuming %u",
+        HTTP_PROXY_PORT_DEFAULT);
+  }
+
+  userinfo = gst_uri_get_userinfo (uri);
+  _parse_userinfo (userinfo, &user, &pass);
+
+  g_object_set (nice->priv->nice_agent,
+      "proxy-ip", ip, "proxy-port", port, "proxy-type", NICE_PROXY_TYPE_HTTP,
+      "proxy-username", user, "proxy-password", pass, NULL);
+
+  g_free (ip);
+  g_free (user);
+  g_free (pass);
+}
+
+static GstUri *
+_set_http_proxy (GstWebRTCICE * ice, const gchar * s)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GstUri *uri = gst_uri_from_string_escaped (s);
+  const gchar *msg =
+      "must be of the form http://[username:password@]<host>[:<port>]";
+  const gchar *host = NULL;
+  const gchar *userinfo;
+  gchar *user = NULL, *pass = NULL;
+
+  GST_DEBUG_OBJECT (ice, "setting http proxy %s", s);
+
+  if (!uri) {
+    GST_ERROR_OBJECT (ice, "Couldn't parse http proxy uri '%s', %s", s, msg);
+    return NULL;
+  }
+
+  if (g_strcmp0 (gst_uri_get_scheme (uri), "http") != 0) {
+    GST_ERROR_OBJECT (ice,
+        "Couldn't parse uri scheme for http proxy server '%s', %s", s, msg);
+    gst_uri_unref (uri);
+    return NULL;
+  }
+
+  host = gst_uri_get_host (uri);
+  if (!host) {
+    GST_ERROR_OBJECT (ice, "http proxy server '%s' has no host, %s", s, msg);
+    gst_uri_unref (uri);
+    return NULL;
+  }
+
+  userinfo = gst_uri_get_userinfo (uri);
+  _parse_userinfo (userinfo, &user, &pass);
+  if ((pass && pass[0] != '\0') && (!user || user[0] == '\0')) {
+    GST_ERROR_OBJECT (ice,
+        "Password specified without user for http proxy '%s', %s", s, msg);
+    uri = NULL;
+    goto out;
+  }
+
+  resolve_host_async (nice, host, (GAsyncReadyCallback) on_http_proxy_resolved,
+      gst_uri_ref (uri), (GDestroyNotify) gst_uri_unref);
+
+out:
+  g_free (user);
+  g_free (pass);
+
+  return uri;
+}
+
 static void
 gst_webrtc_nice_set_stun_server (GstWebRTCICE * ice, const gchar * uri_s)
 {
@@ -1443,6 +1547,30 @@ gst_webrtc_nice_get_turn_server (GstWebRTCICE * ice)
     return NULL;
 }
 
+static void
+gst_webrtc_nice_set_http_proxy (GstWebRTCICE * ice, const gchar * http_proxy)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GstUri *uri = _set_http_proxy (ice, http_proxy);
+
+  if (uri) {
+    if (nice->priv->http_proxy)
+      gst_uri_unref (nice->priv->http_proxy);
+    nice->priv->http_proxy = uri;
+  }
+}
+
+static gchar *
+gst_webrtc_nice_get_http_proxy (GstWebRTCICE * ice)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  if (nice->priv->http_proxy)
+    return gst_uri_to_string (nice->priv->http_proxy);
+  else
+    return NULL;
+}
+
 static void
 gst_webrtc_nice_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
@@ -1526,6 +1654,8 @@ gst_webrtc_nice_finalize (GObject * object)
     gst_uri_unref (ice->priv->turn_server);
   if (ice->priv->stun_server)
     gst_uri_unref (ice->priv->stun_server);
+  if (ice->priv->http_proxy)
+    gst_uri_unref (ice->priv->http_proxy);
 
   g_mutex_clear (&ice->priv->lock);
   g_cond_clear (&ice->priv->cond);
@@ -1573,6 +1703,7 @@ gst_webrtc_nice_class_init (GstWebRTCNiceClass * klass)
   gst_webrtc_ice_class->get_is_controller = gst_webrtc_nice_get_is_controller;
   gst_webrtc_ice_class->get_stun_server = gst_webrtc_nice_get_stun_server;
   gst_webrtc_ice_class->get_turn_server = gst_webrtc_nice_get_turn_server;
+  gst_webrtc_ice_class->get_http_proxy = gst_webrtc_nice_get_http_proxy;
   gst_webrtc_ice_class->set_force_relay = gst_webrtc_nice_set_force_relay;
   gst_webrtc_ice_class->set_is_controller = gst_webrtc_nice_set_is_controller;
   gst_webrtc_ice_class->set_local_credentials =
@@ -1582,6 +1713,7 @@ gst_webrtc_nice_class_init (GstWebRTCNiceClass * klass)
   gst_webrtc_ice_class->set_stun_server = gst_webrtc_nice_set_stun_server;
   gst_webrtc_ice_class->set_tos = gst_webrtc_nice_set_tos;
   gst_webrtc_ice_class->set_turn_server = gst_webrtc_nice_set_turn_server;
+  gst_webrtc_ice_class->set_http_proxy = gst_webrtc_nice_set_http_proxy;
   gst_webrtc_ice_class->set_on_ice_candidate =
       gst_webrtc_nice_set_on_ice_candidate;
   gst_webrtc_ice_class->get_local_candidates =
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/webrtc_fwd.h b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/webrtc_fwd.h
index e55684e183..d3556400ab 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/webrtc_fwd.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/webrtc/webrtc_fwd.h
@@ -308,7 +308,7 @@ typedef enum /*< underscore_name=gst_webrtc_dtls_setup >*/
  * @GST_WEBRTC_STATS_REMOTE_INBOUND_RTP: remote-inbound-rtp
  * @GST_WEBRTC_STATS_REMOTE_OUTBOUND_RTP: remote-outbound-rtp
  * @GST_WEBRTC_STATS_CSRC: csrc
- * @GST_WEBRTC_STATS_PEER_CONNECTION: peer-connectiion
+ * @GST_WEBRTC_STATS_PEER_CONNECTION: peer-connection
  * @GST_WEBRTC_STATS_DATA_CHANNEL: data-channel
  * @GST_WEBRTC_STATS_STREAM: stream
  * @GST_WEBRTC_STATS_TRANSPORT: transport
@@ -316,6 +316,8 @@ typedef enum /*< underscore_name=gst_webrtc_dtls_setup >*/
  * @GST_WEBRTC_STATS_LOCAL_CANDIDATE: local-candidate
  * @GST_WEBRTC_STATS_REMOTE_CANDIDATE: remote-candidate
  * @GST_WEBRTC_STATS_CERTIFICATE: certificate
+ *
+ * See <https://w3c.github.io/webrtc-stats/#dom-rtcstatstype>
  */
 typedef enum /*< underscore_name=gst_webrtc_stats_type >*/
 {
diff --git a/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.c b/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.c
index 6b5741f027..99e3edf3b3 100644
--- a/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.c
+++ b/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.c
@@ -62,6 +62,7 @@ struct _GstCodecTimestamperPrivate
   GstClockTime last_dts;
   GstClockTime dts_offset;
   GstClockTime time_adjustment;
+  GstClockTime last_pts;
 
   GstClockTime latency;
 };
@@ -188,6 +189,7 @@ gst_codec_timestamper_init (GstCodecTimestamper * self,
       g_array_sized_new (FALSE, FALSE, sizeof (GstClockTime), 16);
 
   g_rec_mutex_init (&priv->lock);
+  gst_segment_init (&priv->in_segment, GST_FORMAT_TIME);
 }
 
 static void
@@ -299,6 +301,7 @@ gst_codec_timestamper_flush (GstCodecTimestamper * self)
 
   priv->time_adjustment = GST_CLOCK_TIME_NONE;
   priv->last_dts = GST_CLOCK_TIME_NONE;
+  priv->last_pts = GST_CLOCK_TIME_NONE;
   g_rec_mutex_lock (&priv->lock);
   priv->latency = GST_CLOCK_TIME_NONE;
   g_rec_mutex_unlock (&priv->lock);
@@ -336,10 +339,10 @@ gst_codec_timestamper_sink_event (GstPad * pad, GstObject * parent,
       }
 
       /* Drain on segment update */
-      if (memcmp (&self->in_segment, &segment, sizeof (GstSegment)))
+      if (!gst_segment_is_equal (&priv->in_segment, &segment))
         gst_codec_timestamper_drain (self);
 
-      self->in_segment = segment;
+      priv->in_segment = segment;
       break;
     }
     case GST_EVENT_EOS:
@@ -482,6 +485,7 @@ gst_codec_timestamper_drain (GstCodecTimestamper * self)
 
   priv->time_adjustment = GST_CLOCK_TIME_NONE;
   priv->last_dts = GST_CLOCK_TIME_NONE;
+  priv->last_pts = GST_CLOCK_TIME_NONE;
 }
 
 static gint
@@ -514,9 +518,9 @@ gst_codec_timestamper_chain (GstPad * pad, GstObject * parent,
     GstClockTime start_time = GST_CLOCK_TIME_NONE;
 
     if (GST_CLOCK_TIME_IS_VALID (pts))
-      start_time = MAX (pts, self->in_segment.start);
+      start_time = MAX (pts, priv->in_segment.start);
     else if (GST_CLOCK_TIME_IS_VALID (dts))
-      start_time = MAX (dts, self->in_segment.start);
+      start_time = MAX (dts, priv->in_segment.start);
     else
       start_time = priv->in_segment.start;
 
@@ -540,6 +544,14 @@ gst_codec_timestamper_chain (GstPad * pad, GstObject * parent,
     return ret;
   }
 
+  /* workaround h264/5parse producing pts=NONE buffers when provided with
+   * the same timestamps on sequential buffers */
+  if (GST_CLOCK_TIME_IS_VALID (pts)) {
+    priv->last_pts = pts;
+  } else if (GST_CLOCK_TIME_IS_VALID (priv->last_pts)) {
+    pts = priv->last_pts;
+  }
+
   frame.pts = pts;
   frame.buffer = buffer;
   frame.events = priv->current_frame_events;
@@ -603,6 +615,7 @@ gst_codec_timestamper_reset (GstCodecTimestamper * self)
   priv->latency = GST_CLOCK_TIME_NONE;
   priv->window_size = 0;
   priv->last_dts = GST_CLOCK_TIME_NONE;
+  priv->last_pts = GST_CLOCK_TIME_NONE;
 
   if (priv->current_frame_events) {
     g_list_free_full (priv->current_frame_events,
diff --git a/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.h b/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.h
index 0abb8bd52b..ac9d50bb37 100644
--- a/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.h
+++ b/subprojects/gst-plugins-bad/gst/codectimestamper/gstcodectimestamper.h
@@ -40,8 +40,6 @@ struct _GstCodecTimestamper
   GstPad *sinkpad;
   GstPad *srcpad;
 
-  GstSegment in_segment;
-
   GstCodecTimestamperPrivate *priv;
 };
 
diff --git a/subprojects/gst-plugins-bad/gst/debugutils/gstvideocodectestsink.c b/subprojects/gst-plugins-bad/gst/debugutils/gstvideocodectestsink.c
index 0416659634..468957edd9 100644
--- a/subprojects/gst-plugins-bad/gst/debugutils/gstvideocodectestsink.c
+++ b/subprojects/gst-plugins-bad/gst/debugutils/gstvideocodectestsink.c
@@ -80,7 +80,8 @@ GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
     GST_STATIC_CAPS ("video/x-raw, format = { "
-        "I422_10LE, I420_10LE, Y42B, I420, NV12 }"));
+        "Y444_12LE, I422_12LE, I420_12LE,"
+        "Y444_10LE, I422_10LE, I420_10LE, Y444, Y42B, I420, NV12 }"));
 
 #define gst_video_codec_test_sink_parent_class parent_class
 G_DEFINE_TYPE (GstVideoCodecTestSink, gst_video_codec_test_sink,
@@ -315,6 +316,11 @@ gst_video_codec_test_sink_set_caps (GstBaseSink * sink, GstCaps * caps)
     case GST_VIDEO_FORMAT_I420_10LE:
     case GST_VIDEO_FORMAT_Y42B:
     case GST_VIDEO_FORMAT_I422_10LE:
+    case GST_VIDEO_FORMAT_I420_12LE:
+    case GST_VIDEO_FORMAT_I422_12LE:
+    case GST_VIDEO_FORMAT_Y444:
+    case GST_VIDEO_FORMAT_Y444_10LE:
+    case GST_VIDEO_FORMAT_Y444_12LE:
       self->process = gst_video_codec_test_sink_process_i42x;
       break;
     case GST_VIDEO_FORMAT_NV12:
diff --git a/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc-util.c b/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc-util.c
index c9a152b19c..e1e8d046ee 100644
--- a/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc-util.c
+++ b/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc-util.c
@@ -721,9 +721,35 @@ dvbenc_write_region_segment (GstByteWriter * b, int object_version, int page_id,
   gst_byte_writer_set_pos (b, pos);
 }
 
+static void
+dvbenc_write_display_definition_segment (GstByteWriter * b, int object_version,
+    int page_id, guint16 width, guint16 height)
+{
+  guint seg_size_pos, pos;
+
+  gst_byte_writer_put_uint8 (b, DVB_SEGMENT_SYNC_BYTE);
+  gst_byte_writer_put_uint8 (b, DVB_SEGMENT_TYPE_DISPLAY_DEFINITION);
+  gst_byte_writer_put_uint16_be (b, page_id);
+
+  /* Size placeholder */
+  seg_size_pos = gst_byte_writer_get_pos (b);
+  gst_byte_writer_put_uint16_be (b, 0);
+
+  /* version number, display window flag, reserved bits */
+  gst_byte_writer_put_uint8 (b, (object_version << 4) | (0 << 3) | 0x07);
+  gst_byte_writer_put_uint16_be (b, width);
+  gst_byte_writer_put_uint16_be (b, height);
+
+  /* Re-write the size field */
+  pos = gst_byte_writer_get_pos (b);
+  gst_byte_writer_set_pos (b, seg_size_pos);
+  gst_byte_writer_put_uint16_be (b, pos - (seg_size_pos + 2));
+  gst_byte_writer_set_pos (b, pos);
+}
+
 GstBuffer *
-gst_dvbenc_encode (int object_version, int page_id, SubpictureRect * s,
-    guint num_subpictures)
+gst_dvbenc_encode (int object_version, int page_id, int display_version,
+    guint16 width, guint16 height, SubpictureRect * s, guint num_subpictures)
 {
   GstByteWriter b;
   guint seg_size_pos, pos;
@@ -744,6 +770,11 @@ gst_dvbenc_encode (int object_version, int page_id, SubpictureRect * s,
    * 0x20 0x00 prefixed */
   gst_byte_writer_put_uint16_be (&b, 0x2000);
 
+  /* If non-default width/height are used, write a display definiton segment */
+  if (width != 720 || height != 576)
+    dvbenc_write_display_definition_segment (&b, display_version, page_id,
+        width, height);
+
   /* Page Composition Segment */
   gst_byte_writer_put_uint8 (&b, DVB_SEGMENT_SYNC_BYTE);
   gst_byte_writer_put_uint8 (&b, DVB_SEGMENT_TYPE_PAGE_COMPOSITION);
diff --git a/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.c b/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.c
index ab25ae24f7..ad316f78bc 100644
--- a/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.c
+++ b/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.c
@@ -393,7 +393,9 @@ process_largest_subregion (GstDvbSubEnc * enc, GstVideoFrame * vframe)
     s.x = left;
     s.y = top;
 
-    packet = gst_dvbenc_encode (enc->object_version & 0xF, 1, &s, 1);
+    packet =
+        gst_dvbenc_encode (enc->object_version & 0xF, 1, enc->display_version,
+        enc->in_info.width, enc->in_info.height, &s, 1);
     if (packet == NULL) {
       gst_video_frame_unmap (&ayuv8p_frame);
       goto fail;
@@ -440,7 +442,9 @@ gst_dvb_sub_enc_generate_end_packet (GstDvbSubEnc * enc, GstClockTime pts)
   GST_DEBUG_OBJECT (enc, "Outputting end of page at TS %" GST_TIME_FORMAT,
       GST_TIME_ARGS (enc->current_end_time));
 
-  packet = gst_dvbenc_encode (enc->object_version & 0xF, 1, NULL, 0);
+  packet =
+      gst_dvbenc_encode (enc->object_version & 0xF, 1, enc->display_version,
+      enc->in_info.width, enc->in_info.height, NULL, 0);
   if (packet == NULL) {
     GST_ELEMENT_ERROR (enc, STREAM, FAILED,
         ("Internal data stream error."),
@@ -501,27 +505,34 @@ gst_dvb_sub_enc_sink_setcaps (GstPad * pad, GstCaps * caps)
 {
   GstDvbSubEnc *enc = GST_DVB_SUB_ENC (gst_pad_get_parent (pad));
   gboolean ret = FALSE;
+  GstVideoInfo in_info;
   GstCaps *out_caps = NULL;
 
   GST_DEBUG_OBJECT (enc, "setcaps called with %" GST_PTR_FORMAT, caps);
-  if (!gst_video_info_from_caps (&enc->in_info, caps)) {
+  if (!gst_video_info_from_caps (&in_info, caps)) {
     GST_ERROR_OBJECT (enc, "Failed to parse input caps");
     return FALSE;
   }
 
-  out_caps = gst_caps_new_simple ("subpicture/x-dvb",
-      "width", G_TYPE_INT, enc->in_info.width,
-      "height", G_TYPE_INT, enc->in_info.height,
-      "framerate", GST_TYPE_FRACTION, enc->in_info.fps_n, enc->in_info.fps_d,
-      NULL);
+  if (!enc->in_info.finfo || !gst_video_info_is_equal (&in_info, &enc->in_info)) {
+    enc->in_info = in_info;
+    enc->display_version++;
+
+    out_caps = gst_caps_new_simple ("subpicture/x-dvb",
+        "width", G_TYPE_INT, enc->in_info.width,
+        "height", G_TYPE_INT, enc->in_info.height,
+        "framerate", GST_TYPE_FRACTION, enc->in_info.fps_n, enc->in_info.fps_d,
+        NULL);
+
+    if (!gst_pad_set_caps (enc->srcpad, out_caps)) {
+      GST_WARNING_OBJECT (enc, "failed setting downstream caps");
+      gst_caps_unref (out_caps);
+      goto beach;
+    }
 
-  if (!gst_pad_set_caps (enc->srcpad, out_caps)) {
-    GST_WARNING_OBJECT (enc, "failed setting downstream caps");
     gst_caps_unref (out_caps);
-    goto beach;
   }
 
-  gst_caps_unref (out_caps);
   ret = TRUE;
 
 beach:
diff --git a/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.h b/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.h
index 507e9f54d7..c43c6b1a97 100644
--- a/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.h
+++ b/subprojects/gst-plugins-bad/gst/dvbsubenc/gstdvbsubenc.h
@@ -47,6 +47,7 @@ struct _GstDvbSubEnc
   GstElement element;
 
   GstVideoInfo in_info;
+  int display_version;
   GstPad *sinkpad;
   GstPad *srcpad;
 
@@ -68,4 +69,4 @@ GST_ELEMENT_REGISTER_DECLARE (dvbsubenc);
 
 gboolean gst_dvbsubenc_ayuv_to_ayuv8p (GstVideoFrame * src, GstVideoFrame * dest, int max_colours, guint32 *out_num_colours);
 
-GstBuffer *gst_dvbenc_encode (int object_version, int page_id, SubpictureRect *s, guint num_subpictures);
+GstBuffer *gst_dvbenc_encode (int object_version, int page_id, int display_version, guint16 width, guint16 height, SubpictureRect *s, guint num_subpictures);
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c
index 981019360f..d18475b3a0 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c
@@ -765,6 +765,7 @@ mpegts_base_update_program (MpegTSBase * base, MpegTSBaseProgram * program,
     MpegTSBaseStream *stream = (MpegTSBaseStream *) tmp->data;
     mpegts_base_program_remove_stream (base, program, stream->pid);
   }
+  g_list_free (toremove);
   return TRUE;
 }
 
@@ -1203,6 +1204,10 @@ mpegts_base_apply_pmt (MpegTSBase * base, GstMpegtsSection * section)
   if (G_UNLIKELY (old_program == NULL))
     goto no_program;
 
+  if (G_UNLIKELY (mpegts_base_is_same_program (base, old_program, section->pid,
+              pmt)))
+    goto same_program;
+
   if (base->streams_aware
       && mpegts_base_is_program_update (base, old_program, section->pid, pmt)) {
     GST_FIXME ("We are streams_aware and new program is an update");
@@ -1211,10 +1216,6 @@ mpegts_base_apply_pmt (MpegTSBase * base, GstMpegtsSection * section)
     goto beach;
   }
 
-  if (G_UNLIKELY (mpegts_base_is_same_program (base, old_program, section->pid,
-              pmt)))
-    goto same_program;
-
   /* If the current program is active, this means we have a new program */
   if (old_program->active) {
     MpegTSBaseClass *klass = GST_MPEGTS_BASE_GET_CLASS (base);
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c
index 869f1345ee..7514b29729 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c
@@ -157,7 +157,7 @@ find_subtable (GSList * subtables, guint8 table_id, guint16 subtable_extension)
 static gboolean
 seen_section_before (MpegTSPacketizerStream * stream, guint8 table_id,
     guint16 subtable_extension, guint8 version_number, guint8 section_number,
-    guint8 last_section_number, guint8 * data_start, gsize to_read)
+    guint8 last_section_number)
 {
   MpegTSPacketizerStreamSubtable *subtable;
 
@@ -178,17 +178,7 @@ seen_section_before (MpegTSPacketizerStream * stream, guint8 table_id,
     return FALSE;
   }
   /* Finally return whether we saw that section or not */
-  if (!MPEGTS_BIT_IS_SET (subtable->seen_section, section_number)) {
-    GST_DEBUG ("Different section_number");
-    return FALSE;
-  }
-
-  if (stream->section_data) {
-    /* Everything else is the same, fall back to memcmp */
-    return (memcmp (stream->section_data, data_start, to_read) != 0);
-  }
-
-  return FALSE;
+  return MPEGTS_BIT_IS_SET (subtable->seen_section, section_number);
 }
 
 static MpegTSPacketizerStreamSubtable *
@@ -1203,8 +1193,7 @@ section_start:
    * * same section_number was seen
    */
   if (seen_section_before (stream, table_id, subtable_extension,
-          version_number, section_number, last_section_number, data_start,
-          to_read)) {
+          version_number, section_number, last_section_number)) {
     GST_DEBUG
         ("PID 0x%04x Already processed table_id:0x%02x subtable_extension:0x%04x, version_number:%d, section_number:%d",
         packet->pid, table_id, subtable_extension, version_number,
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c
index 6408c9becc..8adefeba67 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c
@@ -2231,6 +2231,9 @@ gst_ts_demux_update_program (MpegTSBase * base, MpegTSBaseProgram * program)
         gst_pad_push_event (stream->pad, gst_event_new_gap (0, 0));
       }
     }
+    if (stream->pad)
+      gst_pad_push_event (stream->pad,
+          gst_event_new_stream_collection (program->collection));
   }
 }
 
@@ -2317,6 +2320,9 @@ gst_ts_demux_program_started (MpegTSBase * base, MpegTSBaseProgram * program)
         GST_DEBUG_OBJECT (stream->pad, "sparse stream, pushing GAP event");
         gst_pad_push_event (stream->pad, gst_event_new_gap (0, 0));
       }
+      if (stream->pad)
+        gst_pad_push_event (stream->pad,
+            gst_event_new_stream_collection (program->collection));
     }
 
     gst_element_no_more_pads ((GstElement *) demux);
@@ -2732,13 +2738,16 @@ gst_ts_demux_queue_data (GstTSDemux * demux, TSDemuxStream * stream,
         }
         stream->state = PENDING_PACKET_HEADER;
       } else {
+        gchar *pad_name = gst_pad_get_name (stream->pad);
         GST_ELEMENT_WARNING_WITH_DETAILS (demux, STREAM, DEMUX,
             ("CONTINUITY: Mismatch packet %d, stream %d (pid 0x%04x)", cc,
                 stream->continuity_counter, stream->stream.pid), (NULL),
             ("warning-type", G_TYPE_STRING, "continuity-mismatch",
                 "packet", G_TYPE_INT, cc,
                 "stream", G_TYPE_INT, stream->continuity_counter,
-                "pid", G_TYPE_UINT, stream->stream.pid, NULL));
+                "pid", G_TYPE_UINT, stream->stream.pid,
+                "pad-name", G_TYPE_STRING, pad_name, NULL));
+        g_free (pad_name);
         stream->state = PENDING_PACKET_DISCONT;
       }
     }
diff --git a/subprojects/gst-plugins-bad/gst/transcode/gst-cpu-throttling-clock.c b/subprojects/gst-plugins-bad/gst/transcode/gst-cpu-throttling-clock.c
index 45bb51a12f..31dfa8295b 100644
--- a/subprojects/gst-plugins-bad/gst/transcode/gst-cpu-throttling-clock.c
+++ b/subprojects/gst-plugins-bad/gst/transcode/gst-cpu-throttling-clock.c
@@ -165,6 +165,10 @@ gst_cpu_throttling_clock_dispose (GObject * object)
     gst_clock_id_unref (self->priv->evaluate_wait_time);
     self->priv->evaluate_wait_time = 0;
   }
+  if (self->priv->timer) {
+    gst_poll_free (self->priv->timer);
+    self->priv->timer = NULL;
+  }
 }
 
 static void
diff --git a/subprojects/gst-plugins-bad/gst/transcode/gsttranscodebin.c b/subprojects/gst-plugins-bad/gst/transcode/gsttranscodebin.c
index 3e764714a4..aab0bbd9a3 100644
--- a/subprojects/gst-plugins-bad/gst/transcode/gsttranscodebin.c
+++ b/subprojects/gst-plugins-bad/gst/transcode/gsttranscodebin.c
@@ -90,6 +90,8 @@ transcoding_stream_free (TranscodingStream * tstream)
 {
   gst_object_unref (tstream->stream);
   gst_object_unref (tstream->encodebin_pad);
+
+  g_free (tstream);
 }
 
 typedef struct
@@ -175,15 +177,16 @@ filter_handles_any (GstElement * filter)
 
 static GstPad *
 _insert_filter (GstTranscodeBin * self, GstPad * sinkpad, GstPad * pad,
-    GstCaps * caps)
+    const GstCaps * filtercaps)
 {
   GstPad *filter_src = NULL, *filter_sink = NULL, *convert_sink, *convert_src;
   GstElement *filter = NULL, *convert;
   GstObject *filter_parent;
   const gchar *media_type;
   gboolean audio = TRUE;
+  GstCaps *caps;
 
-  media_type = gst_structure_get_name (gst_caps_get_structure (caps, 0));
+  media_type = gst_structure_get_name (gst_caps_get_structure (filtercaps, 0));
 
   if (self->video_filter && g_str_has_prefix (media_type, "video")) {
     audio = FALSE;
@@ -193,7 +196,7 @@ _insert_filter (GstTranscodeBin * self, GstPad * sinkpad, GstPad * pad,
       filter = self->video_filter;
     else
       GST_ERROR_OBJECT (pad, "decodebin pad does not produce raw data (%"
-          GST_PTR_FORMAT "), cannot add video filter '%s'", caps,
+          GST_PTR_FORMAT "), cannot add video filter '%s'", filtercaps,
           GST_ELEMENT_NAME (self->video_filter));
   } else if (self->audio_filter && g_str_has_prefix (media_type, "audio")) {
     if (!g_strcmp0 (media_type, "audio/x-raw")
@@ -201,7 +204,7 @@ _insert_filter (GstTranscodeBin * self, GstPad * sinkpad, GstPad * pad,
       filter = self->audio_filter;
     else
       GST_ERROR_OBJECT (pad, "decodebin pad does not produce raw data (%"
-          GST_PTR_FORMAT "), cannot add audio filter '%s'", caps,
+          GST_PTR_FORMAT "), cannot add audio filter '%s'", filtercaps,
           GST_ELEMENT_NAME (self->audio_filter));
   }
 
@@ -342,7 +345,7 @@ static void
 gst_transcode_bin_link_encodebin_pad (GstTranscodeBin * self, GstPad * pad,
     GstEvent * sstart)
 {
-  GstCaps *caps;
+  GstCaps *caps, *filtercaps;
   GstPadLinkReturn lret;
   const gchar *stream_id;
   TranscodingStream *stream;
@@ -357,6 +360,8 @@ gst_transcode_bin_link_encodebin_pad (GstTranscodeBin * self, GstPad * pad,
       gst_event_parse_stream (sstart, &tmpstream);
 
       stream = setup_stream (self, tmpstream);
+
+      gst_object_unref (tmpstream);
     }
 
     if (!stream) {
@@ -366,8 +371,9 @@ gst_transcode_bin_link_encodebin_pad (GstTranscodeBin * self, GstPad * pad,
     }
   }
 
-  caps = gst_pad_query_caps (pad, NULL);
-  pad = _insert_filter (self, stream->encodebin_pad, pad, caps);
+  filtercaps = gst_pad_query_caps (pad, NULL);
+  pad = _insert_filter (self, stream->encodebin_pad, pad, filtercaps);
+  gst_caps_unref (filtercaps);
   lret = gst_pad_link (pad, stream->encodebin_pad);
   switch (lret) {
     case GST_PAD_LINK_OK:
@@ -507,7 +513,7 @@ no_profile:
 }
 
 static GstPad *
-get_encodebin_pad_for_caps (GstTranscodeBin * self, GstCaps * srccaps)
+get_encodebin_pad_for_caps (GstTranscodeBin * self, const GstCaps * srccaps)
 {
   GstPad *res = NULL;
   GstIterator *pads;
@@ -606,6 +612,7 @@ get_encodebin_pad_from_stream (GstTranscodeBin * self, GstStream * stream)
     sinkpad = get_encodebin_pad_for_caps (self, caps);
   }
 
+  gst_caps_unref (caps);
   return sinkpad;
 }
 
@@ -677,9 +684,11 @@ _setup_avoid_reencoding (GstTranscodeBin * self)
 
     restrictions = gst_encoding_profile_get_restriction (profile);
 
-    if (restrictions && gst_caps_is_any (restrictions)) {
+    if (restrictions) {
+      gboolean is_any = gst_caps_is_any (restrictions);
       gst_caps_unref (restrictions);
-      continue;
+      if (is_any)
+        continue;
     }
 
     encodecaps = gst_encoding_profile_get_format (profile);
@@ -852,6 +861,7 @@ gst_transcode_bin_dispose (GObject * object)
   g_clear_object (&self->video_filter);
   g_clear_object (&self->audio_filter);
   g_clear_pointer (&self->transcoding_streams, g_ptr_array_unref);
+  gst_clear_object (&self->profile);
 
   G_OBJECT_CLASS (gst_transcode_bin_parent_class)->dispose (object);
 }
diff --git a/subprojects/gst-plugins-bad/gst/transcode/gsturitranscodebin.c b/subprojects/gst-plugins-bad/gst/transcode/gsturitranscodebin.c
index 9e42856114..eae77a3247 100644
--- a/subprojects/gst-plugins-bad/gst/transcode/gsturitranscodebin.c
+++ b/subprojects/gst-plugins-bad/gst/transcode/gsturitranscodebin.c
@@ -225,6 +225,7 @@ transcodebin_pad_added_cb (GstElement * transcodebin, GstPad * pad,
         sinkpad);
     /* Let `pad unlinked` error pop up later */
   }
+  gst_object_unref (sinkpad);
 }
 
 static gboolean
@@ -506,6 +507,9 @@ gst_uri_transcode_bin_dispose (GObject * object)
   g_clear_object (&self->video_filter);
   g_clear_object (&self->audio_filter);
   g_clear_object (&self->cpu_clock);
+  g_free (self->source_uri);
+  g_free (self->dest_uri);
+  gst_clear_object (&self->profile);
 
   G_OBJECT_CLASS (gst_uri_transcode_bin_parent_class)->dispose (object);
 }
@@ -599,11 +603,13 @@ gst_uri_transcode_bin_set_property (GObject * object,
       break;
     case PROP_AUDIO_FILTER:
       GST_OBJECT_LOCK (self);
+      gst_object_unref (self->audio_filter);
       self->audio_filter = g_value_dup_object (value);
       GST_OBJECT_UNLOCK (self);
       break;
     case PROP_VIDEO_FILTER:
       GST_OBJECT_LOCK (self);
+      gst_object_unref (self->video_filter);
       self->video_filter = g_value_dup_object (value);
       GST_OBJECT_UNLOCK (self);
       break;
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c
index fee08c4902..2ecc7fabc3 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c
@@ -1275,6 +1275,10 @@ gst_h264_parse_handle_frame_packetized (GstBaseParse * parse,
       tmp_frame.overhead = frame->overhead;
       tmp_frame.buffer = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
           nalu.offset, nalu.size);
+      /* Don't lose timestamp when offset is not 0. */
+      GST_BUFFER_PTS (tmp_frame.buffer) = GST_BUFFER_PTS (buffer);
+      GST_BUFFER_DTS (tmp_frame.buffer) = GST_BUFFER_DTS (buffer);
+      GST_BUFFER_DURATION (tmp_frame.buffer) = GST_BUFFER_DURATION (buffer);
 
       /* Set marker on last packet */
       if (nl + nalu.size == left) {
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c
index 54aa77e800..356385c37d 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c
@@ -1061,6 +1061,10 @@ gst_h265_parse_handle_frame_packetized (GstBaseParse * parse,
       tmp_frame.overhead = frame->overhead;
       tmp_frame.buffer = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
           nalu.offset, nalu.size);
+      /* Don't lose timestamp when offset is not 0. */
+      GST_BUFFER_PTS (tmp_frame.buffer) = GST_BUFFER_PTS (buffer);
+      GST_BUFFER_DTS (tmp_frame.buffer) = GST_BUFFER_DTS (buffer);
+      GST_BUFFER_DURATION (tmp_frame.buffer) = GST_BUFFER_DURATION (buffer);
 
       /* Set marker on last packet */
       if (nl + nalu.size == left) {
diff --git a/subprojects/gst-plugins-bad/meson.build b/subprojects/gst-plugins-bad/meson.build
index 5034ea4142..ae4a0ba79d 100644
--- a/subprojects/gst-plugins-bad/meson.build
+++ b/subprojects/gst-plugins-bad/meson.build
@@ -1,5 +1,5 @@
 project('gst-plugins-bad', 'c', 'cpp',
-  version : '1.21.2',
+  version : '1.21.2.1',
   meson_version : '>= 0.62',
   default_options : [ 'warning_level=1',
                       'buildtype=debugoptimized' ])
diff --git a/subprojects/gst-plugins-bad/meson_options.txt b/subprojects/gst-plugins-bad/meson_options.txt
index ad123512be..55f8e9e0c0 100644
--- a/subprojects/gst-plugins-bad/meson_options.txt
+++ b/subprojects/gst-plugins-bad/meson_options.txt
@@ -174,6 +174,7 @@ option('webrtc', type : 'feature', value : 'auto', description : 'WebRTC audio/v
 option('webrtcdsp', type : 'feature', value : 'auto', description : 'Plugin with various audio filters provided by the WebRTC audio processing library')
 option('wildmidi', type : 'feature', value : 'auto', description : 'WildMidi midi soft synth plugin')
 option('wic', type : 'feature', value : 'auto', description : 'Windows Imaging Component plugin')
+option('win32ipc', type : 'feature', value : 'auto', description : 'Windows IPC plugin')
 option('winks', type : 'feature', value : 'auto', description : 'Windows Kernel Streaming video source plugin')
 option('winscreencap', type : 'feature', value : 'auto', description : 'Windows Screen Capture video source plugin')
 option('x265', type : 'feature', value : 'auto', description : 'HEVC/H.265 video encoder plugin (GPL - only built if gpl option is also enabled!)')
diff --git a/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh264enc.cpp b/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh264enc.cpp
index 858ae2f3d4..cb29720bbf 100644
--- a/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh264enc.cpp
+++ b/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh264enc.cpp
@@ -347,7 +347,7 @@ static gboolean gst_amf_h264_enc_set_format (GstAmfEncoder * encoder,
     GstVideoCodecState * state, gpointer component);
 static gboolean gst_amf_h264_enc_set_output_state (GstAmfEncoder * encoder,
     GstVideoCodecState * state, gpointer component);
-static gboolean gst_amf_h264_enc_set_surfrace_prop (GstAmfEncoder * encoder,
+static gboolean gst_amf_h264_enc_set_surface_prop (GstAmfEncoder * encoder,
     GstVideoCodecFrame * frame, gpointer surface);
 static GstBuffer *gst_amf_h264_enc_create_output_buffer (GstAmfEncoder *
     encoder, gpointer data, gboolean * sync_point);
@@ -455,7 +455,7 @@ gst_amf_h264_enc_class_init (GstAmfH264EncClass * klass, gpointer data)
   amf_class->set_output_state =
       GST_DEBUG_FUNCPTR (gst_amf_h264_enc_set_output_state);
   amf_class->set_surface_prop =
-      GST_DEBUG_FUNCPTR (gst_amf_h264_enc_set_surfrace_prop);
+      GST_DEBUG_FUNCPTR (gst_amf_h264_enc_set_surface_prop);
   amf_class->create_output_buffer =
       GST_DEBUG_FUNCPTR (gst_amf_h264_enc_create_output_buffer);
   amf_class->check_reconfigure =
@@ -1210,7 +1210,7 @@ gst_amf_h264_enc_set_output_state (GstAmfEncoder * encoder,
 }
 
 static gboolean
-gst_amf_h264_enc_set_surfrace_prop (GstAmfEncoder * encoder,
+gst_amf_h264_enc_set_surface_prop (GstAmfEncoder * encoder,
     GstVideoCodecFrame * frame, gpointer surface)
 {
   GstAmfH264Enc *self = GST_AMF_H264_ENC (encoder);
diff --git a/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh265enc.cpp b/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh265enc.cpp
index dabd9b5d17..396d20fad2 100644
--- a/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh265enc.cpp
+++ b/subprojects/gst-plugins-bad/sys/amfcodec/gstamfh265enc.cpp
@@ -340,7 +340,7 @@ static gboolean gst_amf_h265_enc_set_format (GstAmfEncoder * encoder,
     GstVideoCodecState * state, gpointer component);
 static gboolean gst_amf_h265_enc_set_output_state (GstAmfEncoder * encoder,
     GstVideoCodecState * state, gpointer component);
-static gboolean gst_amf_h265_enc_set_surfrace_prop (GstAmfEncoder * encoder,
+static gboolean gst_amf_h265_enc_set_surface_prop (GstAmfEncoder * encoder,
     GstVideoCodecFrame * frame, gpointer surface);
 static GstBuffer *gst_amf_h265_enc_create_output_buffer (GstAmfEncoder *
     encoder, gpointer data, gboolean * sync_point);
@@ -451,7 +451,7 @@ gst_amf_h265_enc_class_init (GstAmfH265EncClass * klass, gpointer data)
   amf_class->set_output_state =
       GST_DEBUG_FUNCPTR (gst_amf_h265_enc_set_output_state);
   amf_class->set_surface_prop =
-      GST_DEBUG_FUNCPTR (gst_amf_h265_enc_set_surfrace_prop);
+      GST_DEBUG_FUNCPTR (gst_amf_h265_enc_set_surface_prop);
   amf_class->create_output_buffer =
       GST_DEBUG_FUNCPTR (gst_amf_h265_enc_create_output_buffer);
   amf_class->check_reconfigure =
@@ -881,7 +881,7 @@ gst_amf_h265_enc_set_output_state (GstAmfEncoder * encoder,
 }
 
 static gboolean
-gst_amf_h265_enc_set_surfrace_prop (GstAmfEncoder * encoder,
+gst_amf_h265_enc_set_surface_prop (GstAmfEncoder * encoder,
     GstVideoCodecFrame * frame, gpointer surface)
 {
   GstAmfH265Enc *self = GST_AMF_H265_ENC (encoder);
diff --git a/subprojects/gst-plugins-bad/sys/amfcodec/plugin.cpp b/subprojects/gst-plugins-bad/sys/amfcodec/plugin.cpp
index 0b10e18417..825f3dfe22 100644
--- a/subprojects/gst-plugins-bad/sys/amfcodec/plugin.cpp
+++ b/subprojects/gst-plugins-bad/sys/amfcodec/plugin.cpp
@@ -105,9 +105,9 @@ plugin_init (GstPlugin * plugin)
 
     if (result == AMF_OK) {
       gst_amf_h264_enc_register_d3d11 (plugin, device,
-          (gpointer) context.GetPtr (), GST_RANK_NONE);
+          (gpointer) context.GetPtr (), GST_RANK_PRIMARY);
       gst_amf_h265_enc_register_d3d11 (plugin, device,
-          (gpointer) context.GetPtr (), GST_RANK_NONE);
+          (gpointer) context.GetPtr (), GST_RANK_PRIMARY);
     }
 
     gst_clear_object (&device);
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11av1dec.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11av1dec.cpp
index 7c3be5e79b..b178361640 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11av1dec.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11av1dec.cpp
@@ -1225,8 +1225,9 @@ gst_d3d11_av1_dec_output_picture (GstAV1Decoder * decoder,
   }
 
   if (!gst_d3d11_decoder_process_output (inner->d3d11_decoder, vdec,
-          picture->frame_hdr.render_width, picture->frame_hdr.render_height,
-          view_buffer, &frame->output_buffer)) {
+          picture->discont_state, picture->frame_hdr.render_width,
+          picture->frame_hdr.render_height, view_buffer,
+          &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to copy buffer");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.cpp
index 765172bf61..c9190726e5 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.cpp
@@ -1592,7 +1592,8 @@ gst_d3d11_decoder_crop_and_copy_buffer (GstD3D11Decoder * self,
 
 gboolean
 gst_d3d11_decoder_process_output (GstD3D11Decoder * decoder,
-    GstVideoDecoder * videodec, gint display_width, gint display_height,
+    GstVideoDecoder * videodec, GstVideoCodecState * input_state,
+    gint display_width, gint display_height,
     GstBuffer * decoder_buffer, GstBuffer ** output)
 {
   g_return_val_if_fail (GST_IS_D3D11_DECODER (decoder), FALSE);
@@ -1600,6 +1601,11 @@ gst_d3d11_decoder_process_output (GstD3D11Decoder * decoder,
   g_return_val_if_fail (GST_IS_BUFFER (decoder_buffer), FALSE);
   g_return_val_if_fail (output != NULL, FALSE);
 
+  if (input_state) {
+    g_clear_pointer (&decoder->input_state, gst_video_codec_state_unref);
+    decoder->input_state = gst_video_codec_state_ref (input_state);
+  }
+
   if (display_width != GST_VIDEO_INFO_WIDTH (&decoder->output_info) ||
       display_height != GST_VIDEO_INFO_HEIGHT (&decoder->output_info)) {
     GST_INFO_OBJECT (videodec, "Frame size changed, do renegotiate");
@@ -1613,6 +1619,11 @@ gst_d3d11_decoder_process_output (GstD3D11Decoder * decoder,
       GST_ERROR_OBJECT (videodec, "Failed to re-negotiate with new frame size");
       return FALSE;
     }
+  } else if (input_state) {
+    if (!gst_video_decoder_negotiate (videodec)) {
+      GST_ERROR_OBJECT (videodec, "Could not re-negotiate with updated state");
+      return FALSE;
+    }
   }
 
   if (gst_d3d11_decoder_can_direct_render (decoder, videodec, decoder_buffer,
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.h b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.h
index 8b2ceb6c15..d1e52b76e2 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.h
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11decoder.h
@@ -97,6 +97,7 @@ ID3D11VideoDecoderOutputView * gst_d3d11_decoder_get_output_view_from_buffer (Gs
 
 gboolean          gst_d3d11_decoder_process_output      (GstD3D11Decoder * decoder,
                                                          GstVideoDecoder * videodec,
+                                                         GstVideoCodecState * in_state,
                                                          gint display_width,
                                                          gint display_height,
                                                          GstBuffer * decoder_buffer,
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h264dec.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h264dec.cpp
index 100ead5db6..43499ad4ae 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h264dec.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h264dec.cpp
@@ -885,7 +885,8 @@ gst_d3d11_h264_dec_output_picture (GstH264Decoder * decoder,
   }
 
   if (!gst_d3d11_decoder_process_output (inner->d3d11_decoder, vdec,
-          inner->width, inner->height, view_buffer, &frame->output_buffer)) {
+          picture->discont_state, inner->width, inner->height, view_buffer,
+          &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to copy buffer");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h265dec.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h265dec.cpp
index 563fc66962..67c68979d2 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h265dec.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11h265dec.cpp
@@ -933,7 +933,8 @@ gst_d3d11_h265_dec_output_picture (GstH265Decoder * decoder,
   }
 
   if (!gst_d3d11_decoder_process_output (inner->d3d11_decoder, vdec,
-          inner->width, inner->height, view_buffer, &frame->output_buffer)) {
+          picture->discont_state, inner->width, inner->height, view_buffer,
+          &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to copy buffer");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11mpeg2dec.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11mpeg2dec.cpp
index 55498534a0..54406f7d1a 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11mpeg2dec.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11mpeg2dec.cpp
@@ -747,7 +747,8 @@ gst_d3d11_mpeg2_dec_output_picture (GstMpeg2Decoder * decoder,
   }
 
   if (!gst_d3d11_decoder_process_output (inner->d3d11_decoder, vdec,
-          inner->width, inner->height, view_buffer, &frame->output_buffer)) {
+          picture->discont_state, inner->width, inner->height, view_buffer,
+          &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to copy buffer");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturedevice.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturedevice.cpp
index ba3d63b4ab..01a87b2312 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturedevice.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturedevice.cpp
@@ -39,8 +39,8 @@ GST_DEBUG_CATEGORY_EXTERN (gst_d3d11_screen_capture_device_debug);
 
 static GstStaticCaps template_caps =
     GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE_WITH_FEATURES
-    (GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY, "BGRA") ";"
-    GST_VIDEO_CAPS_MAKE ("BGRA"));
+    (GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY, "BGRA") ", pixel-aspect-ratio = 1/1;"
+    GST_VIDEO_CAPS_MAKE ("BGRA") ", pixel-aspect-ratio = 1/1");
 
 enum
 {
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturesrc.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturesrc.cpp
index fbeeda2de4..d1f13d65ee 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturesrc.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11screencapturesrc.cpp
@@ -119,8 +119,8 @@ gst_d3d11_screen_capture_api_get_type (void)
 
 static GstStaticCaps template_caps =
     GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE_WITH_FEATURES
-    (GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY, "BGRA") ";"
-    GST_VIDEO_CAPS_MAKE ("BGRA"));
+    (GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY, "BGRA") ", pixel-aspect-ratio = 1/1;"
+    GST_VIDEO_CAPS_MAKE ("BGRA") ", pixel-aspect-ratio = 1/1");
 
 struct _GstD3D11ScreenCaptureSrc
 {
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp8dec.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp8dec.cpp
index 5e1ddb4e48..d933b49168 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp8dec.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp8dec.cpp
@@ -645,7 +645,8 @@ gst_d3d11_vp8_dec_output_picture (GstVp8Decoder * decoder,
   }
 
   if (!gst_d3d11_decoder_process_output (inner->d3d11_decoder, vdec,
-          inner->width, inner->height, view_buffer, &frame->output_buffer)) {
+          picture->discont_state, inner->width, inner->height, view_buffer,
+          &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to copy buffer");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp9dec.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp9dec.cpp
index 52efa02065..444307a78c 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp9dec.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11vp9dec.cpp
@@ -781,8 +781,8 @@ gst_d3d11_vp9_dec_output_picture (GstVp9Decoder * decoder,
   }
 
   if (!gst_d3d11_decoder_process_output (inner->d3d11_decoder, vdec,
-          picture->frame_hdr.width, picture->frame_hdr.height, view_buffer,
-          &frame->output_buffer)) {
+          picture->discont_state, picture->frame_hdr.width,
+          picture->frame_hdr.height, view_buffer, &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to copy buffer");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11winrtcapture.cpp b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11winrtcapture.cpp
index 3c2c2cbd7e..4c876f36cf 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11winrtcapture.cpp
+++ b/subprojects/gst-plugins-bad/sys/d3d11/gstd3d11winrtcapture.cpp
@@ -122,9 +122,6 @@ struct GstD3D11WinRTCaptureInner
 {
   ~GstD3D11WinRTCaptureInner()
   {
-    if (item)
-      item->remove_Closed (closed_token);
-
     CLOSE_COM (session);
     CLOSE_COM (pool);
     CLOSE_COM (item);
@@ -144,7 +141,6 @@ struct GstD3D11WinRTCaptureInner
   ComPtr < IGraphicsCaptureItem > item;
   ComPtr < IDirect3D11CaptureFramePool > pool;
   ComPtr < IGraphicsCaptureSession > session;
-  EventRegistrationToken closed_token;
 
   bool closed = false;
 };
@@ -441,17 +437,6 @@ gst_d3d11_winrt_configure (GstD3D11WinRTCapture * self)
     goto error;
   }
 
-  {
-    /* FIXME: This callback does not work for some reasons */
-    auto closed_handler = Callback < ITypedEventHandler < GraphicsCaptureItem *,
-        IInspectable * >>(inner, &GstD3D11WinRTCaptureInner::OnClosed);
-    hr = inner->item->add_Closed (closed_handler.Get (), &inner->closed_token);
-    if (!gst_d3d11_result (hr, self->device)) {
-      GST_ERROR_OBJECT (self, "Could not install closed callback");
-      goto error;
-    }
-  }
-
   hr = device_handle->QueryInterface (IID_PPV_ARGS (&dxgi_device));
   if (!gst_d3d11_result (hr, device)) {
     GST_WARNING_OBJECT (self, "IDXGIDevice is not available");
diff --git a/subprojects/gst-plugins-bad/sys/d3d11/meson.build b/subprojects/gst-plugins-bad/sys/d3d11/meson.build
index c4a140fff1..1368b79c3e 100644
--- a/subprojects/gst-plugins-bad/sys/d3d11/meson.build
+++ b/subprojects/gst-plugins-bad/sys/d3d11/meson.build
@@ -47,7 +47,7 @@ if d3d11_winapi_only_app and (not d3dcompiler_lib.found() or not runtimeobject_l
   subdir_done()
 endif
 
-win11_sdk = cxx.compiles('''
+have_wgc = cxx.compiles('''
     #include<windows.h>
     #include<winstring.h>
     #include<roapi.h>
@@ -65,7 +65,7 @@ win11_sdk = cxx.compiles('''
     ComPtr<IGraphicsCaptureSession2> session2;
     ComPtr<IGraphicsCaptureSession3> session3;
     ''',
-    name: 'building with Windows 11 SDK')
+    name: 'Windows Graphics Capture support in Windows SDK')
 
 # if build target is Windows 10 and WINAPI_PARTITION_APP is allowed,
 # we can build UWP only modules as well
@@ -88,7 +88,7 @@ if d3d11_winapi_desktop
     extra_dep += [winmm_lib]
   endif
 
-  if win11_sdk
+  if have_wgc
     d3d11_sources += ['gstd3d11winrtcapture.cpp']
     extra_args += ['-DHAVE_WINRT_CAPTURE']
   endif
diff --git a/subprojects/gst-plugins-bad/sys/directshow/plugin.cpp b/subprojects/gst-plugins-bad/sys/directshow/plugin.cpp
index 7db55a8179..b308858aac 100644
--- a/subprojects/gst-plugins-bad/sys/directshow/plugin.cpp
+++ b/subprojects/gst-plugins-bad/sys/directshow/plugin.cpp
@@ -60,7 +60,7 @@ plugin_init (GstPlugin * plugin)
       GST_RANK_NONE, GST_TYPE_DSHOWVIDEOSRC);
 
   gst_device_provider_register (plugin, "dshowdeviceprovider",
-      GST_RANK_MARGINAL, GST_TYPE_DSHOW_DEVICE_PROVIDER);
+      GST_RANK_NONE, GST_TYPE_DSHOW_DEVICE_PROVIDER);
 
   return TRUE;
 }
diff --git a/subprojects/gst-plugins-bad/sys/kms/gstkmsedid.c b/subprojects/gst-plugins-bad/sys/kms/gstkmsedid.c
new file mode 100644
index 0000000000..7c5221a585
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/kms/gstkmsedid.c
@@ -0,0 +1,111 @@
+/*
+* Copyright  2008-2011 Kristian Hgsberg
+* Copyright  2011 Intel Corporation
+* Copyright  2017, 2018 Collabora, Ltd.
+* Copyright  2017, 2018 General Electric Company
+* Copyright (c) 2018 DisplayLink (UK) Ltd.
+*
+* Permission is hereby granted, free of charge, to any person obtaining
+* a copy of this software and associated documentation files (the
+* "Software"), to deal in the Software without restriction, including
+* without limitation the rights to use, copy, modify, merge, publish,
+* distribute, sublicense, and/or sell copies of the Software, and to
+* permit persons to whom the Software is furnished to do so, subject to
+* the following conditions:
+*
+* The above copyright notice and this permission notice (including the
+* next paragraph) shall be included in all copies or substantial
+* portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+* EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+* NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+* BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+* ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+* CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+* SOFTWARE.
+*/
+
+#include <math.h>
+#include "gstkmsedid.h"
+
+/* from  libweston/backend-drm/modes.c unaccepted merge, modified slightly to
+    remove non HDR stuff, return -1 if no HDR in EDID.
+    https://gitlab.freedesktop.org/jcline/weston/-/commit/b3fa65d19ca60a45d0cc0fc1bfa68eea970344ee
+ */
+#define EDID_OFFSET_EXT_COUNT				0x7E
+#define EDID_EXTENSION_SIZE				0x80
+// Indicates the EDID extension is a CTA extension
+#define EDID_CTA_EXTENSION_TAG			0x02
+// Indicates the data block uses the extended tag field
+#define EDID_CTA_EXTENDED_TAG			0x07
+// Value of the extended tag field for HDR static metadata blocks
+#define EDID_CTA_STATIC_HDR_TAG			0x06
+
+/* Extract the HDR static metadata from a CTA EDID extension. */
+static int
+gst_kms_parse_hdr_metadata (const uint8_t * cta_ext_data,
+    struct gst_kms_hdr_static_metadata *metadata)
+{
+  int i, block_len;
+  uint8_t cta_revision = cta_ext_data[1];
+  uint8_t dtd_offset = cta_ext_data[2];
+  const uint8_t *data_blocks = cta_ext_data + 4;
+
+  if (cta_revision != 3) {
+    return -1;
+  }
+  // The data block collection ranges from byte 4 to the dtd_offset; each
+  // block begins with the block size (in bytes) in bits 0-4 of the first byte.
+  for (i = 0; i < dtd_offset; i += (data_blocks[i] & 0x1f) + 1) {
+    if ((data_blocks[i] & 0xe0) >> 5 == EDID_CTA_EXTENDED_TAG) {
+      block_len = data_blocks[i] & 0x1f;
+
+      if (data_blocks[i + 1] == EDID_CTA_STATIC_HDR_TAG) {
+        if (block_len < 2)
+          continue;
+
+        metadata->eotf = data_blocks[i + 2];
+        metadata->metadata_type = data_blocks[i + 3];
+
+        if (block_len > 3 && data_blocks[i + 4])
+          metadata->max_cll = 50.0 * pow (2, data_blocks[i + 4] / 32.0);
+        if (block_len > 4 && data_blocks[i + 5])
+          metadata->max_fall = 50.0 * pow (2, data_blocks[i + 5] / 32.0);
+        if (block_len > 5)
+          metadata->min_cll =
+              metadata->max_cll * pow (data_blocks[i + 6] / 255.0, 2) / 100.0;
+        return 0;
+      }
+    }
+  }
+  return -1;
+}
+
+int
+gst_kms_edid_parse (struct gst_kms_hdr_static_metadata *metadata,
+    const uint8_t * data, size_t length)
+{
+  int i;
+  const uint8_t *edid_extension;
+
+  /* check header */
+  if (length < 128 || length < ((size_t) data[EDID_OFFSET_EXT_COUNT] + 1) * 128)
+    return -1;
+  if (data[0] != 0x00 || data[1] != 0xff)
+    return -1;
+
+  edid_extension = data + 128;
+  for (i = 0; i < data[EDID_OFFSET_EXT_COUNT]; i++) {
+    switch (edid_extension[0]) {
+      case EDID_CTA_EXTENSION_TAG:
+        return gst_kms_parse_hdr_metadata (edid_extension, metadata);
+    }
+    edid_extension += 128;
+  }
+
+  return 0;
+}
+
+/* END from  libweston/backend-drm/modes.c unaccepted merge */
diff --git a/subprojects/gst-plugins-bad/sys/kms/gstkmsedid.h b/subprojects/gst-plugins-bad/sys/kms/gstkmsedid.h
new file mode 100644
index 0000000000..1907ae2549
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/kms/gstkmsedid.h
@@ -0,0 +1,55 @@
+/*
+  * Copyright  2008-2011 Kristian Hgsberg
+  * Copyright  2011 Intel Corporation
+  * Copyright  2017, 2018 Collabora, Ltd.
+  * Copyright  2017, 2018 General Electric Company
+  * Copyright (c) 2018 DisplayLink (UK) Ltd.
+  *
+  * Permission is hereby granted, free of charge, to any person obtaining
+  * a copy of this software and associated documentation files (the
+  * "Software"), to deal in the Software without restriction, including
+  * without limitation the rights to use, copy, modify, merge, publish,
+  * distribute, sublicense, and/or sell copies of the Software, and to
+  * permit persons to whom the Software is furnished to do so, subject to
+  * the following conditions:
+  *
+  * The above copyright notice and this permission notice (including the
+  * next paragraph) shall be included in all copies or substantial
+  * portions of the Software.
+  *
+  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+  * NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+  * SOFTWARE.
+  */
+
+#ifndef __GST_KMS_EDID_H__
+#define __GST_KMS_EDID_H__
+
+/* from  libweston/backend-drm/modes.c unaccepted merge, modified slightly to
+    remove non HDR stuff, return -1 if no HDR in EDID.
+    https://gitlab.freedesktop.org/jcline/weston/-/commit/b3fa65d19ca60a45d0cc0fc1bfa68eea970344ee
+ */
+
+#include <stddef.h>
+#include <stdint.h>
+
+/* HDR Metadata as per 861.G spec from linux/hdmi.h, modified for stdint.h */
+struct gst_kms_hdr_static_metadata
+{
+  uint8_t eotf;
+  uint8_t metadata_type;
+  uint16_t max_cll;
+  uint16_t max_fall;
+  uint16_t min_cll;
+};
+
+int
+gst_kms_edid_parse (struct gst_kms_hdr_static_metadata *metadata, const uint8_t * data,
+    size_t length);
+
+#endif /* __GST_KMS_EDID_H__ */
diff --git a/subprojects/gst-plugins-bad/sys/kms/gstkmssink.c b/subprojects/gst-plugins-bad/sys/kms/gstkmssink.c
index cba6a36ec8..16d4afb8a0 100644
--- a/subprojects/gst-plugins-bad/sys/kms/gstkmssink.c
+++ b/subprojects/gst-plugins-bad/sys/kms/gstkmssink.c
@@ -49,6 +49,7 @@
 
 #include <gst/video/video.h>
 #include <gst/video/videooverlay.h>
+#include <gst/video/video-color.h>
 #include <gst/allocators/gstdmabuf.h>
 
 #include <drm.h>
@@ -62,6 +63,11 @@
 #include "gstkmsbufferpool.h"
 #include "gstkmsallocator.h"
 
+#ifdef HAVE_DRM_HDR
+#include <math.h>
+#include "gstkmsedid.h"
+#endif
+
 #define GST_PLUGIN_NAME "kmssink"
 #define GST_PLUGIN_DESC "Video sink using the Linux kernel mode setting API"
 
@@ -98,11 +104,309 @@ enum
   PROP_CONNECTOR_PROPS,
   PROP_PLANE_PROPS,
   PROP_FD,
+  PROP_SKIP_VSYNC,
   PROP_N,
 };
 
 static GParamSpec *g_properties[PROP_N] = { NULL, };
 
+#ifdef HAVE_DRM_HDR
+enum hdmi_metadata_type
+{
+  HDMI_STATIC_METADATA_TYPE1 = 0,
+};
+enum hdmi_eotf
+{
+  HDMI_EOTF_TRADITIONAL_GAMMA_SDR = 0,
+  HDMI_EOTF_TRADITIONAL_GAMMA_HDR,
+  HDMI_EOTF_SMPTE_ST2084,
+  HDMI_EOTF_BT_2100_HLG,
+};
+
+static void
+gst_kms_populate_infoframe (struct hdr_output_metadata *pinfo_frame,
+    GstVideoMasteringDisplayInfo * p_hdr_minfo,
+    GstVideoContentLightLevel * p_hdr_cll,
+    gchar colorimetry, gboolean clear_it_out)
+{
+  /* From CTA-861.3:
+   * When a source is transmitting the Dynamic Range and Mastering InfoFrame,
+   * it shall signal the end of Dynamic Range... by sending a ... InfoFrame with
+   * the EOTF field to '0', the Static_Metadata_Descriptor_ID field set to '0',
+   * and the fields of the Static_Metadata_Descriptor set to unknown (0)...
+   *
+   * See also https://dri.freedesktop.org/docs/drm/gpu/drm-uapi.html
+   */
+  if (clear_it_out) {
+    /* Static_Metadata_Descriptor_ID */
+    pinfo_frame->metadata_type = 0;
+    (void) memset ((void *) &pinfo_frame->hdmi_metadata_type1, 0,
+        sizeof (pinfo_frame->hdmi_metadata_type1));
+    return;
+  } else {
+    pinfo_frame->metadata_type = HDMI_STATIC_METADATA_TYPE1;
+    pinfo_frame->hdmi_metadata_type1.eotf = colorimetry;
+    pinfo_frame->hdmi_metadata_type1.metadata_type = HDMI_STATIC_METADATA_TYPE1;
+  }
+
+  /* For HDR Infoframe see CTA-861-G, Section 6.9.1
+   * SEI message is in units of 0.0001 cd/m2, HDMI is units of 1 cd/m2 - see
+   * x265 specs */
+  pinfo_frame->hdmi_metadata_type1.max_display_mastering_luminance =
+      round (p_hdr_minfo->max_display_mastering_luminance / 10000.0);
+  pinfo_frame->hdmi_metadata_type1.min_display_mastering_luminance =
+      p_hdr_minfo->min_display_mastering_luminance;
+
+  pinfo_frame->hdmi_metadata_type1.max_cll = p_hdr_cll->max_content_light_level;
+  pinfo_frame->hdmi_metadata_type1.max_fall =
+      p_hdr_cll->max_frame_average_light_level;
+
+  for (int i = 0; i < 3; i++) {
+    pinfo_frame->hdmi_metadata_type1.display_primaries[i].x =
+        p_hdr_minfo->display_primaries[i].x;
+    pinfo_frame->hdmi_metadata_type1.display_primaries[i].y =
+        p_hdr_minfo->display_primaries[i].y;
+  }
+
+  pinfo_frame->hdmi_metadata_type1.white_point.x = p_hdr_minfo->white_point.x;
+  pinfo_frame->hdmi_metadata_type1.white_point.y = p_hdr_minfo->white_point.y;
+}
+
+static void
+gst_kms_push_hdr_infoframe (GstKMSSink * self, gboolean clear_it_out)
+{
+  struct hdr_output_metadata info_frame;
+  drmModeObjectPropertiesPtr props;
+  uint32_t hdrBlobID;
+  int drm_fd = self->fd;
+  uint32_t conn_id = self->conn_id;
+  int ret = 0;
+
+  if (self->no_infoframe || !self->has_hdr_info || (!clear_it_out
+          && self->has_sent_hdrif)) {
+    return;
+  }
+
+  /* Check to see if the connection has the HDR_OUTPUT_METADATA property if
+   * we haven't already found it */
+  if (self->hdrPropID == 0 || self->edidPropID == 0) {
+    props =
+        drmModeObjectGetProperties (drm_fd, conn_id, DRM_MODE_OBJECT_CONNECTOR);
+
+    if (!props) {
+      GST_ERROR_OBJECT (self, "Error on drmModeObjectGetProperties %d %s",
+          errno, g_strerror (errno));
+      return;
+    }
+
+    struct gst_kms_hdr_static_metadata hdr_edid_info = { 0, 0, 0, 0, 0 };
+    for (uint32_t i = 0;
+        i < props->count_props && (self->hdrPropID == 0
+            || self->edidPropID == 0); i++) {
+      drmModePropertyPtr pprop = drmModeGetProperty (drm_fd, props->props[i]);
+
+      if (pprop) {
+        /* 7 16 DRM_MODE_PROP_BLOB HDR_OUTPUT_METADATA */
+        if (!strncmp ("HDR_OUTPUT_METADATA", pprop->name,
+                strlen ("HDR_OUTPUT_METADATA"))) {
+          self->hdrPropID = pprop->prop_id;
+          GST_DEBUG_OBJECT (self, "HDR prop ID = %d", self->hdrPropID);
+        }
+
+        if (!strncmp ("EDID", pprop->name, strlen ("EDID"))) {
+          self->edidPropID = pprop->prop_id;
+
+          /* Check if EDID indicates device supports HDR */
+          drmModePropertyBlobPtr blob;
+          blob = drmModeGetPropertyBlob (drm_fd, props->prop_values[i]);
+          if (blob) {
+            int res =
+                gst_kms_edid_parse (&hdr_edid_info, blob->data, blob->length);
+            if (res != 0) {
+              hdr_edid_info.eotf = 0;
+              hdr_edid_info.metadata_type = 0;
+            }
+          }
+
+          drmModeFreePropertyBlob (blob);
+
+          GST_DEBUG_OBJECT (self, "EDID prop ID = %d", self->edidPropID);
+          /* only these two values are guaranteed to be populated for HDR */
+          GST_DEBUG_OBJECT (self, "EDID EOTF = %u, metadata type = %u",
+              hdr_edid_info.eotf, hdr_edid_info.metadata_type);
+        }
+
+        drmModeFreeProperty (pprop);
+      } else {
+        GST_ERROR_OBJECT (self, "Error on drmModeGetProperty(%d)", i);
+      }
+    }
+
+    drmModeFreeObjectProperties (props);
+
+    if (self->hdrPropID == 0 || self->edidPropID == 0
+        || hdr_edid_info.eotf == 0) {
+      GST_DEBUG_OBJECT (self, "No HDR support on target display");
+      self->no_infoframe = TRUE;
+      /* FIXME: maybe not the right flag here... */
+      self->has_sent_hdrif = TRUE;
+      return;
+    }
+  }
+
+  if (clear_it_out)
+    GST_INFO ("Clearing HDR Infoframe on connector %d", self->conn_id);
+  else
+    GST_INFO ("Setting HDR Infoframe, if available on connector %d",
+        self->conn_id);
+
+  gst_kms_populate_infoframe (&info_frame, &self->hdr_minfo, &self->hdr_cll,
+      self->colorimetry, clear_it_out);
+
+  /* Use non-atomic property setting */
+  ret = drmModeCreatePropertyBlob (drm_fd, &info_frame,
+      sizeof (struct hdr_output_metadata), &hdrBlobID);
+  if (!ret) {
+    ret =
+        drmModeObjectSetProperty (drm_fd, conn_id, DRM_MODE_OBJECT_CONNECTOR,
+        self->hdrPropID, hdrBlobID);
+    if (ret) {
+      GST_ERROR_OBJECT (self, "drmModeObjectSetProperty result %d %d %s", ret,
+          errno, g_strerror (errno));
+    }
+    drmModeDestroyPropertyBlob (drm_fd, hdrBlobID);
+  } else {
+    GST_ERROR_OBJECT (self, "Failed to drmModeCreatePropertyBlob %d %s", errno,
+        g_strerror (errno));
+  }
+
+  if (!ret) {
+    GST_INFO ("Set HDR Infoframe on connector %d", conn_id);
+    self->has_sent_hdrif = TRUE;        // Hooray!
+  }
+}
+
+
+/* From an HDR10 stream caps:
+ *
+ * colorimetry=(string)bt2100-pq
+ * content-light-level=(string)10000:166
+ * mastering-display-info=(string)35400:14600:8500:39850:6550:2300:15635:16450:10000000:1
+ */
+static void
+gst_kms_sink_set_hdr10_caps (GstKMSSink * self, GstCaps * caps)
+{
+  GstVideoMasteringDisplayInfo hdr_minfo;
+  GstVideoContentLightLevel hdr_cll;
+  GstStructure *structure;
+  const gchar *colorimetry_s;
+  GstVideoColorimetry colorimetry;
+  gboolean has_hdr_eotf = FALSE;
+  gboolean has_cll = FALSE;
+
+  structure = gst_caps_get_structure (caps, 0);
+  if ((colorimetry_s = gst_structure_get_string (structure,
+              "colorimetry")) != NULL &&
+      gst_video_colorimetry_from_string (&colorimetry, colorimetry_s)) {
+    switch (colorimetry.transfer) {
+      case GST_VIDEO_TRANSFER_SMPTE2084:
+        self->colorimetry = HDMI_EOTF_SMPTE_ST2084;
+        has_hdr_eotf = TRUE;
+        GST_DEBUG ("Got HDR transfer value GST_VIDEO_TRANSFER_SMPTE2084: %u",
+            self->colorimetry);
+        break;
+      case GST_VIDEO_TRANSFER_BT2020_10:
+      case GST_VIDEO_TRANSFER_ARIB_STD_B67:
+        self->colorimetry = HDMI_EOTF_BT_2100_HLG;
+        has_hdr_eotf = TRUE;
+        GST_DEBUG ("Got HDR transfer value HDMI_EOTF_BT_2100_HLG: %u",
+            self->colorimetry);
+        break;
+      case GST_VIDEO_TRANSFER_BT709:
+        self->colorimetry = HDMI_EOTF_TRADITIONAL_GAMMA_SDR;
+        GST_DEBUG ("Got HDR transfer value GST_VIDEO_TRANSFER_BT709, "
+            "not HDR: %u", self->colorimetry);
+        break;
+      default:
+        /* not an HDMI and/or HDR colorimetry, we will ignore */
+        GST_DEBUG ("Unsupported transfer function, no HDR: %u",
+            colorimetry.transfer);
+        self->no_infoframe = TRUE;
+        self->has_hdr_info = FALSE;
+        break;
+    }
+  }
+
+  if (gst_video_mastering_display_info_from_caps (&hdr_minfo, caps)) {
+    if (!gst_video_mastering_display_info_is_equal (&hdr_minfo,
+            &self->hdr_minfo)) {
+      self->hdr_minfo = hdr_minfo;
+      self->no_infoframe = FALSE;
+      self->has_hdr_info = TRUE;
+      /* to send again */
+      self->has_sent_hdrif = FALSE;
+    }
+
+    GST_DEBUG ("Got mastering info: "
+        "min %u max %u wp %u %u dp[0] %u %u dp[1] %u %u dp[2] %u %u",
+        self->hdr_minfo.min_display_mastering_luminance,
+        self->hdr_minfo.max_display_mastering_luminance,
+        self->hdr_minfo.white_point.x, self->hdr_minfo.white_point.y,
+        self->hdr_minfo.display_primaries[0].x,
+        self->hdr_minfo.display_primaries[0].y,
+        self->hdr_minfo.display_primaries[1].x,
+        self->hdr_minfo.display_primaries[1].y,
+        self->hdr_minfo.display_primaries[2].x,
+        self->hdr_minfo.display_primaries[2].y);
+
+  } else {
+    if (self->has_hdr_info == TRUE) {
+      GST_WARNING ("Missing mastering display info");
+    } else {
+      self->no_infoframe = TRUE;
+      self->has_hdr_info = FALSE;
+    }
+
+    gst_video_mastering_display_info_init (&self->hdr_minfo);
+  }
+
+  if (gst_video_content_light_level_from_caps (&hdr_cll, caps)) {
+    GST_DEBUG ("Got content light level information: Max CLL: %u Max FALL: %u",
+        hdr_cll.max_content_light_level, hdr_cll.max_frame_average_light_level);
+
+    if (!gst_video_content_light_level_is_equal (&hdr_cll, &self->hdr_cll)) {
+      self->hdr_cll = hdr_cll;
+      self->no_infoframe = FALSE;
+      self->has_hdr_info = TRUE;
+      /* to send again */
+      self->has_sent_hdrif = FALSE;
+    }
+
+    has_cll = TRUE;
+  } else {
+    gst_video_content_light_level_init (&self->hdr_cll);
+
+    if (self->has_hdr_info == TRUE) {
+      GST_WARNING ("Missing content light level info");
+    }
+
+    self->no_infoframe = TRUE;
+    self->has_hdr_info = FALSE;
+  }
+
+  /* need all caps set */
+  if ((has_hdr_eotf || has_cll) && !(has_hdr_eotf && has_cll)) {
+    GST_ELEMENT_WARNING (self, STREAM, FORMAT,
+        ("Stream doesn't have all HDR components needed"),
+        ("Check stream caps"));
+
+    self->no_infoframe = TRUE;
+    self->has_hdr_info = FALSE;
+  }
+}
+
+#endif /* HAVE_DRM_HDR */
+
 static void
 gst_kms_sink_set_render_rectangle (GstVideoOverlay * overlay,
     gint x, gint y, gint width, gint height)
@@ -1147,6 +1451,10 @@ gst_kms_sink_set_caps (GstBaseSink * bsink, GstCaps * caps)
   if (GST_VIDEO_SINK_WIDTH (self) <= 0 || GST_VIDEO_SINK_HEIGHT (self) <= 0)
     goto invalid_size;
 
+#ifdef HAVE_DRM_HDR
+  gst_kms_sink_set_hdr10_caps (self, caps);
+#endif
+
   /* discard dumb buffer pool */
   if (self->pool) {
     gst_buffer_pool_set_active (self->pool, FALSE);
@@ -1664,6 +1972,10 @@ retry_set_plane:
     src.w = result.w;
     src.h = result.h;
   }
+#ifdef HAVE_DRM_HDR
+  /* Send the HDR infoframes if appropriate */
+  gst_kms_push_hdr_infoframe (self, FALSE);
+#endif
 
   GST_TRACE_OBJECT (self,
       "drmModeSetPlane at (%i,%i) %ix%i sourcing at (%i,%i) %ix%i",
@@ -1683,7 +1995,7 @@ retry_set_plane:
 
 sync_frame:
   /* Wait for the previous frame to complete redraw */
-  if (!gst_kms_sink_sync (self)) {
+  if (!self->skip_vsync && !gst_kms_sink_sync (self)) {
     GST_OBJECT_UNLOCK (self);
     goto bail;
   }
@@ -1884,6 +2196,9 @@ gst_kms_sink_set_property (GObject * object, guint prop_id,
     case PROP_FD:
       _validate_and_set_external_fd (sink, g_value_get_int (value));
       break;
+    case PROP_SKIP_VSYNC:
+      sink->skip_vsync = g_value_get_boolean (value);
+      break;
     default:
       if (!gst_video_overlay_set_property (object, PROP_N, prop_id, value))
         G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
@@ -1940,6 +2255,9 @@ gst_kms_sink_get_property (GObject * object, guint prop_id,
     case PROP_FD:
       g_value_set_int (value, sink->fd);
       break;
+    case PROP_SKIP_VSYNC:
+      g_value_set_boolean (value, sink->skip_vsync);
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -1973,6 +2291,18 @@ gst_kms_sink_init (GstKMSSink * sink)
   gst_poll_fd_init (&sink->pollfd);
   sink->poll = gst_poll_new (TRUE);
   gst_video_info_init (&sink->vinfo);
+  sink->skip_vsync = FALSE;
+
+#ifdef HAVE_DRM_HDR
+  sink->no_infoframe = FALSE;
+  sink->has_hdr_info = FALSE;
+  sink->has_sent_hdrif = FALSE;
+  sink->edidPropID = 0;
+  sink->hdrPropID = 0;
+  sink->colorimetry = HDMI_EOTF_TRADITIONAL_GAMMA_SDR;
+  gst_video_mastering_display_info_init (&sink->hdr_minfo);
+  gst_video_content_light_level_init (&sink->hdr_cll);
+#endif
 }
 
 static void
@@ -2152,6 +2482,20 @@ gst_kms_sink_class_init (GstKMSSinkClass * klass)
       "DRM file descriptor", -1, G_MAXINT, -1,
       G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
 
+  /**
+   * kmssink:skip-vsync:
+   *
+   *  For some cases, to suppress internal vsync, which can drop framerate
+   *  in half, set this to 1.
+   *
+   *  Since: 1.22
+   */
+  g_properties[PROP_SKIP_VSYNC] =
+      g_param_spec_boolean ("skip-vsync", "Skip Internal VSync",
+      "When enabled will not wait internally for vsync. "
+      "Should be used for atomic drivers to avoid double vsync.", FALSE,
+      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+
   g_object_class_install_properties (gobject_class, PROP_N, g_properties);
 
   gst_video_overlay_install_properties (gobject_class, PROP_N);
diff --git a/subprojects/gst-plugins-bad/sys/kms/gstkmssink.h b/subprojects/gst-plugins-bad/sys/kms/gstkmssink.h
index 536b0a7230..317f789ef9 100644
--- a/subprojects/gst-plugins-bad/sys/kms/gstkmssink.h
+++ b/subprojects/gst-plugins-bad/sys/kms/gstkmssink.h
@@ -27,6 +27,7 @@
 #define __GST_KMS_SINK_H__
 
 #include <gst/video/gstvideosink.h>
+#include <gst/video/video-hdr.h>
 
 G_BEGIN_DECLS
 
@@ -95,6 +96,19 @@ struct _GstKMSSink {
   gboolean reconfigure;
 
   gboolean is_internal_fd;
+  gboolean skip_vsync;
+
+#ifdef HAVE_DRM_HDR
+  /* HDR mastering related structure */
+  gboolean no_infoframe;
+  gboolean has_hdr_info;
+  gboolean has_sent_hdrif;
+  guint32 edidPropID;
+  guint32 hdrPropID;
+  gchar colorimetry;
+  GstVideoMasteringDisplayInfo hdr_minfo;
+  GstVideoContentLightLevel hdr_cll;
+#endif
 };
 
 struct _GstKMSSinkClass {
diff --git a/subprojects/gst-plugins-bad/sys/kms/meson.build b/subprojects/gst-plugins-bad/sys/kms/meson.build
index 54688707f0..2f960c8565 100644
--- a/subprojects/gst-plugins-bad/sys/kms/meson.build
+++ b/subprojects/gst-plugins-bad/sys/kms/meson.build
@@ -4,6 +4,7 @@ kmssink_sources = [
   'gstkmssink.c',
   'gstkmsutils.c',
 ]
+extra_deps = []
 
 if host_system != 'linux'
   subdir_done()
@@ -12,12 +13,22 @@ endif
 libdrm_dep = dependency('libdrm', version : '>= 2.4.98',
                         required : get_option('kms'),
                         fallback: ['libdrm', 'ext_libdrm'])
+libdrm_hdr_dep = dependency('libdrm', version : '>= 2.4.104',
+                            required : false,
+                            fallback: ['libdrm', 'ext_libdrm'])
+mathlib = cc.find_library('m', required : false)
+
+if libdrm_hdr_dep.found() and mathlib.found()
+  cdata.set('HAVE_DRM_HDR', 1)
+  kmssink_sources += 'gstkmsedid.c'
+endif
+
 if libdrm_dep.found()
   gstkmssink = library('gstkms',
     kmssink_sources,
     c_args : gst_plugins_bad_args,
     include_directories : [configinc],
-    dependencies : [gstbase_dep, gstvideo_dep, gstallocators_dep, libdrm_dep],
+    dependencies : [gstbase_dep, gstvideo_dep, gstallocators_dep, libdrm_dep, mathlib],
     install : true,
     install_dir : plugins_install_dir,
   )
diff --git a/subprojects/gst-plugins-bad/sys/mediafoundation/gstmfcapturedshow.cpp b/subprojects/gst-plugins-bad/sys/mediafoundation/gstmfcapturedshow.cpp
index 9bb8f97539..30ebe425e6 100644
--- a/subprojects/gst-plugins-bad/sys/mediafoundation/gstmfcapturedshow.cpp
+++ b/subprojects/gst-plugins-bad/sys/mediafoundation/gstmfcapturedshow.cpp
@@ -168,7 +168,7 @@ public:
     if (callback_)
       callback_ (SampleTime, pBuffer, BufferLen, user_data_);
 
-    return E_NOTIMPL;
+    return S_OK;
   }
 
 private:
@@ -1023,7 +1023,8 @@ gst_mf_dshow_enum_device (GstMFCaptureDShow * self,
       return FALSE;
   }
 
-  if (!gst_mf_result (hr))
+  // Documentation states that the result of CreateClassEnumerator must be checked against S_OK
+  if (hr != S_OK)
     return FALSE;
 
   for (guint i = 0;; i++) {
diff --git a/subprojects/gst-plugins-bad/sys/meson.build b/subprojects/gst-plugins-bad/sys/meson.build
index c95c873234..cfe1778207 100644
--- a/subprojects/gst-plugins-bad/sys/meson.build
+++ b/subprojects/gst-plugins-bad/sys/meson.build
@@ -26,5 +26,6 @@ subdir('va')
 subdir('wasapi')
 subdir('wasapi2')
 subdir('wic')
+subdir('win32ipc')
 subdir('winks')
 subdir('winscreencap')
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator.h b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator.h
index 9035b548bf..53bbdda595 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator.h
@@ -49,9 +49,8 @@ struct _GstMsdkMemoryID {
   VAImage image;
   VADRMPRIMESurfaceDescriptor desc;
 #else
-  /* TODO: This is just to avoid compile errors on Windows.
-   * Implement handling Windows-specific video-memory.
-   */
+  ID3D11Texture2D *texture;
+  guint subresource_index;
   gint pitch;
   guint offset;
 #endif
@@ -75,6 +74,10 @@ mfxStatus gst_msdk_frame_get_hdl(mfxHDL pthis, mfxMemId mid, mfxHDL *hdl);
 
 void gst_msdk_set_frame_allocator (GstMsdkContext * context);
 
+GstMsdkSurface *
+gst_msdk_import_to_msdk_surface (GstBuffer * buf, GstMsdkContext * msdk_context,
+    GstVideoInfo * vinfo, guint map_flag);
+
 G_END_DECLS
 
 #endif /* GST_MSDK_ALLOCATOR_H_ */
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_d3d.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_d3d.c
index 27e457288b..d7388237fa 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_d3d.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_d3d.c
@@ -30,8 +30,22 @@
  * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+#include <gst/d3d11/gstd3d11.h>
 #include "gstmsdkallocator.h"
 
+#define GST_MSDK_FRAME_SURFACE gst_msdk_frame_surface_quark_get ()
+static GQuark
+gst_msdk_frame_surface_quark_get (void)
+{
+  static gsize g_quark;
+
+  if (g_once_init_enter (&g_quark)) {
+    gsize quark = (gsize) g_quark_from_static_string ("GstMsdkFrameSurface");
+    g_once_init_leave (&g_quark, quark);
+  }
+  return g_quark;
+}
+
 mfxStatus
 gst_msdk_frame_alloc (mfxHDL pthis, mfxFrameAllocRequest * req,
     mfxFrameAllocResponse * resp)
@@ -60,9 +74,76 @@ gst_msdk_frame_unlock (mfxHDL pthis, mfxMemId mid, mfxFrameData * ptr)
 mfxStatus
 gst_msdk_frame_get_hdl (mfxHDL pthis, mfxMemId mid, mfxHDL * hdl)
 {
+  GstMsdkMemoryID *mem_id;
+  mfxHDLPair *pair;
+
+  if (!hdl || !mid)
+    return MFX_ERR_INVALID_HANDLE;
+
+  mem_id = (GstMsdkMemoryID *) mid;
+  pair = (mfxHDLPair *) hdl;
+  pair->first = (mfxHDL) mem_id->texture;
+  pair->second = (mfxHDL) GUINT_TO_POINTER (mem_id->subresource_index);
+
   return MFX_ERR_NONE;
 }
 
+GstMsdkSurface *
+gst_msdk_import_to_msdk_surface (GstBuffer * buf, GstMsdkContext * msdk_context,
+    GstVideoInfo * vinfo, guint map_flag)
+{
+  GstMemory *mem = NULL;
+  mfxFrameInfo frame_info = { 0, };
+  GstMsdkSurface *msdk_surface = NULL;
+  mfxFrameSurface1 *mfx_surface = NULL;
+  GstMsdkMemoryID *msdk_mid = NULL;
+  GstMapInfo map_info;
+
+  mem = gst_buffer_peek_memory (buf, 0);
+  msdk_surface = g_slice_new0 (GstMsdkSurface);
+
+  if (!gst_is_d3d11_memory (mem) || gst_buffer_n_memory (buf) > 1) {
+    /* d3d11 buffer should hold single memory object */
+    g_slice_free (GstMsdkSurface, msdk_surface);
+    return NULL;
+  }
+
+  if (!gst_buffer_map (buf, &map_info, map_flag | GST_MAP_D3D11)) {
+    GST_ERROR ("Failed to map buffer");
+    g_slice_free (GstMsdkSurface, msdk_surface);
+    return NULL;
+  }
+
+  /* If buffer has qdata pointing to mfxFrameSurface1, directly extract it */
+  if ((mfx_surface = gst_mini_object_get_qdata (GST_MINI_OBJECT_CAST (mem),
+              GST_MSDK_FRAME_SURFACE))) {
+    msdk_surface->from_qdata = TRUE;
+    msdk_surface->surface = mfx_surface;
+    gst_buffer_unmap (buf, &map_info);
+    return msdk_surface;
+  }
+
+  mfx_surface = g_slice_new0 (mfxFrameSurface1);
+  msdk_mid = g_slice_new0 (GstMsdkMemoryID);
+  mfx_surface->Data.MemId = (mfxMemId) msdk_mid;
+
+  msdk_mid->texture = (ID3D11Texture2D *) (gpointer) map_info.data;
+  msdk_mid->subresource_index = GPOINTER_TO_UINT (map_info.user_data[0]);
+
+  gst_buffer_unmap (buf, &map_info);
+
+  gst_msdk_set_mfx_frame_info_from_video_info (&frame_info, vinfo);
+  mfx_surface->Info = frame_info;
+
+  /* Set mfxFrameSurface1 as qdata in buffer */
+  gst_mini_object_set_qdata (GST_MINI_OBJECT_CAST (mem),
+      GST_MSDK_FRAME_SURFACE, mfx_surface, NULL);
+
+  msdk_surface->surface = mfx_surface;
+
+  return msdk_surface;
+}
+
 void
 gst_msdk_set_frame_allocator (GstMsdkContext * context)
 {
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.c
index 22c7ebb80a..b1a2d29a9e 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.c
@@ -764,9 +764,10 @@ _get_va_surface (GstBuffer * buf, GstVideoInfo * info,
   return va_surface;
 }
 
+/* Currently parameter map_flag is not useful on Linux */
 GstMsdkSurface *
 gst_msdk_import_to_msdk_surface (GstBuffer * buf, GstMsdkContext * msdk_context,
-    GstVideoInfo * vinfo)
+    GstVideoInfo * vinfo, guint map_flag)
 {
   VASurfaceID va_surface = VA_INVALID_ID;
   GstMemory *mem = NULL;
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.h b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.h
index fa25821fd8..da2f4d3bfe 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkallocator_libva.h
@@ -45,10 +45,6 @@ gboolean
 gst_msdk_export_dmabuf_to_vasurface (GstMsdkContext *context,
     GstVideoInfo *vinfo, gint fd, VASurfaceID *surface_id);
 
-GstMsdkSurface *
-gst_msdk_import_to_msdk_surface (GstBuffer * buf, GstMsdkContext * msdk_context,
-    GstVideoInfo * vinfo);
-
 gboolean
 gst_msdk_replace_mfx_memid (GstMsdkContext *context,
     mfxFrameSurface1 *mfx_surface, VASurfaceID surface_id);
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.c
index 6e962e1f0a..60cc61d339 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.c
@@ -38,6 +38,8 @@
 #include <va/va_drm.h>
 #include <gudev/gudev.h>
 #include <gst/va/gstvadisplay_drm.h>
+#else
+#include <gst/d3d11/gstd3d11.h>
 #endif
 
 GST_DEBUG_CATEGORY_STATIC (gst_debug_msdkcontext);
@@ -56,6 +58,8 @@ struct _GstMsdkContextPrivate
   GstMsdkContext *parent_context;
 #ifndef _WIN32
   GstVaDisplay *display;
+#else
+  GstD3D11Device *device;
 #endif
 };
 
@@ -201,6 +205,101 @@ failed:
 
   return FALSE;
 }
+#else
+static GstD3D11Device *
+get_device_by_index (IDXGIFactory1 * factory, guint idx)
+{
+  HRESULT hr;
+  IDXGIAdapter1 *adapter;
+  ID3D11Device *device_handle;
+  ID3D10Multithread *multi_thread;
+  DXGI_ADAPTER_DESC desc;
+  GstD3D11Device *device = NULL;
+  gint64 luid;
+
+  hr = IDXGIFactory1_EnumAdapters1 (factory, idx, &adapter);
+  if (FAILED (hr)) {
+    return NULL;
+  }
+
+  hr = IDXGIAdapter1_GetDesc (adapter, &desc);
+  if (FAILED (hr)) {
+    IDXGIAdapter1_Release (adapter);
+    return NULL;
+  }
+
+  if (desc.VendorId != 0x8086) {
+    IDXGIAdapter1_Release (adapter);
+    return NULL;
+  }
+
+  luid = gst_d3d11_luid_to_int64 (&desc.AdapterLuid);
+  device = gst_d3d11_device_new_for_adapter_luid (luid,
+      D3D11_CREATE_DEVICE_BGRA_SUPPORT);
+  IDXGIAdapter1_Release (adapter);
+
+  device_handle = gst_d3d11_device_get_device_handle (device);
+  hr = ID3D11Device_QueryInterface (device_handle,
+      &IID_ID3D10Multithread, (void **) &multi_thread);
+  if (FAILED (hr)) {
+    gst_object_unref (device);
+    return NULL;
+  }
+
+  hr = ID3D10Multithread_SetMultithreadProtected (multi_thread, TRUE);
+  ID3D10Multithread_Release (multi_thread);
+
+  return device;
+}
+
+static gboolean
+gst_msdk_context_use_d3d11 (GstMsdkContext * context)
+{
+  HRESULT hr;
+  IDXGIFactory1 *factory = NULL;
+  GstD3D11Device *device = NULL;
+  ID3D11Device *device_handle;
+  GstMsdkContextPrivate *priv = context->priv;
+  mfxStatus status;
+  guint idx = 0;
+  gint user_idx = -1;
+  const gchar *user_choice = g_getenv ("GST_MSDK_DEVICE");
+
+  hr = CreateDXGIFactory1 (&IID_IDXGIFactory1, (void **) &factory);
+  if (FAILED (hr)) {
+    GST_ERROR ("Couldn't create DXGI factory");
+    return FALSE;
+  }
+
+  if (user_choice) {
+    user_idx = atoi (user_choice);
+    if (!(device = get_device_by_index (factory, user_idx)))
+      GST_WARNING
+          ("Failed to get device by user index, try to pick the first available device");
+  }
+
+  /* Pick the first available device */
+  while (!device) {
+    device = get_device_by_index (factory, idx++);
+  }
+
+  IDXGIFactory1_Release (factory);
+  device_handle = gst_d3d11_device_get_device_handle (device);
+
+  status =
+      MFXVideoCORE_SetHandle (priv->session.session, MFX_HANDLE_D3D11_DEVICE,
+      gst_d3d11_device_get_device_handle (device));
+  if (status != MFX_ERR_NONE) {
+    GST_ERROR ("Setting D3D11VA handle failed (%s)",
+        msdk_status_to_string (status));
+    gst_object_unref (device);
+    return FALSE;
+  }
+
+  priv->device = device;
+
+  return TRUE;
+}
 #endif
 
 static gboolean
@@ -210,12 +309,18 @@ gst_msdk_context_open (GstMsdkContext * context, gboolean hardware,
   mfxU16 codename;
   GstMsdkContextPrivate *priv = context->priv;
   MsdkSession msdk_session;
+  mfxIMPL impl;
 
   priv->job_type = job_type;
   priv->hardware = hardware;
 
-  msdk_session =
-      msdk_open_session (hardware ? MFX_IMPL_HARDWARE_ANY : MFX_IMPL_SOFTWARE);
+  impl = hardware ? MFX_IMPL_HARDWARE_ANY : MFX_IMPL_SOFTWARE;
+
+#ifdef _WIN32
+  impl |= MFX_IMPL_VIA_D3D11;
+#endif
+
+  msdk_session = msdk_open_session (impl);
   priv->session = msdk_session;
   if (!priv->session.session)
     goto failed;
@@ -225,6 +330,11 @@ gst_msdk_context_open (GstMsdkContext * context, gboolean hardware,
     if (!gst_msdk_context_use_vaapi (context))
       goto failed;
   }
+#else
+  if (hardware) {
+    if (!gst_msdk_context_use_d3d11 (context))
+      goto failed;
+  }
 #endif
 
   codename = msdk_get_platform_codename (priv->session.session);
@@ -281,6 +391,9 @@ gst_msdk_context_finalize (GObject * obj)
 #ifndef _WIN32
   if (priv->display)
     gst_object_unref (priv->display);
+#else
+  if (priv->device)
+    gst_object_unref (priv->device);
 #endif
 
 done:
@@ -336,6 +449,8 @@ gst_msdk_context_new_with_parent (GstMsdkContext * parent)
 
   if (MFX_IMPL_VIA_VAAPI == (0x0f00 & (impl)))
     handle_type = MFX_HANDLE_VA_DISPLAY;
+  else if (MFX_IMPL_VIA_D3D11 == (0x0f00 & (impl)))
+    handle_type = MFX_HANDLE_D3D11_DEVICE;
 
   if (handle_type) {
     status =
@@ -396,19 +511,21 @@ gst_msdk_context_new_with_parent (GstMsdkContext * parent)
       g_list_prepend (parent_priv->child_session_list, priv->session.session);
 #ifndef _WIN32
   priv->display = parent_priv->display;
+#else
+  priv->device = parent_priv->device;
 #endif
   priv->parent_context = gst_object_ref (parent);
 
   return obj;
 }
 
+#ifndef _WIN32
 GstMsdkContext *
 gst_msdk_context_new_with_va_display (GstObject * display_obj,
     gboolean hardware, GstMsdkContextJobType job_type)
 {
   GstMsdkContext *obj = NULL;
 
-#ifndef _WIN32
   GstMsdkContextPrivate *priv;
   mfxU16 codename;
   mfxStatus status;
@@ -451,10 +568,71 @@ gst_msdk_context_new_with_va_display (GstObject * display_obj,
   else
     GST_WARNING ("Unknown MFX platform");
 
-#endif
+  return obj;
+}
+#else
+GstMsdkContext *
+gst_msdk_context_new_with_d3d11_device (GstD3D11Device * device,
+    gboolean hardware, GstMsdkContextJobType job_type)
+{
+  GstMsdkContext *obj = NULL;
+  GstMsdkContextPrivate *priv;
+  mfxU16 codename;
+  mfxStatus status;
+  ID3D10Multithread *multi_thread;
+  ID3D11Device *device_handle;
+  HRESULT hr;
+
+  obj = g_object_new (GST_TYPE_MSDK_CONTEXT, NULL);
+
+  priv = obj->priv;
+  priv->device = gst_object_ref (device);
+
+  priv->job_type = job_type;
+  priv->hardware = hardware;
+  priv->session =
+      msdk_open_session (hardware ? MFX_IMPL_HARDWARE_ANY : MFX_IMPL_SOFTWARE);
+  if (!priv->session.session) {
+    goto failed;
+  }
+
+  device_handle = gst_d3d11_device_get_device_handle (device);
+  hr = ID3D11Device_QueryInterface (device_handle,
+      &IID_ID3D10Multithread, (void **) &multi_thread);
+  if (FAILED (hr)) {
+    GST_ERROR ("ID3D10Multithread interface is unavailable");
+    goto failed;
+  }
+
+  hr = ID3D10Multithread_SetMultithreadProtected (multi_thread, TRUE);
+  ID3D10Multithread_Release (multi_thread);
+
+  if (hardware) {
+    status =
+        MFXVideoCORE_SetHandle (priv->session.session, MFX_HANDLE_D3D11_DEVICE,
+        device_handle);
+    if (status != MFX_ERR_NONE) {
+      GST_ERROR ("Setting D3D11VA handle failed (%s)",
+          msdk_status_to_string (status));
+      goto failed;
+    }
+  }
+
+  codename = msdk_get_platform_codename (priv->session.session);
+
+  if (codename != MFX_PLATFORM_UNKNOWN)
+    GST_INFO ("Detected MFX platform with device code %d", codename);
+  else
+    GST_WARNING ("Unknown MFX platform");
 
   return obj;
+
+failed:
+  gst_object_unref (obj);
+  gst_object_unref (device);
+  return NULL;
 }
+#endif
 
 mfxSession
 gst_msdk_context_get_session (GstMsdkContext * context)
@@ -472,15 +650,23 @@ gst_msdk_context_get_handle (GstMsdkContext * context)
 #endif
 }
 
+#ifndef _WIN32
 GstObject *
-gst_msdk_context_get_display (GstMsdkContext * context)
+gst_msdk_context_get_va_display (GstMsdkContext * context)
 {
-#ifndef _WIN32
   if (context->priv->display)
     return gst_object_ref (GST_OBJECT_CAST (context->priv->display));
-#endif
   return NULL;
 }
+#else
+GstD3D11Device *
+gst_msdk_context_get_d3d11_device (GstMsdkContext * context)
+{
+  if (context->priv->device)
+    return gst_object_ref (context->priv->device);
+  return NULL;
+}
+#endif
 
 static gint
 _find_response (gconstpointer resp, gconstpointer comp_resp)
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.h b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.h
index 141f9062e6..88746bd101 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontext.h
@@ -37,6 +37,8 @@
 #ifndef _WIN32
 #include <va/va.h>
 #include <va/va_drmcommon.h>
+#else
+#include <gst/d3d11/gstd3d11_fwd.h>
 #endif
 
 G_BEGIN_DECLS
@@ -87,12 +89,21 @@ GType gst_msdk_context_get_type (void);
 
 GstMsdkContext * gst_msdk_context_new (gboolean hardware, GstMsdkContextJobType job_type);
 GstMsdkContext * gst_msdk_context_new_with_parent (GstMsdkContext * parent);
+#ifndef _WIN32
 GstMsdkContext * gst_msdk_context_new_with_va_display (GstObject * display_obj,
     gboolean hardware, GstMsdkContextJobType job_type);
+#else
+GstMsdkContext * gst_msdk_context_new_with_d3d11_device (GstD3D11Device * device,
+    gboolean hardware, GstMsdkContextJobType job_type);
+#endif
 mfxSession gst_msdk_context_get_session (GstMsdkContext * context);
 
 gpointer gst_msdk_context_get_handle (GstMsdkContext * context);
-GstObject * gst_msdk_context_get_display (GstMsdkContext * context);
+#ifndef _WIN32
+GstObject * gst_msdk_context_get_va_display (GstMsdkContext * context);
+#else
+GstD3D11Device * gst_msdk_context_get_d3d11_device (GstMsdkContext * context);
+#endif
 
 /* GstMsdkContext contains mfxFrameAllocResponses,
  * if app calls MFXVideoCORE_SetFrameAllocator.
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.c
index 6bbdebb935..c739cae962 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.c
@@ -34,6 +34,8 @@
 #ifndef _WIN32
 #include <gst/va/gstvadisplay.h>
 #include <gst/va/gstvautils.h>
+#else
+#include <gst/d3d11/gstd3d11device.h>
 #endif
 
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_CONTEXT);
@@ -236,7 +238,7 @@ gst_msdk_ensure_new_context (GstElement * element, gboolean hardware,
 
 #ifndef _WIN32
   /* 2) Query the neighbour the VA display. If already a valid VA display,
-     using it by gst_msdk_context_from_external_display() in set_context(). */
+     using it by gst_msdk_context_from_external_va_display() in set_context(). */
   gst_va_context_query (element, GST_VA_DISPLAY_HANDLE_CONTEXT_TYPE_STR);
   msdk_context = g_atomic_pointer_get (context_ptr);
   if (msdk_context) {
@@ -245,9 +247,23 @@ gst_msdk_ensure_new_context (GstElement * element, gboolean hardware,
     ret = TRUE;
     goto done;
   }
+#else
+  /* 2) Query the neighbour the D3D11 device. If already a valid D3D11 device,
+     using it by gst_msdk_context_from_external_d3d11_device() in set_context(). */
+  _context_query (element, GST_D3D11_DEVICE_HANDLE_CONTEXT_TYPE);
+  msdk_context = g_atomic_pointer_get (context_ptr);
+  if (msdk_context) {
+    gst_object_ref (msdk_context);
+    propagate_display = FALSE;
+    ret = TRUE;
+    goto done;
+  }
 #endif
 
-  /* 3) Create a MSDK context from scratch. */
+  /* 3) Create a MSDK context from scratch. Currently we use environment variable
+     to enable user to choose GPU device in multi-GPU environment. This variable
+     is only valid when there's no context returned by upstream or downstream.
+     Otherwise it will use the device that created by upstream or downstream. */
   msdk_context = gst_msdk_context_new (hardware, job);
   if (!msdk_context) {
     GST_ERROR_OBJECT (element, "Context creation failed");
@@ -264,7 +280,7 @@ done:
   if (propagate_display) {
 #ifndef _WIN32
     GstVaDisplay *display =
-        (GstVaDisplay *) gst_msdk_context_get_display (msdk_context);
+        (GstVaDisplay *) gst_msdk_context_get_va_display (msdk_context);
     gst_va_element_propagate_display_context (element, display);
     gst_clear_object (&display);
 #endif
@@ -276,11 +292,12 @@ done:
   return ret;
 }
 
+#ifndef _WIN32
 gboolean
-gst_msdk_context_from_external_display (GstContext * context, gboolean hardware,
-    GstMsdkContextJobType job_type, GstMsdkContext ** msdk_context)
+gst_msdk_context_from_external_va_display (GstContext * context,
+    gboolean hardware, GstMsdkContextJobType job_type,
+    GstMsdkContext ** msdk_context)
 {
-#ifndef _WIN32
   GstObject *va_display = NULL;
   const gchar *type;
   const GstStructure *s;
@@ -309,10 +326,50 @@ gst_msdk_context_from_external_display (GstContext * context, gboolean hardware,
   if (ctx)
     return TRUE;
 
-#endif
+  return FALSE;
+}
+#else
+gboolean
+gst_msdk_context_from_external_d3d11_device (GstContext * context,
+    gboolean hardware, GstMsdkContextJobType job_type,
+    GstMsdkContext ** msdk_context)
+{
+  GstD3D11Device *d3d11_device = NULL;
+  const gchar *type;
+  const GstStructure *s;
+  GstMsdkContext *ctx = NULL;
+  guint vendor_id = 0;
+
+  _init_context_debug ();
+
+  type = gst_context_get_context_type (context);
+  if (g_strcmp0 (type, GST_D3D11_DEVICE_HANDLE_CONTEXT_TYPE))
+    return FALSE;
+
+  s = gst_context_get_structure (context);
+  if (gst_structure_get (s, "device", GST_TYPE_D3D11_DEVICE, &d3d11_device,
+          NULL)) {
+    g_object_get (d3d11_device, "vendor-id", &vendor_id, NULL);
+    if (vendor_id != 0x8086) {
+      GST_ERROR ("Not an Intel device");
+      gst_clear_object (&d3d11_device);
+      return FALSE;
+    }
+    ctx =
+        gst_msdk_context_new_with_d3d11_device (d3d11_device, hardware,
+        job_type);
+    if (ctx)
+      *msdk_context = ctx;
+
+    gst_clear_object (&d3d11_device);
+  }
+
+  if (ctx)
+    return TRUE;
 
   return FALSE;
 }
+#endif
 
 gboolean
 gst_msdk_handle_context_query (GstElement * element, GstQuery * query,
@@ -346,7 +403,7 @@ gst_msdk_handle_context_query (GstElement * element, GstQuery * query,
 #ifndef _WIN32
   if (g_strcmp0 (context_type, GST_VA_DISPLAY_HANDLE_CONTEXT_TYPE_STR) == 0) {
     GstStructure *s;
-    GstObject *display = gst_msdk_context_get_display (msdk_context);
+    GstObject *display = gst_msdk_context_get_va_display (msdk_context);
 
     if (display) {
       GST_CAT_LOG (GST_CAT_CONTEXT,
@@ -360,6 +417,22 @@ gst_msdk_handle_context_query (GstElement * element, GstQuery * query,
       ret = TRUE;
     }
   } else
+#else
+  if (g_strcmp0 (context_type, GST_D3D11_DEVICE_HANDLE_CONTEXT_TYPE) == 0) {
+    GstStructure *s;
+    GstD3D11Device *device = gst_msdk_context_get_d3d11_device (msdk_context);
+
+    if (device) {
+      GST_CAT_LOG (GST_CAT_CONTEXT,
+          "setting GstD3D11Device (%" GST_PTR_FORMAT ") on context (%"
+          GST_PTR_FORMAT ")", device, ctxt);
+
+      s = gst_context_writable_structure (ctxt);
+      gst_structure_set (s, "device", GST_TYPE_D3D11_DEVICE, device, NULL);
+      gst_object_unref (device);
+      ret = TRUE;
+    }
+  } else
 #endif
   if (g_strcmp0 (context_type, GST_MSDK_CONTEXT_TYPE_NAME) == 0) {
     GstStructure *s;
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.h b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.h
index 0994dc0410..b90ca5e70e 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkcontextutil.h
@@ -52,9 +52,15 @@ gst_msdk_ensure_new_context (GstElement * element, gboolean hardware, GstMsdkCon
 gboolean
 gst_msdk_context_get_context (GstContext * context, GstMsdkContext ** msdk_context);
 
+#ifndef _WIN32
+gboolean
+gst_msdk_context_from_external_va_display (GstContext * context, gboolean hardware,
+    GstMsdkContextJobType job_type, GstMsdkContext ** msdk_context);
+#else
 gboolean
-gst_msdk_context_from_external_display (GstContext * context, gboolean hardware,
+gst_msdk_context_from_external_d3d11_device (GstContext * context, gboolean hardware,
     GstMsdkContextJobType job_type, GstMsdkContext ** msdk_context);
+#endif
 
 gboolean
 gst_msdk_handle_context_query (GstElement * element, GstQuery * query, GstMsdkContext * msdk_context);
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkdec.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkdec.c
index 4729d62a3e..bc7fb52884 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkdec.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkdec.c
@@ -58,6 +58,9 @@ static GstStaticPadTemplate src_factory = GST_STATIC_PAD_TEMPLATE ("src",
 #define GST_TO_MFX_TIME(time) ((time) == GST_CLOCK_TIME_NONE ? \
     MFX_TIMESTAMP_UNKNOWN : gst_util_uint64_scale_round ((time), 9, 100000))
 
+#define MFX_TO_GST_TIME(time) ((time) == MFX_TIMESTAMP_UNKNOWN ? \
+    GST_CLOCK_TIME_NONE : gst_util_uint64_scale_round ((time), 100000, 9))
+
 #define MFX_TIME_IS_VALID(time) ((time) != MFX_TIMESTAMP_UNKNOWN)
 
 #define gst_msdkdec_parent_class parent_class
@@ -323,13 +326,24 @@ gst_msdkdec_set_context (GstElement * element, GstContext * context)
     gst_object_replace ((GstObject **) & thiz->context,
         (GstObject *) msdk_context);
     gst_object_unref (msdk_context);
-  } else if (gst_msdk_context_from_external_display (context,
+  } else
+#ifndef _WIN32
+    if (gst_msdk_context_from_external_va_display (context,
           thiz->hardware, 0 /* GST_MSDK_JOB_DECODER will be set later */ ,
           &msdk_context)) {
     gst_object_replace ((GstObject **) & thiz->context,
         (GstObject *) msdk_context);
     gst_object_unref (msdk_context);
   }
+#else
+    if (gst_msdk_context_from_external_d3d11_device (context,
+          thiz->hardware, 0 /* GST_MSDK_JOB_DECODER will be set later */ ,
+          &msdk_context)) {
+    gst_object_replace ((GstObject **) & thiz->context,
+        (GstObject *) msdk_context);
+    gst_object_unref (msdk_context);
+  }
+#endif
 
   GST_ELEMENT_CLASS (parent_class)->set_context (element, context);
 }
@@ -933,6 +947,8 @@ gst_msdkdec_finish_task (GstMsdkDec * thiz, MsdkDecTask * task)
 
     if (decode_only)
       GST_VIDEO_CODEC_FRAME_SET_DECODE_ONLY (frame);
+
+    frame->pts = MFX_TO_GST_TIME (pts);
     flow = gst_video_decoder_finish_frame (decoder, frame);
     if (flow == GST_FLOW_ERROR)
       GST_ERROR_OBJECT (thiz, "Failed to finish frame");
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.c
index 1e265b3659..9ebe398f0c 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.c
@@ -54,6 +54,8 @@
 #ifndef _WIN32
 #include "gstmsdkallocator_libva.h"
 #include <gst/va/gstvaallocator.h>
+#else
+#include <gst/d3d11/gstd3d11.h>
 #endif
 
 static inline void *
@@ -83,7 +85,8 @@ static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
     GST_STATIC_CAPS (GST_MSDK_CAPS_STR
-        ("{ NV12, I420, YV12, YUY2, UYVY, BGRA }", "NV12"))
+        ("{ NV12, I420, YV12, YUY2, UYVY, BGRA }", "NV12") "; "
+        GST_MSDK_CAPS_MAKE_WITH_D3D11_FEATURE ("NV12"))
     );
 #else
 static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
@@ -146,13 +149,24 @@ gst_msdkenc_set_context (GstElement * element, GstContext * context)
     gst_object_replace ((GstObject **) & thiz->context,
         (GstObject *) msdk_context);
     gst_object_unref (msdk_context);
-  } else if (gst_msdk_context_from_external_display (context,
+  } else
+#ifndef _WIN32
+    if (gst_msdk_context_from_external_va_display (context,
+          thiz->hardware, 0 /* GST_MSDK_JOB_ENCODER will be set later */ ,
+          &msdk_context)) {
+    gst_object_replace ((GstObject **) & thiz->context,
+        (GstObject *) msdk_context);
+    gst_object_unref (msdk_context);
+  }
+#else
+    if (gst_msdk_context_from_external_d3d11_device (context,
           thiz->hardware, 0 /* GST_MSDK_JOB_ENCODER will be set later */ ,
           &msdk_context)) {
     gst_object_replace ((GstObject **) & thiz->context,
         (GstObject *) msdk_context);
     gst_object_unref (msdk_context);
   }
+#endif
 
   GST_ELEMENT_CLASS (parent_class)->set_context (element, context);
 }
@@ -1299,7 +1313,7 @@ gst_msdk_create_va_pool (GstMsdkEnc * thiz, GstCaps * caps, guint num_buffers)
   GstVaDisplay *display = NULL;
   GstVideoInfo info = thiz->input_state->info;
 
-  display = (GstVaDisplay *) gst_msdk_context_get_display (thiz->context);
+  display = (GstVaDisplay *) gst_msdk_context_get_va_display (thiz->context);
 
   if (thiz->use_dmabuf) {
     allocator = gst_va_dmabuf_allocator_new (display);
@@ -1326,6 +1340,61 @@ gst_msdk_create_va_pool (GstMsdkEnc * thiz, GstCaps * caps, guint num_buffers)
   GST_LOG_OBJECT (thiz, "Creating va pool");
   return pool;
 }
+#else
+static GstBufferPool *
+gst_msdk_create_d3d11_pool (GstMsdkEnc * thiz, guint num_buffers)
+{
+  GstBufferPool *pool = NULL;
+  GstD3D11Device *device;
+  GstStructure *config;
+  GstD3D11AllocationParams *params;
+  GstD3D11Format device_format;
+  guint bind_flags = 0;
+  GstCaps *aligned_caps = NULL;
+  GstVideoInfo *info = &thiz->input_state->info;
+  GstVideoInfo aligned_info;
+  gint aligned_width;
+  gint aligned_height;
+
+  device = gst_msdk_context_get_d3d11_device (thiz->context);
+
+  aligned_width = GST_ROUND_UP_16 (info->width);
+  if (GST_VIDEO_INFO_IS_INTERLACED (info)) {
+    aligned_height = GST_ROUND_UP_32 (info->height);
+  } else {
+    aligned_height = GST_ROUND_UP_16 (info->height);
+  }
+
+  gst_video_info_set_interlaced_format (&aligned_info,
+      GST_VIDEO_INFO_FORMAT (info), GST_VIDEO_INFO_INTERLACE_MODE (info),
+      aligned_width, aligned_height);
+
+  gst_d3d11_device_get_format (device, GST_VIDEO_INFO_FORMAT (&aligned_info),
+      &device_format);
+  if ((device_format.format_support[0] & D3D11_FORMAT_SUPPORT_RENDER_TARGET) ==
+      D3D11_FORMAT_SUPPORT_RENDER_TARGET) {
+    bind_flags = D3D11_BIND_RENDER_TARGET;
+  }
+
+  aligned_caps = gst_video_info_to_caps (&aligned_info);
+
+  pool = gst_d3d11_buffer_pool_new (device);
+  config = gst_buffer_pool_get_config (pool);
+  params = gst_d3d11_allocation_params_new (device, &aligned_info,
+      GST_D3D11_ALLOCATION_FLAG_DEFAULT, bind_flags,
+      D3D11_RESOURCE_MISC_SHARED);
+
+  gst_buffer_pool_config_set_d3d11_allocation_params (config, params);
+  gst_d3d11_allocation_params_free (params);
+  gst_buffer_pool_config_set_params (config, aligned_caps,
+      GST_VIDEO_INFO_SIZE (&aligned_info), num_buffers, 0);
+  gst_buffer_pool_set_config (pool, config);
+
+  gst_caps_unref (aligned_caps);
+  GST_LOG_OBJECT (thiz, "Creating d3d11 pool");
+
+  return pool;
+}
 #endif
 
 static GstBufferPool *
@@ -1347,12 +1416,10 @@ gst_msdkenc_create_buffer_pool (GstMsdkEnc * thiz, GstCaps * caps,
 #ifndef _WIN32
   pool = gst_msdk_create_va_pool (thiz, caps, num_buffers);
 #else
-  /* Currently use system pool for windows path */
+  pool = gst_msdk_create_d3d11_pool (thiz, num_buffers);
+#endif
   if (!thiz->use_video_memory)
     pool = gst_video_buffer_pool_new ();
-  else
-    GST_ERROR_OBJECT (thiz, "D3D11 video memory pool not implemented");
-#endif
   if (!pool)
     goto error_no_pool;
 
@@ -1446,6 +1513,18 @@ sinkpad_is_va (GstMsdkEnc * thiz)
 
   return FALSE;
 }
+#else
+static gboolean
+sinkpad_is_d3d11 (GstMsdkEnc * thiz)
+{
+  GstCapsFeatures *features =
+      gst_caps_get_features (thiz->input_state->caps, 0);
+  if (gst_caps_features_contains (features,
+          GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY))
+    return TRUE;
+
+  return FALSE;
+}
 #endif
 
 static gboolean
@@ -1465,16 +1544,14 @@ gst_msdkenc_set_format (GstVideoEncoder * encoder, GstVideoCodecState * state)
     }
     thiz->input_state = gst_video_codec_state_ref (state);
   }
-
-  /* TODO: Currently d3d allocator is not implemented.
-   * So encoder uses system memory by default on Windows.
-   */
 #ifndef _WIN32
   thiz->use_video_memory = TRUE;
   if (sinkpad_is_va (thiz))
     thiz->use_va = TRUE;
 #else
-  thiz->use_video_memory = FALSE;
+  thiz->use_video_memory = TRUE;
+  if (sinkpad_is_d3d11 (thiz))
+    thiz->use_d3d11 = TRUE;
 #endif
 
   GST_INFO_OBJECT (encoder, "This MSDK encoder uses %s memory",
@@ -1562,8 +1639,9 @@ done:
   return TRUE;
 }
 
+/* This function will be removed later */
 static GstMsdkSurface *
-gst_msdkenc_get_surface_from_pool (GstMsdkEnc * thiz, GstBufferPool * pool,
+gst_msdkenc_get_surface_from_pool_old (GstMsdkEnc * thiz, GstBufferPool * pool,
     GstBufferPoolAcquireParams * params)
 {
   GstBuffer *new_buffer;
@@ -1581,7 +1659,7 @@ gst_msdkenc_get_surface_from_pool (GstMsdkEnc * thiz, GstBufferPool * pool,
   }
 #ifndef _WIN32
   msdk_surface = gst_msdk_import_to_msdk_surface (new_buffer, thiz->context,
-      &thiz->aligned_info);
+      &thiz->aligned_info, 0);
 #else
   msdk_surface =
       gst_msdk_import_sys_mem_to_msdk_surface (new_buffer, thiz->aligned_info);
@@ -1593,11 +1671,93 @@ gst_msdkenc_get_surface_from_pool (GstMsdkEnc * thiz, GstBufferPool * pool,
   return msdk_surface;
 }
 
+static GstMsdkSurface *
+gst_msdkenc_get_surface_from_pool (GstMsdkEnc * thiz,
+    GstVideoCodecFrame * frame, GstBuffer * buf)
+{
+  GstBuffer *upload_buf;
+  GstMsdkSurface *msdk_surface = NULL;
+  GstVideoFrame src_frame, dst_frame;
+
+  if (!gst_buffer_pool_is_active (thiz->msdk_pool) &&
+      !gst_buffer_pool_set_active (thiz->msdk_pool, TRUE)) {
+    GST_ERROR_OBJECT (thiz->msdk_pool, "failed to activate buffer pool");
+    return NULL;
+  }
+
+  if (gst_buffer_pool_acquire_buffer (thiz->msdk_pool, &upload_buf,
+          NULL) != GST_FLOW_OK) {
+    GST_ERROR_OBJECT (thiz->msdk_pool, "failed to acquire a buffer from pool");
+    return NULL;
+  }
+
+  if (!gst_video_frame_map (&src_frame, &thiz->input_state->info, buf,
+          GST_MAP_READ)) {
+    GST_WARNING ("Failed to map src frame");
+    gst_buffer_unref (upload_buf);
+    return NULL;
+  }
+
+  if (!gst_video_frame_map (&dst_frame, &thiz->aligned_info, upload_buf,
+          GST_MAP_WRITE)) {
+    GST_WARNING ("Failed to map dst frame");
+    gst_video_frame_unmap (&src_frame);
+    gst_buffer_unref (upload_buf);
+    return NULL;
+  }
+
+  for (guint i = 0; i < GST_VIDEO_FRAME_N_PLANES (&src_frame); i++) {
+    guint src_width_in_bytes, src_height;
+    guint dst_width_in_bytes, dst_height;
+    guint width_in_bytes, height;
+    guint src_stride, dst_stride;
+    guint8 *src_data, *dst_data;
+
+    src_width_in_bytes = GST_VIDEO_FRAME_COMP_WIDTH (&src_frame, i) *
+        GST_VIDEO_FRAME_COMP_PSTRIDE (&src_frame, i);
+    src_height = GST_VIDEO_FRAME_COMP_HEIGHT (&src_frame, i);
+    src_stride = GST_VIDEO_FRAME_COMP_STRIDE (&src_frame, i);
+
+    dst_width_in_bytes = GST_VIDEO_FRAME_COMP_WIDTH (&dst_frame, i) *
+        GST_VIDEO_FRAME_COMP_PSTRIDE (&src_frame, i);
+    dst_height = GST_VIDEO_FRAME_COMP_HEIGHT (&src_frame, i);
+    dst_stride = GST_VIDEO_FRAME_COMP_STRIDE (&dst_frame, i);
+
+    width_in_bytes = MIN (src_width_in_bytes, dst_width_in_bytes);
+    height = MIN (src_height, dst_height);
+
+    src_data = (guint8 *) GST_VIDEO_FRAME_PLANE_DATA (&src_frame, i);
+    dst_data = (guint8 *) GST_VIDEO_FRAME_PLANE_DATA (&dst_frame, i);
+
+    for (guint j = 0; j < height; j++) {
+      memcpy (dst_data, src_data, width_in_bytes);
+      dst_data += dst_stride;
+      src_data += src_stride;
+    }
+  }
+
+  gst_video_frame_unmap (&dst_frame);
+  gst_video_frame_unmap (&src_frame);
+
+  if (thiz->use_video_memory) {
+    msdk_surface = gst_msdk_import_to_msdk_surface (upload_buf, thiz->context,
+        &thiz->aligned_info, GST_MAP_READ);
+  } else {
+    msdk_surface =
+        gst_msdk_import_sys_mem_to_msdk_surface (upload_buf,
+        thiz->aligned_info);
+  }
+
+  gst_buffer_replace (&frame->input_buffer, upload_buf);
+  gst_buffer_unref (upload_buf);
+
+  return msdk_surface;
+}
+
 static GstMsdkSurface *
 gst_msdkenc_get_surface_from_frame (GstMsdkEnc * thiz,
     GstVideoCodecFrame * frame)
 {
-  GstVideoFrame src_frame, out_frame;
   GstMsdkSurface *msdk_surface;
   GstBuffer *inbuf;
 
@@ -1607,58 +1767,19 @@ gst_msdkenc_get_surface_from_frame (GstMsdkEnc * thiz,
     msdk_surface->surface = gst_msdk_get_surface_from_buffer (inbuf);
     return msdk_surface;
   }
-#ifndef _WIN32
+
   msdk_surface = gst_msdk_import_to_msdk_surface (inbuf, thiz->context,
-      &thiz->input_state->info);
+      &thiz->input_state->info, GST_MAP_READ);
   if (msdk_surface) {
     msdk_surface->buf = gst_buffer_ref (inbuf);
     return msdk_surface;
   }
-#endif
 
   /* If upstream hasn't accpeted the proposed msdk bufferpool,
    * just copy frame to msdk buffer and take a surface from it.
    */
-  if (!(msdk_surface =
-          gst_msdkenc_get_surface_from_pool (thiz, thiz->msdk_pool, NULL)))
-    goto error;
-
-  if (!gst_video_frame_map (&src_frame, &thiz->input_state->info, inbuf,
-          GST_MAP_READ)) {
-    GST_ERROR_OBJECT (thiz, "failed to map the frame for source");
-    goto error;
-  }
-
-  if (!gst_video_frame_map (&out_frame, &thiz->aligned_info, msdk_surface->buf,
-          GST_MAP_WRITE)) {
-    GST_ERROR_OBJECT (thiz, "failed to map the frame for destination");
-    gst_video_frame_unmap (&src_frame);
-    goto error;
-  }
-
-  if (!gst_video_frame_copy (&out_frame, &src_frame)) {
-    GST_ERROR_OBJECT (thiz, "failed to copy frame");
-    gst_video_frame_unmap (&out_frame);
-    gst_video_frame_unmap (&src_frame);
-    goto error;
-  }
-
-  gst_video_frame_unmap (&out_frame);
-  gst_video_frame_unmap (&src_frame);
-
-  gst_buffer_replace (&frame->input_buffer, msdk_surface->buf);
-  gst_buffer_unref (msdk_surface->buf);
-  msdk_surface->buf = NULL;
-
-  return msdk_surface;
 
-error:
-  if (msdk_surface) {
-    if (msdk_surface->buf)
-      gst_buffer_unref (msdk_surface->buf);
-    g_slice_free (GstMsdkSurface, msdk_surface);
-  }
-  return NULL;
+  return gst_msdkenc_get_surface_from_pool (thiz, frame, inbuf);
 }
 
 static GstFlowReturn
@@ -1694,7 +1815,7 @@ gst_msdkenc_handle_frame (GstVideoEncoder * encoder, GstVideoCodecFrame * frame)
     if (!vpp_surface)
       goto invalid_surface;
     surface =
-        gst_msdkenc_get_surface_from_pool (thiz, thiz->msdk_converted_pool,
+        gst_msdkenc_get_surface_from_pool_old (thiz, thiz->msdk_converted_pool,
         NULL);
     if (!surface)
       goto invalid_surface;
@@ -1901,7 +2022,7 @@ gst_msdkenc_finish (GstVideoEncoder * encoder)
   return GST_FLOW_OK;
 }
 
-
+#ifndef _WIN32
 static gboolean
 gst_msdkenc_propose_allocation (GstVideoEncoder * encoder, GstQuery * query)
 {
@@ -1957,6 +2078,89 @@ gst_msdkenc_propose_allocation (GstVideoEncoder * encoder, GstQuery * query)
   return GST_VIDEO_ENCODER_CLASS (parent_class)->propose_allocation (encoder,
       query);
 }
+#else
+static gboolean
+gst_msdkenc_propose_allocation (GstVideoEncoder * encoder, GstQuery * query)
+{
+  GstMsdkEnc *thiz = GST_MSDKENC (encoder);
+  GstVideoInfo info;
+  GstBufferPool *pool = NULL;
+  GstD3D11Device *device;
+  GstCaps *caps;
+  guint size;
+  GstCapsFeatures *features;
+  guint num_buffers;
+  GstStructure *config;
+  gboolean is_d3d11 = FALSE;
+
+  if (!thiz->input_state)
+    return FALSE;
+
+  gst_query_parse_allocation (query, &caps, NULL);
+
+  if (!caps) {
+    GST_INFO_OBJECT (encoder, "failed to get caps");
+    return FALSE;
+  }
+
+  if (!gst_video_info_from_caps (&info, caps)) {
+    GST_INFO_OBJECT (encoder, "failed to get video info");
+    return FALSE;
+  }
+
+  features = gst_caps_get_features (caps, 0);
+  if (features && gst_caps_features_contains (features,
+          GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY)) {
+    GST_DEBUG_OBJECT (thiz, "upstream support d3d11 memory");
+    device = gst_msdk_context_get_d3d11_device (thiz->context);
+    pool = gst_d3d11_buffer_pool_new (device);
+    is_d3d11 = TRUE;
+  } else {
+    pool = gst_video_buffer_pool_new ();
+  }
+
+  config = gst_buffer_pool_get_config (pool);
+  gst_buffer_pool_config_add_option (config, GST_BUFFER_POOL_OPTION_VIDEO_META);
+
+  if (is_d3d11) {
+    GstD3D11AllocationParams *d3d11_params;
+    GstVideoAlignment align;
+
+    /* d3d11 buffer pool doesn't support generic video alignment
+     * because memory layout of CPU accessible staging texture is uncontrollable.
+     * Do D3D11 specific handling */
+    gst_msdk_set_video_alignment (&info, 0, 0, &align);
+
+    d3d11_params = gst_d3d11_allocation_params_new (device, &info,
+        GST_D3D11_ALLOCATION_FLAG_DEFAULT, 0, 0);
+
+    gst_d3d11_allocation_params_alignment (d3d11_params, &align);
+    gst_buffer_pool_config_set_d3d11_allocation_params (config, d3d11_params);
+    gst_d3d11_allocation_params_free (d3d11_params);
+  } else {
+    gst_buffer_pool_config_add_option (config,
+        GST_BUFFER_POOL_OPTION_VIDEO_ALIGNMENT);
+  }
+
+  num_buffers = gst_msdkenc_maximum_delayed_frames (thiz) + 1;
+  gst_buffer_pool_config_set_params (config,
+      caps, GST_VIDEO_INFO_SIZE (&info), num_buffers, 0);
+  gst_buffer_pool_set_config (pool, config);
+
+  /* d3d11 buffer pool will update actual CPU accessible buffer size based on
+   * allocated staging texture per gst_buffer_pool_set_config() call,
+   * need query again to get the size */
+  config = gst_buffer_pool_get_config (pool);
+  gst_buffer_pool_config_get_params (config, NULL, &size, NULL, NULL);
+  gst_structure_free (config);
+
+  gst_query_add_allocation_pool (query, pool, size, num_buffers, 0);
+  gst_query_add_allocation_meta (query, GST_VIDEO_META_API_TYPE, NULL);
+  gst_object_unref (pool);
+
+  return TRUE;
+}
+#endif
 
 static gboolean
 gst_msdkenc_query (GstVideoEncoder * encoder, GstQuery * query,
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.h b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.h
index cd266a2b49..f71e369370 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkenc.h
@@ -137,6 +137,7 @@ struct _GstMsdkEnc
   gboolean use_video_memory;
   gboolean use_dmabuf;
   gboolean use_va;
+  gboolean use_d3d11;
   gboolean initialized;
 
   /* element properties */
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkh265enc.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkh265enc.c
index 33dfcfe417..0a27e6dff9 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkh265enc.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkh265enc.c
@@ -141,7 +141,8 @@ static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
     GST_STATIC_CAPS (GST_MSDK_CAPS_STR (COMMON_FORMAT,
-            "{ NV12, P010_10LE }")));
+            "{ NV12, P010_10LE }") "; "
+        GST_MSDK_CAPS_MAKE_WITH_D3D11_FEATURE ("{ NV12, P010_10LE }")));
 #else
 static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvp9enc.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvp9enc.c
index da35769a68..c2c0d00f15 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvp9enc.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvp9enc.c
@@ -72,7 +72,8 @@ static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
     GST_STATIC_CAPS (GST_MSDK_CAPS_STR (COMMON_FORMAT,
-            "{ NV12, P010_10LE }")));
+            "{ NV12, P010_10LE }") "; "
+        GST_MSDK_CAPS_MAKE_WITH_D3D11_FEATURE ("{ NV12, P010_10LE }")));
 #else
 static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.c b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.c
index 9fc5f38308..a27f915192 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.c
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.c
@@ -69,6 +69,8 @@
 #undef EXT_FORMATS
 #define EXT_FORMATS     ", BGR10A2_LE"
 #endif
+#else
+#include <gst/d3d11/gstd3d11.h>
 #endif
 
 #if (MFX_VERSION >= 2004)
@@ -100,6 +102,8 @@ GST_DEBUG_CATEGORY_EXTERN (gst_msdkvpp_debug);
     "{ NV12, BGRA, YUY2, UYVY, VUYA, P010_10LE" EXT_SINK_FORMATS "}"
 #define SUPPORTED_VA_FORMAT \
     "{ NV12, VUYA, P010_10LE }"
+#define SUPPORTED_D3D11_FORMAT \
+    "{ NV12, VUYA, P010_10LE }"
 #define SRC_SYSTEM_FORMAT \
     "{ NV12, BGRA, YUY2, UYVY, VUYA, BGRx, P010_10LE" EXT_FORMATS EXT_SRC_FORMATS "}"
 #define SRC_DMABUF_FORMAT       \
@@ -112,8 +116,8 @@ GST_DEBUG_CATEGORY_EXTERN (gst_msdkvpp_debug);
 #define VA_SINK_CAPS_STR \
   GST_VIDEO_CAPS_MAKE_WITH_FEATURES ("memory:VAMemory", SUPPORTED_VA_FORMAT)
 #else
-#define DMABUF_SINK_CAPS_STR ""
-#define VA_SINK_CAPS_STR ""
+#define D3D11_SINK_CAPS_STR \
+  GST_MSDK_CAPS_MAKE_WITH_D3D11_FEATURE (SUPPORTED_D3D11_FORMAT)
 #endif
 
 #ifndef _WIN32
@@ -123,10 +127,11 @@ GST_DEBUG_CATEGORY_EXTERN (gst_msdkvpp_debug);
 #define VA_SRC_CAPS_STR \
   GST_VIDEO_CAPS_MAKE_WITH_FEATURES ("memory:VAMemory", SUPPORTED_VA_FORMAT)
 #else
-#define DMABUF_SRC_CAPS_STR ""
-#define VA_SRC_CAPS_STR ""
+#define D3D11_SRC_CAPS_STR \
+  GST_MSDK_CAPS_MAKE_WITH_D3D11_FEATURE (SUPPORTED_D3D11_FORMAT)
 #endif
 
+#ifndef _WIN32
 static GstStaticPadTemplate gst_msdkvpp_sink_factory =
     GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
@@ -143,7 +148,23 @@ static GstStaticPadTemplate gst_msdkvpp_src_factory =
         GST_VIDEO_CAPS_MAKE (SRC_SYSTEM_FORMAT) ", "
         "interlace-mode = (string){ progressive, interleaved, mixed }" ";"
         VA_SRC_CAPS_STR));
+#else
+static GstStaticPadTemplate gst_msdkvpp_sink_factory =
+    GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE (SUPPORTED_SYSTEM_FORMAT)
+        ", " "interlace-mode = (string){ progressive, interleaved, mixed }" ";"
+        D3D11_SINK_CAPS_STR));
 
+static GstStaticPadTemplate gst_msdkvpp_src_factory =
+    GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE (SRC_SYSTEM_FORMAT) ", "
+        "interlace-mode = (string){ progressive, interleaved, mixed }" ";"
+        D3D11_SRC_CAPS_STR));
+#endif
 enum
 {
   PROP_0,
@@ -420,7 +441,7 @@ gst_msdk_create_va_pool (GstVideoInfo * info, GstMsdkContext * msdk_context,
   GstVaDisplay *display = NULL;
   GstCaps *aligned_caps = NULL;
 
-  display = (GstVaDisplay *) gst_msdk_context_get_display (msdk_context);
+  display = (GstVaDisplay *) gst_msdk_context_get_va_display (msdk_context);
 
   if (use_dmabuf)
     allocator = gst_va_dmabuf_allocator_new (display);
@@ -447,11 +468,63 @@ gst_msdk_create_va_pool (GstVideoInfo * info, GstMsdkContext * msdk_context,
 
   return pool;
 }
+#else
+static GstBufferPool *
+gst_msdk_create_d3d11_pool (GstMsdkVPP * thiz, GstVideoInfo * info,
+    guint num_buffers, gboolean propose)
+{
+  GstBufferPool *pool = NULL;
+  GstD3D11Device *device;
+  GstStructure *config;
+  GstD3D11AllocationParams *params;
+  GstD3D11Format device_format;
+  guint bind_flags = 0;
+  GstCaps *aligned_caps = NULL;
+  GstVideoInfo aligned_info;
+  gint aligned_width;
+  gint aligned_height;
+
+  device = gst_msdk_context_get_d3d11_device (thiz->context);
+
+  aligned_width = GST_ROUND_UP_16 (info->width);
+  aligned_height = GST_ROUND_UP_32 (info->height);
+
+  gst_video_info_set_interlaced_format (&aligned_info,
+      GST_VIDEO_INFO_FORMAT (info), GST_VIDEO_INFO_INTERLACE_MODE (info),
+      aligned_width, aligned_height);
+
+  gst_d3d11_device_get_format (device, GST_VIDEO_INFO_FORMAT (&aligned_info),
+      &device_format);
+  if (!propose
+      && ((device_format.format_support[0] & D3D11_FORMAT_SUPPORT_RENDER_TARGET)
+          == D3D11_FORMAT_SUPPORT_RENDER_TARGET)) {
+    bind_flags = D3D11_BIND_RENDER_TARGET;
+  }
+
+  aligned_caps = gst_video_info_to_caps (&aligned_info);
+
+  pool = gst_d3d11_buffer_pool_new (device);
+  config = gst_buffer_pool_get_config (pool);
+  params = gst_d3d11_allocation_params_new (device, &aligned_info,
+      GST_D3D11_ALLOCATION_FLAG_DEFAULT, bind_flags,
+      D3D11_RESOURCE_MISC_SHARED);
+
+  gst_buffer_pool_config_set_d3d11_allocation_params (config, params);
+  gst_d3d11_allocation_params_free (params);
+  gst_buffer_pool_config_set_params (config, aligned_caps,
+      GST_VIDEO_INFO_SIZE (&aligned_info), num_buffers, 0);
+  gst_buffer_pool_set_config (pool, config);
+
+  gst_caps_unref (aligned_caps);
+  GST_LOG_OBJECT (thiz, "Creating d3d11 pool");
+
+  return pool;
+}
 #endif
 
 static GstBufferPool *
 gst_msdkvpp_create_buffer_pool (GstMsdkVPP * thiz, GstPadDirection direction,
-    GstCaps * caps, guint min_num_buffers)
+    GstCaps * caps, guint min_num_buffers, gboolean propose)
 {
   GstBufferPool *pool = NULL;
   GstStructure *config;
@@ -479,12 +552,10 @@ gst_msdkvpp_create_buffer_pool (GstMsdkVPP * thiz, GstPadDirection direction,
   pool = gst_msdk_create_va_pool (&info, thiz->context, use_dmabuf,
       min_num_buffers);
 #else
-  /* Currently use system pool for windows path */
+  pool = gst_msdk_create_d3d11_pool (thiz, &info, min_num_buffers, propose);
+#endif
   if (!thiz->use_video_memory)
     pool = gst_video_buffer_pool_new ();
-  else
-    GST_ERROR_OBJECT (thiz, "D3D video memory pool is not implemented");
-#endif
 
   if (!pool)
     goto error_no_pool;
@@ -588,7 +659,9 @@ create_src_pool (GstMsdkVPP * thiz, GstQuery * query, GstCaps * caps)
   min_buffers += thiz->async_depth + request.NumFrameSuggested;
   request.NumFrameSuggested = min_buffers;
 
-  pool = gst_msdkvpp_create_buffer_pool (thiz, GST_PAD_SRC, caps, min_buffers);
+  pool =
+      gst_msdkvpp_create_buffer_pool (thiz, GST_PAD_SRC, caps, min_buffers,
+      FALSE);
   if (!pool)
     return NULL;
   /* we do not support dynamic buffer count change */
@@ -623,9 +696,6 @@ gst_msdkvpp_decide_allocation (GstBaseTransform * trans, GstQuery * query)
   if (_gst_caps_has_feature (caps, GST_CAPS_FEATURE_MEMORY_DMABUF)) {
     GST_INFO_OBJECT (thiz, "MSDK VPP srcpad uses DMABuf memory");
     thiz->use_srcpad_dmabuf = TRUE;
-  } else if (_gst_caps_has_feature (caps, GST_CAPS_FEATURE_MEMORY_VA)) {
-    GST_INFO_OBJECT (thiz, "MSDK VPP srcpad uses VA memory");
-    thiz->use_srcpad_va = TRUE;
   }
 #endif
 
@@ -684,14 +754,14 @@ gst_msdkvpp_propose_allocation (GstBaseTransform * trans,
     /* alwys provide a new pool for upstream to help re-negotiation
      * more info here: https://bugzilla.gnome.org/show_bug.cgi?id=748344 */
     pool = gst_msdkvpp_create_buffer_pool (thiz, GST_PAD_SINK, caps,
-        min_buffers);
+        min_buffers, TRUE);
   }
 
   /* Update the internal pool if any allocation attribute changed */
   if (!gst_video_info_is_equal (&thiz->sinkpad_buffer_pool_info, &info)) {
     gst_object_unref (thiz->sinkpad_buffer_pool);
     thiz->sinkpad_buffer_pool = gst_msdkvpp_create_buffer_pool (thiz,
-        GST_PAD_SINK, caps, min_buffers);
+        GST_PAD_SINK, caps, min_buffers, FALSE);
   }
 
   /* get the size and allocator params from configured pool and set it in query */
@@ -716,11 +786,12 @@ gst_msdkvpp_propose_allocation (GstBaseTransform * trans,
 }
 
 static GstMsdkSurface *
-get_surface_from_pool (GstMsdkVPP * thiz, GstBufferPool * pool,
-    GstBufferPoolAcquireParams * params)
+gst_msdkvpp_get_surface_from_pool (GstMsdkVPP * thiz, GstBufferPool * pool,
+    GstBuffer * buf)
 {
-  GstBuffer *new_buffer;
+  GstBuffer *upload_buf;
   GstMsdkSurface *msdk_surface = NULL;
+  GstVideoFrame src_frame, dst_frame;
 
   if (!gst_buffer_pool_is_active (pool) &&
       !gst_buffer_pool_set_active (pool, TRUE)) {
@@ -728,20 +799,69 @@ get_surface_from_pool (GstMsdkVPP * thiz, GstBufferPool * pool,
     return NULL;
   }
 
-  if (gst_buffer_pool_acquire_buffer (pool, &new_buffer, params) != GST_FLOW_OK) {
+  if (gst_buffer_pool_acquire_buffer (pool, &upload_buf, NULL) != GST_FLOW_OK) {
     GST_ERROR_OBJECT (pool, "failed to acquire a buffer from pool");
     return NULL;
   }
-#ifndef _WIN32
-  msdk_surface = gst_msdk_import_to_msdk_surface (new_buffer, thiz->context,
-      &thiz->sinkpad_info);
-#else
-  msdk_surface = gst_msdk_import_sys_mem_to_msdk_surface
-      (new_buffer, thiz->sinkpad_buffer_pool_info);
-#endif
+
+  if (!gst_video_frame_map (&src_frame, &thiz->sinkpad_info, buf, GST_MAP_READ)) {
+    GST_ERROR_OBJECT (thiz, "failed to map the frame for source");
+    gst_buffer_unref (upload_buf);
+    return NULL;
+  }
+
+  if (!gst_video_frame_map (&dst_frame, &thiz->sinkpad_buffer_pool_info,
+          upload_buf, GST_MAP_WRITE)) {
+    GST_ERROR_OBJECT (thiz, "failed to map the frame for destination");
+    gst_video_frame_unmap (&src_frame);
+    gst_buffer_unref (upload_buf);
+    return NULL;
+  }
+
+  for (guint i = 0; i < GST_VIDEO_FRAME_N_PLANES (&src_frame); i++) {
+    guint src_width_in_bytes, src_height;
+    guint dst_width_in_bytes, dst_height;
+    guint width_in_bytes, height;
+    guint src_stride, dst_stride;
+    guint8 *src_data, *dst_data;
+
+    src_width_in_bytes = GST_VIDEO_FRAME_COMP_WIDTH (&src_frame, i) *
+        GST_VIDEO_FRAME_COMP_PSTRIDE (&src_frame, i);
+    src_height = GST_VIDEO_FRAME_COMP_HEIGHT (&src_frame, i);
+    src_stride = GST_VIDEO_FRAME_COMP_STRIDE (&src_frame, i);
+
+    dst_width_in_bytes = GST_VIDEO_FRAME_COMP_WIDTH (&dst_frame, i) *
+        GST_VIDEO_FRAME_COMP_PSTRIDE (&src_frame, i);
+    dst_height = GST_VIDEO_FRAME_COMP_HEIGHT (&src_frame, i);
+    dst_stride = GST_VIDEO_FRAME_COMP_STRIDE (&dst_frame, i);
+
+    width_in_bytes = MIN (src_width_in_bytes, dst_width_in_bytes);
+    height = MIN (src_height, dst_height);
+
+    src_data = (guint8 *) GST_VIDEO_FRAME_PLANE_DATA (&src_frame, i);
+    dst_data = (guint8 *) GST_VIDEO_FRAME_PLANE_DATA (&dst_frame, i);
+
+    for (guint j = 0; j < height; j++) {
+      memcpy (dst_data, src_data, width_in_bytes);
+      dst_data += dst_stride;
+      src_data += src_stride;
+    }
+  }
+
+  gst_video_frame_unmap (&dst_frame);
+  gst_video_frame_unmap (&src_frame);
+
+  if (thiz->use_video_memory) {
+    msdk_surface = gst_msdk_import_to_msdk_surface (upload_buf, thiz->context,
+        &thiz->sinkpad_info, GST_MAP_READ);
+  } else {
+    msdk_surface =
+        gst_msdk_import_sys_mem_to_msdk_surface (upload_buf,
+        thiz->sinkpad_buffer_pool_info);
+  }
 
   if (msdk_surface)
-    msdk_surface->buf = new_buffer;
+    msdk_surface->buf = upload_buf;
 
   return msdk_surface;
 }
@@ -749,7 +869,6 @@ get_surface_from_pool (GstMsdkVPP * thiz, GstBufferPool * pool,
 static GstMsdkSurface *
 get_msdk_surface_from_input_buffer (GstMsdkVPP * thiz, GstBuffer * inbuf)
 {
-  GstVideoFrame src_frame, out_frame;
   GstMsdkSurface *msdk_surface = NULL;
 
   if (gst_msdk_is_msdk_buffer (inbuf)) {
@@ -758,49 +877,20 @@ get_msdk_surface_from_input_buffer (GstMsdkVPP * thiz, GstBuffer * inbuf)
     msdk_surface->buf = gst_buffer_ref (inbuf);
     return msdk_surface;
   }
-#ifndef _WIN32
+
   msdk_surface = gst_msdk_import_to_msdk_surface (inbuf, thiz->context,
-      &thiz->sinkpad_info);
+      &thiz->sinkpad_info, GST_MAP_READ);
   if (msdk_surface) {
     msdk_surface->buf = gst_buffer_ref (inbuf);
     return msdk_surface;
   }
-#endif
 
   /* If upstream hasn't accpeted the proposed msdk bufferpool,
    * just copy frame to msdk buffer and take a surface from it.
    */
-  if (!(msdk_surface =
-          get_surface_from_pool (thiz, thiz->sinkpad_buffer_pool, NULL)))
-    goto error;
-
-  if (!gst_video_frame_map (&src_frame, &thiz->sinkpad_info, inbuf,
-          GST_MAP_READ)) {
-    GST_ERROR_OBJECT (thiz, "failed to map the frame for source");
-    goto error;
-  }
-
-  if (!gst_video_frame_map (&out_frame, &thiz->sinkpad_buffer_pool_info,
-          msdk_surface->buf, GST_MAP_WRITE)) {
-    GST_ERROR_OBJECT (thiz, "failed to map the frame for destination");
-    gst_video_frame_unmap (&src_frame);
-    goto error;
-  }
-
-  if (!gst_video_frame_copy (&out_frame, &src_frame)) {
-    GST_ERROR_OBJECT (thiz, "failed to copy frame");
-    gst_video_frame_unmap (&out_frame);
-    gst_video_frame_unmap (&src_frame);
-    goto error;
-  }
 
-  gst_video_frame_unmap (&out_frame);
-  gst_video_frame_unmap (&src_frame);
-
-  return msdk_surface;
-
-error:
-  return NULL;
+  return gst_msdkvpp_get_surface_from_pool (thiz, thiz->sinkpad_buffer_pool,
+      inbuf);
 }
 
 static GstFlowReturn
@@ -844,13 +934,12 @@ gst_msdkvpp_transform (GstBaseTransform * trans, GstBuffer * inbuf,
     out_surface = g_slice_new0 (GstMsdkSurface);
     out_surface->surface = gst_msdk_get_surface_from_buffer (outbuf);
   } else {
-#ifndef _WIN32
     out_surface = gst_msdk_import_to_msdk_surface (outbuf, thiz->context,
-        &thiz->srcpad_info);
-#else
-    out_surface =
-        gst_msdk_import_sys_mem_to_msdk_surface (outbuf, thiz->srcpad_info);
-#endif
+        &thiz->srcpad_info, GST_MAP_WRITE);
+    if (!thiz->use_video_memory) {
+      out_surface =
+          gst_msdk_import_sys_mem_to_msdk_surface (outbuf, thiz->srcpad_info);
+    }
     if (out_surface)
       out_surface->buf = gst_buffer_ref (outbuf);
     else {
@@ -937,15 +1026,14 @@ gst_msdkvpp_transform (GstBaseTransform * trans, GstBuffer * inbuf,
         create_new_surface = TRUE;
       } else {
         release_out_surface (thiz, out_surface);
-#ifndef _WIN32
         out_surface =
             gst_msdk_import_to_msdk_surface (outbuf_new, thiz->context,
-            &thiz->srcpad_buffer_pool_info);
-#else
-        out_surface =
-            gst_msdk_import_sys_mem_to_msdk_surface (outbuf_new,
-            thiz->srcpad_buffer_pool_info);
-#endif
+            &thiz->srcpad_buffer_pool_info, GST_MAP_WRITE);
+        if (!thiz->use_video_memory) {
+          out_surface =
+              gst_msdk_import_sys_mem_to_msdk_surface (outbuf_new,
+              thiz->srcpad_buffer_pool_info);
+        }
         if (out_surface) {
           out_surface->buf = gst_buffer_ref (outbuf_new);
           create_new_surface = TRUE;
@@ -1282,11 +1370,8 @@ gst_msdkvpp_set_caps (GstBaseTransform * trans, GstCaps * caps,
 
   thiz->sinkpad_info = in_info;
   thiz->srcpad_info = out_info;
-#ifndef _WIN32
+
   thiz->use_video_memory = TRUE;
-#else
-  thiz->use_video_memory = FALSE;
-#endif
 
   /* check for deinterlace requirement */
   deinterlace = gst_msdkvpp_is_deinterlace_enabled (thiz, &in_info);
@@ -1309,7 +1394,7 @@ gst_msdkvpp_set_caps (GstBaseTransform * trans, GstCaps * caps,
 
   thiz->sinkpad_buffer_pool =
       gst_msdkvpp_create_buffer_pool (thiz, GST_PAD_SINK, caps,
-      thiz->in_num_surfaces);
+      thiz->in_num_surfaces, FALSE);
   if (!thiz->sinkpad_buffer_pool) {
     GST_ERROR_OBJECT (thiz, "Failed to ensure the sinkpad buffer pool");
     return FALSE;
@@ -1366,12 +1451,10 @@ gst_msdkvpp_fixate_caps (GstBaseTransform * trans,
   GstMsdkVPP *thiz = GST_MSDKVPP (trans);
   GstCaps *result = NULL;
   gboolean *use_dmabuf;
-  gboolean *use_va;
 
   if (direction == GST_PAD_SRC) {
     result = gst_caps_fixate (result);
     use_dmabuf = &thiz->use_sinkpad_dmabuf;
-    use_va = &thiz->use_sinkpad_va;
   } else {
     /*
      * Override mirroring & rotation properties once video-direction
@@ -1383,7 +1466,6 @@ gst_msdkvpp_fixate_caps (GstBaseTransform * trans,
 
     result = gst_msdkvpp_fixate_srccaps (thiz, caps, othercaps);
     use_dmabuf = &thiz->use_srcpad_dmabuf;
-    use_va = &thiz->use_srcpad_va;
   }
 
   GST_DEBUG_OBJECT (trans, "fixated to %" GST_PTR_FORMAT, result);
@@ -1397,13 +1479,18 @@ gst_msdkvpp_fixate_caps (GstBaseTransform * trans,
           direction == GST_PAD_SRC ? GST_PAD_SINK : GST_PAD_SRC, result)) {
     gst_caps_set_features (result, 0,
         gst_caps_features_new (GST_CAPS_FEATURE_MEMORY_VA, NULL));
-    *use_va = TRUE;
   } else if (pad_accept_memory (thiz, GST_CAPS_FEATURE_MEMORY_DMABUF,
           direction == GST_PAD_SRC ? GST_PAD_SINK : GST_PAD_SRC, result)) {
     gst_caps_set_features (result, 0,
         gst_caps_features_new (GST_CAPS_FEATURE_MEMORY_DMABUF, NULL));
     *use_dmabuf = TRUE;
   }
+#else
+  if (pad_accept_memory (thiz, GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY,
+          direction == GST_PAD_SRC ? GST_PAD_SINK : GST_PAD_SRC, result)) {
+    gst_caps_set_features (result, 0,
+        gst_caps_features_new (GST_CAPS_FEATURE_MEMORY_D3D11_MEMORY, NULL));
+  }
 #endif
 
   return result;
@@ -1661,13 +1748,24 @@ gst_msdkvpp_set_context (GstElement * element, GstContext * context)
     gst_object_replace ((GstObject **) & thiz->context,
         (GstObject *) msdk_context);
     gst_object_unref (msdk_context);
-  } else if (gst_msdk_context_from_external_display (context,
+  } else
+#ifndef _WIN32
+    if (gst_msdk_context_from_external_va_display (context,
           thiz->hardware, 0 /* GST_MSDK_JOB_VPP will be set later */ ,
           &msdk_context)) {
     gst_object_replace ((GstObject **) & thiz->context,
         (GstObject *) msdk_context);
     gst_object_unref (msdk_context);
   }
+#else
+    if (gst_msdk_context_from_external_d3d11_device (context,
+          thiz->hardware, 0 /* GST_MSDK_JOB_VPP will be set later */ ,
+          &msdk_context)) {
+    gst_object_replace ((GstObject **) & thiz->context,
+        (GstObject *) msdk_context);
+    gst_object_unref (msdk_context);
+  }
+#endif
 
   GST_ELEMENT_CLASS (parent_class)->set_context (element, context);
 }
diff --git a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.h b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.h
index 8d0d1a37d7..4be2b90dad 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/gstmsdkvpp.h
@@ -97,8 +97,6 @@ struct _GstMsdkVPP
   gboolean use_video_memory;
   gboolean use_sinkpad_dmabuf;
   gboolean use_srcpad_dmabuf;
-  gboolean use_sinkpad_va;
-  gboolean use_srcpad_va;
   gboolean shared_context;
   gboolean add_video_meta;
   gboolean need_vpp;
diff --git a/subprojects/gst-plugins-bad/sys/msdk/meson.build b/subprojects/gst-plugins-bad/sys/msdk/meson.build
index 924deace98..659b96cbfe 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/meson.build
+++ b/subprojects/gst-plugins-bad/sys/msdk/meson.build
@@ -31,6 +31,10 @@ use_msdk = false
 use_onevpl = false
 onevpl_extra_args = []
 
+extra_args = [
+  '-DGST_USE_UNSTABLE_API',
+]
+
 msdk_option = get_option('msdk')
 if msdk_option.disabled()
   subdir_done()
@@ -38,6 +42,15 @@ endif
 
 if host_machine.system() == 'windows'
   msdk_sources += ['msdk_d3d.c', 'gstmsdkallocator_d3d.c' ]
+  if gstd3d11_dep.found()
+    extra_args += ['-DCOBJMACROS']
+  else
+    if msdk_option.enabled()
+      error('The msdk plugin was enabled explicity, but required d3d11 dependencies were not found.')
+    endif
+    subdir_done()
+  endif
+
 else
   if not gstva_dep.found()
     if msdk_option.enabled()
@@ -167,9 +180,8 @@ if host_machine.system() == 'windows'
     error('msdk plugin can only be built with MSVC')
   endif
   legacy_stdio_dep = cc.find_library('legacy_stdio_definitions', required: get_option('msdk'))
-  d3d11_dep = cc.find_library('d3d11', required: get_option('msdk'))
-  msdk_deps = declare_dependency(dependencies: [d3d11_dep, legacy_stdio_dep])
-  msdk_deps_found = d3d11_dep.found() and legacy_stdio_dep.found() and cc.get_id() == 'msvc'
+  msdk_deps = declare_dependency(dependencies: [gstd3d11_dep, legacy_stdio_dep])
+  msdk_deps_found = gstd3d11_dep.found() and legacy_stdio_dep.found() and cc.get_id() == 'msvc'
 else
   libdl_dep = cc.find_library('dl', required: get_option('msdk'))
   libgudev_dep = dependency('gudev-1.0', required: get_option('msdk'))
@@ -189,7 +201,7 @@ if msdk_deps_found
 
   gstmsdktag = library('gstmsdk',
     msdk_sources,
-    c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API'] + onevpl_extra_args,
+    c_args : gst_plugins_bad_args + extra_args + onevpl_extra_args,
     include_directories : [configinc, mfx_inc],
     dependencies : [gstbase_dep, gstvideo_dep, gstpbutils_dep, gstallocators_dep, gstcodecparsers_dep, mfx_dep, msdk_deps],
     install : true,
diff --git a/subprojects/gst-plugins-bad/sys/msdk/msdk.h b/subprojects/gst-plugins-bad/sys/msdk/msdk.h
index 2b197ccce8..9356330408 100644
--- a/subprojects/gst-plugins-bad/sys/msdk/msdk.h
+++ b/subprojects/gst-plugins-bad/sys/msdk/msdk.h
@@ -78,14 +78,18 @@ G_BEGIN_DECLS
 #define GST_MSDK_CAPS_MAKE_WITH_VA_FEATURE(vaformat) \
   GST_VIDEO_CAPS_MAKE_WITH_FEATURES("memory:VAMemory", vaformat) ", " \
   "interlace-mode = (string) progressive"
-#else
-#define GST_MSDK_CAPS_MAKE_WITH_DMABUF_FEATURE(dmaformat) ""
-#define GST_MSDK_CAPS_MAKE_WITH_VA_FEATURE(vaformat) ""
-#endif
 
 #define GST_MSDK_CAPS_STR(format,dmaformat) \
   GST_MSDK_CAPS_MAKE (format) "; " \
   GST_MSDK_CAPS_MAKE_WITH_DMABUF_FEATURE (dmaformat)
+#else
+#define GST_MSDK_CAPS_MAKE_WITH_D3D11_FEATURE(d3d11format) \
+  GST_VIDEO_CAPS_MAKE_WITH_FEATURES("memory:D3D11Memory", d3d11format) ", " \
+  "interlace-mode = (string) progressive"
+
+#define GST_MSDK_CAPS_STR(format,dmaformat) \
+  GST_MSDK_CAPS_MAKE (format)
+#endif
 
 #if (MFX_VERSION < 2000)
 typedef void * mfxLoader;
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/cuda-converter.c b/subprojects/gst-plugins-bad/sys/nvcodec/cuda-converter.c
deleted file mode 100644
index f2930019a6..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/cuda-converter.c
+++ /dev/null
@@ -1,2090 +0,0 @@
-/* GStreamer
- * Copyright (C) 2010 David Schleef <ds@schleef.org>
- * Copyright (C) 2010 Sebastian Drge <sebastian.droege@collabora.co.uk>
- * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-/**
- * SECTION:cudaconverter
- * @title: GstCudaConverter
- * @short_description: Generic video conversion using CUDA
- *
- * This object is used to convert video frames from one format to another.
- * The object can perform conversion of:
- *
- *  * video format
- *  * video colorspace
- *  * video size
- */
-
-/**
- * TODO:
- *  * Add more interpolation method and make it selectable,
- *    currently default bi-linear interpolation only
- *  * Add fast-path for conversion like videoconvert
- *  * Full colorimetry and chroma-siting support
- *  * cropping, and x, y position support
- */
-
-#ifdef HAVE_CONFIG_H
-#include "config.h"
-#endif
-
-#include "cuda-converter.h"
-#include <gst/cuda/gstcudautils.h>
-#include <gst/cuda/gstcudaloader.h>
-#include <gst/cuda/gstcudanvrtc.h>
-#include <string.h>
-
-#define CUDA_BLOCK_X 16
-#define CUDA_BLOCK_Y 16
-#define DIV_UP(size,block) (((size) + ((block) - 1)) / (block))
-
-static gboolean cuda_converter_lookup_path (GstCudaConverter * convert);
-
-#ifndef GST_DISABLE_GST_DEBUG
-#define GST_CAT_DEFAULT ensure_debug_category()
-static GstDebugCategory *
-ensure_debug_category (void)
-{
-  static gsize cat_gonce = 0;
-
-  if (g_once_init_enter (&cat_gonce)) {
-    gsize cat_done;
-
-    cat_done = (gsize) _gst_debug_category_new ("cuda-converter", 0,
-        "cuda-converter object");
-
-    g_once_init_leave (&cat_gonce, cat_done);
-  }
-
-  return (GstDebugCategory *) cat_gonce;
-}
-#else
-#define ensure_debug_category()
-#endif
-
-#define GST_CUDA_KERNEL_FUNC "gst_cuda_kernel_func"
-
-#define GST_CUDA_KERNEL_FUNC_TO_Y444 "gst_cuda_kernel_func_to_y444"
-
-#define GST_CUDA_KERNEL_FUNC_Y444_TO_YUV "gst_cuda_kernel_func_y444_to_yuv"
-
-#define GST_CUDA_KERNEL_FUNC_TO_ARGB "gst_cuda_kernel_func_to_argb"
-
-#define GST_CUDA_KERNEL_FUNC_SCALE_RGB "gst_cuda_kernel_func_scale_rgb"
-
-/* *INDENT-OFF* */
-/**
- * read_chroma:
- * @tex1: a CUDA texture object representing a semi-planar chroma plane
- * @tex2: dummy object
- * @x: the x coordinate to read data from @tex1
- * @y: the y coordinate to read data from @tex1
- *
- * Returns: a #ushort2 vector representing both chroma pixel values
- */
-static const gchar READ_CHROMA_FROM_SEMI_PLANAR[] =
-"__device__ ushort2\n"
-"read_chroma (cudaTextureObject_t tex1, cudaTextureObject_t tex2, \n"
-"    float x, float y)\n"
-"{\n"
-"  return tex2D<ushort2>(tex1, x, y);\n"
-"}";
-
-/**
- * read_chroma:
- * @tex1: a CUDA texture object representing a chroma planar plane
- * @tex2: a CUDA texture object representing the other planar plane
- * @x: the x coordinate to read data from @tex1 and @tex2
- * @y: the y coordinate to read data from @tex1 and @tex2
- *
- * Returns: a #ushort2 vector representing both chroma pixel values
- */
-static const gchar READ_CHROMA_FROM_PLANAR[] =
-"__device__ ushort2\n"
-"read_chroma (cudaTextureObject_t tex1, cudaTextureObject_t tex2, \n"
-"    float x, float y)\n"
-"{\n"
-"  unsigned short u, v;\n"
-"  u = tex2D<unsigned short>(tex1, x, y);\n"
-"  v = tex2D<unsigned short>(tex2, x, y);\n"
-"  return make_ushort2(u, v);\n"
-"}";
-
-/**
- * write_chroma:
- * @dst1: a CUDA global memory pointing to a semi-planar chroma plane
- * @dst2: dummy
- * @u: a pixel value to write @dst1
- * @v: a pixel value to write @dst1
- * @x: the x coordinate to write data into @tex1
- * @x: the y coordinate to write data into @tex1
- * @pstride: the pixel stride of @dst1
- * @mask: bitmask to be applied to high bitdepth plane
- *
- * Write @u and @v pixel value to @dst1 semi-planar plane
- */
-static const gchar WRITE_CHROMA_TO_SEMI_PLANAR[] =
-"__device__ void\n"
-"write_chroma (unsigned char *dst1, unsigned char *dst2, unsigned short u,\n"
-"    unsigned short v, int x, int y, int pstride, int stride, int mask)\n"
-"{\n"
-"  if (OUT_DEPTH > 8) {\n"
-"    *(unsigned short *)&dst1[x * pstride + y * stride] = (u & mask);\n"
-"    *(unsigned short *)&dst1[x * pstride + 2 + y * stride] = (v & mask);\n"
-"  } else {\n"
-"    dst1[x * pstride + y * stride] = u;\n"
-"    dst1[x * pstride + 1 + y * stride] = v;\n"
-"  }\n"
-"}";
-
-/**
- * write_chroma:
- * @dst1: a CUDA global memory pointing to a planar chroma plane
- * @dst2: a CUDA global memory pointing to a the other planar chroma plane
- * @u: a pixel value to write @dst1
- * @v: a pixel value to write @dst1
- * @x: the x coordinate to write data into @tex1
- * @x: the y coordinate to write data into @tex1
- * @pstride: the pixel stride of @dst1
- * @mask: bitmask to be applied to high bitdepth plane
- *
- * Write @u and @v pixel value into @dst1 and @dst2 planar planes
- */
-static const gchar WRITE_CHROMA_TO_PLANAR[] =
-"__device__ void\n"
-"write_chroma (unsigned char *dst1, unsigned char *dst2, unsigned short u,\n"
-"    unsigned short v, int x, int y, int pstride, int stride, int mask)\n"
-"{\n"
-"  if (OUT_DEPTH > 8) {\n"
-"    *(unsigned short *)&dst1[x * pstride + y * stride] = (u & mask);\n"
-"    *(unsigned short *)&dst2[x * pstride + y * stride] = (v & mask);\n"
-"  } else {\n"
-"    dst1[x * pstride + y * stride] = u;\n"
-"    dst2[x * pstride + y * stride] = v;\n"
-"  }\n"
-"}";
-
-/* CUDA kernel source for from YUV to YUV conversion and scale */
-static const gchar templ_YUV_TO_YUV[] =
-"extern \"C\"{\n"
-"__constant__ float SCALE_H = %s;\n"
-"__constant__ float SCALE_V = %s;\n"
-"__constant__ float CHROMA_SCALE_H = %s;\n"
-"__constant__ float CHROMA_SCALE_V = %s;\n"
-"__constant__ int WIDTH = %d;\n"
-"__constant__ int HEIGHT = %d;\n"
-"__constant__ int CHROMA_WIDTH = %d;\n"
-"__constant__ int CHROMA_HEIGHT = %d;\n"
-"__constant__ int IN_DEPTH = %d;\n"
-"__constant__ int OUT_DEPTH = %d;\n"
-"__constant__ int PSTRIDE = %d;\n"
-"__constant__ int CHROMA_PSTRIDE = %d;\n"
-"__constant__ int IN_SHIFT = %d;\n"
-"__constant__ int OUT_SHIFT = %d;\n"
-"__constant__ int MASK = %d;\n"
-"__constant__ int SWAP_UV = %d;\n"
-"\n"
-"__device__ unsigned short\n"
-"do_scale_pixel (unsigned short val) \n"
-"{\n"
-"  unsigned int diff;\n"
-"  if (OUT_DEPTH > IN_DEPTH) {\n"
-"    diff = OUT_DEPTH - IN_DEPTH;\n"
-"    return (val << diff) | (val >> (IN_DEPTH - diff));\n"
-"  } else if (IN_DEPTH > OUT_DEPTH) {\n"
-"    return val >> (IN_DEPTH - OUT_DEPTH);\n"
-"  }\n"
-"  return val;\n"
-"}\n"
-"\n"
-/* __device__ ushort2
- * read_chroma (cudaTextureObject_t tex1, cudaTextureObject_t tex2, float x, float y);
- */
-"%s\n"
-"\n"
-/* __device__ void
- * write_chroma (unsigned char *dst1, unsigned char *dst2, unsigned short u,
- *     unsigned short v, int x, int y, int pstride, int stride, int mask);
- */
-"%s\n"
-"\n"
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC
-"(cudaTextureObject_t tex0, cudaTextureObject_t tex1, cudaTextureObject_t tex2,\n"
-"    unsigned char *dst0, unsigned char *dst1, unsigned char *dst2,\n"
-"    int stride, int uv_stride)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < WIDTH && y_pos < HEIGHT) {\n"
-"    float src_xpos = SCALE_H * x_pos;\n"
-"    float src_ypos = SCALE_V * y_pos;\n"
-"    unsigned short y = tex2D<unsigned short>(tex0, src_xpos, src_ypos);\n"
-"    y = y >> IN_SHIFT;\n"
-"    y = do_scale_pixel (y);\n"
-"    y = y << OUT_SHIFT;\n"
-"    if (OUT_DEPTH > 8) {\n"
-"      *(unsigned short *)&dst0[x_pos * PSTRIDE + y_pos * stride] = (y & MASK);\n"
-"    } else {\n"
-"      dst0[x_pos * PSTRIDE + y_pos * stride] = y;\n"
-"    }\n"
-"  }\n"
-"  if (x_pos < CHROMA_WIDTH && y_pos < CHROMA_HEIGHT) {\n"
-"    float src_xpos = CHROMA_SCALE_H * x_pos;\n"
-"    float src_ypos = CHROMA_SCALE_V * y_pos;\n"
-"    unsigned short u, v;\n"
-"    ushort2 uv = read_chroma (tex1, tex2, src_xpos, src_ypos);\n"
-"    u = uv.x;\n"
-"    v = uv.y;\n"
-"    u = u >> IN_SHIFT;\n"
-"    v = v >> IN_SHIFT;\n"
-"    u = do_scale_pixel (u);\n"
-"    v = do_scale_pixel (v);\n"
-"    u = u << OUT_SHIFT;\n"
-"    v = v << OUT_SHIFT;\n"
-"    if (SWAP_UV) {\n"
-"      unsigned short tmp = u;\n"
-"      u = v;\n"
-"      v = tmp;\n"
-"    }\n"
-"    write_chroma (dst1,\n"
-"      dst2, u, v, x_pos, y_pos, CHROMA_PSTRIDE, uv_stride, MASK);\n"
-"  }\n"
-"}\n"
-"\n"
-"}";
-
-/* CUDA kernel source for from YUV to RGB conversion and scale */
-static const gchar templ_YUV_TO_RGB[] =
-"extern \"C\"{\n"
-"__constant__ float offset[3] = {%s, %s, %s};\n"
-"__constant__ float rcoeff[3] = {%s, %s, %s};\n"
-"__constant__ float gcoeff[3] = {%s, %s, %s};\n"
-"__constant__ float bcoeff[3] = {%s, %s, %s};\n"
-"\n"
-"__constant__ float SCALE_H = %s;\n"
-"__constant__ float SCALE_V = %s;\n"
-"__constant__ float CHROMA_SCALE_H = %s;\n"
-"__constant__ float CHROMA_SCALE_V = %s;\n"
-"__constant__ int WIDTH = %d;\n"
-"__constant__ int HEIGHT = %d;\n"
-"__constant__ int CHROMA_WIDTH = %d;\n"
-"__constant__ int CHROMA_HEIGHT = %d;\n"
-"__constant__ int IN_DEPTH = %d;\n"
-"__constant__ int OUT_DEPTH = %d;\n"
-"__constant__ int PSTRIDE = %d;\n"
-"__constant__ int CHROMA_PSTRIDE = %d;\n"
-"__constant__ int IN_SHIFT = %d;\n"
-"__constant__ int OUT_SHIFT = %d;\n"
-"__constant__ int MASK = %d;\n"
-"__constant__ int SWAP_UV = %d;\n"
-"__constant__ int MAX_IN_VAL = %d;\n"
-"__constant__ int R_IDX = %d;\n"
-"__constant__ int G_IDX = %d;\n"
-"__constant__ int B_IDX = %d;\n"
-"__constant__ int A_IDX = %d;\n"
-"__constant__ int X_IDX = %d;\n"
-"\n"
-"__device__ unsigned short\n"
-"do_scale_pixel (unsigned short val) \n"
-"{\n"
-"  unsigned int diff;\n"
-"  if (OUT_DEPTH > IN_DEPTH) {\n"
-"    diff = OUT_DEPTH - IN_DEPTH;\n"
-"    return (val << diff) | (val >> (IN_DEPTH - diff));\n"
-"  } else if (IN_DEPTH > OUT_DEPTH) {\n"
-"    return val >> (IN_DEPTH - OUT_DEPTH);\n"
-"  }\n"
-"  return val;\n"
-"}\n"
-"\n"
-"__device__ float\n"
-"dot(float3 val, float *coeff)\n"
-"{\n"
-"  return val.x * coeff[0] + val.y * coeff[1] + val.z * coeff[2];\n"
-"}\n"
-"\n"
-"__device__ uint3\n"
-"yuv_to_rgb (unsigned short y, unsigned short u, unsigned short v, unsigned int max_val)\n"
-"{\n"
-"  float3 yuv = make_float3 (y, u, v);\n"
-"  uint3 rgb;\n"
-"  rgb.x = max ((unsigned int)(dot (yuv, rcoeff) + offset[0]), 0);\n"
-"  rgb.y = max ((unsigned int)(dot (yuv, gcoeff) + offset[1]), 0);\n"
-"  rgb.z = max ((unsigned int)(dot (yuv, bcoeff) + offset[2]), 0);\n"
-"  rgb.x = min (rgb.x, max_val);\n"
-"  rgb.y = min (rgb.y, max_val);\n"
-"  rgb.z = min (rgb.z, max_val);\n"
-"  return rgb;\n"
-"}\n"
-"\n"
-/* __device__ ushort2
- * read_chroma (cudaTextureObject_t tex1, cudaTextureObject_t tex2, float x, float y);
- */
-"%s\n"
-"\n"
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC
-"(cudaTextureObject_t tex0, cudaTextureObject_t tex1, cudaTextureObject_t tex2,\n"
-"    unsigned char *dstRGB, int stride)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < WIDTH && y_pos < HEIGHT) {\n"
-"    float src_xpos = SCALE_H * x_pos;\n"
-"    float src_ypos = SCALE_V * y_pos;\n"
-"    unsigned short y = tex2D<unsigned short>(tex0, src_xpos, src_ypos);\n"
-"    ushort2 uv;\n"
-"    unsigned short u, v;\n"
-"    uint3 rgb;\n"
-"    unsigned int clip_max = MAX_IN_VAL;\n"
-"    src_xpos = CHROMA_SCALE_H * x_pos;\n"
-"    src_ypos = CHROMA_SCALE_V * y_pos;\n"
-"    uv = read_chroma (tex1, tex2, src_xpos, src_ypos);\n"
-"    u = uv.x;\n"
-"    v = uv.y;\n"
-"    y = y >> IN_SHIFT;\n"
-"    u = u >> IN_SHIFT;\n"
-"    v = v >> IN_SHIFT;\n"
-"    if (SWAP_UV) {\n"
-"      unsigned short tmp = u;\n"
-"      u = v;\n"
-"      v = tmp;\n"
-"    }\n"
-     /* conversion matrix is scaled to higher bitdepth between in/out formats */
-"    if (OUT_DEPTH > IN_DEPTH) {\n"
-"      y = do_scale_pixel (y);\n"
-"      u = do_scale_pixel (u);\n"
-"      v = do_scale_pixel (v);\n"
-"      clip_max = MASK;\n"
-"    }"
-"    rgb = yuv_to_rgb (y, u, v, clip_max);\n"
-"    if (OUT_DEPTH < IN_DEPTH) {\n"
-"      rgb.x = do_scale_pixel (rgb.x);\n"
-"      rgb.y = do_scale_pixel (rgb.y);\n"
-"      rgb.z = do_scale_pixel (rgb.z);\n"
-"    }"
-"    if (OUT_DEPTH > 8) {\n"
-"      unsigned int packed_rgb = 0;\n"
-       /* A is always MSB, we support only little endian system */
-"      packed_rgb = 0xc000 << 16;\n"
-"      packed_rgb |= (rgb.x << (30 - (R_IDX * 10)));\n"
-"      packed_rgb |= (rgb.y << (30 - (G_IDX * 10)));\n"
-"      packed_rgb |= (rgb.z << (30 - (B_IDX * 10)));\n"
-"      *(unsigned int *)&dstRGB[x_pos * PSTRIDE + y_pos * stride] = packed_rgb;\n"
-"    } else {\n"
-"      dstRGB[x_pos * PSTRIDE + R_IDX + y_pos * stride] = (unsigned char) rgb.x;\n"
-"      dstRGB[x_pos * PSTRIDE + G_IDX + y_pos * stride] = (unsigned char) rgb.y;\n"
-"      dstRGB[x_pos * PSTRIDE + B_IDX + y_pos * stride] = (unsigned char) rgb.z;\n"
-"      if (A_IDX >= 0 || X_IDX >= 0)\n"
-"        dstRGB[x_pos * PSTRIDE + A_IDX + y_pos * stride] = 0xff;\n"
-"    }\n"
-"  }\n"
-"}\n"
-"\n"
-"}";
-
-/**
- * GST_CUDA_KERNEL_FUNC_TO_ARGB:
- * @srcRGB: a CUDA global memory containing a RGB image
- * @dstRGB: a CUDA global memory to store unpacked ARGB image
- * @width: the width of @srcRGB and @dstRGB
- * @height: the height of @srcRGB and @dstRGB
- * @src_stride: the stride of @srcRGB
- * @src_pstride: the pixel stride of @srcRGB
- * @dst_stride: the stride of @dstRGB
- * @r_idx: the index of red component of @srcRGB
- * @g_idx: the index of green component of @srcRGB
- * @b_idx: the index of blue component of @srcRGB
- * @a_idx: the index of alpha component of @srcRGB
- *
- * Unpack a RGB image from @srcRGB and write the unpacked data into @dstRGB
- */
-static const gchar unpack_to_ARGB[] =
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC_TO_ARGB
-"(unsigned char *srcRGB, unsigned char *dstRGB, int width, int height,\n"
-"    int src_stride, int src_pstride, int dst_stride,\n"
-"    int r_idx, int g_idx, int b_idx, int a_idx)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < width && y_pos < height) {\n"
-"    if (a_idx >= 0) {\n"
-"      dstRGB[x_pos * 4 + y_pos * dst_stride] =\n"
-"          srcRGB[x_pos * src_pstride + a_idx + y_pos * src_stride];\n"
-"    } else {\n"
-"      dstRGB[x_pos * 4 + y_pos * dst_stride] = 0xff;\n"
-"    }\n"
-"    dstRGB[x_pos * 4 + 1 + y_pos * dst_stride] =\n"
-"        srcRGB[x_pos * src_pstride + r_idx + y_pos * src_stride];\n"
-"    dstRGB[x_pos * 4 + 2 + y_pos * dst_stride] =\n"
-"        srcRGB[x_pos * src_pstride + g_idx + y_pos * src_stride];\n"
-"    dstRGB[x_pos * 4 + 3 + y_pos * dst_stride] =\n"
-"        srcRGB[x_pos * src_pstride + b_idx + y_pos * src_stride];\n"
-"  }\n"
-"}\n";
-
-/**
- * GST_CUDA_KERNEL_FUNC_TO_ARGB:
- * @srcRGB: a CUDA global memory containing a RGB image
- * @dstRGB: a CUDA global memory to store unpacked ARGB64 image
- * @width: the width of @srcRGB and @dstRGB
- * @height: the height of @srcRGB and @dstRGB
- * @src_stride: the stride of @srcRGB
- * @src_pstride: the pixel stride of @srcRGB
- * @dst_stride: the stride of @dstRGB
- * @r_idx: the index of red component of @srcRGB
- * @g_idx: the index of green component of @srcRGB
- * @b_idx: the index of blue component of @srcRGB
- * @a_idx: the index of alpha component of @srcRGB
- *
- * Unpack a RGB image from @srcRGB and write the unpacked data into @dstRGB
- */
-static const gchar unpack_to_ARGB64[] =
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC_TO_ARGB
-"(unsigned char *srcRGB, unsigned char *dstRGB, int width, int height,\n"
-"    int src_stride, int src_pstride, int dst_stride,\n"
-"    int r_idx, int g_idx, int b_idx, int a_idx)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < width && y_pos < height) {\n"
-"    unsigned short a, r, g, b;\n"
-"    unsigned int read_val;\n"
-"    read_val = *(unsigned int *)&srcRGB[x_pos * src_pstride + y_pos * src_stride];\n"
-"    a = (read_val >> 30) & 0x03;\n"
-"    a = (a << 14) | (a << 12) | (a << 10) | (a << 8) | (a << 6) | (a << 4) | (a << 2) | (a << 0);\n"
-"    r = ((read_val >> (30 - (r_idx * 10))) & 0x3ff);\n"
-"    r = (r << 6) | (r >> 4);\n"
-"    g = ((read_val >> (30 - (g_idx * 10))) & 0x3ff);\n"
-"    g = (g << 6) | (g >> 4);\n"
-"    b = ((read_val >> (30 - (b_idx * 10))) & 0x3ff);\n"
-"    b = (b << 6) | (b >> 4);\n"
-"    *(unsigned short *)&dstRGB[x_pos * 8 + y_pos * dst_stride] = 0xffff;\n"
-"    *(unsigned short *)&dstRGB[x_pos * 8 + 2 + y_pos * dst_stride] = r;\n"
-"    *(unsigned short *)&dstRGB[x_pos * 8 + 4 + y_pos * dst_stride] = g;\n"
-"    *(unsigned short *)&dstRGB[x_pos * 8 + 6 + y_pos * dst_stride] = b;\n"
-"  }\n"
-"}\n";
-
-/* CUDA kernel source for from RGB to YUV conversion and scale */
-static const gchar templ_RGB_TO_YUV[] =
-"extern \"C\"{\n"
-"__constant__ float offset[3] = {%s, %s, %s};\n"
-"__constant__ float ycoeff[3] = {%s, %s, %s};\n"
-"__constant__ float ucoeff[3] = {%s, %s, %s};\n"
-"__constant__ float vcoeff[3] = {%s, %s, %s};\n"
-"\n"
-"__constant__ float SCALE_H = %s;\n"
-"__constant__ float SCALE_V = %s;\n"
-"__constant__ float CHROMA_SCALE_H = %s;\n"
-"__constant__ float CHROMA_SCALE_V = %s;\n"
-"__constant__ int WIDTH = %d;\n"
-"__constant__ int HEIGHT = %d;\n"
-"__constant__ int CHROMA_WIDTH = %d;\n"
-"__constant__ int CHROMA_HEIGHT = %d;\n"
-"__constant__ int IN_DEPTH = %d;\n"
-"__constant__ int OUT_DEPTH = %d;\n"
-"__constant__ int PSTRIDE = %d;\n"
-"__constant__ int CHROMA_PSTRIDE = %d;\n"
-"__constant__ int IN_SHIFT = %d;\n"
-"__constant__ int OUT_SHIFT = %d;\n"
-"__constant__ int MASK = %d;\n"
-"__constant__ int SWAP_UV = %d;\n"
-"\n"
-"__device__ unsigned short\n"
-"do_scale_pixel (unsigned short val) \n"
-"{\n"
-"  unsigned int diff;\n"
-"  if (OUT_DEPTH > IN_DEPTH) {\n"
-"    diff = OUT_DEPTH - IN_DEPTH;\n"
-"    return (val << diff) | (val >> (IN_DEPTH - diff));\n"
-"  } else if (IN_DEPTH > OUT_DEPTH) {\n"
-"    return val >> (IN_DEPTH - OUT_DEPTH);\n"
-"  }\n"
-"  return val;\n"
-"}\n"
-"\n"
-"__device__ float\n"
-"dot(float3 val, float *coeff)\n"
-"{\n"
-"  return val.x * coeff[0] + val.y * coeff[1] + val.z * coeff[2];\n"
-"}\n"
-"\n"
-"__device__ uint3\n"
-"rgb_to_yuv (unsigned short r, unsigned short g, unsigned short b,\n"
-"    unsigned int max_val)\n"
-"{\n"
-"  float3 rgb = make_float3 (r, g, b);\n"
-"  uint3 yuv;\n"
-"  yuv.x = max ((unsigned int)(dot (rgb, ycoeff) + offset[0]), 0);\n"
-"  yuv.y = max ((unsigned int)(dot (rgb, ucoeff) + offset[1]), 0);\n"
-"  yuv.z = max ((unsigned int)(dot (rgb, vcoeff) + offset[2]), 0);\n"
-"  yuv.x = min (yuv.x, max_val);\n"
-"  yuv.y = min (yuv.y, max_val);\n"
-"  yuv.z = min (yuv.z, max_val);\n"
-"  return yuv;\n"
-"}\n"
-"\n"
-/* __global__ void
- * GST_CUDA_KERNEL_FUNC_TO_ARGB
- */
-"%s\n"
-"\n"
-/* __device__ ushort2
- * read_chroma (cudaTextureObject_t tex1, cudaTextureObject_t tex2, float x, float y);
- */
-"%s\n"
-"\n"
-/* __device__ void
- * write_chroma (unsigned char *dst1, unsigned char *dst2, unsigned short u,
- *     unsigned short v, int x, int y, int pstride, int stride, int mask);
- */
-"%s\n"
-"\n"
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC_TO_Y444
-"(cudaTextureObject_t srcRGB, unsigned char *dstY, int y_stride,\n"
-"    unsigned char *dstU, int u_stride, unsigned char *dstV, int v_stride,\n"
-"    int width, int height, int dst_pstride, int in_depth)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < width && y_pos < height) {\n"
-"    ushort4 argb = tex2D<ushort4>(srcRGB, x_pos, y_pos);\n"
-"    uint3 yuv;\n"
-"    yuv = rgb_to_yuv (argb.y, argb.z, argb.w, (1 << in_depth) - 1);\n"
-"    if (in_depth > 8) {\n"
-"      *(unsigned short *)&dstY[x_pos * dst_pstride + y_pos * y_stride] = yuv.x;\n"
-"      *(unsigned short *)&dstU[x_pos * dst_pstride + y_pos * u_stride] = yuv.y;\n"
-"      *(unsigned short *)&dstV[x_pos * dst_pstride + y_pos * v_stride] = yuv.z;\n"
-"    } else {\n"
-"      dstY[x_pos * dst_pstride + y_pos * y_stride] = yuv.x;\n"
-"      dstU[x_pos * dst_pstride + y_pos * u_stride] = yuv.y;\n"
-"      dstV[x_pos * dst_pstride + y_pos * v_stride] = yuv.z;\n"
-"    }\n"
-"  }\n"
-"}\n"
-"\n"
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC_Y444_TO_YUV
-"(cudaTextureObject_t tex0, cudaTextureObject_t tex1, cudaTextureObject_t tex2,\n"
-"    unsigned char *dst0, unsigned char *dst1, unsigned char *dst2,\n"
-"    int stride, int uv_stride)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < WIDTH && y_pos < HEIGHT) {\n"
-"    float src_xpos = SCALE_H * x_pos;\n"
-"    float src_ypos = SCALE_V * y_pos;\n"
-"    unsigned short y = tex2D<unsigned short>(tex0, src_xpos, src_ypos);\n"
-"    y = y >> IN_SHIFT;\n"
-"    y = do_scale_pixel (y);\n"
-"    y = y << OUT_SHIFT;\n"
-"    if (OUT_DEPTH > 8) {\n"
-"      *(unsigned short *)&dst0[x_pos * PSTRIDE + y_pos * stride] = (y & MASK);\n"
-"    } else {\n"
-"      dst0[x_pos * PSTRIDE + y_pos * stride] = y;\n"
-"    }\n"
-"  }\n"
-"  if (x_pos < CHROMA_WIDTH && y_pos < CHROMA_HEIGHT) {\n"
-"    float src_xpos = CHROMA_SCALE_H * x_pos;\n"
-"    float src_ypos = CHROMA_SCALE_V * y_pos;\n"
-"    unsigned short u, v;\n"
-"    ushort2 uv;\n"
-"    uv = read_chroma (tex1, tex2, src_xpos, src_ypos);\n"
-"    u = uv.x;\n"
-"    v = uv.y;\n"
-"    u = u >> IN_SHIFT;\n"
-"    v = v >> IN_SHIFT;\n"
-"    u = do_scale_pixel (u);\n"
-"    v = do_scale_pixel (v);\n"
-"    u = u << OUT_SHIFT;\n"
-"    v = v << OUT_SHIFT;\n"
-"    if (SWAP_UV) {\n"
-"      unsigned short tmp = u;\n"
-"      u = v;\n"
-"      v = tmp;\n"
-"    }\n"
-"    write_chroma (dst1,\n"
-"      dst2, u, v, x_pos, y_pos, CHROMA_PSTRIDE, uv_stride, MASK);\n"
-"  }\n"
-"}\n"
-"\n"
-"}";
-
-/* CUDA kernel source for from RGB to RGB conversion and scale */
-static const gchar templ_RGB_to_RGB[] =
-"extern \"C\"{\n"
-"__constant__ float SCALE_H = %s;\n"
-"__constant__ float SCALE_V = %s;\n"
-"__constant__ int WIDTH = %d;\n"
-"__constant__ int HEIGHT = %d;\n"
-"__constant__ int IN_DEPTH = %d;\n"
-"__constant__ int OUT_DEPTH = %d;\n"
-"__constant__ int PSTRIDE = %d;\n"
-"__constant__ int R_IDX = %d;\n"
-"__constant__ int G_IDX = %d;\n"
-"__constant__ int B_IDX = %d;\n"
-"__constant__ int A_IDX = %d;\n"
-"__constant__ int X_IDX = %d;\n"
-"\n"
-"__device__ unsigned short\n"
-"do_scale_pixel (unsigned short val) \n"
-"{\n"
-"  unsigned int diff;\n"
-"  if (OUT_DEPTH > IN_DEPTH) {\n"
-"    diff = OUT_DEPTH - IN_DEPTH;\n"
-"    return (val << diff) | (val >> (IN_DEPTH - diff));\n"
-"  } else if (IN_DEPTH > OUT_DEPTH) {\n"
-"    return val >> (IN_DEPTH - OUT_DEPTH);\n"
-"  }\n"
-"  return val;\n"
-"}\n"
-"\n"
-/* __global__ void
- * GST_CUDA_KERNEL_FUNC_TO_ARGB
- */
-"%s\n"
-"\n"
-/* convert ARGB or ARGB64 to other RGB formats with scale */
-"__global__ void\n"
-GST_CUDA_KERNEL_FUNC_SCALE_RGB
-"(cudaTextureObject_t srcRGB, unsigned char *dstRGB, int dst_stride)\n"
-"{\n"
-"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
-"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
-"  if (x_pos < WIDTH && y_pos < HEIGHT) {\n"
-"    float src_xpos = SCALE_H * x_pos;\n"
-"    float src_ypos = SCALE_V * y_pos;\n"
-"    ushort4 argb = tex2D<ushort4>(srcRGB, src_xpos, src_ypos);\n"
-"    argb.x = do_scale_pixel(argb.x);\n"
-"    argb.y = do_scale_pixel(argb.y);\n"
-"    argb.z = do_scale_pixel(argb.z);\n"
-"    argb.w = do_scale_pixel(argb.w);\n"
-     /* FIXME: RGB10A2_LE or BGR10A2_LE only */
-"    if (OUT_DEPTH > 8) {\n"
-"      unsigned int packed_rgb = 0;\n"
-"      unsigned int a, r, g, b;"
-"      a = (argb.x >> 8) & 0x3;\n"
-"      r = argb.y & 0x3ff;\n"
-"      g = argb.z & 0x3ff;\n"
-"      b = argb.w & 0x3ff;\n"
-       /* A is always MSB, we support only little endian system */
-"      packed_rgb = a << 30;\n"
-"      packed_rgb |= (r << (30 - (R_IDX * 10)));\n"
-"      packed_rgb |= (g << (30 - (G_IDX * 10)));\n"
-"      packed_rgb |= (b << (30 - (B_IDX * 10)));\n"
-"      *(unsigned int *)&dstRGB[x_pos * 4 + y_pos * dst_stride] = packed_rgb;\n"
-"    } else {\n"
-"      if (A_IDX >= 0) {\n"
-"        argb.x = do_scale_pixel(argb.x);\n"
-"        dstRGB[x_pos * PSTRIDE + A_IDX + y_pos * dst_stride] = argb.x;\n"
-"      } else if (X_IDX >= 0) {\n"
-"        dstRGB[x_pos * PSTRIDE + X_IDX + y_pos * dst_stride] = 0xff;\n"
-"      }\n"
-"      dstRGB[x_pos * PSTRIDE + R_IDX + y_pos * dst_stride] = argb.y;\n"
-"      dstRGB[x_pos * PSTRIDE + G_IDX + y_pos * dst_stride] = argb.z;\n"
-"      dstRGB[x_pos * PSTRIDE + B_IDX + y_pos * dst_stride] = argb.w;\n"
-"    }\n"
-"  }\n"
-"}\n"
-"\n"
-"}";
-/* *INDENT-ON* */
-
-typedef struct
-{
-  gint R;
-  gint G;
-  gint B;
-  gint A;
-  gint X;
-} GstCudaRGBOrder;
-
-typedef struct
-{
-  CUdeviceptr device_ptr;
-  gsize cuda_stride;
-} GstCudaStageBuffer;
-
-#define CONVERTER_MAX_NUM_FUNC 4
-
-struct _GstCudaConverter
-{
-  GstVideoInfo in_info;
-  GstVideoInfo out_info;
-  gboolean keep_size;
-
-  gint texture_alignment;
-
-  GstCudaContext *cuda_ctx;
-  CUmodule cuda_module;
-  CUfunction kernel_func[CONVERTER_MAX_NUM_FUNC];
-  const gchar *func_names[CONVERTER_MAX_NUM_FUNC];
-  gchar *kernel_source;
-  gchar *ptx;
-  GstCudaStageBuffer fallback_buffer[GST_VIDEO_MAX_PLANES];
-
-  /* *INDENT-OFF* */
-  gboolean (*convert) (GstCudaConverter * convert, GstVideoFrame * src_frame,
-      GstVideoFrame * dst_frame, CUstream cuda_stream);
-  /* *INDENT-ON* */
-
-  const CUdeviceptr src;
-  GstVideoInfo *cur_in_info;
-
-  CUdeviceptr dest;
-  GstVideoInfo *cur_out_info;
-
-  /* rgb to {rgb, yuv} only */
-  GstCudaRGBOrder in_rgb_order;
-  GstCudaStageBuffer unpack_surface;
-  GstCudaStageBuffer y444_surface[GST_VIDEO_MAX_PLANES];
-};
-
-#define LOAD_CUDA_FUNC(module,func,name) G_STMT_START { \
-  if (!gst_cuda_result (CuModuleGetFunction (&(func), (module), name))) { \
-    GST_ERROR ("failed to get %s function", (name)); \
-    goto error; \
-  } \
-} G_STMT_END
-
-/**
- * gst_cuda_converter_new:
- * @in_info: a #GstVideoInfo
- * @out_info: a #GstVideoInfo
- * @cuda_ctx: (transfer none): a #GstCudaContext
- *
- * Create a new converter object to convert between @in_info and @out_info
- * with @config.
- *
- * Returns: a #GstCudaConverter or %NULL if conversion is not possible.
- */
-GstCudaConverter *
-gst_cuda_converter_new (GstVideoInfo * in_info, GstVideoInfo * out_info,
-    GstCudaContext * cuda_ctx)
-{
-  GstCudaConverter *convert;
-  gint i;
-
-  g_return_val_if_fail (in_info != NULL, NULL);
-  g_return_val_if_fail (out_info != NULL, NULL);
-  g_return_val_if_fail (cuda_ctx != NULL, NULL);
-  /* we won't ever do framerate conversion */
-  g_return_val_if_fail (in_info->fps_n == out_info->fps_n, NULL);
-  g_return_val_if_fail (in_info->fps_d == out_info->fps_d, NULL);
-  /* we won't ever do deinterlace */
-  g_return_val_if_fail (in_info->interlace_mode == out_info->interlace_mode,
-      NULL);
-
-  convert = g_new0 (GstCudaConverter, 1);
-
-  convert->in_info = *in_info;
-  convert->out_info = *out_info;
-
-  /* FIXME: should return kernel source */
-  if (!gst_cuda_context_push (cuda_ctx)) {
-    GST_ERROR ("cannot push context");
-    goto error;
-  }
-
-  if (!cuda_converter_lookup_path (convert))
-    goto error;
-
-  convert->ptx = gst_cuda_nvrtc_compile (convert->kernel_source);
-  if (!convert->ptx) {
-    GST_ERROR ("no PTX data to load");
-    goto error;
-  }
-
-  GST_TRACE ("compiled convert ptx \n%s", convert->ptx);
-
-  if (!gst_cuda_result (CuModuleLoadData (&convert->cuda_module, convert->ptx))) {
-    gst_cuda_context_pop (NULL);
-    GST_ERROR ("failed to load cuda module data");
-
-    goto error;
-  }
-
-  for (i = 0; i < CONVERTER_MAX_NUM_FUNC; i++) {
-    if (!convert->func_names[i])
-      break;
-
-    LOAD_CUDA_FUNC (convert->cuda_module, convert->kernel_func[i],
-        convert->func_names[i]);
-    GST_DEBUG ("kernel function \"%s\" loaded", convert->func_names[i]);
-  }
-
-  gst_cuda_context_pop (NULL);
-  convert->cuda_ctx = gst_object_ref (cuda_ctx);
-  convert->texture_alignment =
-      gst_cuda_context_get_texture_alignment (cuda_ctx);
-
-  g_free (convert->kernel_source);
-  g_free (convert->ptx);
-  convert->kernel_source = NULL;
-  convert->ptx = NULL;
-
-  return convert;
-
-error:
-  gst_cuda_context_pop (NULL);
-  gst_cuda_converter_free (convert);
-
-  return NULL;
-}
-
-/**
- * gst_video_converter_free:
- * @convert: a #GstCudaConverter
- *
- * Free @convert
- */
-void
-gst_cuda_converter_free (GstCudaConverter * convert)
-{
-  g_return_if_fail (convert != NULL);
-
-  if (convert->cuda_ctx) {
-    if (gst_cuda_context_push (convert->cuda_ctx)) {
-      gint i;
-
-      if (convert->cuda_module) {
-        gst_cuda_result (CuModuleUnload (convert->cuda_module));
-      }
-
-      for (i = 0; i < GST_VIDEO_MAX_PLANES; i++) {
-        if (convert->fallback_buffer[i].device_ptr)
-          gst_cuda_result (CuMemFree (convert->fallback_buffer[i].device_ptr));
-        if (convert->y444_surface[i].device_ptr)
-          gst_cuda_result (CuMemFree (convert->y444_surface[i].device_ptr));
-      }
-
-      if (convert->unpack_surface.device_ptr)
-        gst_cuda_result (CuMemFree (convert->unpack_surface.device_ptr));
-
-      gst_cuda_context_pop (NULL);
-    }
-
-    gst_object_unref (convert->cuda_ctx);
-  }
-
-  g_free (convert->kernel_source);
-  g_free (convert->ptx);
-  g_free (convert);
-}
-
-gboolean
-gst_cuda_converter_convert_frame (GstCudaConverter * convert,
-    GstVideoFrame * src_frame, GstVideoFrame * dst_frame, CUstream cuda_stream)
-{
-  gboolean ret;
-
-  g_return_val_if_fail (convert, FALSE);
-  g_return_val_if_fail (src_frame, FALSE);
-  g_return_val_if_fail (dst_frame, FALSE);
-
-  gst_cuda_context_push (convert->cuda_ctx);
-
-  ret = convert->convert (convert, src_frame, dst_frame, cuda_stream);
-
-  gst_cuda_context_pop (NULL);
-
-  return ret;
-}
-
-/* allocate fallback memory for texture alignment requirement */
-static gboolean
-convert_ensure_fallback_memory (GstCudaConverter * convert,
-    GstVideoInfo * info, guint plane)
-{
-  CUresult ret;
-  guint element_size = 8;
-
-  if (convert->fallback_buffer[plane].device_ptr)
-    return TRUE;
-
-  if (GST_VIDEO_INFO_COMP_DEPTH (info, 0) > 8)
-    element_size = 16;
-
-  ret = CuMemAllocPitch (&convert->fallback_buffer[plane].device_ptr,
-      &convert->fallback_buffer[plane].cuda_stride,
-      GST_VIDEO_INFO_COMP_WIDTH (info, plane) *
-      GST_VIDEO_INFO_COMP_PSTRIDE (info, plane),
-      GST_VIDEO_INFO_COMP_HEIGHT (info, plane), element_size);
-
-  if (!gst_cuda_result (ret)) {
-    GST_ERROR ("failed to allocated fallback memory");
-    return FALSE;
-  }
-
-  return TRUE;
-}
-
-/* create a 2D CUDA texture without alignment check */
-static CUtexObject
-convert_create_texture_unchecked (const CUdeviceptr src, gint width,
-    gint height, gint channels, gint stride, CUarray_format format,
-    CUfilter_mode mode, CUstream cuda_stream)
-{
-  CUDA_TEXTURE_DESC texture_desc;
-  CUDA_RESOURCE_DESC resource_desc;
-  CUtexObject texture = 0;
-  CUresult cuda_ret;
-
-  memset (&texture_desc, 0, sizeof (CUDA_TEXTURE_DESC));
-  memset (&resource_desc, 0, sizeof (CUDA_RESOURCE_DESC));
-
-  resource_desc.resType = CU_RESOURCE_TYPE_PITCH2D;
-  resource_desc.res.pitch2D.format = format;
-  resource_desc.res.pitch2D.numChannels = channels;
-  resource_desc.res.pitch2D.width = width;
-  resource_desc.res.pitch2D.height = height;
-  resource_desc.res.pitch2D.pitchInBytes = stride;
-  resource_desc.res.pitch2D.devPtr = src;
-
-  texture_desc.filterMode = mode;
-  texture_desc.flags = CU_TRSF_READ_AS_INTEGER;
-
-  gst_cuda_result (CuStreamSynchronize (cuda_stream));
-  cuda_ret = CuTexObjectCreate (&texture, &resource_desc, &texture_desc, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("couldn't create texture");
-
-    return 0;
-  }
-
-  return texture;
-}
-
-static CUtexObject
-convert_create_texture (GstCudaConverter * convert, GstVideoFrame * src_frame,
-    guint plane, CUstream cuda_stream)
-{
-  CUarray_format format = CU_AD_FORMAT_UNSIGNED_INT8;
-  guint channels = 1;
-  CUdeviceptr src_ptr;
-  gsize stride;
-  CUresult cuda_ret;
-  CUfilter_mode mode;
-
-  if (GST_VIDEO_FRAME_COMP_DEPTH (src_frame, plane) > 8)
-    format = CU_AD_FORMAT_UNSIGNED_INT16;
-
-  /* FIXME: more graceful method ? */
-  if (plane != 0 &&
-      GST_VIDEO_FRAME_N_PLANES (src_frame) !=
-      GST_VIDEO_FRAME_N_COMPONENTS (src_frame)) {
-    channels = 2;
-  }
-
-  src_ptr = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (src_frame, plane);
-  stride = GST_VIDEO_FRAME_PLANE_STRIDE (src_frame, plane);
-
-  if (convert->texture_alignment && (src_ptr % convert->texture_alignment)) {
-    CUDA_MEMCPY2D copy_params = { 0, };
-
-    if (!convert_ensure_fallback_memory (convert, &src_frame->info, plane))
-      return 0;
-
-    GST_LOG ("device memory was not aligned, copy to fallback memory");
-
-    copy_params.srcMemoryType = CU_MEMORYTYPE_DEVICE;
-    copy_params.srcPitch = stride;
-    copy_params.srcDevice = (CUdeviceptr) src_ptr;
-
-    copy_params.dstMemoryType = CU_MEMORYTYPE_DEVICE;
-    copy_params.dstPitch = convert->fallback_buffer[plane].cuda_stride;
-    copy_params.dstDevice = convert->fallback_buffer[plane].device_ptr;
-    copy_params.WidthInBytes = GST_VIDEO_FRAME_COMP_WIDTH (src_frame, plane)
-        * GST_VIDEO_FRAME_COMP_PSTRIDE (src_frame, plane);
-    copy_params.Height = GST_VIDEO_FRAME_COMP_HEIGHT (src_frame, plane);
-
-    cuda_ret = CuMemcpy2DAsync (&copy_params, cuda_stream);
-    if (!gst_cuda_result (cuda_ret)) {
-      GST_ERROR ("failed to copy to fallback buffer");
-      return 0;
-    }
-
-    src_ptr = convert->fallback_buffer[plane].device_ptr;
-    stride = convert->fallback_buffer[plane].cuda_stride;
-  }
-
-  /* Use h/w linear interpolation only when resize is required.
-   * Otherwise the image might be blurred */
-  if (convert->keep_size)
-    mode = CU_TR_FILTER_MODE_POINT;
-  else
-    mode = CU_TR_FILTER_MODE_LINEAR;
-
-  return convert_create_texture_unchecked (src_ptr,
-      GST_VIDEO_FRAME_COMP_WIDTH (src_frame, plane),
-      GST_VIDEO_FRAME_COMP_HEIGHT (src_frame, plane), channels, stride, format,
-      mode, cuda_stream);
-}
-
-/* main conversion function for YUV to YUV conversion */
-static gboolean
-convert_YUV_TO_YUV (GstCudaConverter * convert, GstVideoFrame * src_frame,
-    GstVideoFrame * dst_frame, CUstream cuda_stream)
-{
-  CUtexObject texture[GST_VIDEO_MAX_PLANES] = { 0, };
-  CUresult cuda_ret;
-  gboolean ret = FALSE;
-  CUdeviceptr dst_ptr[GST_VIDEO_MAX_PLANES] = { 0, };
-  gint dst_stride, dst_uv_stride;
-  gint width, height;
-  gint i;
-
-  gpointer kernel_args[] = { &texture[0], &texture[1], &texture[2],
-    &dst_ptr[0], &dst_ptr[1], &dst_ptr[2], &dst_stride, &dst_uv_stride
-  };
-
-  /* conversion step
-   * STEP 1: create CUtexObject per plane
-   * STEP 2: call YUV to YUV conversion kernel function.
-   *         resize, uv reordering and bitdepth conversion will be performed in
-   *         the CUDA kernel function
-   */
-
-  /* map CUDA device memory to CUDA texture object */
-  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (src_frame); i++) {
-    texture[i] = convert_create_texture (convert, src_frame, i, cuda_stream);
-    if (!texture[i]) {
-      GST_ERROR ("couldn't create texture for %d th plane", i);
-      goto done;
-    }
-  }
-
-  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (dst_frame); i++) {
-    dst_ptr[i] = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (dst_frame, i);
-  }
-
-  dst_stride = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 0);
-  dst_uv_stride = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 1);
-
-  width = GST_VIDEO_FRAME_WIDTH (dst_frame);
-  height = GST_VIDEO_FRAME_HEIGHT (dst_frame);
-
-  cuda_ret =
-      CuLaunchKernel (convert->kernel_func[0], DIV_UP (width, CUDA_BLOCK_X),
-      DIV_UP (height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
-      cuda_stream, kernel_args, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("could not rescale plane");
-    goto done;
-  }
-
-  ret = TRUE;
-  gst_cuda_result (CuStreamSynchronize (cuda_stream));
-
-done:
-  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (src_frame); i++) {
-    if (texture[i])
-      gst_cuda_result (CuTexObjectDestroy (texture[i]));
-  }
-
-  return ret;
-}
-
-/* main conversion function for YUV to RGB conversion */
-static gboolean
-convert_YUV_TO_RGB (GstCudaConverter * convert, GstVideoFrame * src_frame,
-    GstVideoFrame * dst_frame, CUstream cuda_stream)
-{
-  CUtexObject texture[GST_VIDEO_MAX_PLANES] = { 0, };
-  CUresult cuda_ret;
-  gboolean ret = FALSE;
-  CUdeviceptr dstRGB = 0;
-  gint dst_stride;
-  gint width, height;
-  gint i;
-
-  gpointer kernel_args[] = { &texture[0], &texture[1], &texture[2],
-    &dstRGB, &dst_stride
-  };
-
-  /* conversion step
-   * STEP 1: create CUtexObject per plane
-   * STEP 2: call YUV to RGB conversion kernel function.
-   *         resizing, argb ordering and bitdepth conversion will be performed in
-   *         the CUDA kernel function
-   */
-
-  /* map CUDA device memory to CUDA texture object */
-  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (src_frame); i++) {
-    texture[i] = convert_create_texture (convert, src_frame, i, cuda_stream);
-    if (!texture[i]) {
-      GST_ERROR ("couldn't create texture for %d th plane", i);
-      goto done;
-    }
-  }
-
-  dstRGB = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (dst_frame, 0);
-  dst_stride = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 0);
-
-  width = GST_VIDEO_FRAME_WIDTH (dst_frame);
-  height = GST_VIDEO_FRAME_HEIGHT (dst_frame);
-
-  cuda_ret =
-      CuLaunchKernel (convert->kernel_func[0], DIV_UP (width, CUDA_BLOCK_X),
-      DIV_UP (height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
-      cuda_stream, kernel_args, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("could not rescale plane");
-    goto done;
-  }
-
-  ret = TRUE;
-  gst_cuda_result (CuStreamSynchronize (cuda_stream));
-
-done:
-  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (src_frame); i++) {
-    if (texture[i])
-      gst_cuda_result (CuTexObjectDestroy (texture[i]));
-  }
-
-  return ret;
-}
-
-static gboolean
-convert_UNPACK_RGB (GstCudaConverter * convert, CUfunction kernel_func,
-    CUstream cuda_stream, GstVideoFrame * src_frame,
-    CUdeviceptr dst, gint dst_stride, GstCudaRGBOrder * rgb_order)
-{
-  CUdeviceptr srcRGB = 0;
-  gint width, height;
-  gint src_stride, src_pstride;
-  CUresult cuda_ret;
-
-  gpointer unpack_kernel_args[] = { &srcRGB, &dst,
-    &width, &height,
-    &src_stride, &src_pstride, &dst_stride,
-    &convert->in_rgb_order.R, &convert->in_rgb_order.G,
-    &convert->in_rgb_order.B, &convert->in_rgb_order.A,
-  };
-
-  srcRGB = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (src_frame, 0);
-  src_stride = GST_VIDEO_FRAME_PLANE_STRIDE (src_frame, 0);
-
-  width = GST_VIDEO_FRAME_WIDTH (src_frame);
-  height = GST_VIDEO_FRAME_HEIGHT (src_frame);
-  src_pstride = GST_VIDEO_FRAME_COMP_PSTRIDE (src_frame, 0);
-
-  cuda_ret =
-      CuLaunchKernel (kernel_func, DIV_UP (width, CUDA_BLOCK_X),
-      DIV_UP (height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
-      cuda_stream, unpack_kernel_args, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("could not unpack rgb");
-    return FALSE;
-  }
-
-  return TRUE;
-}
-
-static gboolean
-convert_TO_Y444 (GstCudaConverter * convert, CUfunction kernel_func,
-    CUstream cuda_stream, CUtexObject srcRGB, CUdeviceptr dstY, gint y_stride,
-    CUdeviceptr dstU, gint u_stride, CUdeviceptr dstV, gint v_stride,
-    gint width, gint height, gint pstride, gint bitdepth)
-{
-  CUresult cuda_ret;
-
-  gpointer kernel_args[] = { &srcRGB, &dstY, &y_stride, &dstU, &u_stride, &dstV,
-    &v_stride, &width, &height, &pstride, &bitdepth,
-  };
-
-  cuda_ret =
-      CuLaunchKernel (kernel_func, DIV_UP (width, CUDA_BLOCK_X),
-      DIV_UP (height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
-      cuda_stream, kernel_args, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("could not unpack rgb");
-    return FALSE;
-  }
-
-  return TRUE;
-}
-
-/* main conversion function for RGB to YUV conversion */
-static gboolean
-convert_RGB_TO_YUV (GstCudaConverter * convert, GstVideoFrame * src_frame,
-    GstVideoFrame * dst_frame, CUstream cuda_stream)
-{
-  CUtexObject texture = 0;
-  CUtexObject yuv_texture[3] = { 0, };
-  CUdeviceptr dst_ptr[GST_VIDEO_MAX_PLANES] = { 0, };
-  CUresult cuda_ret;
-  gboolean ret = FALSE;
-  gint in_width, in_height;
-  gint out_width, out_height;
-  gint dst_stride, dst_uv_stride;
-  CUarray_format format = CU_AD_FORMAT_UNSIGNED_INT8;
-  CUfilter_mode mode = CU_TR_FILTER_MODE_POINT;
-  gint pstride = 1;
-  gint bitdepth = 8;
-  gint i;
-
-  gpointer kernel_args[] = { &yuv_texture[0], &yuv_texture[1], &yuv_texture[2],
-    &dst_ptr[0], &dst_ptr[1], &dst_ptr[2], &dst_stride, &dst_uv_stride
-  };
-
-  /* conversion step
-   * STEP 1: unpack src RGB into ARGB or ARGB64 format
-   * STEP 2: convert unpacked ARGB (or ARGB64) to Y444 (or Y444_16LE)
-   * STEP 3: convert Y444 (or Y444_16LE) to final YUV format.
-   *         resizing, bitdepth conversion, uv reordering will be performed in
-   *         the CUDA kernel function
-   */
-  if (!convert_UNPACK_RGB (convert, convert->kernel_func[0], cuda_stream,
-          src_frame, convert->unpack_surface.device_ptr,
-          convert->unpack_surface.cuda_stride, &convert->in_rgb_order)) {
-    GST_ERROR ("could not unpack input rgb");
-
-    goto done;
-  }
-
-  in_width = GST_VIDEO_FRAME_WIDTH (src_frame);
-  in_height = GST_VIDEO_FRAME_HEIGHT (src_frame);
-
-  out_width = GST_VIDEO_FRAME_WIDTH (dst_frame);
-  out_height = GST_VIDEO_FRAME_HEIGHT (dst_frame);
-  dst_stride = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 0);
-  dst_uv_stride = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 1);
-
-  if (GST_VIDEO_FRAME_COMP_DEPTH (src_frame, 0) > 8) {
-    pstride = 2;
-    bitdepth = 16;
-    format = CU_AD_FORMAT_UNSIGNED_INT16;
-  }
-
-  texture =
-      convert_create_texture_unchecked (convert->unpack_surface.device_ptr,
-      in_width, in_height, 4, convert->unpack_surface.cuda_stride, format,
-      mode, cuda_stream);
-
-  if (!texture) {
-    GST_ERROR ("could not create texture");
-    goto done;
-  }
-
-  if (!convert_TO_Y444 (convert, convert->kernel_func[1], cuda_stream, texture,
-          convert->y444_surface[0].device_ptr,
-          convert->y444_surface[0].cuda_stride,
-          convert->y444_surface[1].device_ptr,
-          convert->y444_surface[1].cuda_stride,
-          convert->y444_surface[2].device_ptr,
-          convert->y444_surface[2].cuda_stride, in_width, in_height, pstride,
-          bitdepth)) {
-    GST_ERROR ("could not convert to Y444 or Y444_16LE");
-    goto done;
-  }
-
-  /* Use h/w linear interpolation only when resize is required.
-   * Otherwise the image might be blurred */
-  if (convert->keep_size)
-    mode = CU_TR_FILTER_MODE_POINT;
-  else
-    mode = CU_TR_FILTER_MODE_LINEAR;
-
-  for (i = 0; i < 3; i++) {
-    yuv_texture[i] =
-        convert_create_texture_unchecked (convert->y444_surface[i].device_ptr,
-        in_width, in_height, 1, convert->y444_surface[i].cuda_stride, format,
-        mode, cuda_stream);
-
-    if (!yuv_texture[i]) {
-      GST_ERROR ("could not create %dth yuv texture", i);
-      goto done;
-    }
-  }
-
-  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (dst_frame); i++)
-    dst_ptr[i] = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (dst_frame, i);
-
-  cuda_ret =
-      CuLaunchKernel (convert->kernel_func[2], DIV_UP (out_width, CUDA_BLOCK_X),
-      DIV_UP (out_height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
-      cuda_stream, kernel_args, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("could not rescale plane");
-    goto done;
-  }
-
-  ret = TRUE;
-  gst_cuda_result (CuStreamSynchronize (cuda_stream));
-
-done:
-  if (texture)
-    gst_cuda_result (CuTexObjectDestroy (texture));
-  for (i = 0; i < 3; i++) {
-    if (yuv_texture[i])
-      gst_cuda_result (CuTexObjectDestroy (yuv_texture[i]));
-  }
-
-  return ret;
-}
-
-/* main conversion function for RGB to RGB conversion */
-static gboolean
-convert_RGB_TO_RGB (GstCudaConverter * convert, GstVideoFrame * src_frame,
-    GstVideoFrame * dst_frame, CUstream cuda_stream)
-{
-  CUtexObject texture = 0;
-  CUresult cuda_ret;
-  gboolean ret = FALSE;
-  CUdeviceptr dstRGB = 0;
-  gint in_width, in_height;
-  gint out_width, out_height;
-  gint dst_stride;
-  CUfilter_mode mode;
-  CUarray_format format = CU_AD_FORMAT_UNSIGNED_INT8;
-
-  gpointer rescale_kernel_args[] = { &texture, &dstRGB, &dst_stride };
-
-  /* conversion step
-   * STEP 1: unpack src RGB into ARGB or ARGB64 format
-   * STEP 2: convert ARGB (or ARGB64) to final RGB format.
-   *         resizing, bitdepth conversion, argb reordering will be performed in
-   *         the CUDA kernel function
-   */
-
-  if (!convert_UNPACK_RGB (convert, convert->kernel_func[0], cuda_stream,
-          src_frame, convert->unpack_surface.device_ptr,
-          convert->unpack_surface.cuda_stride, &convert->in_rgb_order)) {
-    GST_ERROR ("could not unpack input rgb");
-
-    goto done;
-  }
-
-  in_width = GST_VIDEO_FRAME_WIDTH (src_frame);
-  in_height = GST_VIDEO_FRAME_HEIGHT (src_frame);
-
-  out_width = GST_VIDEO_FRAME_WIDTH (dst_frame);
-  out_height = GST_VIDEO_FRAME_HEIGHT (dst_frame);
-
-  dstRGB = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (dst_frame, 0);
-  dst_stride = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 0);
-
-  if (GST_VIDEO_FRAME_COMP_DEPTH (src_frame, 0) > 8)
-    format = CU_AD_FORMAT_UNSIGNED_INT16;
-
-  /* Use h/w linear interpolation only when resize is required.
-   * Otherwise the image might be blurred */
-  if (convert->keep_size)
-    mode = CU_TR_FILTER_MODE_POINT;
-  else
-    mode = CU_TR_FILTER_MODE_LINEAR;
-
-  texture =
-      convert_create_texture_unchecked (convert->unpack_surface.device_ptr,
-      in_width, in_height, 4, convert->unpack_surface.cuda_stride, format,
-      mode, cuda_stream);
-
-  if (!texture) {
-    GST_ERROR ("could not create texture");
-    goto done;
-  }
-
-  cuda_ret =
-      CuLaunchKernel (convert->kernel_func[1], DIV_UP (out_width, CUDA_BLOCK_X),
-      DIV_UP (out_height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
-      cuda_stream, rescale_kernel_args, NULL);
-
-  if (!gst_cuda_result (cuda_ret)) {
-    GST_ERROR ("could not rescale plane");
-    goto done;
-  }
-
-  ret = TRUE;
-  gst_cuda_result (CuStreamSynchronize (cuda_stream));
-
-done:
-  if (texture)
-    gst_cuda_result (CuTexObjectDestroy (texture));
-
-  return ret;
-}
-
-/* from video-converter.c */
-typedef struct
-{
-  gdouble dm[4][4];
-} MatrixData;
-
-static void
-color_matrix_set_identity (MatrixData * m)
-{
-  gint i, j;
-
-  for (i = 0; i < 4; i++) {
-    for (j = 0; j < 4; j++) {
-      m->dm[i][j] = (i == j);
-    }
-  }
-}
-
-static void
-color_matrix_copy (MatrixData * d, const MatrixData * s)
-{
-  gint i, j;
-
-  for (i = 0; i < 4; i++)
-    for (j = 0; j < 4; j++)
-      d->dm[i][j] = s->dm[i][j];
-}
-
-/* Perform 4x4 matrix multiplication:
- *  - @dst@ = @a@ * @b@
- *  - @dst@ may be a pointer to @a@ andor @b@
- */
-static void
-color_matrix_multiply (MatrixData * dst, MatrixData * a, MatrixData * b)
-{
-  MatrixData tmp;
-  gint i, j, k;
-
-  for (i = 0; i < 4; i++) {
-    for (j = 0; j < 4; j++) {
-      gdouble x = 0;
-      for (k = 0; k < 4; k++) {
-        x += a->dm[i][k] * b->dm[k][j];
-      }
-      tmp.dm[i][j] = x;
-    }
-  }
-  color_matrix_copy (dst, &tmp);
-}
-
-static void
-color_matrix_offset_components (MatrixData * m, gdouble a1, gdouble a2,
-    gdouble a3)
-{
-  MatrixData a;
-
-  color_matrix_set_identity (&a);
-  a.dm[0][3] = a1;
-  a.dm[1][3] = a2;
-  a.dm[2][3] = a3;
-  color_matrix_multiply (m, &a, m);
-}
-
-static void
-color_matrix_scale_components (MatrixData * m, gdouble a1, gdouble a2,
-    gdouble a3)
-{
-  MatrixData a;
-
-  color_matrix_set_identity (&a);
-  a.dm[0][0] = a1;
-  a.dm[1][1] = a2;
-  a.dm[2][2] = a3;
-  color_matrix_multiply (m, &a, m);
-}
-
-static void
-color_matrix_debug (const MatrixData * s)
-{
-  GST_DEBUG ("[%f %f %f %f]", s->dm[0][0], s->dm[0][1], s->dm[0][2],
-      s->dm[0][3]);
-  GST_DEBUG ("[%f %f %f %f]", s->dm[1][0], s->dm[1][1], s->dm[1][2],
-      s->dm[1][3]);
-  GST_DEBUG ("[%f %f %f %f]", s->dm[2][0], s->dm[2][1], s->dm[2][2],
-      s->dm[2][3]);
-  GST_DEBUG ("[%f %f %f %f]", s->dm[3][0], s->dm[3][1], s->dm[3][2],
-      s->dm[3][3]);
-}
-
-static void
-color_matrix_YCbCr_to_RGB (MatrixData * m, gdouble Kr, gdouble Kb)
-{
-  gdouble Kg = 1.0 - Kr - Kb;
-  MatrixData k = {
-    {
-          {1., 0., 2 * (1 - Kr), 0.},
-          {1., -2 * Kb * (1 - Kb) / Kg, -2 * Kr * (1 - Kr) / Kg, 0.},
-          {1., 2 * (1 - Kb), 0., 0.},
-          {0., 0., 0., 1.},
-        }
-  };
-
-  color_matrix_multiply (m, &k, m);
-}
-
-static void
-color_matrix_RGB_to_YCbCr (MatrixData * m, gdouble Kr, gdouble Kb)
-{
-  gdouble Kg = 1.0 - Kr - Kb;
-  MatrixData k;
-  gdouble x;
-
-  k.dm[0][0] = Kr;
-  k.dm[0][1] = Kg;
-  k.dm[0][2] = Kb;
-  k.dm[0][3] = 0;
-
-  x = 1 / (2 * (1 - Kb));
-  k.dm[1][0] = -x * Kr;
-  k.dm[1][1] = -x * Kg;
-  k.dm[1][2] = x * (1 - Kb);
-  k.dm[1][3] = 0;
-
-  x = 1 / (2 * (1 - Kr));
-  k.dm[2][0] = x * (1 - Kr);
-  k.dm[2][1] = -x * Kg;
-  k.dm[2][2] = -x * Kb;
-  k.dm[2][3] = 0;
-
-  k.dm[3][0] = 0;
-  k.dm[3][1] = 0;
-  k.dm[3][2] = 0;
-  k.dm[3][3] = 1;
-
-  color_matrix_multiply (m, &k, m);
-}
-
-static void
-compute_matrix_to_RGB (GstCudaConverter * convert, MatrixData * data,
-    GstVideoInfo * info)
-{
-  gdouble Kr = 0, Kb = 0;
-  gint offset[4], scale[4];
-
-  /* bring color components to [0..1.0] range */
-  gst_video_color_range_offsets (info->colorimetry.range, info->finfo, offset,
-      scale);
-
-  color_matrix_offset_components (data, -offset[0], -offset[1], -offset[2]);
-  color_matrix_scale_components (data, 1 / ((float) scale[0]),
-      1 / ((float) scale[1]), 1 / ((float) scale[2]));
-
-  if (!GST_VIDEO_INFO_IS_RGB (info)) {
-    /* bring components to R'G'B' space */
-    if (gst_video_color_matrix_get_Kr_Kb (info->colorimetry.matrix, &Kr, &Kb))
-      color_matrix_YCbCr_to_RGB (data, Kr, Kb);
-  }
-  color_matrix_debug (data);
-}
-
-static void
-compute_matrix_to_YUV (GstCudaConverter * convert, MatrixData * data,
-    GstVideoInfo * info)
-{
-  gdouble Kr = 0, Kb = 0;
-  gint offset[4], scale[4];
-
-  if (!GST_VIDEO_INFO_IS_RGB (info)) {
-    /* bring components to YCbCr space */
-    if (gst_video_color_matrix_get_Kr_Kb (info->colorimetry.matrix, &Kr, &Kb))
-      color_matrix_RGB_to_YCbCr (data, Kr, Kb);
-  }
-
-  /* bring color components to nominal range */
-  gst_video_color_range_offsets (info->colorimetry.range, info->finfo, offset,
-      scale);
-
-  color_matrix_scale_components (data, (float) scale[0], (float) scale[1],
-      (float) scale[2]);
-  color_matrix_offset_components (data, offset[0], offset[1], offset[2]);
-
-  color_matrix_debug (data);
-}
-
-static gboolean
-cuda_converter_get_matrix (GstCudaConverter * convert, MatrixData * matrix,
-    GstVideoInfo * in_info, GstVideoInfo * out_info)
-{
-  gboolean same_matrix, same_bits;
-  guint in_bits, out_bits;
-
-  in_bits = GST_VIDEO_INFO_COMP_DEPTH (in_info, 0);
-  out_bits = GST_VIDEO_INFO_COMP_DEPTH (out_info, 0);
-
-  same_bits = in_bits == out_bits;
-  same_matrix = in_info->colorimetry.matrix == out_info->colorimetry.matrix;
-
-  GST_DEBUG ("matrix %d -> %d (%d)", in_info->colorimetry.matrix,
-      out_info->colorimetry.matrix, same_matrix);
-  GST_DEBUG ("bits %d -> %d (%d)", in_bits, out_bits, same_bits);
-
-  color_matrix_set_identity (matrix);
-
-  if (same_bits && same_matrix) {
-    GST_DEBUG ("conversion matrix is not required");
-
-    return FALSE;
-  }
-
-  if (in_bits < out_bits) {
-    gint scale = 1 << (out_bits - in_bits);
-    color_matrix_scale_components (matrix,
-        1 / (float) scale, 1 / (float) scale, 1 / (float) scale);
-  }
-
-  GST_DEBUG ("to RGB matrix");
-  compute_matrix_to_RGB (convert, matrix, in_info);
-  GST_DEBUG ("current matrix");
-  color_matrix_debug (matrix);
-
-  GST_DEBUG ("to YUV matrix");
-  compute_matrix_to_YUV (convert, matrix, out_info);
-  GST_DEBUG ("current matrix");
-  color_matrix_debug (matrix);
-
-  if (in_bits > out_bits) {
-    gint scale = 1 << (in_bits - out_bits);
-    color_matrix_scale_components (matrix,
-        (float) scale, (float) scale, (float) scale);
-  }
-
-  GST_DEBUG ("final matrix");
-  color_matrix_debug (matrix);
-
-  return TRUE;
-}
-
-static gboolean
-is_uv_swapped (GstVideoFormat format)
-{
-  static GstVideoFormat swapped_formats[] = {
-    GST_VIDEO_FORMAT_YV12,
-    GST_VIDEO_FORMAT_NV21,
-  };
-  gint i;
-
-  for (i = 0; i < G_N_ELEMENTS (swapped_formats); i++) {
-    if (format == swapped_formats[i])
-      return TRUE;
-  }
-
-  return FALSE;
-}
-
-typedef struct
-{
-  const gchar *read_chroma;
-  const gchar *write_chroma;
-  const gchar *unpack_function;
-  gfloat scale_h, scale_v;
-  gfloat chroma_scale_h, chroma_scale_v;
-  gint width, height;
-  gint chroma_width, chroma_height;
-  gint in_depth;
-  gint out_depth;
-  gint pstride, chroma_pstride;
-  gint in_shift, out_shift;
-  gint mask;
-  gint swap_uv;
-  /* RGBA specific variables */
-  gint max_in_val;
-  GstCudaRGBOrder rgb_order;
-} GstCudaKernelTempl;
-
-static gchar *
-cuda_converter_generate_yuv_to_yuv_kernel_code (GstCudaConverter * convert,
-    GstCudaKernelTempl * templ)
-{
-  gchar scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar chroma_scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar chroma_scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  g_ascii_formatd (scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_h);
-  g_ascii_formatd (scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_v);
-  g_ascii_formatd (chroma_scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f",
-      templ->chroma_scale_h);
-  g_ascii_formatd (chroma_scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f",
-      templ->chroma_scale_v);
-  return g_strdup_printf (templ_YUV_TO_YUV, scale_h_str, scale_v_str,
-      chroma_scale_h_str, chroma_scale_v_str, templ->width, templ->height,
-      templ->chroma_width, templ->chroma_height, templ->in_depth,
-      templ->out_depth, templ->pstride, templ->chroma_pstride, templ->in_shift,
-      templ->out_shift, templ->mask, templ->swap_uv, templ->read_chroma,
-      templ->write_chroma);
-}
-
-static gchar *
-cuda_converter_generate_yuv_to_rgb_kernel_code (GstCudaConverter * convert,
-    GstCudaKernelTempl * templ, MatrixData * matrix)
-{
-  gchar matrix_dm[4][4][G_ASCII_DTOSTR_BUF_SIZE];
-  gchar scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar chroma_scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar chroma_scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gint i, j;
-  for (i = 0; i < 4; i++) {
-    for (j = 0; j < 4; j++) {
-      g_ascii_formatd (matrix_dm[i][j], G_ASCII_DTOSTR_BUF_SIZE, "%f",
-          matrix->dm[i][j]);
-    }
-  }
-  g_ascii_formatd (scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_h);
-  g_ascii_formatd (scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_v);
-  g_ascii_formatd (chroma_scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f",
-      templ->chroma_scale_h);
-  g_ascii_formatd (chroma_scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f",
-      templ->chroma_scale_v);
-  return g_strdup_printf (templ_YUV_TO_RGB, matrix_dm[0][3], matrix_dm[1][3],
-      matrix_dm[2][3], matrix_dm[0][0], matrix_dm[0][1], matrix_dm[0][2],
-      matrix_dm[1][0], matrix_dm[1][1], matrix_dm[1][2], matrix_dm[2][0],
-      matrix_dm[2][1], matrix_dm[2][2], scale_h_str, scale_v_str,
-      chroma_scale_h_str, chroma_scale_v_str, templ->width, templ->height,
-      templ->chroma_width, templ->chroma_height, templ->in_depth,
-      templ->out_depth, templ->pstride, templ->chroma_pstride, templ->in_shift,
-      templ->out_shift, templ->mask, templ->swap_uv, templ->max_in_val,
-      templ->rgb_order.R, templ->rgb_order.G, templ->rgb_order.B,
-      templ->rgb_order.A, templ->rgb_order.X, templ->read_chroma);
-}
-
-static gchar *
-cuda_converter_generate_rgb_to_yuv_kernel_code (GstCudaConverter * convert,
-    GstCudaKernelTempl * templ, MatrixData * matrix)
-{
-  gchar matrix_dm[4][4][G_ASCII_DTOSTR_BUF_SIZE];
-  gchar scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar chroma_scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar chroma_scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gint i, j;
-  for (i = 0; i < 4; i++) {
-    for (j = 0; j < 4; j++) {
-      g_ascii_formatd (matrix_dm[i][j], G_ASCII_DTOSTR_BUF_SIZE, "%f",
-          matrix->dm[i][j]);
-    }
-  }
-  g_ascii_formatd (scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_h);
-  g_ascii_formatd (scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_v);
-  g_ascii_formatd (chroma_scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f",
-      templ->chroma_scale_h);
-  g_ascii_formatd (chroma_scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f",
-      templ->chroma_scale_v);
-  return g_strdup_printf (templ_RGB_TO_YUV, matrix_dm[0][3], matrix_dm[1][3],
-      matrix_dm[2][3], matrix_dm[0][0], matrix_dm[0][1], matrix_dm[0][2],
-      matrix_dm[1][0], matrix_dm[1][1], matrix_dm[1][2], matrix_dm[2][0],
-      matrix_dm[2][1], matrix_dm[2][2], scale_h_str, scale_v_str,
-      chroma_scale_h_str, chroma_scale_v_str, templ->width, templ->height,
-      templ->chroma_width, templ->chroma_height, templ->in_depth,
-      templ->out_depth, templ->pstride, templ->chroma_pstride, templ->in_shift,
-      templ->out_shift, templ->mask, templ->swap_uv, templ->unpack_function,
-      templ->read_chroma, templ->write_chroma);
-}
-
-static gchar *
-cuda_converter_generate_rgb_to_rgb_kernel_code (GstCudaConverter * convert,
-    GstCudaKernelTempl * templ)
-{
-  gchar scale_h_str[G_ASCII_DTOSTR_BUF_SIZE];
-  gchar scale_v_str[G_ASCII_DTOSTR_BUF_SIZE];
-  g_ascii_formatd (scale_h_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_h);
-  g_ascii_formatd (scale_v_str, G_ASCII_DTOSTR_BUF_SIZE, "%f", templ->scale_v);
-  return g_strdup_printf (templ_RGB_to_RGB,
-      scale_h_str, scale_v_str,
-      templ->width, templ->height,
-      templ->in_depth, templ->out_depth, templ->pstride,
-      templ->rgb_order.R, templ->rgb_order.G,
-      templ->rgb_order.B, templ->rgb_order.A, templ->rgb_order.X,
-      templ->unpack_function);
-}
-
-#define SET_ORDER(o,r,g,b,a,x) G_STMT_START { \
-  (o)->R = (r); \
-  (o)->G = (g); \
-  (o)->B = (b); \
-  (o)->A = (a); \
-  (o)->X = (x); \
-} G_STMT_END
-
-static void
-cuda_converter_get_rgb_order (GstVideoFormat format, GstCudaRGBOrder * order)
-{
-  switch (format) {
-    case GST_VIDEO_FORMAT_RGBA:
-      SET_ORDER (order, 0, 1, 2, 3, -1);
-      break;
-    case GST_VIDEO_FORMAT_RGBx:
-      SET_ORDER (order, 0, 1, 2, -1, 3);
-      break;
-    case GST_VIDEO_FORMAT_BGRA:
-      SET_ORDER (order, 2, 1, 0, 3, -1);
-      break;
-    case GST_VIDEO_FORMAT_BGRx:
-      SET_ORDER (order, 2, 1, 0, -1, 3);
-      break;
-    case GST_VIDEO_FORMAT_ARGB:
-      SET_ORDER (order, 1, 2, 3, 0, -1);
-      break;
-    case GST_VIDEO_FORMAT_ABGR:
-      SET_ORDER (order, 3, 2, 1, 0, -1);
-      break;
-    case GST_VIDEO_FORMAT_RGB:
-      SET_ORDER (order, 0, 1, 2, -1, -1);
-      break;
-    case GST_VIDEO_FORMAT_BGR:
-      SET_ORDER (order, 2, 1, 0, -1, -1);
-      break;
-    case GST_VIDEO_FORMAT_BGR10A2_LE:
-      SET_ORDER (order, 1, 2, 3, 0, -1);
-      break;
-    case GST_VIDEO_FORMAT_RGB10A2_LE:
-      SET_ORDER (order, 3, 2, 1, 0, -1);
-      break;
-    default:
-      g_assert_not_reached ();
-      break;
-  }
-}
-
-static gboolean
-cuda_converter_lookup_path (GstCudaConverter * convert)
-{
-  GstVideoFormat in_format, out_format;
-  gboolean src_yuv, dst_yuv;
-  gboolean src_planar, dst_planar;
-  GstCudaKernelTempl templ = { 0, };
-  GstVideoInfo *in_info, *out_info;
-  gboolean ret = FALSE;
-  CUresult cuda_ret;
-
-  in_info = &convert->in_info;
-  out_info = &convert->out_info;
-
-  in_format = GST_VIDEO_INFO_FORMAT (in_info);
-  out_format = GST_VIDEO_INFO_FORMAT (out_info);
-
-  src_yuv = GST_VIDEO_INFO_IS_YUV (in_info);
-  dst_yuv = GST_VIDEO_INFO_IS_YUV (out_info);
-
-  src_planar = GST_VIDEO_INFO_N_PLANES (in_info) ==
-      GST_VIDEO_INFO_N_COMPONENTS (in_info);
-  dst_planar = GST_VIDEO_INFO_N_PLANES (out_info) ==
-      GST_VIDEO_INFO_N_COMPONENTS (out_info);
-
-  convert->keep_size = (GST_VIDEO_INFO_WIDTH (&convert->in_info) ==
-      GST_VIDEO_INFO_WIDTH (&convert->out_info) &&
-      GST_VIDEO_INFO_HEIGHT (&convert->in_info) ==
-      GST_VIDEO_INFO_HEIGHT (&convert->out_info));
-
-  templ.scale_h = (gfloat) GST_VIDEO_INFO_COMP_WIDTH (in_info, 0) /
-      (gfloat) GST_VIDEO_INFO_COMP_WIDTH (out_info, 0);
-  templ.scale_v = (gfloat) GST_VIDEO_INFO_COMP_HEIGHT (in_info, 0) /
-      (gfloat) GST_VIDEO_INFO_COMP_HEIGHT (out_info, 0);
-  templ.chroma_scale_h = (gfloat) GST_VIDEO_INFO_COMP_WIDTH (in_info, 1) /
-      (gfloat) GST_VIDEO_INFO_COMP_WIDTH (out_info, 1);
-  templ.chroma_scale_v = (gfloat) GST_VIDEO_INFO_COMP_HEIGHT (in_info, 1) /
-      (gfloat) GST_VIDEO_INFO_COMP_HEIGHT (out_info, 1);
-  templ.width = GST_VIDEO_INFO_COMP_WIDTH (out_info, 0);
-  templ.height = GST_VIDEO_INFO_COMP_HEIGHT (out_info, 0);
-  templ.chroma_width = GST_VIDEO_INFO_COMP_WIDTH (out_info, 1);
-  templ.chroma_height = GST_VIDEO_INFO_COMP_HEIGHT (out_info, 1);
-
-  templ.in_depth = GST_VIDEO_INFO_COMP_DEPTH (in_info, 0);
-  templ.out_depth = GST_VIDEO_INFO_COMP_DEPTH (out_info, 0);
-  templ.pstride = GST_VIDEO_INFO_COMP_PSTRIDE (out_info, 0);
-  templ.chroma_pstride = GST_VIDEO_INFO_COMP_PSTRIDE (out_info, 1);
-  templ.in_shift = in_info->finfo->shift[0];
-  templ.out_shift = out_info->finfo->shift[0];
-  templ.mask = ((1 << templ.out_depth) - 1) << templ.out_shift;
-  templ.swap_uv = (is_uv_swapped (in_format) != is_uv_swapped (out_format));
-
-  if (src_yuv && dst_yuv) {
-    convert->convert = convert_YUV_TO_YUV;
-
-    if (src_planar && dst_planar) {
-      templ.read_chroma = READ_CHROMA_FROM_PLANAR;
-      templ.write_chroma = WRITE_CHROMA_TO_PLANAR;
-    } else if (!src_planar && dst_planar) {
-      templ.read_chroma = READ_CHROMA_FROM_SEMI_PLANAR;
-      templ.write_chroma = WRITE_CHROMA_TO_PLANAR;
-    } else if (src_planar && !dst_planar) {
-      templ.read_chroma = READ_CHROMA_FROM_PLANAR;
-      templ.write_chroma = WRITE_CHROMA_TO_SEMI_PLANAR;
-    } else {
-      templ.read_chroma = READ_CHROMA_FROM_SEMI_PLANAR;
-      templ.write_chroma = WRITE_CHROMA_TO_SEMI_PLANAR;
-    }
-
-    convert->kernel_source =
-        cuda_converter_generate_yuv_to_yuv_kernel_code (convert, &templ);
-    convert->func_names[0] = GST_CUDA_KERNEL_FUNC;
-
-    ret = TRUE;
-  } else if (src_yuv && !dst_yuv) {
-    MatrixData matrix;
-
-    if (src_planar) {
-      templ.read_chroma = READ_CHROMA_FROM_PLANAR;
-    } else {
-      templ.read_chroma = READ_CHROMA_FROM_SEMI_PLANAR;
-    }
-
-    templ.max_in_val = (1 << templ.in_depth) - 1;
-    cuda_converter_get_rgb_order (out_format, &templ.rgb_order);
-
-    cuda_converter_get_matrix (convert, &matrix, in_info, out_info);
-    convert->kernel_source =
-        cuda_converter_generate_yuv_to_rgb_kernel_code (convert,
-        &templ, &matrix);
-    convert->func_names[0] = GST_CUDA_KERNEL_FUNC;
-
-    convert->convert = convert_YUV_TO_RGB;
-
-    ret = TRUE;
-  } else if (!src_yuv && dst_yuv) {
-    MatrixData matrix;
-    gsize element_size = 8;
-    GstVideoFormat unpack_format;
-    GstVideoFormat y444_format;
-    GstVideoInfo unpack_info;
-    GstVideoInfo y444_info;
-    gint i;
-
-    if (dst_planar) {
-      templ.write_chroma = WRITE_CHROMA_TO_PLANAR;
-    } else {
-      templ.write_chroma = WRITE_CHROMA_TO_SEMI_PLANAR;
-    }
-    templ.read_chroma = READ_CHROMA_FROM_PLANAR;
-
-    cuda_converter_get_rgb_order (in_format, &convert->in_rgb_order);
-
-    if (templ.in_depth > 8) {
-      /* FIXME: RGB10A2_LE and BGR10A2_LE only */
-      element_size = 16;
-      unpack_format = GST_VIDEO_FORMAT_ARGB64;
-      y444_format = GST_VIDEO_FORMAT_Y444_16LE;
-      templ.unpack_function = unpack_to_ARGB64;
-    } else {
-      unpack_format = GST_VIDEO_FORMAT_ARGB;
-      y444_format = GST_VIDEO_FORMAT_Y444;
-      templ.unpack_function = unpack_to_ARGB;
-    }
-
-    gst_video_info_set_format (&unpack_info,
-        unpack_format, GST_VIDEO_INFO_WIDTH (in_info),
-        GST_VIDEO_INFO_HEIGHT (in_info));
-    gst_video_info_set_format (&y444_info,
-        y444_format, GST_VIDEO_INFO_WIDTH (in_info),
-        GST_VIDEO_INFO_HEIGHT (in_info));
-
-    templ.in_depth = GST_VIDEO_INFO_COMP_DEPTH (&unpack_info, 0);
-
-    cuda_ret = CuMemAllocPitch (&convert->unpack_surface.device_ptr,
-        &convert->unpack_surface.cuda_stride,
-        GST_VIDEO_INFO_COMP_WIDTH (&unpack_info, 0) *
-        GST_VIDEO_INFO_COMP_PSTRIDE (&unpack_info, 0),
-        GST_VIDEO_INFO_HEIGHT (&unpack_info), element_size);
-
-    if (!gst_cuda_result (cuda_ret)) {
-      GST_ERROR ("couldn't alloc unpack surface");
-      return FALSE;
-    }
-
-    for (i = 0; i < 3; i++) {
-      cuda_ret = CuMemAllocPitch (&convert->y444_surface[i].device_ptr,
-          &convert->y444_surface[i].cuda_stride,
-          GST_VIDEO_INFO_COMP_WIDTH (&y444_info, i) *
-          GST_VIDEO_INFO_COMP_PSTRIDE (&y444_info, i),
-          GST_VIDEO_INFO_COMP_HEIGHT (&y444_info, i), element_size);
-
-      if (!gst_cuda_result (cuda_ret)) {
-        GST_ERROR ("couldn't alloc %dth y444 surface", i);
-        return FALSE;
-      }
-    }
-
-    cuda_converter_get_matrix (convert, &matrix, &unpack_info, &y444_info);
-
-    convert->kernel_source =
-        cuda_converter_generate_rgb_to_yuv_kernel_code (convert,
-        &templ, &matrix);
-
-    convert->func_names[0] = GST_CUDA_KERNEL_FUNC_TO_ARGB;
-    convert->func_names[1] = GST_CUDA_KERNEL_FUNC_TO_Y444;
-    convert->func_names[2] = GST_CUDA_KERNEL_FUNC_Y444_TO_YUV;
-
-    convert->convert = convert_RGB_TO_YUV;
-
-    ret = TRUE;
-  } else {
-    gsize element_size = 8;
-    GstVideoFormat unpack_format;
-    GstVideoInfo unpack_info;
-
-    cuda_converter_get_rgb_order (in_format, &convert->in_rgb_order);
-    cuda_converter_get_rgb_order (out_format, &templ.rgb_order);
-
-    if (templ.in_depth > 8) {
-      /* FIXME: RGB10A2_LE and BGR10A2_LE only */
-      element_size = 16;
-      unpack_format = GST_VIDEO_FORMAT_ARGB64;
-      templ.unpack_function = unpack_to_ARGB64;
-    } else {
-      unpack_format = GST_VIDEO_FORMAT_ARGB;
-      templ.unpack_function = unpack_to_ARGB;
-    }
-
-    gst_video_info_set_format (&unpack_info,
-        unpack_format, GST_VIDEO_INFO_WIDTH (in_info),
-        GST_VIDEO_INFO_HEIGHT (in_info));
-
-    templ.in_depth = GST_VIDEO_INFO_COMP_DEPTH (&unpack_info, 0);
-
-    cuda_ret = CuMemAllocPitch (&convert->unpack_surface.device_ptr,
-        &convert->unpack_surface.cuda_stride,
-        GST_VIDEO_INFO_COMP_WIDTH (&unpack_info, 0) *
-        GST_VIDEO_INFO_COMP_PSTRIDE (&unpack_info, 0),
-        GST_VIDEO_INFO_HEIGHT (&unpack_info), element_size);
-
-    if (!gst_cuda_result (cuda_ret)) {
-      GST_ERROR ("couldn't alloc unpack surface");
-      return FALSE;
-    }
-
-    convert->kernel_source =
-        cuda_converter_generate_rgb_to_rgb_kernel_code (convert, &templ);
-
-    convert->func_names[0] = GST_CUDA_KERNEL_FUNC_TO_ARGB;
-    convert->func_names[1] = GST_CUDA_KERNEL_FUNC_SCALE_RGB;
-
-    convert->convert = convert_RGB_TO_RGB;
-
-    ret = TRUE;
-  }
-
-  if (!ret) {
-    GST_DEBUG ("no path found");
-
-    return FALSE;
-  }
-
-  GST_TRACE ("configured CUDA kernel source\n%s", convert->kernel_source);
-
-  return TRUE;
-}
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/cuda-converter.h b/subprojects/gst-plugins-bad/sys/nvcodec/cuda-converter.h
deleted file mode 100644
index 82c5f169eb..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/cuda-converter.h
+++ /dev/null
@@ -1,44 +0,0 @@
-/* GStreamer
- * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-#ifndef __GST_CUDA_CONVERTER_H__
-#define __GST_CUDA_CONVERTER_H__
-
-#include <gst/video/video.h>
-#include <gst/cuda/gstcudacontext.h>
-#include <gst/cuda/gstcudamemory.h>
-
-G_BEGIN_DECLS
-
-typedef struct _GstCudaConverter GstCudaConverter;
-
-GstCudaConverter *    gst_cuda_converter_new           (GstVideoInfo * in_info,
-                                                        GstVideoInfo * out_info,
-                                                        GstCudaContext * cuda_ctx);
-
-void                 gst_cuda_converter_free           (GstCudaConverter * convert);
-
-gboolean             gst_cuda_converter_convert_frame  (GstCudaConverter * convert,
-                                                        GstVideoFrame * src_frame,
-                                                        GstVideoFrame * dst_frame,
-                                                        CUstream cuda_stream);
-
-G_END_DECLS
-
-#endif /* __GST_CUDA_CONVERTER_H__ */
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudabasefilter.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudabasefilter.c
deleted file mode 100644
index 4d7ef7861b..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudabasefilter.c
+++ /dev/null
@@ -1,328 +0,0 @@
-/* GStreamer
- * Copyright (C) <1999> Erik Walthinsen <omega@cse.ogi.edu>
- * Copyright (C) 2005-2012 David Schleef <ds@schleef.org>
- * Copyright (C) <2019> Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-/**
- * GstCudaBaseFilter:
- *
- * Base class for CUDA filters
- *
- * Since: 1.20
- */
-
-#ifdef HAVE_CONFIG_H
-#  include <config.h>
-#endif
-
-#include "gstcudabasefilter.h"
-#include "gstcudaformat.h"
-#include <gst/cuda/gstcudautils.h>
-
-#include <string.h>
-
-GST_DEBUG_CATEGORY_STATIC (gst_cuda_base_filter_debug);
-#define GST_CAT_DEFAULT gst_cuda_base_filter_debug
-
-#define GST_CUDA_FILTER_FORMATS \
-    "{ I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, " \
-    "BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, Y42B, I422_10LE, I422_12LE }"
-
-static GstStaticPadTemplate sink_template = GST_STATIC_PAD_TEMPLATE ("sink",
-    GST_PAD_SINK,
-    GST_PAD_ALWAYS,
-    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE_WITH_FEATURES
-        (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY, GST_CUDA_FILTER_FORMATS))
-    );
-
-static GstStaticPadTemplate src_template = GST_STATIC_PAD_TEMPLATE ("src",
-    GST_PAD_SRC,
-    GST_PAD_ALWAYS,
-    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE_WITH_FEATURES
-        (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY, GST_CUDA_FILTER_FORMATS))
-    );
-
-#define gst_cuda_base_filter_parent_class parent_class
-G_DEFINE_ABSTRACT_TYPE (GstCudaBaseFilter,
-    gst_cuda_base_filter, GST_TYPE_CUDA_BASE_TRANSFORM);
-
-static void gst_cuda_base_filter_dispose (GObject * object);
-static gboolean
-gst_cuda_base_filter_propose_allocation (GstBaseTransform * trans,
-    GstQuery * decide_query, GstQuery * query);
-static gboolean gst_cuda_base_filter_decide_allocation (GstBaseTransform *
-    trans, GstQuery * query);
-static GstFlowReturn gst_cuda_base_filter_transform (GstBaseTransform * trans,
-    GstBuffer * inbuf, GstBuffer * outbuf);
-static gboolean gst_cuda_base_filter_set_info (GstCudaBaseTransform * btrans,
-    GstCaps * incaps, GstVideoInfo * in_info, GstCaps * outcaps,
-    GstVideoInfo * out_info);
-
-static void
-gst_cuda_base_filter_class_init (GstCudaBaseFilterClass * klass)
-{
-  GObjectClass *gobject_class = G_OBJECT_CLASS (klass);
-  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
-  GstBaseTransformClass *trans_class = GST_BASE_TRANSFORM_CLASS (klass);
-  GstCudaBaseTransformClass *btrans_class =
-      GST_CUDA_BASE_TRANSFORM_CLASS (klass);
-
-  gobject_class->dispose = gst_cuda_base_filter_dispose;
-
-  gst_element_class_add_static_pad_template (element_class, &sink_template);
-  gst_element_class_add_static_pad_template (element_class, &src_template);
-
-  trans_class->passthrough_on_same_caps = TRUE;
-
-  trans_class->propose_allocation =
-      GST_DEBUG_FUNCPTR (gst_cuda_base_filter_propose_allocation);
-  trans_class->decide_allocation =
-      GST_DEBUG_FUNCPTR (gst_cuda_base_filter_decide_allocation);
-  trans_class->transform = GST_DEBUG_FUNCPTR (gst_cuda_base_filter_transform);
-
-  btrans_class->set_info = GST_DEBUG_FUNCPTR (gst_cuda_base_filter_set_info);
-
-  GST_DEBUG_CATEGORY_INIT (gst_cuda_base_filter_debug,
-      "cudabasefilter", 0, "CUDA Base Filter");
-
-  gst_type_mark_as_plugin_api (GST_TYPE_CUDA_BASE_FILTER, 0);
-}
-
-static void
-gst_cuda_base_filter_init (GstCudaBaseFilter * convert)
-{
-}
-
-static void
-gst_cuda_base_filter_dispose (GObject * object)
-{
-  GstCudaBaseFilter *filter = GST_CUDA_BASE_FILTER (object);
-
-  if (filter->converter) {
-    gst_cuda_converter_free (filter->converter);
-    filter->converter = NULL;
-  }
-
-  G_OBJECT_CLASS (parent_class)->dispose (object);
-}
-
-static gboolean
-gst_cuda_base_filter_set_info (GstCudaBaseTransform * btrans, GstCaps * incaps,
-    GstVideoInfo * in_info, GstCaps * outcaps, GstVideoInfo * out_info)
-{
-  GstCudaBaseFilter *filter = GST_CUDA_BASE_FILTER (btrans);
-
-  if (filter->converter)
-    gst_cuda_converter_free (filter->converter);
-
-  filter->converter =
-      gst_cuda_converter_new (in_info, out_info, btrans->context);
-
-  if (!filter->converter) {
-    GST_ERROR_OBJECT (filter, "could not create converter");
-    return FALSE;
-  }
-
-  GST_DEBUG_OBJECT (filter, "reconfigured %d %d",
-      GST_VIDEO_INFO_FORMAT (in_info), GST_VIDEO_INFO_FORMAT (out_info));
-
-  return TRUE;
-}
-
-static gboolean
-gst_cuda_base_filter_propose_allocation (GstBaseTransform * trans,
-    GstQuery * decide_query, GstQuery * query)
-{
-  GstCudaBaseTransform *ctrans = GST_CUDA_BASE_TRANSFORM (trans);
-  GstVideoInfo info;
-  GstBufferPool *pool;
-  GstCaps *caps;
-  guint size;
-
-  if (!GST_BASE_TRANSFORM_CLASS (parent_class)->propose_allocation (trans,
-          decide_query, query))
-    return FALSE;
-
-  /* passthrough, we're done */
-  if (decide_query == NULL)
-    return TRUE;
-
-  gst_query_parse_allocation (query, &caps, NULL);
-
-  if (caps == NULL)
-    return FALSE;
-
-  if (!gst_video_info_from_caps (&info, caps))
-    return FALSE;
-
-  if (gst_query_get_n_allocation_pools (query) == 0) {
-    GstStructure *config;
-
-    pool = gst_cuda_buffer_pool_new (ctrans->context);
-
-    config = gst_buffer_pool_get_config (pool);
-
-    gst_buffer_pool_config_add_option (config,
-        GST_BUFFER_POOL_OPTION_VIDEO_META);
-
-    size = GST_VIDEO_INFO_SIZE (&info);
-    gst_buffer_pool_config_set_params (config, caps, size, 0, 0);
-
-    if (!gst_buffer_pool_set_config (pool, config)) {
-      GST_ERROR_OBJECT (ctrans, "failed to set config");
-      gst_object_unref (pool);
-      return FALSE;
-    }
-
-    /* Get updated size by cuda buffer pool */
-    config = gst_buffer_pool_get_config (pool);
-    gst_buffer_pool_config_get_params (config, NULL, &size, NULL, NULL);
-    gst_structure_free (config);
-
-    gst_query_add_allocation_pool (query, pool, size, 0, 0);
-
-    gst_object_unref (pool);
-  }
-
-  gst_query_add_allocation_meta (query, GST_VIDEO_META_API_TYPE, NULL);
-
-  return TRUE;
-}
-
-static gboolean
-gst_cuda_base_filter_decide_allocation (GstBaseTransform * trans,
-    GstQuery * query)
-{
-  GstCudaBaseTransform *ctrans = GST_CUDA_BASE_TRANSFORM (trans);
-  GstCaps *outcaps = NULL;
-  GstBufferPool *pool = NULL;
-  guint size, min, max;
-  GstStructure *config;
-  gboolean update_pool = FALSE;
-
-  gst_query_parse_allocation (query, &outcaps, NULL);
-
-  if (!outcaps)
-    return FALSE;
-
-  if (gst_query_get_n_allocation_pools (query) > 0) {
-    gst_query_parse_nth_allocation_pool (query, 0, &pool, &size, &min, &max);
-    if (pool) {
-      if (!GST_IS_CUDA_BUFFER_POOL (pool)) {
-        gst_clear_object (&pool);
-      } else {
-        GstCudaBufferPool *cpool = GST_CUDA_BUFFER_POOL (pool);
-
-        if (cpool->context != ctrans->context) {
-          gst_clear_object (&pool);
-        }
-      }
-    }
-
-    update_pool = TRUE;
-  } else {
-    GstVideoInfo vinfo;
-    gst_video_info_from_caps (&vinfo, outcaps);
-    size = GST_VIDEO_INFO_SIZE (&vinfo);
-    min = max = 0;
-  }
-
-  if (!pool) {
-    GST_DEBUG_OBJECT (ctrans, "create our pool");
-
-    pool = gst_cuda_buffer_pool_new (ctrans->context);
-  }
-
-  config = gst_buffer_pool_get_config (pool);
-  gst_buffer_pool_config_add_option (config, GST_BUFFER_POOL_OPTION_VIDEO_META);
-  gst_buffer_pool_config_set_params (config, outcaps, size, min, max);
-  gst_buffer_pool_set_config (pool, config);
-
-  /* Get updated size by cuda buffer pool */
-  config = gst_buffer_pool_get_config (pool);
-  gst_buffer_pool_config_get_params (config, NULL, &size, NULL, NULL);
-  gst_structure_free (config);
-
-  if (update_pool)
-    gst_query_set_nth_allocation_pool (query, 0, pool, size, min, max);
-  else
-    gst_query_add_allocation_pool (query, pool, size, min, max);
-
-  gst_object_unref (pool);
-
-  return GST_BASE_TRANSFORM_CLASS (parent_class)->decide_allocation (trans,
-      query);
-}
-
-static GstFlowReturn
-gst_cuda_base_filter_transform (GstBaseTransform * trans,
-    GstBuffer * inbuf, GstBuffer * outbuf)
-{
-  GstCudaBaseFilter *self = GST_CUDA_BASE_FILTER (trans);
-  GstCudaBaseTransform *ctrans = GST_CUDA_BASE_TRANSFORM (trans);
-  GstVideoFrame in_frame, out_frame;
-  GstFlowReturn ret = GST_FLOW_OK;
-  GstMemory *mem;
-
-  if (gst_buffer_n_memory (inbuf) != 1) {
-    GST_ERROR_OBJECT (self, "Invalid input buffer");
-    return GST_FLOW_ERROR;
-  }
-
-  mem = gst_buffer_peek_memory (inbuf, 0);
-  if (!gst_is_cuda_memory (mem)) {
-    GST_ERROR_OBJECT (self, "Input buffer is not CUDA");
-    return GST_FLOW_ERROR;
-  }
-
-  if (gst_buffer_n_memory (outbuf) != 1) {
-    GST_ERROR_OBJECT (self, "Invalid output buffer");
-    return GST_FLOW_ERROR;
-  }
-
-  mem = gst_buffer_peek_memory (outbuf, 0);
-  if (!gst_is_cuda_memory (mem)) {
-    GST_ERROR_OBJECT (self, "Input buffer is not CUDA");
-    return GST_FLOW_ERROR;
-  }
-
-  if (!gst_video_frame_map (&in_frame, &ctrans->in_info, inbuf,
-          GST_MAP_READ | GST_MAP_CUDA)) {
-    GST_ERROR_OBJECT (self, "Failed to map input buffer");
-    return GST_FLOW_ERROR;
-  }
-
-  if (!gst_video_frame_map (&out_frame, &ctrans->out_info, outbuf,
-          GST_MAP_WRITE | GST_MAP_CUDA)) {
-    gst_video_frame_unmap (&in_frame);
-    GST_ERROR_OBJECT (self, "Failed to map output buffer");
-    return GST_FLOW_ERROR;
-  }
-
-  if (!gst_cuda_converter_convert_frame (self->converter, &in_frame, &out_frame,
-          ctrans->cuda_stream)) {
-    GST_ERROR_OBJECT (self, "Failed to convert frame");
-    ret = GST_FLOW_ERROR;
-  }
-
-  gst_video_frame_unmap (&out_frame);
-  gst_video_frame_unmap (&in_frame);
-
-  return ret;
-}
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudabasefilter.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudabasefilter.h
deleted file mode 100644
index c1641dd946..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudabasefilter.h
+++ /dev/null
@@ -1,56 +0,0 @@
-/* GStreamer
- * Copyright (C) <2019> Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-#ifndef __GST_CUDA_BASE_FILTER_H__
-#define __GST_CUDA_BASE_FILTER_H__
-
-#include <gst/gst.h>
-
-#include "gstcudabasetransform.h"
-#include "cuda-converter.h"
-
-G_BEGIN_DECLS
-
-#define GST_TYPE_CUDA_BASE_FILTER             (gst_cuda_base_filter_get_type())
-#define GST_CUDA_BASE_FILTER(obj)             (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_CUDA_BASE_FILTER,GstCudaBaseFilter))
-#define GST_CUDA_BASE_FILTER_CLASS(klass)     (G_TYPE_CHECK_CLASS_CAST((klass), GST_TYPE_CUDA_BASE_FILTER,GstCudaBaseFilterClass))
-#define GST_CUDA_BASE_FILTER_GET_CLASS(obj)   (G_TYPE_INSTANCE_GET_CLASS((obj), GST_TYPE_CUDA_BASE_FILTER,GstCudaBaseFilterClass))
-#define GST_IS_CUDA_BASE_FILTER(obj)          (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_CUDA_BASE_FILTER))
-#define GST_IS_CUDA_BASE_FILTER_CLASS(klass)  (G_TYPE_CHECK_CLASS_TYPE((klass), GST_TYPE_CUDA_BASE_FILTER))
-
-typedef struct _GstCudaBaseFilter GstCudaBaseFilter;
-typedef struct _GstCudaBaseFilterClass GstCudaBaseFilterClass;
-
-struct _GstCudaBaseFilter
-{
-  GstCudaBaseTransform parent;
-
-  GstCudaConverter *converter;
-};
-
-struct _GstCudaBaseFilterClass
-{
-  GstCudaBaseTransformClass parent_class;
-};
-
-GType gst_cuda_base_filter_get_type (void);
-
-G_END_DECLS
-
-#endif /* __GST_CUDA_BASE_FILTER_H__ */
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvert.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvert.c
deleted file mode 100644
index 81580913d9..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvert.c
+++ /dev/null
@@ -1,417 +0,0 @@
-/* GStreamer
- * Copyright (C) <1999> Erik Walthinsen <omega@cse.ogi.edu>
- * Copyright (C) 2005-2012 David Schleef <ds@schleef.org>
- * Copyright (C) <2019> Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-/**
- * SECTION:element-cudaconvert
- * @title: cudaconvert
- *
- * Convert video frames between supported video formats.
- *
- * ## Example launch line
- * |[
- * gst-launch-1.0 -v videotestsrc ! video/x-raw,format=Y444_16LE ! cudaupload ! cudaconvert ! cudadownload ! autovideosink
- * ]|
- *  This will output a test video (generated in Y444_16LE format) in a video
- * window. If the video sink selected does not support Y444_16LE
- * cudaconvert will automatically convert the video to a format understood
- * by the video sink.
- *
- * Since: 1.20
- */
-
-#ifdef HAVE_CONFIG_H
-#  include <config.h>
-#endif
-
-#include <gst/cuda/gstcudautils.h>
-
-#include "gstcudaconvert.h"
-
-GST_DEBUG_CATEGORY_STATIC (gst_cuda_convert_debug);
-#define GST_CAT_DEFAULT gst_cuda_convert_debug
-
-#define gst_cuda_convert_parent_class parent_class
-G_DEFINE_TYPE (GstCudaConvert, gst_cuda_convert, GST_TYPE_CUDA_BASE_FILTER);
-
-static GstCaps *gst_cuda_convert_transform_caps (GstBaseTransform * trans,
-    GstPadDirection direction, GstCaps * caps, GstCaps * filter);
-static GstCaps *gst_cuda_convert_fixate_caps (GstBaseTransform * base,
-    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps);
-static gboolean gst_cuda_convert_filter_meta (GstBaseTransform * trans,
-    GstQuery * query, GType api, const GstStructure * params);
-static gboolean
-gst_cuda_convert_set_info (GstCudaBaseTransform * btrans, GstCaps * incaps,
-    GstVideoInfo * in_info, GstCaps * outcaps, GstVideoInfo * out_info);
-
-/* copies the given caps */
-static GstCaps *
-gst_cuda_convert_caps_remove_format_info (GstCaps * caps)
-{
-  GstStructure *st;
-  GstCapsFeatures *f;
-  gint i, n;
-  GstCaps *res;
-  GstCapsFeatures *feature =
-      gst_caps_features_from_string (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY);
-
-  res = gst_caps_new_empty ();
-
-  n = gst_caps_get_size (caps);
-  for (i = 0; i < n; i++) {
-    st = gst_caps_get_structure (caps, i);
-    f = gst_caps_get_features (caps, i);
-
-    /* If this is already expressed by the existing caps
-     * skip this structure */
-    if (i > 0 && gst_caps_is_subset_structure_full (res, st, f))
-      continue;
-
-    st = gst_structure_copy (st);
-    /* Only remove format info for the cases when we can actually convert */
-    if (!gst_caps_features_is_any (f)
-        && gst_caps_features_is_equal (f, feature))
-      gst_structure_remove_fields (st, "format", "colorimetry", "chroma-site",
-          NULL);
-
-    gst_caps_append_structure_full (res, st, gst_caps_features_copy (f));
-  }
-  gst_caps_features_free (feature);
-
-  return res;
-}
-
-/*
- * This is an incomplete matrix of in formats and a score for the prefered output
- * format.
- *
- *         out: RGB24   RGB16  ARGB  AYUV  YUV444  YUV422 YUV420 YUV411 YUV410  PAL  GRAY
- *  in
- * RGB24          0      2       1     2     2       3      4      5      6      7    8
- * RGB16          1      0       1     2     2       3      4      5      6      7    8
- * ARGB           2      3       0     1     4       5      6      7      8      9    10
- * AYUV           3      4       1     0     2       5      6      7      8      9    10
- * YUV444         2      4       3     1     0       5      6      7      8      9    10
- * YUV422         3      5       4     2     1       0      6      7      8      9    10
- * YUV420         4      6       5     3     2       1      0      7      8      9    10
- * YUV411         4      6       5     3     2       1      7      0      8      9    10
- * YUV410         6      8       7     5     4       3      2      1      0      9    10
- * PAL            1      3       2     6     4       6      7      8      9      0    10
- * GRAY           1      4       3     2     1       5      6      7      8      9    0
- *
- * PAL or GRAY are never preferred, if we can we would convert to PAL instead
- * of GRAY, though
- * less subsampling is preferred and if any, preferably horizontal
- * We would like to keep the alpha, even if we would need to to colorspace conversion
- * or lose depth.
- */
-#define SCORE_FORMAT_CHANGE       1
-#define SCORE_DEPTH_CHANGE        1
-#define SCORE_ALPHA_CHANGE        1
-#define SCORE_CHROMA_W_CHANGE     1
-#define SCORE_CHROMA_H_CHANGE     1
-#define SCORE_PALETTE_CHANGE      1
-
-#define SCORE_COLORSPACE_LOSS     2     /* RGB <-> YUV */
-#define SCORE_DEPTH_LOSS          4     /* change bit depth */
-#define SCORE_ALPHA_LOSS          8     /* lose the alpha channel */
-#define SCORE_CHROMA_W_LOSS      16     /* vertical subsample */
-#define SCORE_CHROMA_H_LOSS      32     /* horizontal subsample */
-#define SCORE_PALETTE_LOSS       64     /* convert to palette format */
-#define SCORE_COLOR_LOSS        128     /* convert to GRAY */
-
-#define COLORSPACE_MASK (GST_VIDEO_FORMAT_FLAG_YUV | \
-                         GST_VIDEO_FORMAT_FLAG_RGB | GST_VIDEO_FORMAT_FLAG_GRAY)
-#define ALPHA_MASK      (GST_VIDEO_FORMAT_FLAG_ALPHA)
-#define PALETTE_MASK    (GST_VIDEO_FORMAT_FLAG_PALETTE)
-
-/* calculate how much loss a conversion would be */
-static void
-score_value (GstBaseTransform * base, const GstVideoFormatInfo * in_info,
-    const GValue * val, gint * min_loss, const GstVideoFormatInfo ** out_info)
-{
-  const gchar *fname;
-  const GstVideoFormatInfo *t_info;
-  GstVideoFormatFlags in_flags, t_flags;
-  gint loss;
-
-  fname = g_value_get_string (val);
-  t_info = gst_video_format_get_info (gst_video_format_from_string (fname));
-  if (!t_info)
-    return;
-
-  /* accept input format immediately without loss */
-  if (in_info == t_info) {
-    *min_loss = 0;
-    *out_info = t_info;
-    return;
-  }
-
-  loss = SCORE_FORMAT_CHANGE;
-
-  in_flags = GST_VIDEO_FORMAT_INFO_FLAGS (in_info);
-  in_flags &= ~GST_VIDEO_FORMAT_FLAG_LE;
-  in_flags &= ~GST_VIDEO_FORMAT_FLAG_COMPLEX;
-  in_flags &= ~GST_VIDEO_FORMAT_FLAG_UNPACK;
-
-  t_flags = GST_VIDEO_FORMAT_INFO_FLAGS (t_info);
-  t_flags &= ~GST_VIDEO_FORMAT_FLAG_LE;
-  t_flags &= ~GST_VIDEO_FORMAT_FLAG_COMPLEX;
-  t_flags &= ~GST_VIDEO_FORMAT_FLAG_UNPACK;
-
-  if ((t_flags & PALETTE_MASK) != (in_flags & PALETTE_MASK)) {
-    loss += SCORE_PALETTE_CHANGE;
-    if (t_flags & PALETTE_MASK)
-      loss += SCORE_PALETTE_LOSS;
-  }
-
-  if ((t_flags & COLORSPACE_MASK) != (in_flags & COLORSPACE_MASK)) {
-    loss += SCORE_COLORSPACE_LOSS;
-    if (t_flags & GST_VIDEO_FORMAT_FLAG_GRAY)
-      loss += SCORE_COLOR_LOSS;
-  }
-
-  if ((t_flags & ALPHA_MASK) != (in_flags & ALPHA_MASK)) {
-    loss += SCORE_ALPHA_CHANGE;
-    if (in_flags & ALPHA_MASK)
-      loss += SCORE_ALPHA_LOSS;
-  }
-
-  if ((in_info->h_sub[1]) != (t_info->h_sub[1])) {
-    loss += SCORE_CHROMA_H_CHANGE;
-    if ((in_info->h_sub[1]) < (t_info->h_sub[1]))
-      loss += SCORE_CHROMA_H_LOSS;
-  }
-  if ((in_info->w_sub[1]) != (t_info->w_sub[1])) {
-    loss += SCORE_CHROMA_W_CHANGE;
-    if ((in_info->w_sub[1]) < (t_info->w_sub[1]))
-      loss += SCORE_CHROMA_W_LOSS;
-  }
-
-  if ((in_info->bits) != (t_info->bits)) {
-    loss += SCORE_DEPTH_CHANGE;
-    if ((in_info->bits) > (t_info->bits))
-      loss += SCORE_DEPTH_LOSS;
-  }
-
-  GST_DEBUG_OBJECT (base, "score %s -> %s = %d",
-      GST_VIDEO_FORMAT_INFO_NAME (in_info),
-      GST_VIDEO_FORMAT_INFO_NAME (t_info), loss);
-
-  if (loss < *min_loss) {
-    GST_DEBUG_OBJECT (base, "found new best %d", loss);
-    *out_info = t_info;
-    *min_loss = loss;
-  }
-}
-
-static void
-gst_cuda_convert_class_init (GstCudaConvertClass * klass)
-{
-  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
-  GstBaseTransformClass *trans_class = GST_BASE_TRANSFORM_CLASS (klass);
-  GstCudaBaseTransformClass *btrans_class =
-      GST_CUDA_BASE_TRANSFORM_CLASS (klass);
-
-  gst_element_class_set_static_metadata (element_class,
-      "CUDA Colorspace converter",
-      "Filter/Converter/Video/Hardware",
-      "Converts video from one colorspace to another using CUDA",
-      "Seungha Yang <seungha.yang@navercorp.com>");
-
-  trans_class->passthrough_on_same_caps = TRUE;
-
-  trans_class->transform_caps =
-      GST_DEBUG_FUNCPTR (gst_cuda_convert_transform_caps);
-  trans_class->fixate_caps = GST_DEBUG_FUNCPTR (gst_cuda_convert_fixate_caps);
-  trans_class->filter_meta = GST_DEBUG_FUNCPTR (gst_cuda_convert_filter_meta);
-
-  btrans_class->set_info = GST_DEBUG_FUNCPTR (gst_cuda_convert_set_info);
-
-  GST_DEBUG_CATEGORY_INIT (gst_cuda_convert_debug,
-      "cudaconvert", 0, "Video ColorSpace convert using CUDA");
-}
-
-static void
-gst_cuda_convert_init (GstCudaConvert * convert)
-{
-}
-
-static GstCaps *
-gst_cuda_convert_transform_caps (GstBaseTransform * trans,
-    GstPadDirection direction, GstCaps * caps, GstCaps * filter)
-{
-  GstCaps *tmp, *tmp2;
-  GstCaps *result;
-
-  /* Get all possible caps that we can transform to */
-  tmp = gst_cuda_convert_caps_remove_format_info (caps);
-
-  if (filter) {
-    tmp2 = gst_caps_intersect_full (filter, tmp, GST_CAPS_INTERSECT_FIRST);
-    gst_caps_unref (tmp);
-    tmp = tmp2;
-  }
-
-  result = tmp;
-
-  GST_DEBUG_OBJECT (trans, "transformed %" GST_PTR_FORMAT " into %"
-      GST_PTR_FORMAT, caps, result);
-
-  return result;
-}
-
-/* fork of gstvideoconvert */
-static void
-gst_cuda_convert_fixate_format (GstBaseTransform * base, GstCaps * caps,
-    GstCaps * result)
-{
-  GstStructure *ins, *outs;
-  const gchar *in_format;
-  const GstVideoFormatInfo *in_info, *out_info = NULL;
-  gint min_loss = G_MAXINT;
-  guint i, capslen;
-
-  ins = gst_caps_get_structure (caps, 0);
-  in_format = gst_structure_get_string (ins, "format");
-  if (!in_format)
-    return;
-
-  GST_DEBUG_OBJECT (base, "source format %s", in_format);
-
-  in_info =
-      gst_video_format_get_info (gst_video_format_from_string (in_format));
-  if (!in_info)
-    return;
-
-  outs = gst_caps_get_structure (result, 0);
-
-  capslen = gst_caps_get_size (result);
-  GST_DEBUG_OBJECT (base, "iterate %d structures", capslen);
-  for (i = 0; i < capslen; i++) {
-    GstStructure *tests;
-    const GValue *format;
-
-    tests = gst_caps_get_structure (result, i);
-    format = gst_structure_get_value (tests, "format");
-    /* should not happen */
-    if (format == NULL)
-      continue;
-
-    if (GST_VALUE_HOLDS_LIST (format)) {
-      gint j, len;
-
-      len = gst_value_list_get_size (format);
-      GST_DEBUG_OBJECT (base, "have %d formats", len);
-      for (j = 0; j < len; j++) {
-        const GValue *val;
-
-        val = gst_value_list_get_value (format, j);
-        if (G_VALUE_HOLDS_STRING (val)) {
-          score_value (base, in_info, val, &min_loss, &out_info);
-          if (min_loss == 0)
-            break;
-        }
-      }
-    } else if (G_VALUE_HOLDS_STRING (format)) {
-      score_value (base, in_info, format, &min_loss, &out_info);
-    }
-  }
-  if (out_info)
-    gst_structure_set (outs, "format", G_TYPE_STRING,
-        GST_VIDEO_FORMAT_INFO_NAME (out_info), NULL);
-}
-
-static GstCaps *
-gst_cuda_convert_fixate_caps (GstBaseTransform * trans,
-    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps)
-{
-  GstCaps *result;
-
-  GST_DEBUG_OBJECT (trans, "trying to fixate othercaps %" GST_PTR_FORMAT
-      " based on caps %" GST_PTR_FORMAT, othercaps, caps);
-
-  result = gst_caps_intersect (othercaps, caps);
-  if (gst_caps_is_empty (result)) {
-    gst_caps_unref (result);
-    result = othercaps;
-  } else {
-    gst_caps_unref (othercaps);
-  }
-
-  GST_DEBUG_OBJECT (trans, "now fixating %" GST_PTR_FORMAT, result);
-
-  result = gst_caps_make_writable (result);
-  gst_cuda_convert_fixate_format (trans, caps, result);
-
-  /* fixate remaining fields */
-  result = gst_caps_fixate (result);
-
-  if (direction == GST_PAD_SINK) {
-    if (gst_caps_is_subset (caps, result)) {
-      gst_caps_replace (&result, caps);
-    }
-  }
-
-  return result;
-}
-
-static gboolean
-gst_cuda_convert_filter_meta (GstBaseTransform * trans, GstQuery * query,
-    GType api, const GstStructure * params)
-{
-  /* This element cannot passthrough the crop meta, because it would convert the
-   * wrong sub-region of the image, and worst, our output image may not be large
-   * enough for the crop to be applied later */
-  if (api == GST_VIDEO_CROP_META_API_TYPE)
-    return FALSE;
-
-  /* propose all other metadata upstream */
-  return TRUE;
-}
-
-#define CHECK_INFO_FIELDS_MATCHES(field) { \
-  if (in_info->field != in_info->field) { \
-    GST_ERROR_OBJECT (btrans, "%s do not match %d != %d", G_STRINGIFY(field), \
-      in_info->field, out_info->field); \
-    return FALSE;\
-  } \
-}
-
-static gboolean
-gst_cuda_convert_set_info (GstCudaBaseTransform * btrans, GstCaps * incaps,
-    GstVideoInfo * in_info, GstCaps * outcaps, GstVideoInfo * out_info)
-{
-  CHECK_INFO_FIELDS_MATCHES (width);
-  CHECK_INFO_FIELDS_MATCHES (height);
-  CHECK_INFO_FIELDS_MATCHES (fps_n);
-  CHECK_INFO_FIELDS_MATCHES (fps_d);
-  CHECK_INFO_FIELDS_MATCHES (par_n);
-
-  /* if present, these must match too */
-  CHECK_INFO_FIELDS_MATCHES (par_d);
-  CHECK_INFO_FIELDS_MATCHES (interlace_mode);
-
-
-  return GST_CUDA_BASE_TRANSFORM_CLASS (parent_class)->set_info (btrans, incaps,
-      in_info, outcaps, out_info);
-}
-
-#undef CHECK_INFO_FIELDS_MATCHES
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvert.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvert.h
deleted file mode 100644
index f8c2f50d0d..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvert.h
+++ /dev/null
@@ -1,53 +0,0 @@
-/* GStreamer
- * Copyright (C) <2019> Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-#ifndef __GST_CUDA_CONVERT_H__
-#define __GST_CUDA_CONVERT_H__
-
-#include <gst/gst.h>
-
-#include "gstcudabasefilter.h"
-
-G_BEGIN_DECLS
-
-#define GST_TYPE_CUDA_CONVERT             (gst_cuda_convert_get_type())
-#define GST_CUDA_CONVERT(obj)             (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_CUDA_CONVERT,GstCudaConvert))
-#define GST_CUDA_CONVERT_CLASS(klass)     (G_TYPE_CHECK_CLASS_CAST((klass), GST_TYPE_CUDA_CONVERT,GstCudaConvertClass))
-#define GST_CUDA_CONVERT_GET_CLASS(obj)   (G_TYPE_INSTANCE_GET_CLASS((obj), GST_TYPE_CUDA_CONVERT,GstCudaConvertClass))
-#define GST_IS_CUDA_CONVERT(obj)          (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_CUDA_CONVERT))
-#define GST_IS_CUDA_CONVERT_CLASS(klass)  (G_TYPE_CHECK_CLASS_TYPE((klass), GST_TYPE_CUDA_CONVERT))
-
-typedef struct _GstCudaConvert GstCudaConvert;
-typedef struct _GstCudaConvertClass GstCudaConvertClass;
-
-struct _GstCudaConvert
-{
-  GstCudaBaseFilter parent;
-};
-
-struct _GstCudaConvertClass
-{
-  GstCudaBaseFilterClass parent_class;
-};
-
-GType gst_cuda_convert_get_type (void);
-
-G_END_DECLS
-
-#endif /* __GST_CUDA_CONVERT_H__ */
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconverter.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconverter.c
new file mode 100644
index 0000000000..a7ea73d141
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconverter.c
@@ -0,0 +1,2243 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "gstcudaconverter.h"
+#include <gst/cuda/gstcudautils.h>
+#include <gst/cuda/gstcudaloader.h>
+#include <gst/cuda/gstcudanvrtc.h>
+#include <string.h>
+
+GST_DEBUG_CATEGORY_STATIC (gst_cuda_converter_debug);
+#define GST_CAT_DEFAULT gst_cuda_converter_debug
+
+#define CUDA_BLOCK_X 16
+#define CUDA_BLOCK_Y 16
+#define DIV_UP(size,block) (((size) + ((block) - 1)) / (block))
+
+/* from GstD3D11 */
+typedef struct _GstCudaColorMatrix
+{
+  gdouble matrix[3][3];
+  gdouble offset[3];
+  gdouble min[3];
+  gdouble max[3];
+} GstCudaColorMatrix;
+
+static gchar *
+gst_cuda_dump_color_matrix (GstCudaColorMatrix * matrix)
+{
+  /* *INDENT-OFF* */
+  static const gchar format[] =
+      "[MATRIX]\n"
+      "|% .6f, % .6f, % .6f|\n"
+      "|% .6f, % .6f, % .6f|\n"
+      "|% .6f, % .6f, % .6f|\n"
+      "[OFFSET]\n"
+      "|% .6f, % .6f, % .6f|\n"
+      "[MIN]\n"
+      "|% .6f, % .6f, % .6f|\n"
+      "[MAX]\n"
+      "|% .6f, % .6f, % .6f|";
+  /* *INDENT-ON* */
+
+  return g_strdup_printf (format,
+      matrix->matrix[0][0], matrix->matrix[0][1], matrix->matrix[0][2],
+      matrix->matrix[1][0], matrix->matrix[1][1], matrix->matrix[1][2],
+      matrix->matrix[2][0], matrix->matrix[2][1], matrix->matrix[2][2],
+      matrix->offset[0], matrix->offset[1], matrix->offset[2],
+      matrix->min[0], matrix->min[1], matrix->min[2],
+      matrix->max[0], matrix->max[1], matrix->max[2]);
+}
+
+static void
+color_matrix_copy (GstCudaColorMatrix * dst, const GstCudaColorMatrix * src)
+{
+  for (guint i = 0; i < 3; i++) {
+    for (guint j = 0; j < 3; j++) {
+      dst->matrix[i][j] = src->matrix[i][j];
+    }
+  }
+}
+
+static void
+color_matrix_multiply (GstCudaColorMatrix * dst, GstCudaColorMatrix * a,
+    GstCudaColorMatrix * b)
+{
+  GstCudaColorMatrix tmp;
+
+  for (guint i = 0; i < 3; i++) {
+    for (guint j = 0; j < 3; j++) {
+      gdouble val = 0;
+      for (guint k = 0; k < 3; k++) {
+        val += a->matrix[i][k] * b->matrix[k][j];
+      }
+
+      tmp.matrix[i][j] = val;
+    }
+  }
+
+  color_matrix_copy (dst, &tmp);
+}
+
+static void
+color_matrix_identity (GstCudaColorMatrix * m)
+{
+  for (guint i = 0; i < 3; i++) {
+    for (guint j = 0; j < 3; j++) {
+      if (i == j)
+        m->matrix[i][j] = 1.0;
+      else
+        m->matrix[i][j] = 0;
+    }
+  }
+}
+
+/**
+ * gst_cuda_color_range_adjust_matrix_unorm:
+ * @in_info: a #GstVideoInfo
+ * @out_info: a #GstVideoInfo
+ * @matrix: a #GstCudaColorMatrix
+ *
+ * Calculates matrix for color range adjustment. Both input and output
+ * signals are in normalized [0.0..1.0] space.
+ *
+ * Resulting values can be calculated by
+ * | Yout |                           | Yin |   | matrix.offset[0] |
+ * | Uout | = clamp ( matrix.matrix * | Uin | + | matrix.offset[1] |, matrix.min, matrix.max )
+ * | Vout |                           | Vin |   | matrix.offset[2] |
+ *
+ * Returns: %TRUE if successful
+ */
+static gboolean
+gst_cuda_color_range_adjust_matrix_unorm (const GstVideoInfo * in_info,
+    const GstVideoInfo * out_info, GstCudaColorMatrix * matrix)
+{
+  gboolean in_rgb, out_rgb;
+  gint in_offset[GST_VIDEO_MAX_COMPONENTS];
+  gint in_scale[GST_VIDEO_MAX_COMPONENTS];
+  gint out_offset[GST_VIDEO_MAX_COMPONENTS];
+  gint out_scale[GST_VIDEO_MAX_COMPONENTS];
+  GstVideoColorRange in_range;
+  GstVideoColorRange out_range;
+  gdouble src_fullscale, dst_fullscale;
+
+  memset (matrix, 0, sizeof (GstCudaColorMatrix));
+  for (guint i = 0; i < 3; i++) {
+    matrix->matrix[i][i] = 1.0;
+    matrix->matrix[i][i] = 1.0;
+    matrix->matrix[i][i] = 1.0;
+    matrix->max[i] = 1.0;
+  }
+
+  in_rgb = GST_VIDEO_INFO_IS_RGB (in_info);
+  out_rgb = GST_VIDEO_INFO_IS_RGB (out_info);
+
+  if (in_rgb != out_rgb) {
+    GST_WARNING ("Invalid format conversion");
+    return FALSE;
+  }
+
+  in_range = in_info->colorimetry.range;
+  out_range = out_info->colorimetry.range;
+
+  if (in_range == GST_VIDEO_COLOR_RANGE_UNKNOWN) {
+    GST_WARNING ("Unknown input color range");
+    if (in_rgb || GST_VIDEO_INFO_IS_GRAY (in_info))
+      in_range = GST_VIDEO_COLOR_RANGE_0_255;
+    else
+      in_range = GST_VIDEO_COLOR_RANGE_16_235;
+  }
+
+  if (out_range == GST_VIDEO_COLOR_RANGE_UNKNOWN) {
+    GST_WARNING ("Unknown output color range");
+    if (out_rgb || GST_VIDEO_INFO_IS_GRAY (out_info))
+      out_range = GST_VIDEO_COLOR_RANGE_0_255;
+    else
+      out_range = GST_VIDEO_COLOR_RANGE_16_235;
+  }
+
+  src_fullscale = (gdouble) ((1 << in_info->finfo->depth[0]) - 1);
+  dst_fullscale = (gdouble) ((1 << out_info->finfo->depth[0]) - 1);
+
+  gst_video_color_range_offsets (in_range, in_info->finfo, in_offset, in_scale);
+  gst_video_color_range_offsets (out_range,
+      out_info->finfo, out_offset, out_scale);
+
+  matrix->min[0] = matrix->min[1] = matrix->min[2] =
+      (gdouble) out_offset[0] / dst_fullscale;
+
+  matrix->max[0] = (out_scale[0] + out_offset[0]) / dst_fullscale;
+  matrix->max[1] = matrix->max[2] =
+      (out_scale[1] + out_offset[0]) / dst_fullscale;
+
+  if (in_info->colorimetry.range == out_info->colorimetry.range) {
+    GST_DEBUG ("Same color range");
+    return TRUE;
+  }
+
+  /* Formula
+   *
+   * 1) Scales and offset compensates input to [0..1] range
+   * SRC_NORM[i] = (src[i] * src_fullscale - in_offset[i]) / in_scale[i]
+   *             = (src[i] * src_fullscale / in_scale[i]) - in_offset[i] / in_scale[i]
+   *
+   * 2) Reverse to output UNIT scale
+   * DST_UINT[i] = SRC_NORM[i] * out_scale[i] + out_offset[i]
+   *             = src[i] * src_fullscale * out_scale[i] / in_scale[i]
+   *               - in_offset[i] * out_scale[i] / in_scale[i]
+   *               + out_offset[i]
+   *
+   * 3) Back to [0..1] scale
+   * dst[i] = DST_UINT[i] / dst_fullscale
+   *        = COEFF[i] * src[i] + OFF[i]
+   * where
+   *             src_fullscale * out_scale[i]
+   * COEFF[i] = ------------------------------
+   *             dst_fullscale * in_scale[i]
+   *
+   *            out_offset[i]     in_offset[i] * out_scale[i]
+   * OFF[i] =  -------------- -  ------------------------------
+   *            dst_fullscale     dst_fullscale * in_scale[i]
+   */
+  for (guint i = 0; i < 3; i++) {
+    matrix->matrix[i][i] = (src_fullscale * out_scale[i]) /
+        (dst_fullscale * in_scale[i]);
+    matrix->offset[i] = (out_offset[i] / dst_fullscale) -
+        ((gdouble) in_offset[i] * out_scale[i] / (dst_fullscale * in_scale[i]));
+  }
+
+  return TRUE;
+}
+
+/**
+ * gst_cuda_yuv_to_rgb_matrix_unorm:
+ * @in_yuv_info: a #GstVideoInfo of input YUV signal
+ * @out_rgb_info: a #GstVideoInfo of output RGB signal
+ * @matrix: a #GstCudaColorMatrix
+ *
+ * Calculates transform matrix from YUV to RGB conversion. Both input and output
+ * signals are in normalized [0.0..1.0] space and additional gamma decoding
+ * or primary/transfer function transform is not performed by this matrix.
+ *
+ * Resulting non-linear RGB values can be calculated by
+ * | R' |                           | Y' |   | matrix.offset[0] |
+ * | G' | = clamp ( matrix.matrix * | Cb | + | matrix.offset[1] | matrix.min, matrix.max )
+ * | B' |                           | Cr |   | matrix.offset[2] |
+ *
+ * Returns: %TRUE if successful
+ */
+static gboolean
+gst_cuda_yuv_to_rgb_matrix_unorm (const GstVideoInfo * in_yuv_info,
+    const GstVideoInfo * out_rgb_info, GstCudaColorMatrix * matrix)
+{
+  gint offset[4], scale[4];
+  gdouble Kr, Kb, Kg;
+
+  /*
+   * <Formula>
+   *
+   * Input: Unsigned normalized Y'CbCr(unorm), [0.0..1.0] range
+   * Output: Unsigned normalized non-linear R'G'B'(unorm), [0.0..1.0] range
+   *
+   * 1) Y'CbCr(unorm) to scaled Y'CbCr
+   * | Y' |     | Y'(unorm) |
+   * | Cb | = S | Cb(unorm) |
+   * | Cb |     | Cr(unorm) |
+   * where S = (2 ^ bitdepth) - 1
+   *
+   * 2) Y'CbCr to YPbPr
+   * Y  = (Y' - offsetY )    / scaleY
+   * Pb = [(Cb - offsetCbCr) / scaleCbCr]
+   * Pr = [(Cr - offsetCrCr) / scaleCrCr]
+   * =>
+   * Y  = Y'(unorm) * Sy  + Oy
+   * Pb = Cb(unorm) * Suv + Ouv
+   * Pb = Cr(unorm) * Suv + Ouv
+   * where
+   * Sy  = S / scaleY
+   * Suv = S / scaleCbCr
+   * Oy  = -(offsetY / scaleY)
+   * Ouv = -(offsetCbCr / scaleCbCr)
+   *
+   * 3) YPbPr to R'G'B'
+   * | R' |      | Y  |
+   * | G' | = M *| Pb |
+   * | B' |      | Pr |
+   * where
+   *     | vecR |
+   * M = | vecG |
+   *     | vecB |
+   * vecR = | 1,         0           ,       2(1 - Kr)      |
+   * vecG = | 1, -(Kb/Kg) * 2(1 - Kb), -(Kr/Kg) * 2(1 - Kr) |
+   * vecB = | 1,       2(1 - Kb)     ,          0           |
+   * =>
+   * R' = dot(vecR, (Syuv * Y'CbCr(unorm))) + dot(vecR, Offset)
+   * G' = dot(vecG, (Svuy * Y'CbCr(unorm))) + dot(vecG, Offset)
+   * B' = dot(vecB, (Syuv * Y'CbCr(unorm)) + dot(vecB, Offset)
+   * where
+   *        | Sy,   0,   0 |
+   * Syuv = |  0, Suv,   0 |
+   *        |  0    0, Suv |
+   *
+   *          | Oy  |
+   * Offset = | Ouv |
+   *          | Ouv |
+   *
+   * 4) YUV -> RGB matrix
+   * | R' |            | Y'(unorm) |   | offsetA |
+   * | G' | = Matrix * | Cb(unorm) | + | offsetB |
+   * | B' |            | Cr(unorm) |   | offsetC |
+   *
+   * where
+   *          | vecR |
+   * Matrix = | vecG | * Syuv
+   *          | vecB |
+   *
+   * offsetA = dot(vecR, Offset)
+   * offsetB = dot(vecG, Offset)
+   * offsetC = dot(vecB, Offset)
+   *
+   * 4) Consider 16-235 scale RGB
+   * RGBfull(0..255) -> RGBfull(16..235) matrix is represented by
+   * | Rs |      | Rf |   | Or |
+   * | Gs | = Ms | Gf | + | Og |
+   * | Bs |      | Bf |   | Ob |
+   *
+   * Combining all matrix into
+   * | Rs |                   | Y'(unorm) |   | offsetA |     | Or |
+   * | Gs | = Ms * ( Matrix * | Cb(unorm) | + | offsetB | ) + | Og |
+   * | Bs |                   | Cr(unorm) |   | offsetC |     | Ob |
+   *
+   *                        | Y'(unorm) |      | offsetA |   | Or |
+   *        = Ms * Matrix * | Cb(unorm) | + Ms | offsetB | + | Og |
+   *                        | Cr(unorm) |      | offsetC |   | Ob |
+   */
+
+  memset (matrix, 0, sizeof (GstCudaColorMatrix));
+  for (guint i = 0; i < 3; i++)
+    matrix->max[i] = 1.0;
+
+  gst_video_color_range_offsets (in_yuv_info->colorimetry.range,
+      in_yuv_info->finfo, offset, scale);
+
+  if (gst_video_color_matrix_get_Kr_Kb (in_yuv_info->colorimetry.matrix,
+          &Kr, &Kb)) {
+    guint S;
+    gdouble Sy, Suv;
+    gdouble Oy, Ouv;
+    gdouble vecR[3], vecG[3], vecB[3];
+
+    Kg = 1.0 - Kr - Kb;
+
+    vecR[0] = 1.0;
+    vecR[1] = 0;
+    vecR[2] = 2 * (1 - Kr);
+
+    vecG[0] = 1.0;
+    vecG[1] = -(Kb / Kg) * 2 * (1 - Kb);
+    vecG[2] = -(Kr / Kg) * 2 * (1 - Kr);
+
+    vecB[0] = 1.0;
+    vecB[1] = 2 * (1 - Kb);
+    vecB[2] = 0;
+
+    /* Assume all components has the same bitdepth */
+    S = (1 << in_yuv_info->finfo->depth[0]) - 1;
+    Sy = (gdouble) S / scale[0];
+    Suv = (gdouble) S / scale[1];
+    Oy = -((gdouble) offset[0] / scale[0]);
+    Ouv = -((gdouble) offset[1] / scale[1]);
+
+    matrix->matrix[0][0] = Sy * vecR[0];
+    matrix->matrix[1][0] = Sy * vecG[0];
+    matrix->matrix[2][0] = Sy * vecB[0];
+
+    matrix->matrix[0][1] = Suv * vecR[1];
+    matrix->matrix[1][1] = Suv * vecG[1];
+    matrix->matrix[2][1] = Suv * vecB[1];
+
+    matrix->matrix[0][2] = Suv * vecR[2];
+    matrix->matrix[1][2] = Suv * vecG[2];
+    matrix->matrix[2][2] = Suv * vecB[2];
+
+    matrix->offset[0] = vecR[0] * Oy + vecR[1] * Ouv + vecR[2] * Ouv;
+    matrix->offset[1] = vecG[0] * Oy + vecG[1] * Ouv + vecG[2] * Ouv;
+    matrix->offset[2] = vecB[0] * Oy + vecB[1] * Ouv + vecB[2] * Ouv;
+
+    /* Apply RGB range scale matrix */
+    if (out_rgb_info->colorimetry.range == GST_VIDEO_COLOR_RANGE_16_235) {
+      GstCudaColorMatrix scale_matrix, rst;
+      GstVideoInfo full_rgb = *out_rgb_info;
+
+      full_rgb.colorimetry.range = GST_VIDEO_COLOR_RANGE_0_255;
+
+      if (gst_cuda_color_range_adjust_matrix_unorm (&full_rgb,
+              out_rgb_info, &scale_matrix)) {
+        /* Ms * Matrix */
+        color_matrix_multiply (&rst, &scale_matrix, matrix);
+
+        /* Ms * transform offsets */
+        for (guint i = 0; i < 3; i++) {
+          gdouble val = 0;
+          for (guint j = 0; j < 3; j++) {
+            val += scale_matrix.matrix[i][j] * matrix->offset[j];
+          }
+          rst.offset[i] = val + scale_matrix.offset[i];
+        }
+
+        /* copy back to output matrix */
+        for (guint i = 0; i < 3; i++) {
+          for (guint j = 0; j < 3; j++) {
+            matrix->matrix[i][j] = rst.matrix[i][j];
+          }
+          matrix->offset[i] = rst.offset[i];
+          matrix->min[i] = scale_matrix.min[i];
+          matrix->max[i] = scale_matrix.max[i];
+        }
+      }
+    }
+  } else {
+    /* Unknown matrix */
+    matrix->matrix[0][0] = 1.0;
+    matrix->matrix[1][1] = 1.0;
+    matrix->matrix[2][2] = 1.0;
+  }
+
+  return TRUE;
+}
+
+/**
+ * gst_cuda_rgb_to_yuv_matrix_unorm:
+ * @in_rgb_info: a #GstVideoInfo of input RGB signal
+ * @out_yuv_info: a #GstVideoInfo of output YUV signal
+ * @matrix: a #GstCudaColorMatrix
+ *
+ * Calculates transform matrix from RGB to YUV conversion. Both input and output
+ * signals are in normalized [0.0..1.0] space and additional gamma decoding
+ * or primary/transfer function transform is not performed by this matrix.
+ *
+ * Resulting RGB values can be calculated by
+ * | Y' |                           | R' |   | matrix.offset[0] |
+ * | Cb | = clamp ( matrix.matrix * | G' | + | matrix.offset[1] |, matrix.min, matrix.max )
+ * | Cr |                           | B' |   | matrix.offset[2] |
+ *
+ * Returns: %TRUE if successful
+ */
+static gboolean
+gst_cuda_rgb_to_yuv_matrix_unorm (const GstVideoInfo * in_rgb_info,
+    const GstVideoInfo * out_yuv_info, GstCudaColorMatrix * matrix)
+{
+  gint offset[4], scale[4];
+  gdouble Kr, Kb, Kg;
+
+  /*
+   * <Formula>
+   *
+   * Input: Unsigned normalized non-linear R'G'B'(unorm), [0.0..1.0] range
+   * Output: Unsigned normalized Y'CbCr(unorm), [0.0..1.0] range
+   *
+   * 1) R'G'B' to YPbPr
+   * | Y  |      | R' |
+   * | Pb | = M *| G' |
+   * | Pr |      | B' |
+   * where
+   *     | vecY |
+   * M = | vecU |
+   *     | vecV |
+   * vecY = |       Kr      ,       Kg      ,      Kb       |
+   * vecU = | -0.5*Kr/(1-Kb), -0.5*Kg/(1-Kb),     0.5       |
+   * vecV = |      0.5      , -0.5*Kg/(1-Kr), -0.5*Kb(1-Kr) |
+   *
+   * 2) YPbPr to Y'CbCr(unorm)
+   * Y'(unorm) = (Y  * scaleY + offsetY)       / S
+   * Cb(unorm) = (Pb * scaleCbCr + offsetCbCr) / S
+   * Cr(unorm) = (Pr * scaleCbCr + offsetCbCr) / S
+   * =>
+   * Y'(unorm) = (Y  * scaleY    / S) + (offsetY    / S)
+   * Cb(unorm) = (Pb * scaleCbCr / S) + (offsetCbCr / S)
+   * Cr(unorm) = (Pb * scaleCbCr / S) + (offsetCbCr / S)
+   * where S = (2 ^ bitdepth) - 1
+   *
+   * 3) RGB -> YUV matrix
+   * | Y'(unorm) |            | R' |   | offsetA |
+   * | Cb(unorm) | = Matrix * | G' | + | offsetB |
+   * | Cr(unorm) |            | B' |   | offsetC |
+   *
+   * where
+   *          | (scaleY/S)    * vecY |
+   * Matrix = | (scaleCbCr/S) * vecU |
+   *          | (scaleCbCr/S) * vecV |
+   *
+   * offsetA = offsetY    / S
+   * offsetB = offsetCbCr / S
+   * offsetC = offsetCbCr / S
+   *
+   * 4) Consider 16-235 scale RGB
+   * RGBstudio(16..235) -> RGBfull(0..255) matrix is represented by
+   * | Rf |      | Rs |   | Or |
+   * | Gf | = Ms | Gs | + | Og |
+   * | Bf |      | Bs |   | Ob |
+   *
+   * Combining all matrix into
+   * | Y'(unorm) |                 | Rs |   | Or |     | offsetA |
+   * | Cb(unorm) | = Matrix * ( Ms | Gs | + | Og | ) + | offsetB |
+   * | Cr(unorm) |                 | Bs |   | Ob |     | offsetC |
+   *
+   *                             | Rs |          | Or |   | offsetA |
+   *               = Matrix * Ms | Gs | + Matrix | Og | + | offsetB |
+   *                             | Bs |          | Ob |   | offsetB |
+   */
+
+  memset (matrix, 0, sizeof (GstCudaColorMatrix));
+  for (guint i = 0; i < 3; i++)
+    matrix->max[i] = 1.0;
+
+  gst_video_color_range_offsets (out_yuv_info->colorimetry.range,
+      out_yuv_info->finfo, offset, scale);
+
+  if (gst_video_color_matrix_get_Kr_Kb (out_yuv_info->colorimetry.matrix,
+          &Kr, &Kb)) {
+    guint S;
+    gdouble Sy, Suv;
+    gdouble Oy, Ouv;
+    gdouble vecY[3], vecU[3], vecV[3];
+
+    Kg = 1.0 - Kr - Kb;
+
+    vecY[0] = Kr;
+    vecY[1] = Kg;
+    vecY[2] = Kb;
+
+    vecU[0] = -0.5 * Kr / (1 - Kb);
+    vecU[1] = -0.5 * Kg / (1 - Kb);
+    vecU[2] = 0.5;
+
+    vecV[0] = 0.5;
+    vecV[1] = -0.5 * Kg / (1 - Kr);
+    vecV[2] = -0.5 * Kb / (1 - Kr);
+
+    /* Assume all components has the same bitdepth */
+    S = (1 << out_yuv_info->finfo->depth[0]) - 1;
+    Sy = (gdouble) scale[0] / S;
+    Suv = (gdouble) scale[1] / S;
+    Oy = (gdouble) offset[0] / S;
+    Ouv = (gdouble) offset[1] / S;
+
+    for (guint i = 0; i < 3; i++) {
+      matrix->matrix[0][i] = Sy * vecY[i];
+      matrix->matrix[1][i] = Suv * vecU[i];
+      matrix->matrix[2][i] = Suv * vecV[i];
+    }
+
+    matrix->offset[0] = Oy;
+    matrix->offset[1] = Ouv;
+    matrix->offset[2] = Ouv;
+
+    matrix->min[0] = Oy;
+    matrix->min[1] = Oy;
+    matrix->min[2] = Oy;
+
+    matrix->max[0] = ((gdouble) scale[0] + offset[0]) / S;
+    matrix->max[1] = ((gdouble) scale[1] + offset[0]) / S;
+    matrix->max[2] = ((gdouble) scale[1] + offset[0]) / S;
+
+    /* Apply RGB range scale matrix */
+    if (in_rgb_info->colorimetry.range == GST_VIDEO_COLOR_RANGE_16_235) {
+      GstCudaColorMatrix scale_matrix, rst;
+      GstVideoInfo full_rgb = *in_rgb_info;
+
+      full_rgb.colorimetry.range = GST_VIDEO_COLOR_RANGE_0_255;
+
+      if (gst_cuda_color_range_adjust_matrix_unorm (in_rgb_info,
+              &full_rgb, &scale_matrix)) {
+        /* Matrix * Ms */
+        color_matrix_multiply (&rst, matrix, &scale_matrix);
+
+        /* Matrix * scale offsets */
+        for (guint i = 0; i < 3; i++) {
+          gdouble val = 0;
+          for (guint j = 0; j < 3; j++) {
+            val += matrix->matrix[i][j] * scale_matrix.offset[j];
+          }
+          rst.offset[i] = val + matrix->offset[i];
+        }
+
+        /* copy back to output matrix */
+        for (guint i = 0; i < 3; i++) {
+          for (guint j = 0; j < 3; j++) {
+            matrix->matrix[i][j] = rst.matrix[i][j];
+          }
+          matrix->offset[i] = rst.offset[i];
+        }
+      }
+    }
+  } else {
+    /* Unknown matrix */
+    matrix->matrix[0][0] = 1.0;
+    matrix->matrix[1][1] = 1.0;
+    matrix->matrix[2][2] = 1.0;
+  }
+
+  return TRUE;
+}
+
+typedef struct
+{
+  float coeffX[3];
+  float coeffY[3];
+  float coeffZ[3];
+  float offset[3];
+  float min[3];
+  float max[3];
+} ColorMatrix;
+
+typedef struct
+{
+  ColorMatrix toRGBCoeff;
+  ColorMatrix toYuvCoeff;
+  ColorMatrix primariesCoeff;
+} ConstBuffer;
+
+#define COLOR_SPACE_IDENTITY "color_space_identity"
+#define COLOR_SPACE_CONVERT "color_space_convert"
+
+#define SAMPLE_YUV_PLANAR "sample_yuv_planar"
+#define SAMPLE_YV12 "sample_yv12"
+#define SAMPLE_YUV_PLANAR_10BIS "sample_yuv_planar_10bits"
+#define SAMPLE_YUV_PLANAR_12BIS "sample_yuv_planar_12bits"
+#define SAMPLE_SEMI_PLANAR "sample_semi_planar"
+#define SAMPLE_SEMI_PLANAR_SWAP "sample_semi_planar_swap"
+#define SAMPLE_RGBA "sample_rgba"
+#define SAMPLE_BGRA "sample_bgra"
+#define SAMPLE_RGBx "sample_rgbx"
+#define SAMPLE_BGRx "sample_bgrx"
+#define SAMPLE_ARGB "sample_argb"
+/* same as ARGB */
+#define SAMPLE_ARGB64 "sample_argb"
+#define SAMPLE_AGBR "sample_abgr"
+#define SAMPLE_RGBP "sample_rgbp"
+#define SAMPLE_BGRP "sample_bgrp"
+#define SAMPLE_GBR "sample_gbr"
+#define SAMPLE_GBRA "sample_gbra"
+
+#define WRITE_I420 "write_i420"
+#define WRITE_YV12 "write_yv12"
+#define WRITE_NV12 "write_nv12"
+#define WRITE_NV21 "write_nv21"
+#define WRITE_P010 "write_p010"
+/* same as P010 */
+#define WRITE_P016 "write_p010"
+#define WRITE_I420_10 "write_i420_10"
+#define WRITE_Y444 "write_y444"
+#define WRITE_Y444_16 "write_y444_16"
+#define WRITE_RGBA "write_rgba"
+#define WRITE_RGBx "write_rgbx"
+#define WRITE_BGRA "write_bgra"
+#define WRITE_BGRx "write_bgrx"
+#define WRITE_ARGB "write_argb"
+#define WRITE_ABGR "write_abgr"
+#define WRITE_RGB "write_rgb"
+#define WRITE_BGR "write_bgr"
+#define WRITE_RGB10A2 "write_rgb10a2"
+#define WRITE_BGR10A2 "write_bgr10a2"
+#define WRITE_Y42B "write_y42b"
+#define WRITE_I422_10 "write_i422_10"
+#define WRITE_I422_12 "write_i422_12"
+#define WRITE_RGBP "write_rgbp"
+#define WRITE_BGRP "write_bgrp"
+#define WRITE_GBR "write_gbr"
+#define WRITE_GBRA "write_gbra"
+
+/* *INDENT-OFF* */
+const static gchar KERNEL_COMMON[] =
+"struct ColorMatrix\n"
+"{\n"
+"  float CoeffX[3];\n"
+"  float CoeffY[3];\n"
+"  float CoeffZ[3];\n"
+"  float Offset[3];\n"
+"  float Min[3];\n"
+"  float Max[3];\n"
+"};\n"
+"\n"
+"__device__ inline float\n"
+"dot (const float coeff[3], float3 val)\n"
+"{\n"
+"  return coeff[0] * val.x + coeff[1] * val.y + coeff[2] * val.z;\n"
+"}\n"
+"\n"
+"__device__ inline float\n"
+"clamp (float val, float min_val, float max_val)\n"
+"{\n"
+"  return max (min_val, min (val, max_val));\n"
+"}\n"
+"\n"
+"__device__ inline float3\n"
+"clamp3 (float3 val, const float min_val[3], const float max_val[3])\n"
+"{\n"
+"  return make_float3 (clamp (val.x, min_val[0], max_val[0]),\n"
+"      clamp (val.y, min_val[1], max_val[2]),\n"
+"      clamp (val.z, min_val[1], max_val[2]));\n"
+"}\n"
+"\n"
+"__device__ inline unsigned char\n"
+"scale_to_2bits (float val)\n"
+"{\n"
+"  return (unsigned short) __float2int_rz (val * 3.0);\n"
+"}\n"
+"\n"
+"__device__ inline unsigned char\n"
+"scale_to_uchar (float val)\n"
+"{\n"
+"  return (unsigned char) __float2int_rz (val * 255.0);\n"
+"}\n"
+"\n"
+"__device__ inline unsigned short\n"
+"scale_to_ushort (float val)\n"
+"{\n"
+"  return (unsigned short) __float2int_rz (val * 65535.0);\n"
+"}\n"
+"\n"
+"__device__ inline unsigned short\n"
+"scale_to_10bits (float val)\n"
+"{\n"
+"  return (unsigned short) __float2int_rz (val * 1023.0);\n"
+"}\n"
+"\n"
+"__device__ inline unsigned short\n"
+"scale_to_12bits (float val)\n"
+"{\n"
+"  return (unsigned short) __float2int_rz (val * 4095.0);\n"
+"}\n"
+"\n"
+"__device__ inline float3\n"
+COLOR_SPACE_IDENTITY "(float3 sample, const ColorMatrix * matrix)\n"
+"{\n"
+"  return sample;\n"
+"}\n"
+"\n"
+"__device__ inline float3\n"
+COLOR_SPACE_CONVERT "(float3 sample, const ColorMatrix * matrix)\n"
+"{\n"
+"  float3 out;\n"
+"  out.x = dot (matrix->CoeffX, sample);\n"
+"  out.y = dot (matrix->CoeffY, sample);\n"
+"  out.z = dot (matrix->CoeffZ, sample);\n"
+"  out.x += matrix->Offset[0];\n"
+"  out.y += matrix->Offset[1];\n"
+"  out.z += matrix->Offset[2];\n"
+"  return clamp3 (out, matrix->Min, matrix->Max);\n"
+"}\n"
+"/* All 8bits yuv planar except for yv12 */\n"
+"__device__ inline float4\n"
+SAMPLE_YUV_PLANAR "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float luma = tex2D<float>(tex0, x, y);\n"
+"  float u = tex2D<float>(tex1, x, y);\n"
+"  float v = tex2D<float>(tex2, x, y);\n"
+"  return make_float4 (luma, u, v, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_YV12 "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float luma = tex2D<float>(tex0, x, y);\n"
+"  float u = tex2D<float>(tex2, x, y);\n"
+"  float v = tex2D<float>(tex1, x, y);\n"
+"  return make_float4 (luma, u, v, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_YUV_PLANAR_10BIS "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float luma = tex2D<float>(tex0, x, y);\n"
+"  float u = tex2D<float>(tex1, x, y);\n"
+"  float v = tex2D<float>(tex2, x, y);\n"
+"  /* (1 << 6) to scale [0, 1.0) range */\n"
+"  return make_float4 (luma * 64, u * 64, v * 64, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_YUV_PLANAR_12BIS "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float luma = tex2D<float>(tex0, x, y);\n"
+"  float u = tex2D<float>(tex1, x, y);\n"
+"  float v = tex2D<float>(tex2, x, y);\n"
+"  /* (1 << 6) to scale [0, 1.0) range */\n"
+"  return make_float4 (luma * 16, u * 16, v * 16, 1);\n"
+"}\n"
+"\n"
+"/* NV12, P010, and P016 */\n"
+"__device__ inline float4\n"
+SAMPLE_SEMI_PLANAR "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float luma = tex2D<float>(tex0, x, y);\n"
+"  float2 uv = tex2D<float2>(tex1, x, y);\n"
+"  return make_float4 (luma, uv.x, uv.y, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_SEMI_PLANAR_SWAP "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float luma = tex2D<float>(tex0, x, y);\n"
+"  float2 vu = tex2D<float2>(tex1, x, y);\n"
+"  return make_float4 (luma, vu.y, vu.x, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_RGBA "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  return tex2D<float4>(tex0, x, y);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_BGRA "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float4 bgra = tex2D<float4>(tex0, x, y);\n"
+"  return make_float4 (bgra.z, bgra.y, bgra.x, bgra.w);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_RGBx "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float4 rgbx = tex2D<float4>(tex0, x, y);\n"
+"  rgbx.w = 1;\n"
+"  return rgbx;\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_BGRx "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float4 bgrx = tex2D<float4>(tex0, x, y);\n"
+"  return make_float4 (bgrx.z, bgrx.y, bgrx.x, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_ARGB "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float4 argb = tex2D<float4>(tex0, x, y);\n"
+"  return make_float4 (argb.y, argb.z, argb.w, argb.x);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_AGBR "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float4 abgr = tex2D<float4>(tex0, x, y);\n"
+"  return make_float4 (abgr.w, abgr.z, abgr.y, abgr.x);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_RGBP "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float r = tex2D<float>(tex0, x, y);\n"
+"  float g = tex2D<float>(tex1, x, y);\n"
+"  float b = tex2D<float>(tex2, x, y);\n"
+"  return make_float4 (r, g, b, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_BGRP "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float b = tex2D<float>(tex0, x, y);\n"
+"  float g = tex2D<float>(tex1, x, y);\n"
+"  float r = tex2D<float>(tex2, x, y);\n"
+"  return make_float4 (r, g, b, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_GBR "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float g = tex2D<float>(tex0, x, y);\n"
+"  float b = tex2D<float>(tex1, x, y);\n"
+"  float r = tex2D<float>(tex2, x, y);\n"
+"  return make_float4 (r, g, b, 1);\n"
+"}\n"
+"\n"
+"__device__ inline float4\n"
+SAMPLE_GBRA "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, float x, float y)\n"
+"{\n"
+"  float g = tex2D<float>(tex0, x, y);\n"
+"  float b = tex2D<float>(tex1, x, y);\n"
+"  float r = tex2D<float>(tex2, x, y);\n"
+"  float a = tex2D<float>(tex3, x, y);\n"
+"  return make_float4 (r, g, b, a);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_I420 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  dst0[x + y * stride0] = scale_to_uchar (sample.x);\n"
+"  if (x % 2 == 0 && y % 2 == 0) {\n"
+"    unsigned int pos = x / 2 + (y / 2) * stride1;\n"
+"    dst1[pos] = scale_to_uchar (sample.y);\n"
+"    dst2[pos] = scale_to_uchar (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_YV12 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  dst0[x + y * stride0] = scale_to_uchar (sample.x);\n"
+"  if (x % 2 == 0 && y % 2 == 0) {\n"
+"    unsigned int pos = x / 2 + (y / 2) * stride1;\n"
+"    dst1[pos] = scale_to_uchar (sample.z);\n"
+"    dst2[pos] = scale_to_uchar (sample.y);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_NV12 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  dst0[x + y * stride0] = scale_to_uchar (sample.x);\n"
+"  if (x % 2 == 0 && y % 2 == 0) {\n"
+"    unsigned int pos = x + (y / 2) * stride1;\n"
+"    dst1[pos] = scale_to_uchar (sample.y);\n"
+"    dst1[pos + 1] = scale_to_uchar (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_NV21 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  dst0[x + y * stride0] = scale_to_uchar (sample.x);\n"
+"  if (x % 2 == 0 && y % 2 == 0) {\n"
+"    unsigned int pos = x + (y / 2) * stride1;\n"
+"    dst1[pos] = scale_to_uchar (sample.z);\n"
+"    dst1[pos + 1] = scale_to_uchar (sample.y);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_P010 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  *(unsigned short *) &dst0[x * 2 + y * stride0] = scale_to_ushort (sample.x);\n"
+"  if (x % 2 == 0 && y % 2 == 0) {\n"
+"    unsigned int pos = x * 2 + (y / 2) * stride1;\n"
+"    *(unsigned short *) &dst1[pos] = scale_to_ushort (sample.y);\n"
+"    *(unsigned short *) &dst1[pos + 2] = scale_to_ushort (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_I420_10 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  *(unsigned short *) &dst0[x * 2 + y * stride0] = scale_to_10bits (sample.x);\n"
+"  if (x % 2 == 0 && y % 2 == 0) {\n"
+"    unsigned int pos = x + (y / 2) * stride1;\n"
+"    *(unsigned short *) &dst1[pos] = scale_to_10bits (sample.y);\n"
+"    *(unsigned short *) &dst2[pos] = scale_to_10bits (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_Y444 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.x);\n"
+"  dst1[pos] = scale_to_uchar (sample.y);\n"
+"  dst2[pos] = scale_to_uchar (sample.z);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_Y444_16 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 2 + y * stride0;\n"
+"  *(unsigned short *) &dst0[pos] = scale_to_ushort (sample.x);\n"
+"  *(unsigned short *) &dst1[pos] = scale_to_ushort (sample.y);\n"
+"  *(unsigned short *) &dst2[pos] = scale_to_ushort (sample.z);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_RGBA "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 4 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.x);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.z);\n"
+"  dst0[pos + 3] = scale_to_uchar (sample.w);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_RGBx "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 4 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.x);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.z);\n"
+"  dst0[pos + 3] = 255;\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_BGRA "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 4 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.z);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.x);\n"
+"  dst0[pos + 3] = scale_to_uchar (sample.w);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_BGRx "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 4 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.z);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.x);\n"
+"  dst0[pos + 3] = 255;\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_ARGB "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 4 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.w);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.x);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 3] = scale_to_uchar (sample.z);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_ABGR "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 4 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.w);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.z);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 3] = scale_to_uchar (sample.x);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_RGB "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 3 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.x);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.z);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_BGR "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x * 3 + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.z);\n"
+"  dst0[pos + 1] = scale_to_uchar (sample.y);\n"
+"  dst0[pos + 2] = scale_to_uchar (sample.x);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_RGB10A2 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  unsigned int alpha = (unsigned int) scale_to_2bits (sample.x);\n"
+"  unsigned int packed_rgb = alpha << 30;\n"
+"  packed_rgb |= ((unsigned int) scale_to_10bits (sample.x));\n"
+"  packed_rgb |= ((unsigned int) scale_to_10bits (sample.y)) << 10;\n"
+"  packed_rgb |= ((unsigned int) scale_to_10bits (sample.z)) << 20;\n"
+"  *(unsigned int *) &dst0[x * 4 + y * stride0] = packed_rgb;\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_BGR10A2 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  unsigned int alpha = (unsigned int) scale_to_2bits (sample.x);\n"
+"  unsigned int packed_rgb = alpha << 30;\n"
+"  packed_rgb |= ((unsigned int) scale_to_10bits (sample.x)) << 20;\n"
+"  packed_rgb |= ((unsigned int) scale_to_10bits (sample.y)) << 10;\n"
+"  packed_rgb |= ((unsigned int) scale_to_10bits (sample.z));\n"
+"  *(unsigned int *) &dst0[x * 4 + y * stride0] = packed_rgb;\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_Y42B "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  dst0[x + y * stride0] = scale_to_uchar (sample.x);\n"
+"  if (x % 2 == 0) {\n"
+"    unsigned int pos = x / 2 + y * stride1;\n"
+"    dst1[pos] = scale_to_uchar (sample.y);\n"
+"    dst2[pos] = scale_to_uchar (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_I422_10 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  *(unsigned short *) &dst0[x * 2 + y * stride0] = scale_to_10bits (sample.x);\n"
+"  if (x % 2 == 0) {\n"
+"    unsigned int pos = x + y * stride1;\n"
+"    *(unsigned short *) &dst1[pos] = scale_to_10bits (sample.y);\n"
+"    *(unsigned short *) &dst2[pos] = scale_to_10bits (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_I422_12 "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  *(unsigned short *) &dst0[x * 2 + y * stride0] = scale_to_12bits (sample.x);\n"
+"  if (x % 2 == 0) {\n"
+"    unsigned int pos = x + y * stride1;\n"
+"    *(unsigned short *) &dst1[pos] = scale_to_12bits (sample.y);\n"
+"    *(unsigned short *) &dst2[pos] = scale_to_12bits (sample.z);\n"
+"  }\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_RGBP "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.x);\n"
+"  dst1[pos] = scale_to_uchar (sample.y);\n"
+"  dst2[pos] = scale_to_uchar (sample.z);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_BGRP "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.z);\n"
+"  dst1[pos] = scale_to_uchar (sample.y);\n"
+"  dst2[pos] = scale_to_uchar (sample.x);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_GBR "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.y);\n"
+"  dst1[pos] = scale_to_uchar (sample.z);\n"
+"  dst2[pos] = scale_to_uchar (sample.x);\n"
+"}\n"
+"\n"
+"__device__ inline void\n"
+WRITE_GBRA "(unsigned char * dst0, unsigned char * dst1, unsigned char * dst2,\n"
+"    unsigned char * dst3, float4 sample, int x, int y, int stride0, int stride1)\n"
+"{\n"
+"  int pos = x + y * stride0;\n"
+"  dst0[pos] = scale_to_uchar (sample.y);\n"
+"  dst1[pos] = scale_to_uchar (sample.z);\n"
+"  dst2[pos] = scale_to_uchar (sample.x);\n"
+"  dst3[pos] = scale_to_uchar (sample.w);\n"
+"}\n";
+
+#define GST_CUDA_KERNEL_UNPACK_FUNC "gst_cuda_kernel_unpack_func"
+static const gchar RGB_TO_RGBx[] =
+"extern \"C\" {\n"
+"__global__ void\n"
+GST_CUDA_KERNEL_UNPACK_FUNC
+"(unsigned char *src, unsigned char *dst, int width, int height,\n"
+"    int src_stride, int dst_stride)\n"
+"{\n"
+"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
+"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
+"  if (x_pos < width && y_pos < height) {\n"
+"    int dst_pos = x_pos * 4 + y_pos * dst_stride;\n"
+"    int src_pos = x_pos * 3 + y_pos * src_stride;\n"
+"    dst[dst_pos] = src[src_pos];\n"
+"    dst[dst_pos + 1] = src[src_pos + 1];\n"
+"    dst[dst_pos + 2] = src[src_pos + 2];\n"
+"    dst[dst_pos + 3] = 0xff;\n"
+"  }\n"
+"}\n"
+"}\n";
+
+static const gchar RGB10A2_TO_ARGB64[] =
+"extern \"C\" {\n"
+"__global__ void\n"
+GST_CUDA_KERNEL_UNPACK_FUNC
+"(unsigned char *src, unsigned char *dst, int width, int height,\n"
+"    int src_stride, int dst_stride)\n"
+"{\n"
+"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
+"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
+"  if (x_pos < width && y_pos < height) {\n"
+"    unsigned short a, r, g, b;\n"
+"    unsigned int val;\n"
+"    int dst_pos = x_pos * 8 + y_pos * dst_stride;\n"
+"    val = *(unsigned int *)&src[x_pos * 4 + y_pos * src_stride];\n"
+"    a = (val >> 30) & 0x03;\n"
+"    a = (a << 14) | (a << 12) | (a << 10) | (a << 8) | (a << 6) | (a << 4) | (a << 2) | (a << 0);\n"
+"    r = (val & 0x3ff);\n"
+"    r = (r << 6) | (r >> 4);\n"
+"    g = ((val >> 10) & 0x3ff);\n"
+"    g = (g << 6) | (g >> 4);\n"
+"    b = ((val >> 20) & 0x3ff);\n"
+"    b = (b << 6) | (b >> 4);\n"
+"    *(unsigned short *) &dst[dst_pos] = a;\n"
+"    *(unsigned short *) &dst[dst_pos + 2] = r;\n"
+"    *(unsigned short *) &dst[dst_pos + 4] = g;\n"
+"    *(unsigned short *) &dst[dst_pos + 6] = b;\n"
+"  }\n"
+"}\n"
+"}\n";
+
+static const gchar BGR10A2_TO_ARGB64[] =
+"extern \"C\" {\n"
+"__global__ void\n"
+GST_CUDA_KERNEL_UNPACK_FUNC
+"(unsigned char *src, unsigned char *dst, int width, int height,\n"
+"    int src_stride, int dst_stride)\n"
+"{\n"
+"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
+"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
+"  if (x_pos < width && y_pos < height) {\n"
+"    unsigned short a, r, g, b;\n"
+"    unsigned int val;\n"
+"    int dst_pos = x_pos * 8 + y_pos * dst_stride;\n"
+"    val = *(unsigned int *)&src[x_pos * 4 + y_pos * src_stride];\n"
+"    a = (val >> 30) & 0x03;\n"
+"    a = (a << 14) | (a << 12) | (a << 10) | (a << 8) | (a << 6) | (a << 4) | (a << 2) | (a << 0);\n"
+"    b = (val & 0x3ff);\n"
+"    b = (b << 6) | (b >> 4);\n"
+"    g = ((val >> 10) & 0x3ff);\n"
+"    g = (g << 6) | (g >> 4);\n"
+"    r = ((val >> 20) & 0x3ff);\n"
+"    r = (r << 6) | (r >> 4);\n"
+"    *(unsigned short *) &dst[dst_pos] = a;\n"
+"    *(unsigned short *) &dst[dst_pos + 2] = r;\n"
+"    *(unsigned short *) &dst[dst_pos + 4] = g;\n"
+"    *(unsigned short *) &dst[dst_pos + 6] = b;\n"
+"  }\n"
+"}\n"
+"}\n";
+
+#define GST_CUDA_KERNEL_MAIN_FUNC "KernelMain"
+
+static const gchar TEMPLETA_KERNEL[] =
+/* KERNEL_COMMON */
+"%s\n"
+/* UNPACK FUNCTION */
+"%s\n"
+"__constant__ ColorMatrix TO_RGB_MATRIX = { { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s } };\n"
+"__constant__ ColorMatrix TO_YUV_MATRIX = { { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s },\n"
+"                                           { %s, %s, %s } };\n"
+"__constant__ int WIDTH = %d;\n"
+"__constant__ int HEIGHT = %d;\n"
+"__constant__ int LEFT = %d;\n"
+"__constant__ int TOP = %d;\n"
+"__constant__ int RIGHT = %d;\n"
+"__constant__ int BOTTOM = %d;\n"
+"__constant__ int VIEW_WIDTH = %d;\n"
+"__constant__ int VIEW_HEIGHT = %d;\n"
+"__constant__ float OFFSET_X = %s;\n"
+"__constant__ float OFFSET_Y = %s;\n"
+"__constant__ float BORDER_X = %s;\n"
+"__constant__ float BORDER_Y = %s;\n"
+"__constant__ float BORDER_Z = %s;\n"
+"__constant__ float BORDER_W = %s;\n"
+"\n"
+"extern \"C\" {\n"
+"__global__ void\n"
+GST_CUDA_KERNEL_MAIN_FUNC "(cudaTextureObject_t tex0, cudaTextureObject_t tex1,\n"
+"    cudaTextureObject_t tex2, cudaTextureObject_t tex3, unsigned char * dst0,\n"
+"    unsigned char * dst1, unsigned char * dst2, unsigned char * dst3,\n"
+"    int stride0, int stride1)\n"
+"{\n"
+"  int x_pos = blockIdx.x * blockDim.x + threadIdx.x;\n"
+"  int y_pos = blockIdx.y * blockDim.y + threadIdx.y;\n"
+"  float4 sample;\n"
+"  if (x_pos >= WIDTH || y_pos >= HEIGHT)\n"
+"    return;\n"
+"  if (x_pos < LEFT || x_pos >= RIGHT || y_pos < TOP || y_pos >= BOTTOM) {\n"
+"    sample = make_float4 (BORDER_X, BORDER_Y, BORDER_Z, BORDER_W);\n"
+"  } else {\n"
+"    float x = OFFSET_X + (float) (x_pos - LEFT) / VIEW_WIDTH;\n"
+"    float y = OFFSET_Y + (float) (y_pos - TOP) / VIEW_HEIGHT;\n"
+"    float4 s = %s (tex0, tex1, tex2, tex3, x, y);\n"
+"    float3 xyz = make_float3 (s.x, s.y, s.z);\n"
+"    float3 rgb = %s (xyz, &TO_RGB_MATRIX);\n"
+"    float3 yuv = %s (rgb, &TO_YUV_MATRIX);\n"
+"    sample = make_float4 (yuv.x, yuv.y, yuv.z, s.w);\n"
+"  }\n"
+"  %s (dst0, dst1, dst2, dst3, sample, x_pos, y_pos, stride0, stride1);\n"
+"}\n"
+"}\n";
+/* *INDENT-ON* */
+
+typedef struct _TextureFormat
+{
+  GstVideoFormat format;
+  CUarray_format array_format[GST_VIDEO_MAX_COMPONENTS];
+  guint channels[GST_VIDEO_MAX_COMPONENTS];
+  const gchar *sample_func;
+} TextureFormat;
+
+#define CU_AD_FORMAT_NONE 0
+#define MAKE_FORMAT_YUV_PLANAR(f,cf,sample_func) \
+  { GST_VIDEO_FORMAT_ ##f,  { CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_ ##cf, \
+      CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_NONE },  {1, 1, 1, 0}, sample_func }
+#define MAKE_FORMAT_YUV_SEMI_PLANAR(f,cf,sample_func) \
+  { GST_VIDEO_FORMAT_ ##f,  { CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_ ##cf, \
+      CU_AD_FORMAT_NONE, CU_AD_FORMAT_NONE }, {1, 2, 0, 0}, sample_func }
+#define MAKE_FORMAT_RGB(f,cf,sample_func) \
+  { GST_VIDEO_FORMAT_ ##f,  { CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_NONE, \
+      CU_AD_FORMAT_NONE, CU_AD_FORMAT_NONE }, {4, 0, 0, 0}, sample_func }
+#define MAKE_FORMAT_RGBP(f,cf,sample_func) \
+  { GST_VIDEO_FORMAT_ ##f,  { CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_ ##cf, \
+      CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_NONE }, {1, 1, 1, 0}, sample_func }
+#define MAKE_FORMAT_RGBAP(f,cf,sample_func) \
+  { GST_VIDEO_FORMAT_ ##f,  { CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_ ##cf, \
+      CU_AD_FORMAT_ ##cf, CU_AD_FORMAT_ ##cf }, {1, 1, 1, 1}, sample_func }
+
+static const TextureFormat format_map[] = {
+  MAKE_FORMAT_YUV_PLANAR (I420, UNSIGNED_INT8, SAMPLE_YUV_PLANAR),
+  MAKE_FORMAT_YUV_PLANAR (YV12, UNSIGNED_INT8, SAMPLE_YV12),
+  MAKE_FORMAT_YUV_SEMI_PLANAR (NV12, UNSIGNED_INT8, SAMPLE_SEMI_PLANAR),
+  MAKE_FORMAT_YUV_SEMI_PLANAR (NV21, UNSIGNED_INT8, SAMPLE_SEMI_PLANAR_SWAP),
+  MAKE_FORMAT_YUV_SEMI_PLANAR (P010_10LE, UNSIGNED_INT16, SAMPLE_SEMI_PLANAR),
+  MAKE_FORMAT_YUV_SEMI_PLANAR (P016_LE, UNSIGNED_INT16, SAMPLE_SEMI_PLANAR),
+  MAKE_FORMAT_YUV_PLANAR (I420_10LE, UNSIGNED_INT16, SAMPLE_YUV_PLANAR_10BIS),
+  MAKE_FORMAT_YUV_PLANAR (Y444, UNSIGNED_INT8, SAMPLE_YUV_PLANAR),
+  MAKE_FORMAT_YUV_PLANAR (Y444_16LE, UNSIGNED_INT16, SAMPLE_YUV_PLANAR),
+  MAKE_FORMAT_RGB (RGBA, UNSIGNED_INT8, SAMPLE_RGBA),
+  MAKE_FORMAT_RGB (BGRA, UNSIGNED_INT8, SAMPLE_BGRA),
+  MAKE_FORMAT_RGB (RGBx, UNSIGNED_INT8, SAMPLE_RGBx),
+  MAKE_FORMAT_RGB (BGRx, UNSIGNED_INT8, SAMPLE_BGRx),
+  MAKE_FORMAT_RGB (ARGB, UNSIGNED_INT8, SAMPLE_ARGB),
+  MAKE_FORMAT_RGB (ARGB64, UNSIGNED_INT16, SAMPLE_ARGB64),
+  MAKE_FORMAT_RGB (ABGR, UNSIGNED_INT8, SAMPLE_AGBR),
+  MAKE_FORMAT_YUV_PLANAR (Y42B, UNSIGNED_INT8, SAMPLE_YUV_PLANAR),
+  MAKE_FORMAT_YUV_PLANAR (I422_10LE, UNSIGNED_INT16, SAMPLE_YUV_PLANAR_10BIS),
+  MAKE_FORMAT_YUV_PLANAR (I422_12LE, UNSIGNED_INT16, SAMPLE_YUV_PLANAR_12BIS),
+  MAKE_FORMAT_RGBP (RGBP, UNSIGNED_INT8, SAMPLE_RGBP),
+  MAKE_FORMAT_RGBP (BGRP, UNSIGNED_INT8, SAMPLE_BGRP),
+  MAKE_FORMAT_RGBP (GBR, UNSIGNED_INT8, SAMPLE_GBR),
+  MAKE_FORMAT_RGBAP (GBRA, UNSIGNED_INT8, SAMPLE_GBRA),
+};
+
+typedef struct _TextureBuffer
+{
+  CUdeviceptr ptr;
+  gsize stride;
+} TextureBuffer;
+
+typedef struct
+{
+  gint x;
+  gint y;
+  gint width;
+  gint height;
+} ConverterRect;
+
+struct _GstCudaConverterPrivate
+{
+  GstVideoInfo in_info;
+  GstVideoInfo out_info;
+
+  GstStructure *config;
+
+  GstVideoInfo texture_info;
+  const TextureFormat *texture_fmt;
+  gint texture_align;
+  ConverterRect dest_rect;
+
+  TextureBuffer fallback_buffer[GST_VIDEO_MAX_COMPONENTS];
+  CUfilter_mode filter_mode[GST_VIDEO_MAX_COMPONENTS];
+  TextureBuffer unpack_buffer;
+
+  CUmodule module;
+  CUfunction main_func;
+  CUfunction unpack_func;
+};
+
+static void gst_cuda_converter_dispose (GObject * object);
+static void gst_cuda_converter_finalize (GObject * object);
+
+#define gst_cuda_converter_parent_class parent_class
+G_DEFINE_TYPE_WITH_PRIVATE (GstCudaConverter, gst_cuda_converter,
+    GST_TYPE_OBJECT);
+
+static void
+gst_cuda_converter_class_init (GstCudaConverterClass * klass)
+{
+  GObjectClass *object_class = G_OBJECT_CLASS (klass);
+
+  object_class->dispose = gst_cuda_converter_dispose;
+  object_class->finalize = gst_cuda_converter_finalize;
+
+  GST_DEBUG_CATEGORY_INIT (gst_cuda_converter_debug,
+      "cudaconverter", 0, "cudaconverter");
+}
+
+static void
+gst_cuda_converter_init (GstCudaConverter * self)
+{
+  GstCudaConverterPrivate *priv;
+
+  self->priv = priv = gst_cuda_converter_get_instance_private (self);
+  priv->config = gst_structure_new_empty ("GstCudaConverter");
+}
+
+static void
+gst_cuda_converter_dispose (GObject * object)
+{
+  GstCudaConverter *self = GST_CUDA_CONVERTER (object);
+  GstCudaConverterPrivate *priv = self->priv;
+  guint i;
+
+  if (self->context && gst_cuda_context_push (self->context)) {
+    if (priv->module) {
+      CuModuleUnload (priv->module);
+      priv->module = NULL;
+    }
+
+    for (i = 0; i < G_N_ELEMENTS (priv->fallback_buffer); i++) {
+      if (priv->fallback_buffer[i].ptr) {
+        CuMemFree (priv->fallback_buffer[i].ptr);
+        priv->fallback_buffer[i].ptr = 0;
+      }
+    }
+
+    if (priv->unpack_buffer.ptr) {
+      CuMemFree (priv->unpack_buffer.ptr);
+      priv->unpack_buffer.ptr = 0;
+    }
+
+    gst_cuda_context_pop (NULL);
+  }
+
+  gst_clear_object (&self->context);
+
+  G_OBJECT_CLASS (parent_class)->dispose (object);
+}
+
+static void
+gst_cuda_converter_finalize (GObject * object)
+{
+  GstCudaConverter *self = GST_CUDA_CONVERTER (object);
+  GstCudaConverterPrivate *priv = self->priv;
+
+  gst_structure_free (priv->config);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static const gchar *
+get_color_range_name (GstVideoColorRange range)
+{
+  switch (range) {
+    case GST_VIDEO_COLOR_RANGE_0_255:
+      return "FULL";
+    case GST_VIDEO_COLOR_RANGE_16_235:
+      return "STUDIO";
+    default:
+      break;
+  }
+
+  return "UNKNOWN";
+}
+
+typedef struct _GstCudaColorMatrixString
+{
+  gchar matrix[3][3][G_ASCII_DTOSTR_BUF_SIZE];
+  gchar offset[3][G_ASCII_DTOSTR_BUF_SIZE];
+  gchar min[3][G_ASCII_DTOSTR_BUF_SIZE];
+  gchar max[3][G_ASCII_DTOSTR_BUF_SIZE];
+} GstCudaColorMatrixString;
+
+static void
+color_matrix_to_string (const GstCudaColorMatrix * m,
+    GstCudaColorMatrixString * str)
+{
+  guint i, j;
+  for (i = 0; i < 3; i++) {
+    for (j = 0; j < 3; j++) {
+      g_ascii_formatd (str->matrix[i][j], G_ASCII_DTOSTR_BUF_SIZE, "%f",
+          m->matrix[i][j]);
+    }
+
+    g_ascii_formatd (str->offset[i],
+        G_ASCII_DTOSTR_BUF_SIZE, "%f", m->offset[i]);
+    g_ascii_formatd (str->min[i], G_ASCII_DTOSTR_BUF_SIZE, "%f", m->min[i]);
+    g_ascii_formatd (str->max[i], G_ASCII_DTOSTR_BUF_SIZE, "%f", m->max[i]);
+  }
+}
+
+static gboolean
+gst_cuda_converter_setup (GstCudaConverter * self)
+{
+  GstCudaConverterPrivate *priv = self->priv;
+  const GstVideoInfo *in_info;
+  const GstVideoInfo *out_info;
+  const GstVideoInfo *texture_info;
+  GstCudaColorMatrix to_rgb_matrix;
+  GstCudaColorMatrix to_yuv_matrix;
+  GstCudaColorMatrix border_color_matrix;
+  GstCudaColorMatrixString to_rgb_matrix_str;
+  GstCudaColorMatrixString to_yuv_matrix_str;
+  gchar border_color_str[4][G_ASCII_DTOSTR_BUF_SIZE];
+  gdouble border_color[4];
+  gchar offset_x[G_ASCII_DTOSTR_BUF_SIZE];
+  gchar offset_y[G_ASCII_DTOSTR_BUF_SIZE];
+  gint i, j;
+  const gchar *unpack_function = NULL;
+  const gchar *write_func = NULL;
+  const gchar *to_rgb_func = COLOR_SPACE_IDENTITY;
+  const gchar *to_yuv_func = COLOR_SPACE_IDENTITY;
+  const GstVideoColorimetry *in_color;
+  const GstVideoColorimetry *out_color;
+  gchar *str;
+  gchar *ptx;
+  CUresult ret;
+
+  in_info = &priv->in_info;
+  out_info = &priv->out_info;
+  texture_info = &priv->texture_info;
+  in_color = &in_info->colorimetry;
+  out_color = &out_info->colorimetry;
+
+  memset (&to_rgb_matrix, 0, sizeof (GstCudaColorMatrix));
+  color_matrix_identity (&to_rgb_matrix);
+
+  memset (&to_yuv_matrix, 0, sizeof (GstCudaColorMatrix));
+  color_matrix_identity (&to_yuv_matrix);
+
+  switch (GST_VIDEO_INFO_FORMAT (out_info)) {
+    case GST_VIDEO_FORMAT_I420:
+      write_func = WRITE_I420;
+      break;
+    case GST_VIDEO_FORMAT_YV12:
+      write_func = WRITE_YV12;
+      break;
+    case GST_VIDEO_FORMAT_NV12:
+      write_func = WRITE_NV12;
+      break;
+    case GST_VIDEO_FORMAT_NV21:
+      write_func = WRITE_NV21;
+      break;
+    case GST_VIDEO_FORMAT_P010_10LE:
+      write_func = WRITE_P010;
+      break;
+    case GST_VIDEO_FORMAT_P016_LE:
+      write_func = WRITE_P016;
+      break;
+    case GST_VIDEO_FORMAT_I420_10LE:
+      write_func = WRITE_I420_10;
+      break;
+    case GST_VIDEO_FORMAT_Y444:
+      write_func = WRITE_Y444;
+      break;
+    case GST_VIDEO_FORMAT_Y444_16LE:
+      write_func = WRITE_Y444_16;
+      break;
+    case GST_VIDEO_FORMAT_RGBA:
+      write_func = WRITE_RGBA;
+      break;
+    case GST_VIDEO_FORMAT_RGBx:
+      write_func = WRITE_RGBx;
+      break;
+    case GST_VIDEO_FORMAT_BGRA:
+      write_func = WRITE_BGRA;
+      break;
+    case GST_VIDEO_FORMAT_BGRx:
+      write_func = WRITE_BGRx;
+      break;
+    case GST_VIDEO_FORMAT_ARGB:
+      write_func = WRITE_ARGB;
+      break;
+    case GST_VIDEO_FORMAT_ABGR:
+      write_func = WRITE_ABGR;
+      break;
+    case GST_VIDEO_FORMAT_RGB:
+      write_func = WRITE_RGB;
+      break;
+    case GST_VIDEO_FORMAT_BGR:
+      write_func = WRITE_BGR;
+      break;
+    case GST_VIDEO_FORMAT_RGB10A2_LE:
+      write_func = WRITE_RGB10A2;
+      break;
+    case GST_VIDEO_FORMAT_BGR10A2_LE:
+      write_func = WRITE_BGR10A2;
+      break;
+    case GST_VIDEO_FORMAT_Y42B:
+      write_func = WRITE_Y42B;
+      break;
+    case GST_VIDEO_FORMAT_I422_10LE:
+      write_func = WRITE_I422_10;
+      break;
+    case GST_VIDEO_FORMAT_I422_12LE:
+      write_func = WRITE_I422_12;
+      break;
+    case GST_VIDEO_FORMAT_RGBP:
+      write_func = WRITE_RGBP;
+      break;
+    case GST_VIDEO_FORMAT_BGRP:
+      write_func = WRITE_BGRP;
+      break;
+    case GST_VIDEO_FORMAT_GBR:
+      write_func = WRITE_GBR;
+      break;
+    case GST_VIDEO_FORMAT_GBRA:
+      write_func = WRITE_GBRA;
+      break;
+    default:
+      break;
+  }
+
+  if (!write_func) {
+    GST_ERROR_OBJECT (self, "Unknown write function for format %s",
+        gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (out_info)));
+    return FALSE;
+  }
+
+  /* Decide texture info to use, 3 channel RGB or 10bits packed RGB
+   * need be converted to other format */
+  priv->texture_info = priv->in_info;
+  switch (GST_VIDEO_INFO_FORMAT (in_info)) {
+    case GST_VIDEO_FORMAT_RGB:
+      gst_video_info_set_format (&priv->texture_info,
+          GST_VIDEO_FORMAT_RGBx, GST_VIDEO_INFO_WIDTH (in_info),
+          GST_VIDEO_INFO_HEIGHT (in_info));
+      unpack_function = RGB_TO_RGBx;
+      break;
+    case GST_VIDEO_FORMAT_BGR:
+      gst_video_info_set_format (&priv->texture_info,
+          GST_VIDEO_FORMAT_BGRx, GST_VIDEO_INFO_WIDTH (in_info),
+          GST_VIDEO_INFO_HEIGHT (in_info));
+      unpack_function = RGB_TO_RGBx;
+      break;
+    case GST_VIDEO_FORMAT_RGB10A2_LE:
+      gst_video_info_set_format (&priv->texture_info,
+          GST_VIDEO_FORMAT_ARGB64, GST_VIDEO_INFO_WIDTH (in_info),
+          GST_VIDEO_INFO_HEIGHT (in_info));
+      unpack_function = RGB10A2_TO_ARGB64;
+      break;
+    case GST_VIDEO_FORMAT_BGR10A2_LE:
+      gst_video_info_set_format (&priv->texture_info,
+          GST_VIDEO_FORMAT_ARGB64, GST_VIDEO_INFO_WIDTH (in_info),
+          GST_VIDEO_INFO_HEIGHT (in_info));
+      unpack_function = BGR10A2_TO_ARGB64;
+      break;
+    default:
+      break;
+  }
+
+  for (i = 0; i < G_N_ELEMENTS (format_map); i++) {
+    if (format_map[i].format == GST_VIDEO_INFO_FORMAT (texture_info)) {
+      priv->texture_fmt = &format_map[i];
+      break;
+    }
+  }
+
+  if (!priv->texture_fmt) {
+    GST_ERROR_OBJECT (self, "Couldn't find texture format for %s (%s)",
+        gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (in_info)),
+        gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (texture_info)));
+    return FALSE;
+  }
+
+  /* calculate black color
+   * TODO: add support border color */
+  if (GST_VIDEO_INFO_IS_RGB (out_info)) {
+    GstVideoInfo rgb_info = *out_info;
+    rgb_info.colorimetry.range = GST_VIDEO_COLOR_RANGE_0_255;
+    gst_cuda_color_range_adjust_matrix_unorm (&rgb_info, out_info,
+        &border_color_matrix);
+  } else {
+    GstVideoInfo rgb_info;
+
+    gst_video_info_set_format (&rgb_info, GST_VIDEO_FORMAT_RGBA64_LE,
+        out_info->width, out_info->height);
+
+    gst_cuda_rgb_to_yuv_matrix_unorm (&rgb_info,
+        out_info, &border_color_matrix);
+  }
+
+  for (i = 0; i < 3; i++) {
+    /* TODO: property */
+    gdouble border_rgba[4] = { 0, 0, 0 };
+    border_color[i] = 0;
+    for (j = 0; j < 3; j++)
+      border_color[i] += border_color_matrix.matrix[i][j] * border_rgba[i];
+    border_color[i] = border_color_matrix.offset[i];
+    border_color[i] = CLAMP (border_color[i],
+        border_color_matrix.min[i], border_color_matrix.max[i]);
+
+    g_ascii_formatd (border_color_str[i],
+        G_ASCII_DTOSTR_BUF_SIZE, "%f", border_color[i]);
+  }
+  g_ascii_formatd (border_color_str[3], G_ASCII_DTOSTR_BUF_SIZE, "%f", 1);
+
+  /* FIXME: handle primaries and transfer functions */
+  if (GST_VIDEO_INFO_IS_RGB (texture_info)) {
+    if (GST_VIDEO_INFO_IS_RGB (out_info)) {
+      /* RGB -> RGB */
+      if (in_color->range == out_color->range) {
+        GST_DEBUG_OBJECT (self, "RGB -> RGB conversion without matrix");
+      } else {
+        if (!gst_cuda_color_range_adjust_matrix_unorm (in_info, out_info,
+                &to_rgb_matrix)) {
+          GST_ERROR_OBJECT (self, "Failed to get RGB range adjust matrix");
+          return FALSE;
+        }
+
+        str = gst_cuda_dump_color_matrix (&to_rgb_matrix);
+        GST_DEBUG_OBJECT (self, "RGB range adjust %s -> %s\n%s",
+            get_color_range_name (in_color->range),
+            get_color_range_name (out_color->range), str);
+        g_free (str);
+
+        to_rgb_func = COLOR_SPACE_CONVERT;
+      }
+    } else {
+      /* RGB -> YUV */
+      if (!gst_cuda_rgb_to_yuv_matrix_unorm (in_info, out_info, &to_yuv_matrix)) {
+        GST_ERROR_OBJECT (self, "Failed to get RGB -> YUV transform matrix");
+        return FALSE;
+      }
+
+      str = gst_cuda_dump_color_matrix (&to_yuv_matrix);
+      GST_DEBUG_OBJECT (self, "RGB -> YUV matrix:\n%s", str);
+      g_free (str);
+
+      to_yuv_func = COLOR_SPACE_CONVERT;
+    }
+  } else {
+    if (GST_VIDEO_INFO_IS_RGB (out_info)) {
+      /* YUV -> RGB */
+      if (!gst_cuda_yuv_to_rgb_matrix_unorm (in_info, out_info, &to_rgb_matrix)) {
+        GST_ERROR_OBJECT (self, "Failed to get YUV -> RGB transform matrix");
+        return FALSE;
+      }
+
+      str = gst_cuda_dump_color_matrix (&to_rgb_matrix);
+      GST_DEBUG_OBJECT (self, "YUV -> RGB matrix:\n%s", str);
+      g_free (str);
+
+      to_rgb_func = COLOR_SPACE_CONVERT;
+    } else {
+      /* YUV -> YUV */
+      if (in_color->range == out_color->range) {
+        GST_DEBUG_OBJECT (self, "YUV -> YU conversion without matrix");
+      } else {
+        if (!gst_cuda_color_range_adjust_matrix_unorm (in_info, out_info,
+                &to_yuv_matrix)) {
+          GST_ERROR_OBJECT (self, "Failed to get GRAY range adjust matrix");
+          return FALSE;
+        }
+
+        str = gst_cuda_dump_color_matrix (&to_yuv_matrix);
+        GST_DEBUG_OBJECT (self, "YUV range adjust matrix:\n%s", str);
+        g_free (str);
+
+        to_yuv_func = COLOR_SPACE_CONVERT;
+      }
+    }
+  }
+
+  color_matrix_to_string (&to_rgb_matrix, &to_rgb_matrix_str);
+  color_matrix_to_string (&to_yuv_matrix, &to_yuv_matrix_str);
+
+  /* half pixel offset, to sample texture at center of the pixel position */
+  g_ascii_formatd (offset_x, G_ASCII_DTOSTR_BUF_SIZE, "%f",
+      (gdouble) 0.5 / priv->dest_rect.width);
+  g_ascii_formatd (offset_y, G_ASCII_DTOSTR_BUF_SIZE, "%f",
+      (gdouble) 0.5 / priv->dest_rect.height);
+
+  str = g_strdup_printf (TEMPLETA_KERNEL, KERNEL_COMMON,
+      unpack_function ? unpack_function : "",
+      /* TO RGB matrix */
+      to_rgb_matrix_str.matrix[0][0],
+      to_rgb_matrix_str.matrix[0][1],
+      to_rgb_matrix_str.matrix[0][2],
+      to_rgb_matrix_str.matrix[1][0],
+      to_rgb_matrix_str.matrix[1][1],
+      to_rgb_matrix_str.matrix[1][2],
+      to_rgb_matrix_str.matrix[2][0],
+      to_rgb_matrix_str.matrix[2][1],
+      to_rgb_matrix_str.matrix[2][2],
+      to_rgb_matrix_str.offset[0],
+      to_rgb_matrix_str.offset[1],
+      to_rgb_matrix_str.offset[2],
+      to_rgb_matrix_str.min[0],
+      to_rgb_matrix_str.min[1],
+      to_rgb_matrix_str.min[2],
+      to_rgb_matrix_str.max[0],
+      to_rgb_matrix_str.max[1], to_rgb_matrix_str.max[2],
+      /* TO YUV matrix */
+      to_yuv_matrix_str.matrix[0][0],
+      to_yuv_matrix_str.matrix[0][1],
+      to_yuv_matrix_str.matrix[0][2],
+      to_yuv_matrix_str.matrix[1][0],
+      to_yuv_matrix_str.matrix[1][1],
+      to_yuv_matrix_str.matrix[1][2],
+      to_yuv_matrix_str.matrix[2][0],
+      to_yuv_matrix_str.matrix[2][1],
+      to_yuv_matrix_str.matrix[2][2],
+      to_yuv_matrix_str.offset[0],
+      to_yuv_matrix_str.offset[1],
+      to_yuv_matrix_str.offset[2],
+      to_yuv_matrix_str.min[0],
+      to_yuv_matrix_str.min[1],
+      to_yuv_matrix_str.min[2],
+      to_yuv_matrix_str.max[0],
+      to_yuv_matrix_str.max[1], to_yuv_matrix_str.max[2],
+      /* width/height */
+      GST_VIDEO_INFO_WIDTH (out_info), GST_VIDEO_INFO_HEIGHT (out_info),
+      /* viewport */
+      priv->dest_rect.x, priv->dest_rect.y,
+      priv->dest_rect.x + priv->dest_rect.width,
+      priv->dest_rect.y + priv->dest_rect.height,
+      priv->dest_rect.width, priv->dest_rect.height,
+      /* half pixel offsets */
+      offset_x, offset_y,
+      /* border colors */
+      border_color_str[0], border_color_str[1],
+      border_color_str[2], border_color_str[3],
+      /* sampler function name */
+      priv->texture_fmt->sample_func,
+      /* TO RGB conversion function name */
+      to_rgb_func,
+      /* TO YUV conversion function name */
+      to_yuv_func,
+      /* write function name */
+      write_func);
+
+  GST_LOG_OBJECT (self, "kernel code:\n%s\n", str);
+  ptx = gst_cuda_nvrtc_compile (str);
+  g_free (str);
+
+  if (!ptx) {
+    GST_ERROR_OBJECT (self, "Could not compile code");
+    return FALSE;
+  }
+
+  if (!gst_cuda_context_push (self->context)) {
+    GST_ERROR_OBJECT (self, "Couldn't push context");
+    return FALSE;
+  }
+
+  /* Allocates intermediate memory for texture */
+  if (unpack_function) {
+    ret = CuMemAllocPitch (&priv->unpack_buffer.ptr,
+        &priv->unpack_buffer.stride,
+        GST_VIDEO_INFO_COMP_WIDTH (texture_info, 0) *
+        GST_VIDEO_INFO_COMP_PSTRIDE (texture_info, 0),
+        GST_VIDEO_INFO_HEIGHT (texture_info), 16);
+    if (!gst_cuda_result (ret)) {
+      GST_ERROR_OBJECT (self, "Couldn't allocate unpack buffer");
+      goto error;
+    }
+  }
+
+  ret = CuModuleLoadData (&priv->module, ptx);
+  g_free (ptx);
+  if (!gst_cuda_result (ret)) {
+    GST_ERROR_OBJECT (self, "Could not load module");
+    priv->module = NULL;
+    goto error;
+  }
+
+  ret = CuModuleGetFunction (&priv->main_func,
+      priv->module, GST_CUDA_KERNEL_MAIN_FUNC);
+  if (!gst_cuda_result (ret)) {
+    GST_ERROR_OBJECT (self, "Could not get main function");
+    goto error;
+  }
+
+  if (unpack_function) {
+    ret = CuModuleGetFunction (&priv->unpack_func,
+        priv->module, GST_CUDA_KERNEL_UNPACK_FUNC);
+    if (!gst_cuda_result (ret)) {
+      GST_ERROR_OBJECT (self, "Could not get unpack function");
+      goto error;
+    }
+  }
+
+  gst_cuda_context_pop (NULL);
+
+  if (priv->dest_rect.x != 0 || priv->dest_rect.y != 0 ||
+      priv->dest_rect.width != out_info->width ||
+      priv->dest_rect.height != out_info->height ||
+      in_info->width != out_info->width
+      || in_info->height != out_info->height) {
+    for (i = 0; i < G_N_ELEMENTS (priv->filter_mode); i++)
+      priv->filter_mode[i] = CU_TR_FILTER_MODE_LINEAR;
+  } else {
+    for (i = 0; i < G_N_ELEMENTS (priv->filter_mode); i++)
+      priv->filter_mode[i] = CU_TR_FILTER_MODE_POINT;
+  }
+
+  return TRUE;
+
+error:
+  gst_cuda_context_pop (NULL);
+  return FALSE;
+}
+
+static gboolean
+copy_config (GQuark field_id, const GValue * value, gpointer user_data)
+{
+  GstCudaConverter *self = (GstCudaConverter *) user_data;
+
+  gst_structure_id_set_value (self->priv->config, field_id, value);
+
+  return TRUE;
+}
+
+static void
+gst_cuda_converter_set_config (GstCudaConverter * self, GstStructure * config)
+{
+  gst_structure_foreach (config, copy_config, self);
+  gst_structure_free (config);
+}
+
+static gint
+get_opt_int (GstCudaConverter * self, const gchar * opt, gint def)
+{
+  gint res;
+  if (!gst_structure_get_int (self->priv->config, opt, &res))
+    res = def;
+  return res;
+}
+
+GstCudaConverter *
+gst_cuda_converter_new (const GstVideoInfo * in_info,
+    const GstVideoInfo * out_info, GstCudaContext * context,
+    GstStructure * config)
+{
+  GstCudaConverter *self;
+  GstCudaConverterPrivate *priv;
+
+  g_return_val_if_fail (in_info != NULL, NULL);
+  g_return_val_if_fail (out_info != NULL, NULL);
+  g_return_val_if_fail (GST_IS_CUDA_CONTEXT (context), NULL);
+
+  self = g_object_new (GST_TYPE_CUDA_CONVERTER, NULL);
+
+  if (!GST_IS_CUDA_CONTEXT (context)) {
+    GST_WARNING_OBJECT (self, "Not a valid cuda context object");
+    goto error;
+  }
+
+  self->context = gst_object_ref (context);
+  priv = self->priv;
+  priv->in_info = *in_info;
+  priv->out_info = *out_info;
+
+  if (config)
+    gst_cuda_converter_set_config (self, config);
+
+  priv->dest_rect.x = get_opt_int (self, GST_CUDA_CONVERTER_OPT_DEST_X, 0);
+  priv->dest_rect.y = get_opt_int (self, GST_CUDA_CONVERTER_OPT_DEST_Y, 0);
+  priv->dest_rect.width = get_opt_int (self,
+      GST_CUDA_CONVERTER_OPT_DEST_WIDTH, out_info->width);
+  priv->dest_rect.height = get_opt_int (self,
+      GST_CUDA_CONVERTER_OPT_DEST_HEIGHT, out_info->height);
+
+  if (!gst_cuda_converter_setup (self))
+    goto error;
+
+  priv->texture_align = gst_cuda_context_get_texture_alignment (context);
+
+  gst_object_ref_sink (self);
+  return self;
+
+error:
+  gst_object_unref (self);
+  return NULL;
+}
+
+
+static CUtexObject
+gst_cuda_converter_create_texture_unchecked (GstCudaConverter * self,
+    CUdeviceptr src, gint width, gint height, CUarray_format format,
+    guint channels, gint stride, gint plane, CUfilter_mode mode)
+{
+  CUDA_TEXTURE_DESC texture_desc;
+  CUDA_RESOURCE_DESC resource_desc;
+  CUtexObject texture = 0;
+  CUresult cuda_ret;
+
+  memset (&texture_desc, 0, sizeof (CUDA_TEXTURE_DESC));
+  memset (&resource_desc, 0, sizeof (CUDA_RESOURCE_DESC));
+
+  resource_desc.resType = CU_RESOURCE_TYPE_PITCH2D;
+  resource_desc.res.pitch2D.format = format;
+  resource_desc.res.pitch2D.numChannels = channels;
+  resource_desc.res.pitch2D.width = width;
+  resource_desc.res.pitch2D.height = height;
+  resource_desc.res.pitch2D.pitchInBytes = stride;
+  resource_desc.res.pitch2D.devPtr = src;
+
+  texture_desc.filterMode = mode;
+  /* Will read texture value as a normalized [0, 1] float value
+   * with [0, 1) coordinates */
+  /* CU_TRSF_NORMALIZED_COORDINATES */
+  texture_desc.flags = 0x2;
+  /* CU_TR_ADDRESS_MODE_CLAMP */
+  texture_desc.addressMode[0] = 1;
+  texture_desc.addressMode[1] = 1;
+  texture_desc.addressMode[2] = 1;
+
+  cuda_ret = CuTexObjectCreate (&texture, &resource_desc, &texture_desc, NULL);
+
+  if (!gst_cuda_result (cuda_ret)) {
+    GST_ERROR_OBJECT (self, "Could not create texture");
+    return 0;
+  }
+
+  return texture;
+}
+
+static gboolean
+ensure_fallback_buffer (GstCudaConverter * self, gint width_in_bytes,
+    gint height, guint plane)
+{
+  GstCudaConverterPrivate *priv = self->priv;
+  CUresult ret;
+
+  if (priv->fallback_buffer[plane].ptr)
+    return TRUE;
+
+  ret = CuMemAllocPitch (&priv->fallback_buffer[plane].ptr,
+      &priv->fallback_buffer[plane].stride, width_in_bytes, height, 16);
+
+  if (!gst_cuda_result (ret)) {
+    GST_ERROR_OBJECT (self, "Couldn't allocate fallback buffer");
+    return FALSE;
+  }
+
+  return TRUE;
+}
+
+static CUtexObject
+gst_cuda_converter_create_texture (GstCudaConverter * self,
+    CUdeviceptr src, gint width, gint height, gint stride, CUfilter_mode mode,
+    CUarray_format format, guint channles, gint plane, CUstream stream)
+{
+  GstCudaConverterPrivate *priv = self->priv;
+  CUresult ret;
+  CUdeviceptr src_ptr;
+
+  src_ptr = src;
+
+  if (priv->texture_align > 0 && (src_ptr % priv->texture_align) != 0) {
+    CUDA_MEMCPY2D params = { 0, };
+
+    GST_DEBUG_OBJECT (self, "Plane %d is not aligned, copying", plane);
+
+    if (!ensure_fallback_buffer (self, stride, height, plane))
+      return 0;
+
+    params.srcMemoryType = CU_MEMORYTYPE_DEVICE;
+    params.srcPitch = stride;
+    params.srcDevice = (CUdeviceptr) src_ptr;
+
+    params.dstMemoryType = CU_MEMORYTYPE_DEVICE;
+    params.dstPitch = priv->fallback_buffer[plane].stride;
+    params.dstDevice = priv->fallback_buffer[plane].ptr;
+    params.WidthInBytes = GST_VIDEO_INFO_COMP_WIDTH (&priv->in_info, plane)
+        * GST_VIDEO_INFO_COMP_PSTRIDE (&priv->in_info, plane),
+        params.Height = GST_VIDEO_INFO_COMP_HEIGHT (&priv->in_info, plane);
+
+    ret = CuMemcpy2D (&params);
+    if (!gst_cuda_result (ret)) {
+      GST_ERROR_OBJECT (self, "Couldn't copy to fallback buffer");
+      return 0;
+    }
+
+    src_ptr = priv->fallback_buffer[plane].ptr;
+    stride = priv->fallback_buffer[plane].stride;
+  }
+
+  return gst_cuda_converter_create_texture_unchecked (self,
+      src_ptr, width, height, format, channles, stride, plane, mode);
+}
+
+static gboolean
+gst_cuda_converter_unpack_rgb (GstCudaConverter * self,
+    GstVideoFrame * src_frame, CUstream stream)
+{
+  GstCudaConverterPrivate *priv = self->priv;
+  CUdeviceptr src;
+  gint width, height, src_stride, dst_stride;
+  CUresult ret;
+  gpointer args[] = { &src, &priv->unpack_buffer.ptr,
+    &width, &height, &src_stride, &dst_stride
+  };
+
+  g_assert (priv->unpack_buffer.ptr);
+  g_assert (priv->unpack_buffer.stride > 0);
+
+  src = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (src_frame, 0);
+  width = GST_VIDEO_FRAME_WIDTH (src_frame);
+  height = GST_VIDEO_FRAME_HEIGHT (src_frame);
+  src_stride = GST_VIDEO_FRAME_PLANE_STRIDE (src_frame, 0);
+  dst_stride = (gint) priv->unpack_buffer.stride;
+
+  ret = CuLaunchKernel (priv->unpack_func, DIV_UP (width, CUDA_BLOCK_X),
+      DIV_UP (height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
+      stream, args, NULL);
+
+  if (!gst_cuda_result (ret)) {
+    GST_ERROR_OBJECT (self, "Couldn't unpack source RGB");
+    return FALSE;
+  }
+
+  return TRUE;
+}
+
+gboolean
+gst_cuda_converter_convert_frame (GstCudaConverter * converter,
+    GstVideoFrame * src_frame, GstVideoFrame * dst_frame, CUstream stream)
+{
+  GstCudaConverterPrivate *priv;
+  const TextureFormat *format;
+  CUtexObject texture[GST_VIDEO_MAX_COMPONENTS] = { 0, };
+  guint8 *dst[GST_VIDEO_MAX_COMPONENTS] = { NULL, };
+  gint stride[2] = { 0, };
+  gint i;
+  gboolean ret = FALSE;
+  CUresult cuda_ret;
+  gint width, height;
+  gpointer args[] = { &texture[0], &texture[1], &texture[2], &texture[3],
+    &dst[0], &dst[1], &dst[2], &dst[3], &stride[0], &stride[1]
+  };
+
+  g_return_val_if_fail (GST_IS_CUDA_CONVERTER (converter), FALSE);
+  g_return_val_if_fail (src_frame != NULL, FALSE);
+  g_return_val_if_fail (dst_frame != NULL, FALSE);
+
+  priv = converter->priv;
+  format = priv->texture_fmt;
+
+  g_assert (format);
+
+  if (!gst_cuda_context_push (converter->context)) {
+    GST_ERROR_OBJECT (converter, "Couldn't push context");
+    return FALSE;
+  }
+
+  if (priv->unpack_func) {
+    if (!gst_cuda_converter_unpack_rgb (converter, src_frame, stream))
+      goto out;
+
+    texture[0] = gst_cuda_converter_create_texture_unchecked (converter,
+        priv->unpack_buffer.ptr, priv->in_info.width, priv->in_info.height,
+        format->array_format[0], 4, priv->unpack_buffer.stride, 0,
+        priv->filter_mode[0]);
+    if (!texture[0]) {
+      GST_ERROR_OBJECT (converter, "Couldn't create texture");
+      goto out;
+    }
+  } else {
+    for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (src_frame); i++) {
+      CUdeviceptr src;
+
+      src = (CUdeviceptr) GST_VIDEO_FRAME_PLANE_DATA (src_frame, i);
+      texture[i] = gst_cuda_converter_create_texture (converter,
+          src, GST_VIDEO_FRAME_COMP_WIDTH (src_frame, i),
+          GST_VIDEO_FRAME_COMP_HEIGHT (src_frame, i),
+          GST_VIDEO_FRAME_PLANE_STRIDE (src_frame, i),
+          priv->filter_mode[i], format->array_format[i], format->channels[i], i,
+          stream);
+      if (!texture[i]) {
+        GST_ERROR_OBJECT (converter, "Couldn't create texture %d", i);
+        goto out;
+      }
+    }
+  }
+
+  width = GST_VIDEO_FRAME_WIDTH (dst_frame);
+  height = GST_VIDEO_FRAME_HEIGHT (dst_frame);
+
+  for (i = 0; i < GST_VIDEO_FRAME_N_PLANES (dst_frame); i++)
+    dst[i] = GST_VIDEO_FRAME_PLANE_DATA (dst_frame, i);
+
+  stride[0] = stride[1] = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 0);
+  if (GST_VIDEO_FRAME_N_PLANES (dst_frame) > 1)
+    stride[1] = GST_VIDEO_FRAME_PLANE_STRIDE (dst_frame, 1);
+
+  cuda_ret = CuLaunchKernel (priv->main_func, DIV_UP (width, CUDA_BLOCK_X),
+      DIV_UP (height, CUDA_BLOCK_Y), 1, CUDA_BLOCK_X, CUDA_BLOCK_Y, 1, 0,
+      stream, args, NULL);
+
+  if (!gst_cuda_result (cuda_ret)) {
+    GST_ERROR_OBJECT (converter, "Couldn't convert frame");
+    goto out;
+  }
+
+  CuStreamSynchronize (stream);
+
+  ret = TRUE;
+
+out:
+  for (i = 0; i < G_N_ELEMENTS (texture); i++) {
+    if (texture[i])
+      CuTexObjectDestroy (texture[i]);
+    else
+      break;
+  }
+
+  gst_cuda_context_pop (NULL);
+  return ret;
+}
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconverter.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconverter.h
new file mode 100644
index 0000000000..d7b009a545
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconverter.h
@@ -0,0 +1,99 @@
+/* GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#pragma once
+
+#include <gst/video/video.h>
+#include <gst/cuda/gstcudacontext.h>
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_CUDA_CONVERTER             (gst_cuda_converter_get_type())
+#define GST_CUDA_CONVERTER(obj)             (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_CUDA_CONVERTER,GstCudaConverter))
+#define GST_CUDA_CONVERTER_CLASS(klass)     (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_CUDA_CONVERTER,GstCudaConverterClass))
+#define GST_CUDA_CONVERTER_GET_CLASS(obj)   (GST_CUDA_CONVERTER_CLASS(G_OBJECT_GET_CLASS(obj)))
+#define GST_IS_CUDA_CONVERTER(obj)          (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_CUDA_CONVERTER))
+#define GST_IS_CUDA_CONVERTER_CLASS(klass)  (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_CUDA_CONVERTER))
+#define GST_CUDA_CONVERTER_CAST(obj)        ((GstCudaConverter*)(obj))
+
+typedef struct _GstCudaConverter GstCudaConverter;
+typedef struct _GstCudaConverterClass GstCudaConverterClass;
+typedef struct _GstCudaConverterPrivate GstCudaConverterPrivate;
+
+/**
+ * GST_CUDA_CONVERTER_OPT_DEST_X:
+ *
+ * #G_TYPE_INT, x position in the destination frame, default 0
+ */
+#define GST_CUDA_CONVERTER_OPT_DEST_X   "GstCudaConverter.dest-x"
+
+/**
+ * GST_CUDA_CONVERTER_OPT_DEST_Y:
+ *
+ * #G_TYPE_INT, y position in the destination frame, default 0
+ */
+#define GST_CUDA_CONVERTER_OPT_DEST_Y   "GstCudaConverter.dest-y"
+
+/**
+ * GST_CUDA_CONVERTER_OPT_DEST_WIDTH:
+ *
+ * #G_TYPE_INT, width in the destination frame, default destination width
+ */
+#define GST_CUDA_CONVERTER_OPT_DEST_WIDTH   "GstCudaConverter.dest-width"
+
+/**
+ * GST_CUDA_CONVERTER_OPT_DEST_HEIGHT:
+ *
+ * #G_TYPE_INT, height in the destination frame, default destination height
+ */
+#define GST_CUDA_CONVERTER_OPT_DEST_HEIGHT   "GstCudaConverter.dest-height"
+
+struct _GstCudaConverter
+{
+  GstObject parent;
+
+  GstCudaContext *context;
+
+  /*< private >*/
+  GstCudaConverterPrivate *priv;
+  gpointer _gst_reserved[GST_PADDING];
+};
+
+struct _GstCudaConverterClass
+{
+  GstObjectClass parent_class;
+
+  /*< private >*/
+  gpointer _gst_reserved[GST_PADDING];
+};
+
+GType gst_cuda_converter_get_type (void);
+
+GstCudaConverter *  gst_cuda_converter_new (const GstVideoInfo * in_info,
+                                            const GstVideoInfo * out_info,
+                                            GstCudaContext * context,
+                                            GstStructure * config);
+
+gboolean            gst_cuda_converter_convert_frame (GstCudaConverter * converter,
+                                                      GstVideoFrame * src_frame,
+                                                      GstVideoFrame * dst_frame,
+                                                      CUstream cuda_stream);
+
+G_END_DECLS
+
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvertscale.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvertscale.c
new file mode 100644
index 0000000000..93f54e314f
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvertscale.c
@@ -0,0 +1,1747 @@
+/* GStreamer
+ * Copyright (C) 2020 Thibault Saunier <tsaunier@igalia.com>
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include <gst/cuda/gstcudautils.h>
+#include "gstcudaconvertscale.h"
+#include "gstcudaconverter.h"
+
+GST_DEBUG_CATEGORY_STATIC (gst_cuda_base_convert_debug);
+#define GST_CAT_DEFAULT gst_cuda_base_convert_debug
+
+#define GST_CUDA_CONVET_FORMATS \
+    "{ I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, " \
+    "BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, " \
+    "Y42B, I422_10LE, I422_12LE, RGBP, BGRP, GBR, GBRA }"
+
+static GstStaticPadTemplate sink_template = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE_WITH_FEATURES
+        (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY, GST_CUDA_CONVET_FORMATS))
+    );
+
+static GstStaticPadTemplate src_template = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE_WITH_FEATURES
+        (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY, GST_CUDA_CONVET_FORMATS))
+    );
+
+#define DEFAULT_ADD_BORDERS TRUE
+
+struct _GstCudaBaseConvert
+{
+  GstCudaBaseTransform parent;
+
+  GstCudaConverter *converter;
+
+  gint borders_h;
+  gint borders_w;
+  gboolean add_borders;
+};
+
+static void gst_cuda_base_convert_dispose (GObject * object);
+static GstCaps *gst_cuda_base_convert_transform_caps (GstBaseTransform * trans,
+    GstPadDirection direction, GstCaps * caps, GstCaps * filter);
+static GstCaps *gst_cuda_base_convert_fixate_caps (GstBaseTransform * trans,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps);
+static gboolean
+gst_cuda_base_convert_propose_allocation (GstBaseTransform * trans,
+    GstQuery * decide_query, GstQuery * query);
+static gboolean gst_cuda_base_convert_decide_allocation (GstBaseTransform *
+    trans, GstQuery * query);
+static gboolean gst_cuda_base_convert_filter_meta (GstBaseTransform * trans,
+    GstQuery * query, GType api, const GstStructure * params);
+static GstFlowReturn gst_cuda_base_convert_transform (GstBaseTransform * trans,
+    GstBuffer * inbuf, GstBuffer * outbuf);
+static gboolean gst_cuda_base_convert_set_info (GstCudaBaseTransform * btrans,
+    GstCaps * incaps, GstVideoInfo * in_info, GstCaps * outcaps,
+    GstVideoInfo * out_info);
+
+/**
+ * GstCudaBaseConvert:
+ *
+ * A baseclass implementation for cuda convert elements
+ *
+ * Since: 1.22
+ */
+#define gst_cuda_base_convert_parent_class parent_class
+G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstCudaBaseConvert,
+    gst_cuda_base_convert, GST_TYPE_CUDA_BASE_TRANSFORM,
+    GST_DEBUG_CATEGORY_INIT (gst_cuda_base_convert_debug,
+        "cudaconvertscale", 0, "CUDA Base Filter"));
+
+static void
+gst_cuda_base_convert_class_init (GstCudaBaseConvertClass * klass)
+{
+  GObjectClass *gobject_class = G_OBJECT_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+  GstBaseTransformClass *trans_class = GST_BASE_TRANSFORM_CLASS (klass);
+  GstCudaBaseTransformClass *btrans_class =
+      GST_CUDA_BASE_TRANSFORM_CLASS (klass);
+
+  gobject_class->dispose = gst_cuda_base_convert_dispose;
+
+  gst_element_class_add_static_pad_template (element_class, &sink_template);
+  gst_element_class_add_static_pad_template (element_class, &src_template);
+
+  trans_class->passthrough_on_same_caps = TRUE;
+
+  trans_class->transform_caps =
+      GST_DEBUG_FUNCPTR (gst_cuda_base_convert_transform_caps);
+  trans_class->fixate_caps =
+      GST_DEBUG_FUNCPTR (gst_cuda_base_convert_fixate_caps);
+  trans_class->propose_allocation =
+      GST_DEBUG_FUNCPTR (gst_cuda_base_convert_propose_allocation);
+  trans_class->decide_allocation =
+      GST_DEBUG_FUNCPTR (gst_cuda_base_convert_decide_allocation);
+  trans_class->filter_meta =
+      GST_DEBUG_FUNCPTR (gst_cuda_base_convert_filter_meta);
+  trans_class->transform = GST_DEBUG_FUNCPTR (gst_cuda_base_convert_transform);
+
+  btrans_class->set_info = GST_DEBUG_FUNCPTR (gst_cuda_base_convert_set_info);
+
+  gst_type_mark_as_plugin_api (GST_TYPE_CUDA_BASE_CONVERT, 0);
+}
+
+static void
+gst_cuda_base_convert_init (GstCudaBaseConvert * self)
+{
+  self->add_borders = DEFAULT_ADD_BORDERS;
+}
+
+static void
+gst_cuda_base_convert_dispose (GObject * object)
+{
+  GstCudaBaseConvert *self = GST_CUDA_BASE_CONVERT (object);
+
+  gst_clear_object (&self->converter);
+
+  G_OBJECT_CLASS (parent_class)->dispose (object);
+}
+
+static GstCaps *
+gst_cuda_base_convert_caps_remove_format_info (GstCaps * caps)
+{
+  GstStructure *st;
+  GstCapsFeatures *f;
+  gint i, n;
+  GstCaps *res;
+  GstCapsFeatures *feature =
+      gst_caps_features_from_string (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY);
+
+  res = gst_caps_new_empty ();
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    st = gst_caps_get_structure (caps, i);
+    f = gst_caps_get_features (caps, i);
+
+    /* If this is already expressed by the existing caps
+     * skip this structure */
+    if (i > 0 && gst_caps_is_subset_structure_full (res, st, f))
+      continue;
+
+    st = gst_structure_copy (st);
+    /* Only remove format info for the cases when we can actually convert */
+    if (!gst_caps_features_is_any (f)
+        && gst_caps_features_is_equal (f, feature)) {
+      gst_structure_remove_fields (st, "format", "colorimetry", "chroma-site",
+          NULL);
+    }
+
+    gst_caps_append_structure_full (res, st, gst_caps_features_copy (f));
+  }
+  gst_caps_features_free (feature);
+
+  return res;
+}
+
+static GstCaps *
+gst_cuda_base_convert_caps_rangify_size_info (GstCaps * caps)
+{
+  GstStructure *st;
+  GstCapsFeatures *f;
+  gint i, n;
+  GstCaps *res;
+  GstCapsFeatures *feature =
+      gst_caps_features_from_string (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY);
+
+  res = gst_caps_new_empty ();
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    st = gst_caps_get_structure (caps, i);
+    f = gst_caps_get_features (caps, i);
+
+    /* If this is already expressed by the existing caps
+     * skip this structure */
+    if (i > 0 && gst_caps_is_subset_structure_full (res, st, f))
+      continue;
+
+    st = gst_structure_copy (st);
+    /* Only remove format info for the cases when we can actually convert */
+    if (!gst_caps_features_is_any (f)
+        && gst_caps_features_is_equal (f, feature)) {
+      gst_structure_set (st, "width", GST_TYPE_INT_RANGE, 1, G_MAXINT,
+          "height", GST_TYPE_INT_RANGE, 1, G_MAXINT, NULL);
+
+      /* if pixel aspect ratio, make a range of it */
+      if (gst_structure_has_field (st, "pixel-aspect-ratio")) {
+        gst_structure_set (st, "pixel-aspect-ratio",
+            GST_TYPE_FRACTION_RANGE, 1, G_MAXINT, G_MAXINT, 1, NULL);
+      }
+    }
+
+    gst_caps_append_structure_full (res, st, gst_caps_features_copy (f));
+  }
+  gst_caps_features_free (feature);
+
+  return res;
+}
+
+static GstCaps *
+gst_cuda_base_convert_caps_remove_format_and_rangify_size_info (GstCaps * caps)
+{
+  GstStructure *st;
+  GstCapsFeatures *f;
+  gint i, n;
+  GstCaps *res;
+  GstCapsFeatures *feature =
+      gst_caps_features_from_string (GST_CAPS_FEATURE_MEMORY_CUDA_MEMORY);
+
+  res = gst_caps_new_empty ();
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    st = gst_caps_get_structure (caps, i);
+    f = gst_caps_get_features (caps, i);
+
+    /* If this is already expressed by the existing caps
+     * skip this structure */
+    if (i > 0 && gst_caps_is_subset_structure_full (res, st, f))
+      continue;
+
+    st = gst_structure_copy (st);
+    /* Only remove format info for the cases when we can actually convert */
+    if (!gst_caps_features_is_any (f)
+        && gst_caps_features_is_equal (f, feature)) {
+      gst_structure_set (st, "width", GST_TYPE_INT_RANGE, 1, G_MAXINT,
+          "height", GST_TYPE_INT_RANGE, 1, G_MAXINT, NULL);
+      /* if pixel aspect ratio, make a range of it */
+      if (gst_structure_has_field (st, "pixel-aspect-ratio")) {
+        gst_structure_set (st, "pixel-aspect-ratio",
+            GST_TYPE_FRACTION_RANGE, 1, G_MAXINT, G_MAXINT, 1, NULL);
+      }
+      gst_structure_remove_fields (st, "format", "colorimetry", "chroma-site",
+          NULL);
+    }
+
+    gst_caps_append_structure_full (res, st, gst_caps_features_copy (f));
+  }
+  gst_caps_features_free (feature);
+
+  return res;
+}
+
+static GstCaps *
+gst_cuda_base_convert_transform_caps (GstBaseTransform *
+    trans, GstPadDirection direction, GstCaps * caps, GstCaps * filter)
+{
+  GstCaps *tmp, *tmp2;
+  GstCaps *result;
+
+  /* Get all possible caps that we can transform to */
+  tmp = gst_cuda_base_convert_caps_remove_format_and_rangify_size_info (caps);
+
+  if (filter) {
+    tmp2 = gst_caps_intersect_full (filter, tmp, GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (tmp);
+    tmp = tmp2;
+  }
+
+  result = tmp;
+
+  GST_DEBUG_OBJECT (trans, "transformed %" GST_PTR_FORMAT " into %"
+      GST_PTR_FORMAT, caps, result);
+
+  return result;
+}
+
+/*
+ * This is an incomplete matrix of in formats and a score for the prefered output
+ * format.
+ *
+ *         out: RGB24   RGB16  ARGB  AYUV  YUV444  YUV422 YUV420 YUV411 YUV410  PAL  GRAY
+ *  in
+ * RGB24          0      2       1     2     2       3      4      5      6      7    8
+ * RGB16          1      0       1     2     2       3      4      5      6      7    8
+ * ARGB           2      3       0     1     4       5      6      7      8      9    10
+ * AYUV           3      4       1     0     2       5      6      7      8      9    10
+ * YUV444         2      4       3     1     0       5      6      7      8      9    10
+ * YUV422         3      5       4     2     1       0      6      7      8      9    10
+ * YUV420         4      6       5     3     2       1      0      7      8      9    10
+ * YUV411         4      6       5     3     2       1      7      0      8      9    10
+ * YUV410         6      8       7     5     4       3      2      1      0      9    10
+ * PAL            1      3       2     6     4       6      7      8      9      0    10
+ * GRAY           1      4       3     2     1       5      6      7      8      9    0
+ *
+ * PAL or GRAY are never prefered, if we can we would convert to PAL instead
+ * of GRAY, though
+ * less subsampling is prefered and if any, preferably horizontal
+ * We would like to keep the alpha, even if we would need to to colorspace conversion
+ * or lose depth.
+ */
+#define SCORE_FORMAT_CHANGE       1
+#define SCORE_DEPTH_CHANGE        1
+#define SCORE_ALPHA_CHANGE        1
+#define SCORE_CHROMA_W_CHANGE     1
+#define SCORE_CHROMA_H_CHANGE     1
+#define SCORE_PALETTE_CHANGE      1
+
+#define SCORE_COLORSPACE_LOSS     2     /* RGB <-> YUV */
+#define SCORE_DEPTH_LOSS          4     /* change bit depth */
+#define SCORE_ALPHA_LOSS          8     /* lose the alpha channel */
+#define SCORE_CHROMA_W_LOSS      16     /* vertical subsample */
+#define SCORE_CHROMA_H_LOSS      32     /* horizontal subsample */
+#define SCORE_PALETTE_LOSS       64     /* convert to palette format */
+#define SCORE_COLOR_LOSS        128     /* convert to GRAY */
+
+#define COLORSPACE_MASK (GST_VIDEO_FORMAT_FLAG_YUV | \
+                         GST_VIDEO_FORMAT_FLAG_RGB | GST_VIDEO_FORMAT_FLAG_GRAY)
+#define ALPHA_MASK      (GST_VIDEO_FORMAT_FLAG_ALPHA)
+#define PALETTE_MASK    (GST_VIDEO_FORMAT_FLAG_PALETTE)
+
+/* calculate how much loss a conversion would be */
+static void
+score_value (GstBaseTransform * base, const GstVideoFormatInfo * in_info,
+    const GValue * val, gint * min_loss, const GstVideoFormatInfo ** out_info)
+{
+  const gchar *fname;
+  const GstVideoFormatInfo *t_info;
+  guint in_flags, t_flags;
+  gint loss;
+
+  fname = g_value_get_string (val);
+  t_info = gst_video_format_get_info (gst_video_format_from_string (fname));
+  if (!t_info || t_info->format == GST_VIDEO_FORMAT_UNKNOWN)
+    return;
+
+  /* accept input format immediately without loss */
+  if (in_info == t_info) {
+    *min_loss = 0;
+    *out_info = t_info;
+    return;
+  }
+
+  loss = SCORE_FORMAT_CHANGE;
+
+  in_flags = GST_VIDEO_FORMAT_INFO_FLAGS (in_info);
+  in_flags &= ~GST_VIDEO_FORMAT_FLAG_LE;
+  in_flags &= ~GST_VIDEO_FORMAT_FLAG_COMPLEX;
+  in_flags &= ~GST_VIDEO_FORMAT_FLAG_UNPACK;
+
+  t_flags = GST_VIDEO_FORMAT_INFO_FLAGS (t_info);
+  t_flags &= ~GST_VIDEO_FORMAT_FLAG_LE;
+  t_flags &= ~GST_VIDEO_FORMAT_FLAG_COMPLEX;
+  t_flags &= ~GST_VIDEO_FORMAT_FLAG_UNPACK;
+
+  if ((t_flags & PALETTE_MASK) != (in_flags & PALETTE_MASK)) {
+    loss += SCORE_PALETTE_CHANGE;
+    if (t_flags & PALETTE_MASK)
+      loss += SCORE_PALETTE_LOSS;
+  }
+
+  if ((t_flags & COLORSPACE_MASK) != (in_flags & COLORSPACE_MASK)) {
+    loss += SCORE_COLORSPACE_LOSS;
+    if (t_flags & GST_VIDEO_FORMAT_FLAG_GRAY)
+      loss += SCORE_COLOR_LOSS;
+  }
+
+  if ((t_flags & ALPHA_MASK) != (in_flags & ALPHA_MASK)) {
+    loss += SCORE_ALPHA_CHANGE;
+    if (in_flags & ALPHA_MASK)
+      loss += SCORE_ALPHA_LOSS;
+  }
+
+  if ((in_info->h_sub[1]) != (t_info->h_sub[1])) {
+    loss += SCORE_CHROMA_H_CHANGE;
+    if ((in_info->h_sub[1]) < (t_info->h_sub[1]))
+      loss += SCORE_CHROMA_H_LOSS;
+  }
+  if ((in_info->w_sub[1]) != (t_info->w_sub[1])) {
+    loss += SCORE_CHROMA_W_CHANGE;
+    if ((in_info->w_sub[1]) < (t_info->w_sub[1]))
+      loss += SCORE_CHROMA_W_LOSS;
+  }
+
+  if ((in_info->bits) != (t_info->bits)) {
+    loss += SCORE_DEPTH_CHANGE;
+    if ((in_info->bits) > (t_info->bits))
+      loss += SCORE_DEPTH_LOSS + (in_info->bits - t_info->bits);
+  }
+
+  GST_DEBUG_OBJECT (base, "score %s -> %s = %d",
+      GST_VIDEO_FORMAT_INFO_NAME (in_info),
+      GST_VIDEO_FORMAT_INFO_NAME (t_info), loss);
+
+  if (loss < *min_loss) {
+    GST_DEBUG_OBJECT (base, "found new best %d", loss);
+    *out_info = t_info;
+    *min_loss = loss;
+  }
+}
+
+static void
+gst_cuda_base_convert_fixate_format (GstBaseTransform * trans,
+    GstCaps * caps, GstCaps * result)
+{
+  GstStructure *ins, *outs;
+  const gchar *in_format;
+  const GstVideoFormatInfo *in_info, *out_info = NULL;
+  gint min_loss = G_MAXINT;
+  guint i, capslen;
+
+  ins = gst_caps_get_structure (caps, 0);
+  in_format = gst_structure_get_string (ins, "format");
+  if (!in_format) {
+    return;
+  }
+
+  GST_DEBUG_OBJECT (trans, "source format %s", in_format);
+
+  in_info =
+      gst_video_format_get_info (gst_video_format_from_string (in_format));
+  if (!in_info)
+    return;
+
+  outs = gst_caps_get_structure (result, 0);
+
+  capslen = gst_caps_get_size (result);
+  GST_DEBUG ("iterate %d structures", capslen);
+  for (i = 0; i < capslen; i++) {
+    GstStructure *tests;
+    const GValue *format;
+
+    tests = gst_caps_get_structure (result, i);
+    format = gst_structure_get_value (tests, "format");
+
+    /* should not happen */
+    if (format == NULL)
+      continue;
+
+    if (GST_VALUE_HOLDS_LIST (format)) {
+      gint j, len;
+
+      len = gst_value_list_get_size (format);
+      GST_DEBUG_OBJECT (trans, "have %d formats", len);
+      for (j = 0; j < len; j++) {
+        const GValue *val;
+
+        val = gst_value_list_get_value (format, j);
+        if (G_VALUE_HOLDS_STRING (val)) {
+          score_value (trans, in_info, val, &min_loss, &out_info);
+          if (min_loss == 0)
+            break;
+        }
+      }
+    } else if (G_VALUE_HOLDS_STRING (format)) {
+      score_value (trans, in_info, format, &min_loss, &out_info);
+    }
+  }
+  if (out_info)
+    gst_structure_set (outs, "format", G_TYPE_STRING,
+        GST_VIDEO_FORMAT_INFO_NAME (out_info), NULL);
+}
+
+static gboolean
+subsampling_unchanged (GstVideoInfo * in_info, GstVideoInfo * out_info)
+{
+  guint i;
+  const GstVideoFormatInfo *in_format, *out_format;
+
+  if (GST_VIDEO_INFO_N_COMPONENTS (in_info) !=
+      GST_VIDEO_INFO_N_COMPONENTS (out_info))
+    return FALSE;
+
+  in_format = in_info->finfo;
+  out_format = out_info->finfo;
+
+  for (i = 0; i < GST_VIDEO_INFO_N_COMPONENTS (in_info); i++) {
+    if (GST_VIDEO_FORMAT_INFO_W_SUB (in_format,
+            i) != GST_VIDEO_FORMAT_INFO_W_SUB (out_format, i))
+      return FALSE;
+    if (GST_VIDEO_FORMAT_INFO_H_SUB (in_format,
+            i) != GST_VIDEO_FORMAT_INFO_H_SUB (out_format, i))
+      return FALSE;
+  }
+
+  return TRUE;
+}
+
+static void
+transfer_colorimetry_from_input (GstBaseTransform * trans, GstCaps * in_caps,
+    GstCaps * out_caps)
+{
+  GstStructure *out_caps_s = gst_caps_get_structure (out_caps, 0);
+  GstStructure *in_caps_s = gst_caps_get_structure (in_caps, 0);
+  gboolean have_colorimetry =
+      gst_structure_has_field (out_caps_s, "colorimetry");
+  gboolean have_chroma_site =
+      gst_structure_has_field (out_caps_s, "chroma-site");
+
+  /* If the output already has colorimetry and chroma-site, stop,
+   * otherwise try and transfer what we can from the input caps */
+  if (have_colorimetry && have_chroma_site)
+    return;
+
+  {
+    GstVideoInfo in_info, out_info;
+    const GValue *in_colorimetry =
+        gst_structure_get_value (in_caps_s, "colorimetry");
+
+    if (!gst_video_info_from_caps (&in_info, in_caps)) {
+      GST_WARNING_OBJECT (trans,
+          "Failed to convert sink pad caps to video info");
+      return;
+    }
+    if (!gst_video_info_from_caps (&out_info, out_caps)) {
+      GST_WARNING_OBJECT (trans,
+          "Failed to convert src pad caps to video info");
+      return;
+    }
+
+    if (!have_colorimetry && in_colorimetry != NULL) {
+      if ((GST_VIDEO_INFO_IS_YUV (&out_info)
+              && GST_VIDEO_INFO_IS_YUV (&in_info))
+          || (GST_VIDEO_INFO_IS_RGB (&out_info)
+              && GST_VIDEO_INFO_IS_RGB (&in_info))
+          || (GST_VIDEO_INFO_IS_GRAY (&out_info)
+              && GST_VIDEO_INFO_IS_GRAY (&in_info))) {
+        /* Can transfer the colorimetry intact from the input if it has it */
+        gst_structure_set_value (out_caps_s, "colorimetry", in_colorimetry);
+      } else {
+        gchar *colorimetry_str;
+
+        /* Changing between YUV/RGB - forward primaries and transfer function, but use
+         * default range and matrix.
+         * the primaries is used for conversion between RGB and XYZ (CIE 1931 coordinate).
+         * the transfer function could be another reference (e.g., HDR)
+         */
+        out_info.colorimetry.primaries = in_info.colorimetry.primaries;
+        out_info.colorimetry.transfer = in_info.colorimetry.transfer;
+
+        colorimetry_str =
+            gst_video_colorimetry_to_string (&out_info.colorimetry);
+        gst_caps_set_simple (out_caps, "colorimetry", G_TYPE_STRING,
+            colorimetry_str, NULL);
+        g_free (colorimetry_str);
+      }
+    }
+
+    /* Only YUV output needs chroma-site. If the input was also YUV and had the same chroma
+     * subsampling, transfer the siting. If the sub-sampling is changing, then the planes get
+     * scaled anyway so there's no real reason to prefer the input siting. */
+    if (!have_chroma_site && GST_VIDEO_INFO_IS_YUV (&out_info)) {
+      if (GST_VIDEO_INFO_IS_YUV (&in_info)) {
+        const GValue *in_chroma_site =
+            gst_structure_get_value (in_caps_s, "chroma-site");
+        if (in_chroma_site != NULL
+            && subsampling_unchanged (&in_info, &out_info))
+          gst_structure_set_value (out_caps_s, "chroma-site", in_chroma_site);
+      }
+    }
+  }
+}
+
+static GstCaps *
+gst_cuda_base_convert_get_fixed_format (GstBaseTransform * trans,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps)
+{
+  GstCaps *result;
+
+  result = gst_caps_intersect (othercaps, caps);
+  if (gst_caps_is_empty (result)) {
+    gst_caps_unref (result);
+    result = gst_caps_copy (othercaps);
+  }
+
+  gst_cuda_base_convert_fixate_format (trans, caps, result);
+
+  /* fixate remaining fields */
+  result = gst_caps_fixate (result);
+
+  if (direction == GST_PAD_SINK) {
+    if (gst_caps_is_subset (caps, result)) {
+      gst_caps_replace (&result, caps);
+    } else {
+      /* Try and preserve input colorimetry / chroma information */
+      transfer_colorimetry_from_input (trans, caps, result);
+    }
+  }
+
+  return result;
+}
+
+static GstCaps *
+gst_cuda_base_convert_fixate_size (GstBaseTransform * base,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps)
+{
+  GstStructure *ins, *outs;
+  const GValue *from_par, *to_par;
+  GValue fpar = G_VALUE_INIT, tpar = G_VALUE_INIT;
+
+  othercaps = gst_caps_truncate (othercaps);
+  othercaps = gst_caps_make_writable (othercaps);
+  ins = gst_caps_get_structure (caps, 0);
+  outs = gst_caps_get_structure (othercaps, 0);
+
+  from_par = gst_structure_get_value (ins, "pixel-aspect-ratio");
+  to_par = gst_structure_get_value (outs, "pixel-aspect-ratio");
+
+  if (direction == GST_PAD_SINK) {
+    if (!from_par) {
+      g_value_init (&fpar, GST_TYPE_FRACTION);
+      gst_value_set_fraction (&fpar, 1, 1);
+      from_par = &fpar;
+    }
+    if (!to_par) {
+      g_value_init (&tpar, GST_TYPE_FRACTION_RANGE);
+      gst_value_set_fraction_range_full (&tpar, 1, G_MAXINT, G_MAXINT, 1);
+      to_par = &tpar;
+    }
+  } else {
+    gint from_par_n, from_par_d;
+
+    if (!from_par) {
+      g_value_init (&fpar, GST_TYPE_FRACTION);
+      gst_value_set_fraction (&fpar, 1, 1);
+      from_par = &fpar;
+
+      from_par_n = from_par_d = 1;
+    } else {
+      from_par_n = gst_value_get_fraction_numerator (from_par);
+      from_par_d = gst_value_get_fraction_denominator (from_par);
+    }
+
+    if (!to_par) {
+      gint to_par_n, to_par_d;
+
+      to_par_n = from_par_n;
+      to_par_d = from_par_d;
+
+      g_value_init (&tpar, GST_TYPE_FRACTION);
+      gst_value_set_fraction (&tpar, to_par_n, to_par_d);
+      to_par = &tpar;
+
+      gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+          to_par_n, to_par_d, NULL);
+    }
+  }
+
+  /* we have both PAR but they might not be fixated */
+  {
+    gint from_w, from_h, from_par_n, from_par_d, to_par_n, to_par_d;
+    gint w = 0, h = 0;
+    gint from_dar_n, from_dar_d;
+    gint num, den;
+
+    /* from_par should be fixed */
+    g_return_val_if_fail (gst_value_is_fixed (from_par), othercaps);
+
+    from_par_n = gst_value_get_fraction_numerator (from_par);
+    from_par_d = gst_value_get_fraction_denominator (from_par);
+
+    gst_structure_get_int (ins, "width", &from_w);
+    gst_structure_get_int (ins, "height", &from_h);
+
+    gst_structure_get_int (outs, "width", &w);
+    gst_structure_get_int (outs, "height", &h);
+
+    /* if both width and height are already fixed, we can't do anything
+     * about it anymore */
+    if (w && h) {
+      guint n, d;
+
+      GST_DEBUG_OBJECT (base, "dimensions already set to %dx%d, not fixating",
+          w, h);
+      if (!gst_value_is_fixed (to_par)) {
+        if (gst_video_calculate_display_ratio (&n, &d, from_w, from_h,
+                from_par_n, from_par_d, w, h)) {
+          GST_DEBUG_OBJECT (base, "fixating to_par to %dx%d", n, d);
+          if (gst_structure_has_field (outs, "pixel-aspect-ratio"))
+            gst_structure_fixate_field_nearest_fraction (outs,
+                "pixel-aspect-ratio", n, d);
+          else if (n != d)
+            gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+                n, d, NULL);
+        }
+      }
+      goto done;
+    }
+
+    /* Calculate input DAR */
+    if (!gst_util_fraction_multiply (from_w, from_h, from_par_n, from_par_d,
+            &from_dar_n, &from_dar_d)) {
+      GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+          ("Error calculating the output scaled size - integer overflow"));
+      goto done;
+    }
+
+    GST_DEBUG_OBJECT (base, "Input DAR is %d/%d", from_dar_n, from_dar_d);
+
+    /* If either width or height are fixed there's not much we
+     * can do either except choosing a height or width and PAR
+     * that matches the DAR as good as possible
+     */
+    if (h) {
+      GstStructure *tmp;
+      gint set_w, set_par_n, set_par_d;
+
+      GST_DEBUG_OBJECT (base, "height is fixed (%d)", h);
+
+      /* If the PAR is fixed too, there's not much to do
+       * except choosing the width that is nearest to the
+       * width with the same DAR */
+      if (gst_value_is_fixed (to_par)) {
+        to_par_n = gst_value_get_fraction_numerator (to_par);
+        to_par_d = gst_value_get_fraction_denominator (to_par);
+
+        GST_DEBUG_OBJECT (base, "PAR is fixed %d/%d", to_par_n, to_par_d);
+
+        if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, to_par_d,
+                to_par_n, &num, &den)) {
+          GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+              ("Error calculating the output scaled size - integer overflow"));
+          goto done;
+        }
+
+        w = (guint) gst_util_uint64_scale_int_round (h, num, den);
+        gst_structure_fixate_field_nearest_int (outs, "width", w);
+
+        goto done;
+      }
+
+      /* The PAR is not fixed and it's quite likely that we can set
+       * an arbitrary PAR. */
+
+      /* Check if we can keep the input width */
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "width", from_w);
+      gst_structure_get_int (tmp, "width", &set_w);
+
+      /* Might have failed but try to keep the DAR nonetheless by
+       * adjusting the PAR */
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, h, set_w,
+              &to_par_n, &to_par_d)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scaled size - integer overflow"));
+        gst_structure_free (tmp);
+        goto done;
+      }
+
+      if (!gst_structure_has_field (tmp, "pixel-aspect-ratio"))
+        gst_structure_set_value (tmp, "pixel-aspect-ratio", to_par);
+      gst_structure_fixate_field_nearest_fraction (tmp, "pixel-aspect-ratio",
+          to_par_n, to_par_d);
+      gst_structure_get_fraction (tmp, "pixel-aspect-ratio", &set_par_n,
+          &set_par_d);
+      gst_structure_free (tmp);
+
+      /* Check if the adjusted PAR is accepted */
+      if (set_par_n == to_par_n && set_par_d == to_par_d) {
+        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+            set_par_n != set_par_d)
+          gst_structure_set (outs, "width", G_TYPE_INT, set_w,
+              "pixel-aspect-ratio", GST_TYPE_FRACTION, set_par_n, set_par_d,
+              NULL);
+        goto done;
+      }
+
+      /* Otherwise scale the width to the new PAR and check if the
+       * adjusted with is accepted. If all that fails we can't keep
+       * the DAR */
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_par_d,
+              set_par_n, &num, &den)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scaled size - integer overflow"));
+        goto done;
+      }
+
+      w = (guint) gst_util_uint64_scale_int_round (h, num, den);
+      gst_structure_fixate_field_nearest_int (outs, "width", w);
+      if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+          set_par_n != set_par_d)
+        gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+            set_par_n, set_par_d, NULL);
+
+      goto done;
+    } else if (w) {
+      GstStructure *tmp;
+      gint set_h, set_par_n, set_par_d;
+
+      GST_DEBUG_OBJECT (base, "width is fixed (%d)", w);
+
+      /* If the PAR is fixed too, there's not much to do
+       * except choosing the height that is nearest to the
+       * height with the same DAR */
+      if (gst_value_is_fixed (to_par)) {
+        to_par_n = gst_value_get_fraction_numerator (to_par);
+        to_par_d = gst_value_get_fraction_denominator (to_par);
+
+        GST_DEBUG_OBJECT (base, "PAR is fixed %d/%d", to_par_n, to_par_d);
+
+        if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, to_par_d,
+                to_par_n, &num, &den)) {
+          GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+              ("Error calculating the output scaled size - integer overflow"));
+          goto done;
+        }
+
+        h = (guint) gst_util_uint64_scale_int_round (w, den, num);
+        gst_structure_fixate_field_nearest_int (outs, "height", h);
+
+        goto done;
+      }
+
+      /* The PAR is not fixed and it's quite likely that we can set
+       * an arbitrary PAR. */
+
+      /* Check if we can keep the input height */
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "height", from_h);
+      gst_structure_get_int (tmp, "height", &set_h);
+
+      /* Might have failed but try to keep the DAR nonetheless by
+       * adjusting the PAR */
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_h, w,
+              &to_par_n, &to_par_d)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scaled size - integer overflow"));
+        gst_structure_free (tmp);
+        goto done;
+      }
+      if (!gst_structure_has_field (tmp, "pixel-aspect-ratio"))
+        gst_structure_set_value (tmp, "pixel-aspect-ratio", to_par);
+      gst_structure_fixate_field_nearest_fraction (tmp, "pixel-aspect-ratio",
+          to_par_n, to_par_d);
+      gst_structure_get_fraction (tmp, "pixel-aspect-ratio", &set_par_n,
+          &set_par_d);
+      gst_structure_free (tmp);
+
+      /* Check if the adjusted PAR is accepted */
+      if (set_par_n == to_par_n && set_par_d == to_par_d) {
+        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+            set_par_n != set_par_d)
+          gst_structure_set (outs, "height", G_TYPE_INT, set_h,
+              "pixel-aspect-ratio", GST_TYPE_FRACTION, set_par_n, set_par_d,
+              NULL);
+        goto done;
+      }
+
+      /* Otherwise scale the height to the new PAR and check if the
+       * adjusted with is accepted. If all that fails we can't keep
+       * the DAR */
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_par_d,
+              set_par_n, &num, &den)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scale sized - integer overflow"));
+        goto done;
+      }
+
+      h = (guint) gst_util_uint64_scale_int_round (w, den, num);
+      gst_structure_fixate_field_nearest_int (outs, "height", h);
+      if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+          set_par_n != set_par_d)
+        gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+            set_par_n, set_par_d, NULL);
+
+      goto done;
+    } else if (gst_value_is_fixed (to_par)) {
+      GstStructure *tmp;
+      gint set_h, set_w, f_h, f_w;
+
+      to_par_n = gst_value_get_fraction_numerator (to_par);
+      to_par_d = gst_value_get_fraction_denominator (to_par);
+
+      /* Calculate scale factor for the PAR change */
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, to_par_n,
+              to_par_d, &num, &den)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scaled size - integer overflow"));
+        goto done;
+      }
+
+      /* Try to keep the input height (because of interlacing) */
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "height", from_h);
+      gst_structure_get_int (tmp, "height", &set_h);
+
+      /* This might have failed but try to scale the width
+       * to keep the DAR nonetheless */
+      w = (guint) gst_util_uint64_scale_int_round (set_h, num, den);
+      gst_structure_fixate_field_nearest_int (tmp, "width", w);
+      gst_structure_get_int (tmp, "width", &set_w);
+      gst_structure_free (tmp);
+
+      /* We kept the DAR and the height is nearest to the original height */
+      if (set_w == w) {
+        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
+            G_TYPE_INT, set_h, NULL);
+        goto done;
+      }
+
+      f_h = set_h;
+      f_w = set_w;
+
+      /* If the former failed, try to keep the input width at least */
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "width", from_w);
+      gst_structure_get_int (tmp, "width", &set_w);
+
+      /* This might have failed but try to scale the width
+       * to keep the DAR nonetheless */
+      h = (guint) gst_util_uint64_scale_int_round (set_w, den, num);
+      gst_structure_fixate_field_nearest_int (tmp, "height", h);
+      gst_structure_get_int (tmp, "height", &set_h);
+      gst_structure_free (tmp);
+
+      /* We kept the DAR and the width is nearest to the original width */
+      if (set_h == h) {
+        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
+            G_TYPE_INT, set_h, NULL);
+        goto done;
+      }
+
+      /* If all this failed, keep the dimensions with the DAR that was closest
+       * to the correct DAR. This changes the DAR but there's not much else to
+       * do here.
+       */
+      if (set_w * ABS (set_h - h) < ABS (f_w - w) * f_h) {
+        f_h = set_h;
+        f_w = set_w;
+      }
+      gst_structure_set (outs, "width", G_TYPE_INT, f_w, "height", G_TYPE_INT,
+          f_h, NULL);
+      goto done;
+    } else {
+      GstStructure *tmp;
+      gint set_h, set_w, set_par_n, set_par_d, tmp2;
+
+      /* width, height and PAR are not fixed but passthrough is not possible */
+
+      /* First try to keep the height and width as good as possible
+       * and scale PAR */
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "height", from_h);
+      gst_structure_get_int (tmp, "height", &set_h);
+      gst_structure_fixate_field_nearest_int (tmp, "width", from_w);
+      gst_structure_get_int (tmp, "width", &set_w);
+
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_h, set_w,
+              &to_par_n, &to_par_d)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scaled size - integer overflow"));
+        gst_structure_free (tmp);
+        goto done;
+      }
+
+      if (!gst_structure_has_field (tmp, "pixel-aspect-ratio"))
+        gst_structure_set_value (tmp, "pixel-aspect-ratio", to_par);
+      gst_structure_fixate_field_nearest_fraction (tmp, "pixel-aspect-ratio",
+          to_par_n, to_par_d);
+      gst_structure_get_fraction (tmp, "pixel-aspect-ratio", &set_par_n,
+          &set_par_d);
+      gst_structure_free (tmp);
+
+      if (set_par_n == to_par_n && set_par_d == to_par_d) {
+        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
+            G_TYPE_INT, set_h, NULL);
+
+        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+            set_par_n != set_par_d)
+          gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+              set_par_n, set_par_d, NULL);
+        goto done;
+      }
+
+      /* Otherwise try to scale width to keep the DAR with the set
+       * PAR and height */
+      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_par_d,
+              set_par_n, &num, &den)) {
+        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
+            ("Error calculating the output scaled size - integer overflow"));
+        goto done;
+      }
+
+      w = (guint) gst_util_uint64_scale_int_round (set_h, num, den);
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "width", w);
+      gst_structure_get_int (tmp, "width", &tmp2);
+      gst_structure_free (tmp);
+
+      if (tmp2 == w) {
+        gst_structure_set (outs, "width", G_TYPE_INT, tmp2, "height",
+            G_TYPE_INT, set_h, NULL);
+        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+            set_par_n != set_par_d)
+          gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+              set_par_n, set_par_d, NULL);
+        goto done;
+      }
+
+      /* ... or try the same with the height */
+      h = (guint) gst_util_uint64_scale_int_round (set_w, den, num);
+      tmp = gst_structure_copy (outs);
+      gst_structure_fixate_field_nearest_int (tmp, "height", h);
+      gst_structure_get_int (tmp, "height", &tmp2);
+      gst_structure_free (tmp);
+
+      if (tmp2 == h) {
+        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
+            G_TYPE_INT, tmp2, NULL);
+        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+            set_par_n != set_par_d)
+          gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+              set_par_n, set_par_d, NULL);
+        goto done;
+      }
+
+      /* If all fails we can't keep the DAR and take the nearest values
+       * for everything from the first try */
+      gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
+          G_TYPE_INT, set_h, NULL);
+      if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
+          set_par_n != set_par_d)
+        gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+            set_par_n, set_par_d, NULL);
+    }
+  }
+
+done:
+  if (from_par == &fpar)
+    g_value_unset (&fpar);
+  if (to_par == &tpar)
+    g_value_unset (&tpar);
+
+  return othercaps;
+}
+
+static GstCaps *
+gst_cuda_base_convert_fixate_caps (GstBaseTransform * trans,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps)
+{
+  GstCaps *format = NULL;
+
+  GST_DEBUG_OBJECT (trans,
+      "trying to fixate othercaps %" GST_PTR_FORMAT " based on caps %"
+      GST_PTR_FORMAT, othercaps, caps);
+
+  format = gst_cuda_base_convert_get_fixed_format (trans, direction, caps,
+      othercaps);
+
+  if (gst_caps_is_empty (format)) {
+    GST_ERROR_OBJECT (trans, "Could not convert formats");
+    return format;
+  }
+
+  /* convert mode is "all" or "size" here */
+  othercaps =
+      gst_cuda_base_convert_fixate_size (trans, direction, caps, othercaps);
+
+  if (gst_caps_get_size (othercaps) == 1) {
+    guint i;
+    const gchar *format_fields[] = { "format", "colorimetry", "chroma-site" };
+    GstStructure *format_struct = gst_caps_get_structure (format, 0);
+    GstStructure *fixated_struct;
+
+    othercaps = gst_caps_make_writable (othercaps);
+    fixated_struct = gst_caps_get_structure (othercaps, 0);
+
+    for (i = 0; i < G_N_ELEMENTS (format_fields); i++) {
+      if (gst_structure_has_field (format_struct, format_fields[i])) {
+        gst_structure_set (fixated_struct, format_fields[i], G_TYPE_STRING,
+            gst_structure_get_string (format_struct, format_fields[i]), NULL);
+      } else {
+        gst_structure_remove_field (fixated_struct, format_fields[i]);
+      }
+    }
+  }
+  gst_caps_unref (format);
+
+  GST_DEBUG_OBJECT (trans, "fixated othercaps to %" GST_PTR_FORMAT, othercaps);
+
+  return othercaps;
+}
+
+static gboolean
+gst_cuda_base_convert_propose_allocation (GstBaseTransform * trans,
+    GstQuery * decide_query, GstQuery * query)
+{
+  GstCudaBaseTransform *ctrans = GST_CUDA_BASE_TRANSFORM (trans);
+  GstVideoInfo info;
+  GstBufferPool *pool;
+  GstCaps *caps;
+  guint size;
+
+  if (!GST_BASE_TRANSFORM_CLASS (parent_class)->propose_allocation (trans,
+          decide_query, query))
+    return FALSE;
+
+  /* passthrough, we're done */
+  if (decide_query == NULL)
+    return TRUE;
+
+  gst_query_parse_allocation (query, &caps, NULL);
+
+  if (caps == NULL)
+    return FALSE;
+
+  if (!gst_video_info_from_caps (&info, caps))
+    return FALSE;
+
+  if (gst_query_get_n_allocation_pools (query) == 0) {
+    GstStructure *config;
+
+    pool = gst_cuda_buffer_pool_new (ctrans->context);
+
+    config = gst_buffer_pool_get_config (pool);
+
+    gst_buffer_pool_config_add_option (config,
+        GST_BUFFER_POOL_OPTION_VIDEO_META);
+
+    size = GST_VIDEO_INFO_SIZE (&info);
+    gst_buffer_pool_config_set_params (config, caps, size, 0, 0);
+
+    if (!gst_buffer_pool_set_config (pool, config)) {
+      GST_ERROR_OBJECT (ctrans, "failed to set config");
+      gst_object_unref (pool);
+      return FALSE;
+    }
+
+    /* Get updated size by cuda buffer pool */
+    config = gst_buffer_pool_get_config (pool);
+    gst_buffer_pool_config_get_params (config, NULL, &size, NULL, NULL);
+    gst_structure_free (config);
+
+    gst_query_add_allocation_pool (query, pool, size, 0, 0);
+
+    gst_object_unref (pool);
+  }
+
+  gst_query_add_allocation_meta (query, GST_VIDEO_META_API_TYPE, NULL);
+
+  return TRUE;
+}
+
+static gboolean
+gst_cuda_base_convert_decide_allocation (GstBaseTransform * trans,
+    GstQuery * query)
+{
+  GstCudaBaseTransform *ctrans = GST_CUDA_BASE_TRANSFORM (trans);
+  GstCaps *outcaps = NULL;
+  GstBufferPool *pool = NULL;
+  guint size, min, max;
+  GstStructure *config;
+  gboolean update_pool = FALSE;
+
+  gst_query_parse_allocation (query, &outcaps, NULL);
+
+  if (!outcaps)
+    return FALSE;
+
+  if (gst_query_get_n_allocation_pools (query) > 0) {
+    gst_query_parse_nth_allocation_pool (query, 0, &pool, &size, &min, &max);
+    if (pool) {
+      if (!GST_IS_CUDA_BUFFER_POOL (pool)) {
+        gst_clear_object (&pool);
+      } else {
+        GstCudaBufferPool *cpool = GST_CUDA_BUFFER_POOL (pool);
+
+        if (cpool->context != ctrans->context) {
+          gst_clear_object (&pool);
+        }
+      }
+    }
+
+    update_pool = TRUE;
+  } else {
+    GstVideoInfo vinfo;
+    gst_video_info_from_caps (&vinfo, outcaps);
+    size = GST_VIDEO_INFO_SIZE (&vinfo);
+    min = max = 0;
+  }
+
+  if (!pool) {
+    GST_DEBUG_OBJECT (ctrans, "create our pool");
+
+    pool = gst_cuda_buffer_pool_new (ctrans->context);
+  }
+
+  config = gst_buffer_pool_get_config (pool);
+  gst_buffer_pool_config_add_option (config, GST_BUFFER_POOL_OPTION_VIDEO_META);
+  gst_buffer_pool_config_set_params (config, outcaps, size, min, max);
+  gst_buffer_pool_set_config (pool, config);
+
+  /* Get updated size by cuda buffer pool */
+  config = gst_buffer_pool_get_config (pool);
+  gst_buffer_pool_config_get_params (config, NULL, &size, NULL, NULL);
+  gst_structure_free (config);
+
+  if (update_pool)
+    gst_query_set_nth_allocation_pool (query, 0, pool, size, min, max);
+  else
+    gst_query_add_allocation_pool (query, pool, size, min, max);
+
+  gst_object_unref (pool);
+
+  return GST_BASE_TRANSFORM_CLASS (parent_class)->decide_allocation (trans,
+      query);
+}
+
+static gboolean
+gst_cuda_base_convert_set_info (GstCudaBaseTransform * btrans,
+    GstCaps * incaps, GstVideoInfo * in_info, GstCaps * outcaps,
+    GstVideoInfo * out_info)
+{
+  GstCudaBaseConvert *self = GST_CUDA_BASE_CONVERT (btrans);
+  gint from_dar_n, from_dar_d, to_dar_n, to_dar_d;
+  GstVideoInfo tmp_info;
+
+  gst_clear_object (&self->converter);
+
+  if (!gst_util_fraction_multiply (in_info->width,
+          in_info->height, in_info->par_n, in_info->par_d, &from_dar_n,
+          &from_dar_d)) {
+    from_dar_n = from_dar_d = -1;
+  }
+
+  if (!gst_util_fraction_multiply (out_info->width,
+          out_info->height, out_info->par_n, out_info->par_d, &to_dar_n,
+          &to_dar_d)) {
+    to_dar_n = to_dar_d = -1;
+  }
+
+  self->borders_w = self->borders_h = 0;
+  if (to_dar_n != from_dar_n || to_dar_d != from_dar_d) {
+    if (self->add_borders) {
+      gint n, d, to_h, to_w;
+
+      if (from_dar_n != -1 && from_dar_d != -1
+          && gst_util_fraction_multiply (from_dar_n, from_dar_d,
+              out_info->par_d, out_info->par_n, &n, &d)) {
+        to_h = gst_util_uint64_scale_int (out_info->width, d, n);
+        if (to_h <= out_info->height) {
+          self->borders_h = out_info->height - to_h;
+          self->borders_w = 0;
+        } else {
+          to_w = gst_util_uint64_scale_int (out_info->height, n, d);
+          g_assert (to_w <= out_info->width);
+          self->borders_h = 0;
+          self->borders_w = out_info->width - to_w;
+        }
+      } else {
+        GST_WARNING_OBJECT (self, "Can't calculate borders");
+      }
+    } else {
+      GST_WARNING_OBJECT (self, "Can't keep DAR!");
+    }
+  }
+
+  /* if present, these must match */
+  if (in_info->interlace_mode != out_info->interlace_mode) {
+    GST_ERROR_OBJECT (self, "input and output formats do not match");
+    return FALSE;
+  }
+
+  /* if the only thing different in the caps is the transfer function, and
+   * we're converting between equivalent transfer functions, do passthrough */
+  tmp_info = *in_info;
+  tmp_info.colorimetry.transfer = out_info->colorimetry.transfer;
+  if (gst_video_info_is_equal (&tmp_info, out_info) &&
+      gst_video_transfer_function_is_equivalent (in_info->colorimetry.transfer,
+          in_info->finfo->bits, out_info->colorimetry.transfer,
+          out_info->finfo->bits)) {
+    gst_base_transform_set_passthrough (GST_BASE_TRANSFORM (self), TRUE);
+  } else {
+    GstStructure *config;
+
+    gst_base_transform_set_passthrough (GST_BASE_TRANSFORM (self), FALSE);
+
+    config = gst_structure_new_empty ("GstCudaConverter");
+    gst_structure_set (config,
+        GST_CUDA_CONVERTER_OPT_DEST_X, G_TYPE_INT, self->borders_w / 2,
+        GST_CUDA_CONVERTER_OPT_DEST_Y, G_TYPE_INT, self->borders_h / 2,
+        GST_CUDA_CONVERTER_OPT_DEST_WIDTH,
+        G_TYPE_INT, out_info->width - self->borders_w,
+        GST_CUDA_CONVERTER_OPT_DEST_HEIGHT,
+        G_TYPE_INT, out_info->height - self->borders_h, NULL);
+
+    self->converter = gst_cuda_converter_new (in_info,
+        out_info, btrans->context, config);
+    if (!self->converter) {
+      GST_ERROR_OBJECT (self, "Couldn't create converter");
+      return FALSE;
+    }
+  }
+
+  GST_DEBUG_OBJECT (self, "%s from=%dx%d (par=%d/%d dar=%d/%d), size %"
+      G_GSIZE_FORMAT " -> %s to=%dx%d (par=%d/%d dar=%d/%d borders=%d:%d), "
+      "size %" G_GSIZE_FORMAT,
+      gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (in_info)),
+      in_info->width, in_info->height, in_info->par_n, in_info->par_d,
+      from_dar_n, from_dar_d, in_info->size,
+      gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (out_info)),
+      out_info->width,
+      out_info->height, out_info->par_n, out_info->par_d, to_dar_n, to_dar_d,
+      self->borders_w, self->borders_h, out_info->size);
+
+  return TRUE;
+}
+
+static gboolean
+gst_cuda_base_convert_filter_meta (GstBaseTransform * trans, GstQuery * query,
+    GType api, const GstStructure * params)
+{
+  /* This element cannot passthrough the crop meta, because it would convert the
+   * wrong sub-region of the image, and worst, our output image may not be large
+   * enough for the crop to be applied later */
+  if (api == GST_VIDEO_CROP_META_API_TYPE)
+    return FALSE;
+
+  /* propose all other metadata upstream */
+  return TRUE;
+}
+
+static GstFlowReturn
+gst_cuda_base_convert_transform (GstBaseTransform * trans,
+    GstBuffer * inbuf, GstBuffer * outbuf)
+{
+  GstCudaBaseConvert *self = GST_CUDA_BASE_CONVERT (trans);
+  GstCudaBaseTransform *btrans = GST_CUDA_BASE_TRANSFORM (trans);
+  GstVideoFrame in_frame, out_frame;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstMemory *mem;
+
+  if (gst_buffer_n_memory (inbuf) != 1) {
+    GST_ERROR_OBJECT (self, "Invalid input buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  mem = gst_buffer_peek_memory (inbuf, 0);
+  if (!gst_is_cuda_memory (mem)) {
+    GST_ERROR_OBJECT (self, "Input buffer is not CUDA");
+    return GST_FLOW_ERROR;
+  }
+
+  if (gst_buffer_n_memory (outbuf) != 1) {
+    GST_ERROR_OBJECT (self, "Invalid output buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  mem = gst_buffer_peek_memory (outbuf, 0);
+  if (!gst_is_cuda_memory (mem)) {
+    GST_ERROR_OBJECT (self, "Input buffer is not CUDA");
+    return GST_FLOW_ERROR;
+  }
+
+  if (!gst_video_frame_map (&in_frame, &btrans->in_info, inbuf,
+          GST_MAP_READ | GST_MAP_CUDA)) {
+    GST_ERROR_OBJECT (self, "Failed to map input buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  if (!gst_video_frame_map (&out_frame, &btrans->out_info, outbuf,
+          GST_MAP_WRITE | GST_MAP_CUDA)) {
+    gst_video_frame_unmap (&in_frame);
+    GST_ERROR_OBJECT (self, "Failed to map output buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  if (!gst_cuda_converter_convert_frame (self->converter, &in_frame, &out_frame,
+          btrans->cuda_stream)) {
+    GST_ERROR_OBJECT (self, "Failed to convert frame");
+    ret = GST_FLOW_ERROR;
+  }
+
+  gst_video_frame_unmap (&out_frame);
+  gst_video_frame_unmap (&in_frame);
+
+  return ret;
+}
+
+static void
+gst_cuda_base_convert_set_add_border (GstCudaBaseConvert * self,
+    gboolean add_border)
+{
+  gboolean prev = self->add_borders;
+
+  self->add_borders = add_border;
+  if (prev != self->add_borders)
+    gst_base_transform_reconfigure_src (GST_BASE_TRANSFORM_CAST (self));
+}
+
+/**
+ * SECTION:element-cudaconvertscale
+ * @title: cudaconvertscale
+ * @short_description: A CUDA based color conversion and video resizing element
+ *
+ * This element resizes video frames and change color space.
+ * By default the element will try to negotiate to the same size on the source
+ * and sinkpad so that no scaling is needed.
+ * It is therefore safe to insert this element in a pipeline to
+ * get more robust behaviour without any cost if no scaling is needed.
+ *
+ * ## Example launch line
+ * ```
+ * gst-launch-1.0 videotestsrc ! cudaupload ! cudaconvertscale ! cudadownload ! autovideosink
+ * ```
+ *
+ * Since: 1.22
+ */
+
+enum
+{
+  PROP_CONVERT_SCALE_0,
+  PROP_CONVERT_SCALE_ADD_BORDERS,
+};
+
+struct _GstCudaConvertScale
+{
+  GstCudaBaseConvert parent;
+};
+
+static void gst_cuda_convert_scale_set_property (GObject * object,
+    guint prop_id, const GValue * value, GParamSpec * pspec);
+static void gst_cuda_convert_scale_get_property (GObject * object,
+    guint prop_id, GValue * value, GParamSpec * pspec);
+
+G_DEFINE_TYPE (GstCudaConvertScale, gst_cuda_convert_scale,
+    GST_TYPE_CUDA_BASE_CONVERT);
+
+static void
+gst_cuda_convert_scale_class_init (GstCudaConvertScaleClass * klass)
+{
+  GObjectClass *gobject_class = G_OBJECT_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+
+  gobject_class->set_property = gst_cuda_convert_scale_set_property;
+  gobject_class->get_property = gst_cuda_convert_scale_get_property;
+
+  g_object_class_install_property (gobject_class,
+      PROP_CONVERT_SCALE_ADD_BORDERS,
+      g_param_spec_boolean ("add-borders", "Add Borders",
+          "Add borders if necessary to keep the display aspect ratio",
+          DEFAULT_ADD_BORDERS, (GParamFlags) (GST_PARAM_MUTABLE_PLAYING |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  gst_element_class_set_static_metadata (element_class,
+      "CUDA colorspace converter and scaler",
+      "Filter/Converter/Video/Scaler/Colorspace/Hardware",
+      "Resizes video and allow color conversion using CUDA",
+      "Seungha Yang <seungha@centricular.com>");
+}
+
+static void
+gst_cuda_convert_scale_init (GstCudaConvertScale * self)
+{
+}
+
+static void
+gst_cuda_convert_scale_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstCudaBaseConvert *base = GST_CUDA_BASE_CONVERT (object);
+
+  switch (prop_id) {
+    case PROP_CONVERT_SCALE_ADD_BORDERS:
+      gst_cuda_base_convert_set_add_border (base, g_value_get_boolean (value));
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_cuda_convert_scale_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstCudaBaseConvert *base = GST_CUDA_BASE_CONVERT (object);
+
+  switch (prop_id) {
+    case PROP_CONVERT_SCALE_ADD_BORDERS:
+      g_value_set_boolean (value, base->add_borders);
+      break;
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+/**
+ * SECTION:element-cudaconvert
+ * @title: cudaconvert
+ *
+ * Convert video frames between supported video formats.
+ *
+ * ## Example launch line
+ * ```
+ * gst-launch-1.0 videotestsrc ! cudaupload ! cudaconvert ! cudadownload ! autovideosink
+ * ```
+ *
+ * Since: 1.20
+ */
+
+struct _GstCudaConvert
+{
+  GstCudaBaseConvert parent;
+};
+
+static GstCaps *gst_cuda_convert_transform_caps (GstBaseTransform *
+    trans, GstPadDirection direction, GstCaps * caps, GstCaps * filter);
+static GstCaps *gst_cuda_convert_fixate_caps (GstBaseTransform * base,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps);
+
+G_DEFINE_TYPE (GstCudaConvert, gst_cuda_convert, GST_TYPE_CUDA_BASE_CONVERT);
+
+static void
+gst_cuda_convert_class_init (GstCudaConvertClass * klass)
+{
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+  GstBaseTransformClass *trans_class = GST_BASE_TRANSFORM_CLASS (klass);
+
+  gst_element_class_set_static_metadata (element_class,
+      "CUDA colorspace converter",
+      "Filter/Converter/Video/Hardware",
+      "Converts video from one colorspace to another using CUDA",
+      "Seungha Yang <seungha.yang@navercorp.com>");
+
+  trans_class->transform_caps =
+      GST_DEBUG_FUNCPTR (gst_cuda_convert_transform_caps);
+  trans_class->fixate_caps = GST_DEBUG_FUNCPTR (gst_cuda_convert_fixate_caps);
+}
+
+static void
+gst_cuda_convert_init (GstCudaConvert * self)
+{
+}
+
+static GstCaps *
+gst_cuda_convert_transform_caps (GstBaseTransform *
+    trans, GstPadDirection direction, GstCaps * caps, GstCaps * filter)
+{
+  GstCaps *tmp, *tmp2;
+  GstCaps *result;
+
+  /* Get all possible caps that we can transform to */
+  tmp = gst_cuda_base_convert_caps_remove_format_info (caps);
+
+  if (filter) {
+    tmp2 = gst_caps_intersect_full (filter, tmp, GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (tmp);
+    tmp = tmp2;
+  }
+
+  result = tmp;
+
+  GST_DEBUG_OBJECT (trans, "transformed %" GST_PTR_FORMAT " into %"
+      GST_PTR_FORMAT, caps, result);
+
+  return result;
+}
+
+static GstCaps *
+gst_cuda_convert_fixate_caps (GstBaseTransform * base,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps)
+{
+  GstCaps *format = NULL;
+
+  GST_DEBUG_OBJECT (base,
+      "trying to fixate othercaps %" GST_PTR_FORMAT " based on caps %"
+      GST_PTR_FORMAT, othercaps, caps);
+
+  format = gst_cuda_base_convert_get_fixed_format (base, direction, caps,
+      othercaps);
+  gst_caps_unref (othercaps);
+
+  if (gst_caps_is_empty (format)) {
+    GST_ERROR_OBJECT (base, "Could not convert formats");
+  } else {
+    GST_DEBUG_OBJECT (base, "fixated othercaps to %" GST_PTR_FORMAT, format);
+  }
+
+  return format;
+}
+
+/**
+ * SECTION:element-cudascale
+ * @title: cudascale
+ *
+ * A CUDA based video resizing element
+ *
+ * ## Example launch line
+ * ```
+ * gst-launch-1.0 videotestsrc ! video/x-raw,width=640,height=480 ! cudaupload ! cudascale ! cudadownload ! video/x-raw,width=1280,height=720 ! fakesink
+ * ```
+ *  This will upload a 640x480 resolution test video to CUDA
+ * memory space and resize it to 1280x720 resolution. Then a resized CUDA
+ * frame will be downloaded to system memory space.
+ *
+ * Since: 1.20
+ */
+
+enum
+{
+  PROP_SCALE_0,
+  PROP_SCALE_ADD_BORDERS,
+};
+
+struct _GstCudaScale
+{
+  GstCudaBaseConvert parent;
+};
+
+static void gst_cuda_scale_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec);
+static void gst_cuda_scale_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec);
+static GstCaps *gst_cuda_scale_transform_caps (GstBaseTransform *
+    trans, GstPadDirection direction, GstCaps * caps, GstCaps * filter);
+static GstCaps *gst_cuda_scale_fixate_caps (GstBaseTransform * base,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps);
+
+G_DEFINE_TYPE (GstCudaScale, gst_cuda_scale, GST_TYPE_CUDA_BASE_CONVERT);
+
+static void
+gst_cuda_scale_class_init (GstCudaScaleClass * klass)
+{
+  GObjectClass *gobject_class = G_OBJECT_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+  GstBaseTransformClass *trans_class = GST_BASE_TRANSFORM_CLASS (klass);
+
+  gobject_class->set_property = gst_cuda_scale_set_property;
+  gobject_class->get_property = gst_cuda_scale_get_property;
+
+  /**
+   * GstCudaScale:add-borders:
+   *
+   * Add borders if necessary to keep the display aspect ratio
+   *
+   * Since: 1.22
+   */
+  g_object_class_install_property (gobject_class, PROP_SCALE_ADD_BORDERS,
+      g_param_spec_boolean ("add-borders", "Add Borders",
+          "Add borders if necessary to keep the display aspect ratio",
+          DEFAULT_ADD_BORDERS, (GParamFlags) (GST_PARAM_MUTABLE_PLAYING |
+              G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  gst_element_class_set_static_metadata (element_class,
+      "CUDA video scaler",
+      "Filter/Converter/Video/Scaler/Hardware",
+      "Resize video using CUDA", "Seungha Yang <seungha.yang@navercorp.com>");
+
+  trans_class->transform_caps =
+      GST_DEBUG_FUNCPTR (gst_cuda_scale_transform_caps);
+  trans_class->fixate_caps = GST_DEBUG_FUNCPTR (gst_cuda_scale_fixate_caps);
+}
+
+static void
+gst_cuda_scale_init (GstCudaScale * self)
+{
+}
+
+static void
+gst_cuda_scale_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstCudaBaseConvert *base = GST_CUDA_BASE_CONVERT (object);
+
+  switch (prop_id) {
+    case PROP_SCALE_ADD_BORDERS:
+      gst_cuda_base_convert_set_add_border (base, g_value_get_boolean (value));
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_cuda_scale_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstCudaBaseConvert *base = GST_CUDA_BASE_CONVERT (object);
+
+  switch (prop_id) {
+    case PROP_SCALE_ADD_BORDERS:
+      g_value_set_boolean (value, base->add_borders);
+      break;
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static GstCaps *
+gst_cuda_scale_transform_caps (GstBaseTransform * trans,
+    GstPadDirection direction, GstCaps * caps, GstCaps * filter)
+{
+  GstCaps *tmp, *tmp2;
+  GstCaps *result;
+
+  /* Get all possible caps that we can transform to */
+  tmp = gst_cuda_base_convert_caps_rangify_size_info (caps);
+
+  if (filter) {
+    tmp2 = gst_caps_intersect_full (filter, tmp, GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (tmp);
+    tmp = tmp2;
+  }
+
+  result = tmp;
+
+  GST_DEBUG_OBJECT (trans, "transformed %" GST_PTR_FORMAT " into %"
+      GST_PTR_FORMAT, caps, result);
+
+  return result;
+}
+
+static GstCaps *
+gst_cuda_scale_fixate_caps (GstBaseTransform * base,
+    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps)
+{
+  GST_DEBUG_OBJECT (base,
+      "trying to fixate othercaps %" GST_PTR_FORMAT " based on caps %"
+      GST_PTR_FORMAT, othercaps, caps);
+
+  othercaps =
+      gst_cuda_base_convert_fixate_size (base, direction, caps, othercaps);
+
+  GST_DEBUG_OBJECT (base, "fixated othercaps to %" GST_PTR_FORMAT, othercaps);
+
+  return othercaps;
+}
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvertscale.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvertscale.h
new file mode 100644
index 0000000000..2aca840297
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaconvertscale.h
@@ -0,0 +1,58 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#pragma once
+
+#include <gst/gst.h>
+#include "gstcudabasetransform.h"
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_CUDA_BASE_CONVERT             (gst_cuda_base_convert_get_type())
+#define GST_CUDA_BASE_CONVERT(obj)             (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_CUDA_BASE_CONVERT,GstCudaBaseConvert))
+#define GST_CUDA_BASE_CONVERT_CLASS(klass)     (G_TYPE_CHECK_CLASS_CAST((klass), GST_TYPE_CUDA_BASE_CONVERT,GstCudaBaseConvertClass))
+#define GST_CUDA_BASE_CONVERT_GET_CLASS(obj)   (G_TYPE_INSTANCE_GET_CLASS((obj), GST_TYPE_CUDA_BASE_CONVERT,GstCudaBaseConvertClass))
+#define GST_IS_CUDA_BASE_CONVERT(obj)          (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_CUDA_BASE_CONVERT))
+#define GST_IS_CUDA_BASE_CONVERT_CLASS(klass)  (G_TYPE_CHECK_CLASS_TYPE((klass), GST_TYPE_CUDA_BASE_CONVERT))
+
+typedef struct _GstCudaBaseConvert GstCudaBaseConvert;
+typedef struct _GstCudaBaseConvertClass GstCudaBaseConvertClass;
+
+struct _GstCudaBaseConvertClass
+{
+  GstCudaBaseTransform parent_class;
+};
+
+GType gst_cuda_base_convert_get_type (void);
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstCudaBaseConvert, gst_object_unref)
+
+#define GST_TYPE_CUDA_CONVERT_SCALE (gst_cuda_convert_scale_get_type())
+G_DECLARE_FINAL_TYPE (GstCudaConvertScale, gst_cuda_convert_scale,
+    GST, CUDA_CONVERT_SCALE, GstCudaBaseConvert)
+
+#define GST_TYPE_CUDA_CONVERT (gst_cuda_convert_get_type())
+G_DECLARE_FINAL_TYPE (GstCudaConvert, gst_cuda_convert,
+    GST, CUDA_CONVERT, GstCudaBaseConvert)
+
+#define GST_TYPE_CUDA_SCALE (gst_cuda_scale_get_type())
+G_DECLARE_FINAL_TYPE (GstCudaScale, gst_cuda_scale,
+    GST, CUDA_SCALE, GstCudaBaseConvert)
+
+G_END_DECLS
+
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudafilter.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudafilter.c
index 001dbd2cbc..9118a5ce5d 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudafilter.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudafilter.c
@@ -25,8 +25,7 @@
 #include <gst/cuda/gstcudanvrtc.h>
 
 #include "gstcudafilter.h"
-#include "gstcudaconvert.h"
-#include "gstcudascale.h"
+#include "gstcudaconvertscale.h"
 
 /* *INDENT-OFF* */
 const gchar *nvrtc_test_source =
@@ -53,4 +52,6 @@ gst_cuda_filter_plugin_init (GstPlugin * plugin)
       GST_TYPE_CUDA_CONVERT);
   gst_element_register (plugin, "cudascale", GST_RANK_NONE,
       GST_TYPE_CUDA_SCALE);
+  gst_element_register (plugin, "cudaconvertscale", GST_RANK_NONE,
+      GST_TYPE_CUDA_CONVERT_SCALE);
 }
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaformat.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaformat.h
index 5f756af1ff..2a29657668 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaformat.h
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudaformat.h
@@ -26,12 +26,12 @@ G_BEGIN_DECLS
 #define GST_CUDA_FORMATS \
     "{ I420, YV12, NV12, NV21, P010_10LE, P016_LE, I420_10LE, Y444, Y444_16LE, " \
     "BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, " \
-    "Y42B, I422_10LE, I422_12LE, YUY2, UYVY }"
+    "Y42B, I422_10LE, I422_12LE, YUY2, UYVY, RGBP, BGRP, GBR, GBRA }"
 
 #define GST_CUDA_GL_FORMATS \
     "{ I420, YV12, NV12, NV21, P010_10LE, P016_LE, Y444, " \
     "BGRA, RGBA, RGBx, BGRx, ARGB, ABGR, RGB, BGR, BGR10A2_LE, RGB10A2_LE, " \
-    "YUY2, UYVY }"
+    "YUY2, UYVY, RGBP, BGRP, GBR, GBRA }"
 
 #define GST_CUDA_D3D11_FORMATS \
     "{ I420, YV12, I420_10LE, Y444, Y444_16LE, " \
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudascale.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudascale.c
deleted file mode 100644
index 06fb782921..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudascale.c
+++ /dev/null
@@ -1,608 +0,0 @@
-/* GStreamer
- * Copyright (C) <1999> Erik Walthinsen <omega@cse.ogi.edu>
- * Copyright (C) 2005-2012 David Schleef <ds@schleef.org>
- * Copyright (C) <2019> Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-/**
- * SECTION:element-cudascale
- * @title: cudascale
- * @see_also: cudaconvert
- *
- * This element resizes video frames. By default the element will try to
- * negotiate to the same size on the source and sinkpad so that no scaling
- * is needed. It is therefore safe to insert this element in a pipeline to
- * get more robust behaviour without any cost if no scaling is needed.
- *
- * This element supports some YUV formats which are are also supported by
- * nvidia encoders and decoders.
- *
- * ## Example pipelines
- * |[
- * gst-launch-1.0 -v filesrc location=videotestsrc.mp4 ! qtdemux ! h264parse ! nvh264dec ! cudaconvert ! cudascale ! cudaconvert ! cudadownload ! autovideosink
- * ]|
- *  Decode a mp4/h264 and display the video. If the video sink chosen
- * cannot perform scaling, the video scaling will be performed by cudascale
- * |[
- * gst-launch-1.0 -v filesrc location=videotestsrc.mp4 ! qtdemux ! h264parse ! nvh264dec ! cudaconvert ! cudascale ! cudaconvert ! cudadownload ! video/x-raw,width=100 ! autovideosink
- * ]|
- *  Decode an mp4/h264 and display the video with a width of 100.
- *
- * Since: 1.20
- */
-
-#ifdef HAVE_CONFIG_H
-#  include <config.h>
-#endif
-
-#include <gst/cuda/gstcudautils.h>
-
-#include "gstcudascale.h"
-
-GST_DEBUG_CATEGORY_STATIC (gst_cuda_scale_debug);
-#define GST_CAT_DEFAULT gst_cuda_scale_debug
-
-#define gst_cuda_scale_parent_class parent_class
-G_DEFINE_TYPE (GstCudaScale, gst_cuda_scale, GST_TYPE_CUDA_BASE_FILTER);
-
-static GstCaps *gst_cuda_scale_transform_caps (GstBaseTransform * trans,
-    GstPadDirection direction, GstCaps * caps, GstCaps * filter);
-static GstCaps *gst_cuda_scale_fixate_caps (GstBaseTransform * base,
-    GstPadDirection direction, GstCaps * caps, GstCaps * othercaps);
-static gboolean gst_cuda_scale_set_info (GstCudaBaseTransform * filter,
-    GstCaps * incaps, GstVideoInfo * in_info, GstCaps * outcaps,
-    GstVideoInfo * out_info);
-
-static void
-gst_cuda_scale_class_init (GstCudaScaleClass * klass)
-{
-  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
-  GstBaseTransformClass *trans_class = GST_BASE_TRANSFORM_CLASS (klass);
-  GstCudaBaseTransformClass *btrans_class =
-      GST_CUDA_BASE_TRANSFORM_CLASS (klass);
-
-  gst_element_class_set_static_metadata (element_class,
-      "CUDA Video scaler",
-      "Filter/Converter/Video/Scaler/Hardware",
-      "Resizes Video using CUDA", "Seungha Yang <seungha.yang@navercorp.com>");
-
-  trans_class->transform_caps =
-      GST_DEBUG_FUNCPTR (gst_cuda_scale_transform_caps);
-  trans_class->fixate_caps = GST_DEBUG_FUNCPTR (gst_cuda_scale_fixate_caps);
-
-  btrans_class->set_info = GST_DEBUG_FUNCPTR (gst_cuda_scale_set_info);
-
-  GST_DEBUG_CATEGORY_INIT (gst_cuda_scale_debug,
-      "cudascale", 0, "Video Resize using CUDA");
-}
-
-static void
-gst_cuda_scale_init (GstCudaScale * cuda)
-{
-}
-
-static GstCaps *
-gst_cuda_scale_transform_caps (GstBaseTransform * trans,
-    GstPadDirection direction, GstCaps * caps, GstCaps * filter)
-{
-  GstCaps *ret;
-  GstStructure *structure;
-  GstCapsFeatures *features;
-  gint i, n;
-
-  GST_DEBUG_OBJECT (trans,
-      "Transforming caps %" GST_PTR_FORMAT " in direction %s", caps,
-      (direction == GST_PAD_SINK) ? "sink" : "src");
-
-  ret = gst_caps_new_empty ();
-  n = gst_caps_get_size (caps);
-  for (i = 0; i < n; i++) {
-    structure = gst_caps_get_structure (caps, i);
-    features = gst_caps_get_features (caps, i);
-
-    /* If this is already expressed by the existing caps
-     * skip this structure */
-    if (i > 0 && gst_caps_is_subset_structure_full (ret, structure, features))
-      continue;
-
-    /* make copy */
-    structure = gst_structure_copy (structure);
-
-    gst_structure_set (structure, "width", GST_TYPE_INT_RANGE, 1, G_MAXINT,
-        "height", GST_TYPE_INT_RANGE, 1, G_MAXINT, NULL);
-
-    /* if pixel aspect ratio, make a range of it */
-    if (gst_structure_has_field (structure, "pixel-aspect-ratio")) {
-      gst_structure_set (structure, "pixel-aspect-ratio",
-          GST_TYPE_FRACTION_RANGE, 1, G_MAXINT, G_MAXINT, 1, NULL);
-    }
-
-    gst_caps_append_structure_full (ret, structure,
-        gst_caps_features_copy (features));
-  }
-
-  if (filter) {
-    GstCaps *intersection;
-
-    intersection =
-        gst_caps_intersect_full (filter, ret, GST_CAPS_INTERSECT_FIRST);
-    gst_caps_unref (ret);
-    ret = intersection;
-  }
-
-  GST_DEBUG_OBJECT (trans, "returning caps: %" GST_PTR_FORMAT, ret);
-
-  return ret;
-}
-
-/* fork of gstvideoscale */
-static GstCaps *
-gst_cuda_scale_fixate_caps (GstBaseTransform * base, GstPadDirection direction,
-    GstCaps * caps, GstCaps * othercaps)
-{
-  GstStructure *ins, *outs;
-  const GValue *from_par, *to_par;
-  GValue fpar = G_VALUE_INIT;
-  GValue tpar = G_VALUE_INIT;
-
-  othercaps = gst_caps_truncate (othercaps);
-  othercaps = gst_caps_make_writable (othercaps);
-
-  GST_DEBUG_OBJECT (base, "trying to fixate othercaps %" GST_PTR_FORMAT
-      " based on caps %" GST_PTR_FORMAT, othercaps, caps);
-
-  ins = gst_caps_get_structure (caps, 0);
-  outs = gst_caps_get_structure (othercaps, 0);
-
-  from_par = gst_structure_get_value (ins, "pixel-aspect-ratio");
-  to_par = gst_structure_get_value (outs, "pixel-aspect-ratio");
-
-  /* If we're fixating from the sinkpad we always set the PAR and
-   * assume that missing PAR on the sinkpad means 1/1 and
-   * missing PAR on the srcpad means undefined
-   */
-  if (direction == GST_PAD_SINK) {
-    if (!from_par) {
-      g_value_init (&fpar, GST_TYPE_FRACTION);
-      gst_value_set_fraction (&fpar, 1, 1);
-      from_par = &fpar;
-    }
-    if (!to_par) {
-      g_value_init (&tpar, GST_TYPE_FRACTION_RANGE);
-      gst_value_set_fraction_range_full (&tpar, 1, G_MAXINT, G_MAXINT, 1);
-      to_par = &tpar;
-    }
-  } else {
-    if (!to_par) {
-      g_value_init (&tpar, GST_TYPE_FRACTION);
-      gst_value_set_fraction (&tpar, 1, 1);
-      to_par = &tpar;
-
-      gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION, 1, 1,
-          NULL);
-    }
-    if (!from_par) {
-      g_value_init (&fpar, GST_TYPE_FRACTION);
-      gst_value_set_fraction (&fpar, 1, 1);
-      from_par = &fpar;
-    }
-  }
-
-  /* we have both PAR but they might not be fixated */
-  {
-    gint from_w, from_h, from_par_n, from_par_d, to_par_n, to_par_d;
-    gint w = 0, h = 0;
-    gint from_dar_n, from_dar_d;
-    gint num, den;
-
-    /* from_par should be fixed */
-    g_return_val_if_fail (gst_value_is_fixed (from_par), othercaps);
-
-    from_par_n = gst_value_get_fraction_numerator (from_par);
-    from_par_d = gst_value_get_fraction_denominator (from_par);
-
-    gst_structure_get_int (ins, "width", &from_w);
-    gst_structure_get_int (ins, "height", &from_h);
-
-    gst_structure_get_int (outs, "width", &w);
-    gst_structure_get_int (outs, "height", &h);
-
-    /* if both width and height are already fixed, we can't do anything
-     * about it anymore */
-    if (w && h) {
-      guint n, d;
-
-      GST_DEBUG_OBJECT (base, "dimensions already set to %dx%d, not fixating",
-          w, h);
-      if (!gst_value_is_fixed (to_par)) {
-        if (gst_video_calculate_display_ratio (&n, &d, from_w, from_h,
-                from_par_n, from_par_d, w, h)) {
-          GST_DEBUG_OBJECT (base, "fixating to_par to %dx%d", n, d);
-          if (gst_structure_has_field (outs, "pixel-aspect-ratio"))
-            gst_structure_fixate_field_nearest_fraction (outs,
-                "pixel-aspect-ratio", n, d);
-          else if (n != d)
-            gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-                n, d, NULL);
-        }
-      }
-      goto done;
-    }
-
-    /* Calculate input DAR */
-    if (!gst_util_fraction_multiply (from_w, from_h, from_par_n, from_par_d,
-            &from_dar_n, &from_dar_d)) {
-      GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-          ("Error calculating the output scaled size - integer overflow"));
-      goto done;
-    }
-
-    GST_DEBUG_OBJECT (base, "Input DAR is %d/%d", from_dar_n, from_dar_d);
-
-    /* If either width or height are fixed there's not much we
-     * can do either except choosing a height or width and PAR
-     * that matches the DAR as good as possible
-     */
-    if (h) {
-      GstStructure *tmp;
-      gint set_w, set_par_n, set_par_d;
-
-      GST_DEBUG_OBJECT (base, "height is fixed (%d)", h);
-
-      /* If the PAR is fixed too, there's not much to do
-       * except choosing the width that is nearest to the
-       * width with the same DAR */
-      if (gst_value_is_fixed (to_par)) {
-        to_par_n = gst_value_get_fraction_numerator (to_par);
-        to_par_d = gst_value_get_fraction_denominator (to_par);
-
-        GST_DEBUG_OBJECT (base, "PAR is fixed %d/%d", to_par_n, to_par_d);
-
-        if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, to_par_d,
-                to_par_n, &num, &den)) {
-          GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-              ("Error calculating the output scaled size - integer overflow"));
-          goto done;
-        }
-
-        w = (guint) gst_util_uint64_scale_int_round (h, num, den);
-        gst_structure_fixate_field_nearest_int (outs, "width", w);
-
-        goto done;
-      }
-
-      /* The PAR is not fixed and it's quite likely that we can set
-       * an arbitrary PAR. */
-
-      /* Check if we can keep the input width */
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "width", from_w);
-      gst_structure_get_int (tmp, "width", &set_w);
-
-      /* Might have failed but try to keep the DAR nonetheless by
-       * adjusting the PAR */
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, h, set_w,
-              &to_par_n, &to_par_d)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        gst_structure_free (tmp);
-        goto done;
-      }
-
-      if (!gst_structure_has_field (tmp, "pixel-aspect-ratio"))
-        gst_structure_set_value (tmp, "pixel-aspect-ratio", to_par);
-      gst_structure_fixate_field_nearest_fraction (tmp, "pixel-aspect-ratio",
-          to_par_n, to_par_d);
-      gst_structure_get_fraction (tmp, "pixel-aspect-ratio", &set_par_n,
-          &set_par_d);
-      gst_structure_free (tmp);
-
-      /* Check if the adjusted PAR is accepted */
-      if (set_par_n == to_par_n && set_par_d == to_par_d) {
-        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-            set_par_n != set_par_d)
-          gst_structure_set (outs, "width", G_TYPE_INT, set_w,
-              "pixel-aspect-ratio", GST_TYPE_FRACTION, set_par_n, set_par_d,
-              NULL);
-        goto done;
-      }
-
-      /* Otherwise scale the width to the new PAR and check if the
-       * adjusted with is accepted. If all that fails we can't keep
-       * the DAR */
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_par_d,
-              set_par_n, &num, &den)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        goto done;
-      }
-
-      w = (guint) gst_util_uint64_scale_int_round (h, num, den);
-      gst_structure_fixate_field_nearest_int (outs, "width", w);
-      if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-          set_par_n != set_par_d)
-        gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-            set_par_n, set_par_d, NULL);
-
-      goto done;
-    } else if (w) {
-      GstStructure *tmp;
-      gint set_h, set_par_n, set_par_d;
-
-      GST_DEBUG_OBJECT (base, "width is fixed (%d)", w);
-
-      /* If the PAR is fixed too, there's not much to do
-       * except choosing the height that is nearest to the
-       * height with the same DAR */
-      if (gst_value_is_fixed (to_par)) {
-        to_par_n = gst_value_get_fraction_numerator (to_par);
-        to_par_d = gst_value_get_fraction_denominator (to_par);
-
-        GST_DEBUG_OBJECT (base, "PAR is fixed %d/%d", to_par_n, to_par_d);
-
-        if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, to_par_d,
-                to_par_n, &num, &den)) {
-          GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-              ("Error calculating the output scaled size - integer overflow"));
-          goto done;
-        }
-
-        h = (guint) gst_util_uint64_scale_int_round (w, den, num);
-        gst_structure_fixate_field_nearest_int (outs, "height", h);
-
-        goto done;
-      }
-
-      /* The PAR is not fixed and it's quite likely that we can set
-       * an arbitrary PAR. */
-
-      /* Check if we can keep the input height */
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "height", from_h);
-      gst_structure_get_int (tmp, "height", &set_h);
-
-      /* Might have failed but try to keep the DAR nonetheless by
-       * adjusting the PAR */
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_h, w,
-              &to_par_n, &to_par_d)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        gst_structure_free (tmp);
-        goto done;
-      }
-      if (!gst_structure_has_field (tmp, "pixel-aspect-ratio"))
-        gst_structure_set_value (tmp, "pixel-aspect-ratio", to_par);
-      gst_structure_fixate_field_nearest_fraction (tmp, "pixel-aspect-ratio",
-          to_par_n, to_par_d);
-      gst_structure_get_fraction (tmp, "pixel-aspect-ratio", &set_par_n,
-          &set_par_d);
-      gst_structure_free (tmp);
-
-      /* Check if the adjusted PAR is accepted */
-      if (set_par_n == to_par_n && set_par_d == to_par_d) {
-        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-            set_par_n != set_par_d)
-          gst_structure_set (outs, "height", G_TYPE_INT, set_h,
-              "pixel-aspect-ratio", GST_TYPE_FRACTION, set_par_n, set_par_d,
-              NULL);
-        goto done;
-      }
-
-      /* Otherwise scale the height to the new PAR and check if the
-       * adjusted with is accepted. If all that fails we can't keep
-       * the DAR */
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_par_d,
-              set_par_n, &num, &den)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        goto done;
-      }
-
-      h = (guint) gst_util_uint64_scale_int_round (w, den, num);
-      gst_structure_fixate_field_nearest_int (outs, "height", h);
-      if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-          set_par_n != set_par_d)
-        gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-            set_par_n, set_par_d, NULL);
-
-      goto done;
-    } else if (gst_value_is_fixed (to_par)) {
-      GstStructure *tmp;
-      gint set_h, set_w, f_h, f_w;
-
-      to_par_n = gst_value_get_fraction_numerator (to_par);
-      to_par_d = gst_value_get_fraction_denominator (to_par);
-
-      /* Calculate scale factor for the PAR change */
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, to_par_n,
-              to_par_d, &num, &den)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        goto done;
-      }
-
-      /* Try to keep the input height (because of interlacing) */
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "height", from_h);
-      gst_structure_get_int (tmp, "height", &set_h);
-
-      /* This might have failed but try to scale the width
-       * to keep the DAR nonetheless */
-      w = (guint) gst_util_uint64_scale_int_round (set_h, num, den);
-      gst_structure_fixate_field_nearest_int (tmp, "width", w);
-      gst_structure_get_int (tmp, "width", &set_w);
-      gst_structure_free (tmp);
-
-      /* We kept the DAR and the height is nearest to the original height */
-      if (set_w == w) {
-        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
-            G_TYPE_INT, set_h, NULL);
-        goto done;
-      }
-
-      f_h = set_h;
-      f_w = set_w;
-
-      /* If the former failed, try to keep the input width at least */
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "width", from_w);
-      gst_structure_get_int (tmp, "width", &set_w);
-
-      /* This might have failed but try to scale the width
-       * to keep the DAR nonetheless */
-      h = (guint) gst_util_uint64_scale_int_round (set_w, den, num);
-      gst_structure_fixate_field_nearest_int (tmp, "height", h);
-      gst_structure_get_int (tmp, "height", &set_h);
-      gst_structure_free (tmp);
-
-      /* We kept the DAR and the width is nearest to the original width */
-      if (set_h == h) {
-        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
-            G_TYPE_INT, set_h, NULL);
-        goto done;
-      }
-
-      /* If all this failed, keep the dimensions with the DAR that was closest
-       * to the correct DAR. This changes the DAR but there's not much else to
-       * do here.
-       */
-      if (set_w * ABS (set_h - h) < ABS (f_w - w) * f_h) {
-        f_h = set_h;
-        f_w = set_w;
-      }
-      gst_structure_set (outs, "width", G_TYPE_INT, f_w, "height", G_TYPE_INT,
-          f_h, NULL);
-      goto done;
-    } else {
-      GstStructure *tmp;
-      gint set_h, set_w, set_par_n, set_par_d, tmp2;
-
-      /* width, height and PAR are not fixed but passthrough is not possible */
-
-      /* First try to keep the height and width as good as possible
-       * and scale PAR */
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "height", from_h);
-      gst_structure_get_int (tmp, "height", &set_h);
-      gst_structure_fixate_field_nearest_int (tmp, "width", from_w);
-      gst_structure_get_int (tmp, "width", &set_w);
-
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_h, set_w,
-              &to_par_n, &to_par_d)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        gst_structure_free (tmp);
-        goto done;
-      }
-
-      if (!gst_structure_has_field (tmp, "pixel-aspect-ratio"))
-        gst_structure_set_value (tmp, "pixel-aspect-ratio", to_par);
-      gst_structure_fixate_field_nearest_fraction (tmp, "pixel-aspect-ratio",
-          to_par_n, to_par_d);
-      gst_structure_get_fraction (tmp, "pixel-aspect-ratio", &set_par_n,
-          &set_par_d);
-      gst_structure_free (tmp);
-
-      if (set_par_n == to_par_n && set_par_d == to_par_d) {
-        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
-            G_TYPE_INT, set_h, NULL);
-
-        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-            set_par_n != set_par_d)
-          gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-              set_par_n, set_par_d, NULL);
-        goto done;
-      }
-
-      /* Otherwise try to scale width to keep the DAR with the set
-       * PAR and height */
-      if (!gst_util_fraction_multiply (from_dar_n, from_dar_d, set_par_d,
-              set_par_n, &num, &den)) {
-        GST_ELEMENT_ERROR (base, CORE, NEGOTIATION, (NULL),
-            ("Error calculating the output scaled size - integer overflow"));
-        goto done;
-      }
-
-      w = (guint) gst_util_uint64_scale_int_round (set_h, num, den);
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "width", w);
-      gst_structure_get_int (tmp, "width", &tmp2);
-      gst_structure_free (tmp);
-
-      if (tmp2 == w) {
-        gst_structure_set (outs, "width", G_TYPE_INT, tmp2, "height",
-            G_TYPE_INT, set_h, NULL);
-        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-            set_par_n != set_par_d)
-          gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-              set_par_n, set_par_d, NULL);
-        goto done;
-      }
-
-      /* ... or try the same with the height */
-      h = (guint) gst_util_uint64_scale_int_round (set_w, den, num);
-      tmp = gst_structure_copy (outs);
-      gst_structure_fixate_field_nearest_int (tmp, "height", h);
-      gst_structure_get_int (tmp, "height", &tmp2);
-      gst_structure_free (tmp);
-
-      if (tmp2 == h) {
-        gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
-            G_TYPE_INT, tmp2, NULL);
-        if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-            set_par_n != set_par_d)
-          gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-              set_par_n, set_par_d, NULL);
-        goto done;
-      }
-
-      /* If all fails we can't keep the DAR and take the nearest values
-       * for everything from the first try */
-      gst_structure_set (outs, "width", G_TYPE_INT, set_w, "height",
-          G_TYPE_INT, set_h, NULL);
-      if (gst_structure_has_field (outs, "pixel-aspect-ratio") ||
-          set_par_n != set_par_d)
-        gst_structure_set (outs, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-            set_par_n, set_par_d, NULL);
-    }
-  }
-
-done:
-  GST_DEBUG_OBJECT (base, "fixated othercaps to %" GST_PTR_FORMAT, othercaps);
-
-  if (from_par == &fpar)
-    g_value_unset (&fpar);
-  if (to_par == &tpar)
-    g_value_unset (&tpar);
-
-  return othercaps;
-}
-
-static gboolean
-gst_cuda_scale_set_info (GstCudaBaseTransform * btrans, GstCaps * incaps,
-    GstVideoInfo * in_info, GstCaps * outcaps, GstVideoInfo * out_info)
-{
-  if (GST_VIDEO_INFO_WIDTH (in_info) == GST_VIDEO_INFO_WIDTH (out_info) &&
-      GST_VIDEO_INFO_HEIGHT (in_info) == GST_VIDEO_INFO_HEIGHT (out_info) &&
-      GST_VIDEO_INFO_FORMAT (in_info) == GST_VIDEO_INFO_FORMAT (out_info)) {
-    gst_base_transform_set_passthrough (GST_BASE_TRANSFORM (btrans), TRUE);
-  }
-
-  return GST_CUDA_BASE_TRANSFORM_CLASS (parent_class)->set_info (btrans,
-      incaps, in_info, outcaps, out_info);
-}
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudascale.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstcudascale.h
deleted file mode 100644
index d343f7d52e..0000000000
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstcudascale.h
+++ /dev/null
@@ -1,59 +0,0 @@
-/* GStreamer
- * Copyright (C) <2019> Seungha Yang <seungha.yang@navercorp.com>
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Library General Public
- * License as published by the Free Software Foundation; either
- * version 2 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Library General Public License for more details.
- *
- * You should have received a copy of the GNU Library General Public
- * License along with this library; if not, write to the
- * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
- * Boston, MA 02110-1301, USA.
- */
-
-#ifndef __GST_CUDA_SCALE_H__
-#define __GST_CUDA_SCALE_H__
-
-#include <gst/gst.h>
-
-#include "gstcudabasefilter.h"
-#include "cuda-converter.h"
-
-G_BEGIN_DECLS
-
-#define GST_TYPE_CUDA_SCALE             (gst_cuda_scale_get_type())
-#define GST_CUDA_SCALE(obj)             (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_CUDA_SCALE,GstCudaScale))
-#define GST_CUDA_SCALE_CLASS(klass)     (G_TYPE_CHECK_CLASS_CAST((klass), GST_TYPE_CUDA_SCALE,GstCudaScaleClass))
-#define GST_CUDA_SCALE_GET_CLASS(obj)   (G_TYPE_INSTANCE_GET_CLASS((obj), GST_TYPE_CUDA_SCALE,GstCudaScaleClass))
-#define GST_IS_CUDA_SCALE(obj)          (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_CUDA_SCALE))
-#define GST_IS_CUDA_SCALE_CLASS(klass)  (G_TYPE_CHECK_CLASS_TYPE((klass), GST_TYPE_CUDA_SCALE))
-
-typedef struct _GstCudaScale GstCudaScale;
-typedef struct _GstCudaScaleClass GstCudaScaleClass;
-
-struct _GstCudaScale
-{
-  GstCudaBaseFilter parent;
-
-  GstCudaConverter *converter;
-
-  CUdeviceptr in_fallback;
-  CUdeviceptr out_fallback;
-};
-
-struct _GstCudaScaleClass
-{
-  GstCudaBaseFilterClass parent_class;
-};
-
-GType gst_cuda_scale_get_type (void);
-
-G_END_DECLS
-
-#endif /* __GST_CUDA_SCALE_H__ */
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvav1dec.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvav1dec.c
index bf717ecf98..31e23ebcff 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvav1dec.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvav1dec.c
@@ -50,8 +50,6 @@ typedef struct _GstNvAV1Dec
 {
   GstAV1Decoder parent;
 
-  GstVideoCodecState *output_state;
-
   GstCudaContext *context;
   GstNvDecoder *decoder;
 
@@ -266,7 +264,6 @@ gst_nv_av1_dec_close (GstVideoDecoder * decoder)
 {
   GstNvAV1Dec *self = GST_NV_AV1_DEC (decoder);
 
-  g_clear_pointer (&self->output_state, gst_video_codec_state_unref);
   gst_clear_object (&self->decoder);
   gst_clear_object (&self->context);
 
@@ -292,8 +289,7 @@ gst_nv_av1_dec_negotiate (GstVideoDecoder * decoder)
 
   GST_DEBUG_OBJECT (self, "negotiate");
 
-  gst_nv_decoder_negotiate (self->decoder, decoder, av1dec->input_state,
-      &self->output_state);
+  gst_nv_decoder_negotiate (self->decoder, decoder, av1dec->input_state);
 
   return GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder);
 }
@@ -867,8 +863,8 @@ gst_nv_av1_dec_output_picture (GstAV1Decoder * decoder,
     goto error;
   }
 
-  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, decoder_frame,
-          &frame->output_buffer)) {
+  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, picture->discont_state,
+          decoder_frame, &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to handle output picture");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.c
index bbffc7b12e..d39938c1c0 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.c
@@ -819,7 +819,8 @@ done:
 
 gboolean
 gst_nv_decoder_finish_frame (GstNvDecoder * decoder, GstVideoDecoder * videodec,
-    GstNvDecoderFrame * frame, GstBuffer ** buffer)
+    GstVideoCodecState * input_state, GstNvDecoderFrame * frame,
+    GstBuffer ** buffer)
 {
   GstBuffer *outbuf = NULL;
   gboolean ret = FALSE;
@@ -829,6 +830,13 @@ gst_nv_decoder_finish_frame (GstNvDecoder * decoder, GstVideoDecoder * videodec,
   g_return_val_if_fail (frame != NULL, GST_FLOW_ERROR);
   g_return_val_if_fail (buffer != NULL, GST_FLOW_ERROR);
 
+  if (input_state) {
+    if (!gst_nv_decoder_negotiate (decoder, videodec, input_state)) {
+      GST_ERROR_OBJECT (videodec, "Couldn't re-negotiate with updated state");
+      return FALSE;
+    }
+  }
+
   outbuf = gst_video_decoder_allocate_output_buffer (videodec);
   if (!outbuf) {
     GST_ERROR_OBJECT (videodec, "Couldn't allocate output buffer");
@@ -1454,8 +1462,7 @@ gst_nv_decoder_ensure_gl_context (GstNvDecoder * decoder, GstElement * videodec)
 
 gboolean
 gst_nv_decoder_negotiate (GstNvDecoder * decoder,
-    GstVideoDecoder * videodec, GstVideoCodecState * input_state,
-    GstVideoCodecState ** output_state)
+    GstVideoDecoder * videodec, GstVideoCodecState * input_state)
 {
   GstVideoCodecState *state;
   GstVideoInfo *info;
@@ -1463,7 +1470,6 @@ gst_nv_decoder_negotiate (GstNvDecoder * decoder,
   g_return_val_if_fail (GST_IS_NV_DECODER (decoder), FALSE);
   g_return_val_if_fail (GST_IS_VIDEO_DECODER (videodec), FALSE);
   g_return_val_if_fail (input_state != NULL, FALSE);
-  g_return_val_if_fail (output_state != NULL, FALSE);
 
   if (!decoder->configured) {
     GST_ERROR_OBJECT (videodec, "Should configure decoder first");
@@ -1476,9 +1482,8 @@ gst_nv_decoder_negotiate (GstNvDecoder * decoder,
       GST_VIDEO_INFO_WIDTH (info), GST_VIDEO_INFO_HEIGHT (info), input_state);
   state->caps = gst_video_info_to_caps (&state->info);
 
-  if (*output_state)
-    gst_video_codec_state_unref (*output_state);
-  *output_state = state;
+  /* decoder baseclass will hold other reference to output state */
+  gst_video_codec_state_unref (state);
 
   decoder->output_type = GST_NV_DECODER_OUTPUT_TYPE_SYSTEM;
 
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.h b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.h
index 635b301192..b30ceafec9 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.h
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvdecoder.h
@@ -80,6 +80,7 @@ gboolean gst_nv_decoder_decode_picture (GstNvDecoder * decoder,
 
 gboolean gst_nv_decoder_finish_frame   (GstNvDecoder * decoder,
                                         GstVideoDecoder * videodec,
+                                        GstVideoCodecState * input_state,
                                         GstNvDecoderFrame *frame,
                                         GstBuffer ** buffer);
 
@@ -102,8 +103,7 @@ gboolean gst_nv_decoder_handle_context_query (GstNvDecoder * decoder,
 
 gboolean gst_nv_decoder_negotiate            (GstNvDecoder * decoder,
                                               GstVideoDecoder * videodec,
-                                              GstVideoCodecState * input_state,
-                                              GstVideoCodecState ** output_state);
+                                              GstVideoCodecState * input_state);
 
 gboolean gst_nv_decoder_decide_allocation    (GstNvDecoder * decoder,
                                               GstVideoDecoder * videodec,
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh264dec.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh264dec.c
index 61e9296c84..f34da14420 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh264dec.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh264dec.c
@@ -103,8 +103,6 @@ typedef struct _GstNvH264Dec
 {
   GstH264Decoder parent;
 
-  GstVideoCodecState *output_state;
-
   GstCudaContext *context;
   GstNvDecoder *decoder;
   CUVIDPICPARAMS params;
@@ -354,7 +352,6 @@ gst_nv_h264_dec_close (GstVideoDecoder * decoder)
 {
   GstNvH264Dec *self = GST_NV_H264_DEC (decoder);
 
-  g_clear_pointer (&self->output_state, gst_video_codec_state_unref);
   gst_clear_object (&self->decoder);
   gst_clear_object (&self->context);
 
@@ -375,8 +372,7 @@ gst_nv_h264_dec_negotiate (GstVideoDecoder * decoder)
 
   GST_DEBUG_OBJECT (self, "negotiate");
 
-  gst_nv_decoder_negotiate (self->decoder, decoder, h264dec->input_state,
-      &self->output_state);
+  gst_nv_decoder_negotiate (self->decoder, decoder, h264dec->input_state);
 
   /* TODO: add support D3D11 memory */
 
@@ -582,8 +578,8 @@ gst_nv_h264_dec_output_picture (GstH264Decoder * decoder,
     goto error;
   }
 
-  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, decoder_frame,
-          &frame->output_buffer)) {
+  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, picture->discont_state,
+          decoder_frame, &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to handle output picture");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh265dec.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh265dec.c
index 0bba5b33da..918f13ccf4 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh265dec.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvh265dec.c
@@ -102,8 +102,6 @@ typedef struct _GstNvH265Dec
 {
   GstH265Decoder parent;
 
-  GstVideoCodecState *output_state;
-
   GstCudaContext *context;
   GstNvDecoder *decoder;
   CUVIDPICPARAMS params;
@@ -311,7 +309,6 @@ gst_nv_h265_dec_close (GstVideoDecoder * decoder)
 {
   GstNvH265Dec *self = GST_NV_H265_DEC (decoder);
 
-  g_clear_pointer (&self->output_state, gst_video_codec_state_unref);
   gst_clear_object (&self->decoder);
   gst_clear_object (&self->context);
 
@@ -332,8 +329,7 @@ gst_nv_h265_dec_negotiate (GstVideoDecoder * decoder)
 
   GST_DEBUG_OBJECT (self, "negotiate");
 
-  gst_nv_decoder_negotiate (self->decoder, decoder, h265dec->input_state,
-      &self->output_state);
+  gst_nv_decoder_negotiate (self->decoder, decoder, h265dec->input_state);
 
   /* TODO: add support D3D11 memory */
 
@@ -512,8 +508,8 @@ gst_nv_h265_dec_output_picture (GstH265Decoder * decoder,
     goto error;
   }
 
-  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, decoder_frame,
-          &frame->output_buffer)) {
+  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, picture->discont_state,
+          decoder_frame, &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to handle output picture");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp8dec.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp8dec.c
index 520c1697f1..f4a8ed4f62 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp8dec.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp8dec.c
@@ -50,8 +50,6 @@ typedef struct _GstNvVp8Dec
 {
   GstVp8Decoder parent;
 
-  GstVideoCodecState *output_state;
-
   GstCudaContext *context;
   GstNvDecoder *decoder;
   CUVIDPICPARAMS params;
@@ -235,7 +233,6 @@ gst_nv_vp8_dec_close (GstVideoDecoder * decoder)
 {
   GstNvVp8Dec *self = GST_NV_VP8_DEC (decoder);
 
-  g_clear_pointer (&self->output_state, gst_video_codec_state_unref);
   gst_clear_object (&self->decoder);
   gst_clear_object (&self->context);
 
@@ -250,8 +247,7 @@ gst_nv_vp8_dec_negotiate (GstVideoDecoder * decoder)
 
   GST_DEBUG_OBJECT (self, "negotiate");
 
-  gst_nv_decoder_negotiate (self->decoder, decoder, vp8dec->input_state,
-      &self->output_state);
+  gst_nv_decoder_negotiate (self->decoder, decoder, vp8dec->input_state);
 
   /* TODO: add support D3D11 memory */
 
@@ -482,8 +478,8 @@ gst_nv_vp8_dec_output_picture (GstVp8Decoder * decoder,
     goto error;
   }
 
-  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, decoder_frame,
-          &frame->output_buffer)) {
+  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, picture->discont_state,
+          decoder_frame, &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to handle output picture");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp9dec.c b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp9dec.c
index c21fbd351b..75bb956db2 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp9dec.c
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/gstnvvp9dec.c
@@ -50,8 +50,6 @@ typedef struct _GstNvVp9Dec
 {
   GstVp9Decoder parent;
 
-  GstVideoCodecState *output_state;
-
   GstCudaContext *context;
   GstNvDecoder *decoder;
   CUVIDPICPARAMS params;
@@ -245,7 +243,6 @@ gst_nv_vp9_dec_close (GstVideoDecoder * decoder)
 {
   GstNvVp9Dec *self = GST_NV_VP9_DEC (decoder);
 
-  g_clear_pointer (&self->output_state, gst_video_codec_state_unref);
   gst_clear_object (&self->decoder);
   gst_clear_object (&self->context);
 
@@ -260,8 +257,7 @@ gst_nv_vp9_dec_negotiate (GstVideoDecoder * decoder)
 
   GST_DEBUG_OBJECT (self, "negotiate");
 
-  gst_nv_decoder_negotiate (self->decoder, decoder, vp9dec->input_state,
-      &self->output_state);
+  gst_nv_decoder_negotiate (self->decoder, decoder, vp9dec->input_state);
 
   /* TODO: add support D3D11 memory */
 
@@ -577,8 +573,8 @@ gst_nv_vp9_dec_output_picture (GstVp9Decoder * decoder,
     goto error;
   }
 
-  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, decoder_frame,
-          &frame->output_buffer)) {
+  if (!gst_nv_decoder_finish_frame (self->decoder, vdec, picture->discont_state,
+          decoder_frame, &frame->output_buffer)) {
     GST_ERROR_OBJECT (self, "Failed to handle output picture");
     goto error;
   }
diff --git a/subprojects/gst-plugins-bad/sys/nvcodec/meson.build b/subprojects/gst-plugins-bad/sys/nvcodec/meson.build
index eaa4702de0..9010b7c7a1 100644
--- a/subprojects/gst-plugins-bad/sys/nvcodec/meson.build
+++ b/subprojects/gst-plugins-bad/sys/nvcodec/meson.build
@@ -1,27 +1,25 @@
 nvcodec_sources = [
-  'plugin.c',
-  'gstnvenc.c',
-  'gstnvbaseenc.c',
-  'gstnvh264enc.c',
-  'gstnvh265enc.c',
-  'gstnvdec.c',
+  'gstcudabasetransform.c',
+  'gstcudaconverter.c',
+  'gstcudaconvertscale.c',
+  'gstcudafilter.c',
+  'gstcudamemorycopy.c',
   'gstcuvidloader.c',
   'gstnvav1dec.c',
+  'gstnvbaseenc.c',
+  'gstnvdec.c',
   'gstnvdecoder.c',
+  'gstnvenc.c',
+  'gstnvencoder.cpp',
+  'gstnvh264enc.c',
+  'gstnvh264encoder.cpp',
+  'gstnvh265enc.c',
+  'gstnvh265encoder.cpp',
   'gstnvh264dec.c',
   'gstnvh265dec.c',
-  'gstcudabasetransform.c',
-  'gstcudamemorycopy.c',
-  'cuda-converter.c',
-  'gstcudafilter.c',
-  'gstcudabasefilter.c',
-  'gstcudaconvert.c',
-  'gstcudascale.c',
   'gstnvvp8dec.c',
   'gstnvvp9dec.c',
-  'gstnvencoder.cpp',
-  'gstnvh264encoder.cpp',
-  'gstnvh265encoder.cpp',
+  'plugin.c',
 ]
 
 nvmm_sources = [
diff --git a/subprojects/gst-plugins-bad/sys/qsv/plugin.cpp b/subprojects/gst-plugins-bad/sys/qsv/plugin.cpp
index b71a01a0ff..15887f888f 100644
--- a/subprojects/gst-plugins-bad/sys/qsv/plugin.cpp
+++ b/subprojects/gst-plugins-bad/sys/qsv/plugin.cpp
@@ -209,12 +209,15 @@ plugin_init (GstPlugin * plugin)
   mfxLoader loader;
   guint i = 0;
   GList *platform_devices = nullptr;
+  GstRank enc_rank = GST_RANK_NONE;
 
 #ifdef G_OS_WIN32
   /* D3D11 Video API is supported since Windows 8.
    * Do we want to support old OS (Windows 7 for example) with D3D9 ?? */
   if (!IsWindows8OrGreater ())
     return TRUE;
+
+  enc_rank = GST_RANK_PRIMARY;
 #endif
 
   GST_DEBUG_CATEGORY_INIT (gst_qsv_debug, "qsv", 0, "Intel Quick Sync Video");
@@ -261,11 +264,11 @@ plugin_init (GstPlugin * plugin)
     gst_qsv_jpeg_dec_register (plugin, GST_RANK_SECONDARY, i, device, session);
     gst_qsv_vp9_dec_register (plugin, GST_RANK_MARGINAL, i, device, session);
 
-    gst_qsv_h264_enc_register (plugin, GST_RANK_NONE, i, device, session);
-    gst_qsv_h265_enc_register (plugin, GST_RANK_NONE, i, device, session);
-    gst_qsv_jpeg_enc_register (plugin, GST_RANK_NONE, i, device, session);
-    gst_qsv_vp9_enc_register (plugin, GST_RANK_NONE, i, device, session);
-    gst_qsv_av1_enc_register (plugin, GST_RANK_NONE, i, device, session);
+    gst_qsv_h264_enc_register (plugin, enc_rank, i, device, session);
+    gst_qsv_h265_enc_register (plugin, enc_rank, i, device, session);
+    gst_qsv_jpeg_enc_register (plugin, enc_rank, i, device, session);
+    gst_qsv_vp9_enc_register (plugin, enc_rank, i, device, session);
+    gst_qsv_av1_enc_register (plugin, enc_rank, i, device, session);
 
   next:
     MFXDispReleaseImplDescription (loader, desc);
diff --git a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech264dec.c b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech264dec.c
index f2657c0837..4ae62e9dc2 100644
--- a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech264dec.c
+++ b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech264dec.c
@@ -75,7 +75,7 @@ struct _GstV4l2CodecH264Dec
   GstV4l2CodecPool *src_pool;
   gint min_pool_size;
   gboolean has_videometa;
-  gboolean need_negotiation;
+  gboolean streaming;
   gboolean interlaced;
   gboolean need_sequence;
   gboolean copy_frames;
@@ -233,6 +233,16 @@ gst_v4l2_codec_h264_dec_close (GstVideoDecoder * decoder)
   return TRUE;
 }
 
+static void
+gst_v4l2_codec_h264_dec_streamoff (GstV4l2CodecH264Dec * self)
+{
+  if (self->streaming) {
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
+    self->streaming = FALSE;
+  }
+}
+
 static void
 gst_v4l2_codec_h264_dec_reset_allocation (GstV4l2CodecH264Dec * self)
 {
@@ -253,9 +263,7 @@ gst_v4l2_codec_h264_dec_stop (GstVideoDecoder * decoder)
 {
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
+  gst_v4l2_codec_h264_dec_streamoff (self);
   gst_v4l2_codec_h264_dec_reset_allocation (self);
 
   if (self->output_state)
@@ -314,15 +322,11 @@ gst_v4l2_codec_h264_dec_negotiate (GstVideoDecoder * decoder)
   GstCaps *filter, *caps;
 
   /* Ignore downstream renegotiation request. */
-  if (!self->need_negotiation)
-    return TRUE;
-  self->need_negotiation = FALSE;
+  if (self->streaming)
+    goto done;
 
   GST_DEBUG_OBJECT (self, "Negotiate");
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
   gst_v4l2_codec_h264_dec_reset_allocation (self);
 
   if (!gst_v4l2_decoder_set_sink_fmt (self->decoder, V4L2_PIX_FMT_H264_SLICE,
@@ -366,6 +370,7 @@ gst_v4l2_codec_h264_dec_negotiate (GstVideoDecoder * decoder)
   if (self->output_state)
     gst_video_codec_state_unref (self->output_state);
 
+done:
   self->output_state =
       gst_video_decoder_set_output_state (GST_VIDEO_DECODER (self),
       self->vinfo.finfo->format, self->display_width,
@@ -377,6 +382,9 @@ gst_v4l2_codec_h264_dec_negotiate (GstVideoDecoder * decoder)
   self->output_state->caps = gst_video_info_to_caps (&self->output_state->info);
 
   if (GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder)) {
+    if (self->streaming)
+      return TRUE;
+
     if (!gst_v4l2_decoder_streamon (self->decoder, GST_PAD_SINK)) {
       GST_ELEMENT_ERROR (self, RESOURCE, FAILED,
           ("Could not enable the decoder driver."),
@@ -391,6 +399,8 @@ gst_v4l2_codec_h264_dec_negotiate (GstVideoDecoder * decoder)
       return FALSE;
     }
 
+    self->streaming = TRUE;
+
     return TRUE;
   }
 
@@ -404,6 +414,11 @@ gst_v4l2_codec_h264_dec_decide_allocation (GstVideoDecoder * decoder,
   GstV4l2CodecH264Dec *self = GST_V4L2_CODEC_H264_DEC (decoder);
   guint min = 0, num_bitstream;
 
+  /* If we are streaming here, then it means there is nothing allocation
+   * related in the new state and allocation can be ignored */
+  if (self->streaming)
+    return TRUE;
+
   self->has_videometa = gst_query_find_allocation_meta (query,
       GST_VIDEO_META_API_TYPE, NULL);
 
@@ -894,7 +909,7 @@ gst_v4l2_codec_h264_dec_new_sequence (GstH264Decoder * decoder,
   self->need_sequence = TRUE;
 
   if (negotiation_needed) {
-    self->need_negotiation = TRUE;
+    gst_v4l2_codec_h264_dec_streamoff (self);
     if (!gst_video_decoder_negotiate (GST_VIDEO_DECODER (self))) {
       GST_ERROR_OBJECT (self, "Failed to negotiate with downstream");
       return GST_FLOW_NOT_NEGOTIATED;
@@ -1046,6 +1061,13 @@ gst_v4l2_codec_h264_dec_output_picture (GstH264Decoder * decoder,
   GstV4l2Request *request = gst_h264_picture_get_user_data (picture);
   gint ret;
 
+  if (picture->discont_state) {
+    if (!gst_video_decoder_negotiate (vdec)) {
+      GST_ERROR_OBJECT (vdec, "Could not re-negotiate with updated state");
+      return FALSE;
+    }
+  }
+
   GST_DEBUG_OBJECT (self, "Output picture %u", picture->system_frame_number);
 
   ret = gst_v4l2_request_set_done (request);
diff --git a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech265dec.c b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech265dec.c
index 45c3e72cdd..242c855c43 100644
--- a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech265dec.c
+++ b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codech265dec.c
@@ -76,7 +76,7 @@ struct _GstV4l2CodecH265Dec
   GstV4l2CodecPool *src_pool;
   gint min_pool_size;
   gboolean has_videometa;
-  gboolean need_negotiation;
+  gboolean streaming;
   gboolean copy_frames;
   gboolean need_sequence;
 
@@ -267,6 +267,16 @@ gst_v4l2_codec_h265_dec_close (GstVideoDecoder * decoder)
   return TRUE;
 }
 
+static void
+gst_v4l2_codec_h265_dec_streamoff (GstV4l2CodecH265Dec * self)
+{
+  if (self->streaming) {
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
+    self->streaming = FALSE;
+  }
+}
+
 static void
 gst_v4l2_codec_h265_dec_reset_allocation (GstV4l2CodecH265Dec * self)
 {
@@ -287,9 +297,7 @@ gst_v4l2_codec_h265_dec_stop (GstVideoDecoder * decoder)
 {
   GstV4l2CodecH265Dec *self = GST_V4L2_CODEC_H265_DEC (decoder);
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
+  gst_v4l2_codec_h265_dec_streamoff (self);
   gst_v4l2_codec_h265_dec_reset_allocation (self);
 
   if (self->output_state)
@@ -348,15 +356,11 @@ gst_v4l2_codec_h265_dec_negotiate (GstVideoDecoder * decoder)
   GstCaps *filter, *caps;
 
   /* Ignore downstream renegotiation request. */
-  if (!self->need_negotiation)
-    return TRUE;
-  self->need_negotiation = FALSE;
+  if (self->streaming)
+    goto done;
 
   GST_DEBUG_OBJECT (self, "Negotiate");
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
   gst_v4l2_codec_h265_dec_reset_allocation (self);
 
   if (!gst_v4l2_decoder_set_sink_fmt (self->decoder, V4L2_PIX_FMT_HEVC_SLICE,
@@ -397,6 +401,7 @@ gst_v4l2_codec_h265_dec_negotiate (GstVideoDecoder * decoder)
   }
   gst_caps_unref (caps);
 
+done:
   if (self->output_state)
     gst_video_codec_state_unref (self->output_state);
 
@@ -408,6 +413,9 @@ gst_v4l2_codec_h265_dec_negotiate (GstVideoDecoder * decoder)
   self->output_state->caps = gst_video_info_to_caps (&self->output_state->info);
 
   if (GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder)) {
+    if (self->streaming)
+      return TRUE;
+
     if (!gst_v4l2_decoder_streamon (self->decoder, GST_PAD_SINK)) {
       GST_ELEMENT_ERROR (self, RESOURCE, FAILED,
           ("Could not enable the decoder driver."),
@@ -422,6 +430,8 @@ gst_v4l2_codec_h265_dec_negotiate (GstVideoDecoder * decoder)
       return FALSE;
     }
 
+    self->streaming = TRUE;
+
     return TRUE;
   }
 
@@ -435,6 +445,9 @@ gst_v4l2_codec_h265_dec_decide_allocation (GstVideoDecoder * decoder,
   GstV4l2CodecH265Dec *self = GST_V4L2_CODEC_H265_DEC (decoder);
   guint min = 0;
 
+  if (self->streaming)
+    return TRUE;
+
   self->has_videometa = gst_query_find_allocation_meta (query,
       GST_VIDEO_META_API_TYPE, NULL);
 
@@ -902,7 +915,7 @@ gst_v4l2_codec_h265_dec_new_sequence (GstH265Decoder * decoder,
   gst_v4l2_codec_h265_dec_fill_sequence (self, sps);
 
   if (negotiation_needed) {
-    self->need_negotiation = TRUE;
+    gst_v4l2_codec_h265_dec_streamoff (self);
     if (!gst_video_decoder_negotiate (GST_VIDEO_DECODER (self))) {
       GST_ERROR_OBJECT (self, "Failed to negotiate with downstream");
       return GST_FLOW_NOT_NEGOTIATED;
@@ -1174,9 +1187,17 @@ gst_v4l2_codec_h265_dec_output_picture (GstH265Decoder * decoder,
     GstVideoCodecFrame * frame, GstH265Picture * picture)
 {
   GstV4l2CodecH265Dec *self = GST_V4L2_CODEC_H265_DEC (decoder);
+  GstVideoDecoder *vdec = GST_VIDEO_DECODER (decoder);
   GstV4l2Request *request = gst_h265_picture_get_user_data (picture);
   gint ret;
 
+  if (picture->discont_state) {
+    if (!gst_video_decoder_negotiate (vdec)) {
+      GST_ERROR_OBJECT (vdec, "Could not re-negotiate with updated state");
+      return FALSE;
+    }
+  }
+
   GST_DEBUG_OBJECT (self, "Output picture %u", picture->system_frame_number);
 
   ret = gst_v4l2_request_set_done (request);
@@ -1207,10 +1228,10 @@ gst_v4l2_codec_h265_dec_output_picture (GstH265Decoder * decoder,
 
   gst_h265_picture_unref (picture);
 
-  return gst_video_decoder_finish_frame (GST_VIDEO_DECODER (self), frame);
+  return gst_video_decoder_finish_frame (vdec, frame);
 
 error:
-  gst_video_decoder_drop_frame (GST_VIDEO_DECODER (self), frame);
+  gst_video_decoder_drop_frame (vdec, frame);
   gst_h265_picture_unref (picture);
 
   return GST_FLOW_ERROR;
diff --git a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecmpeg2dec.c b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecmpeg2dec.c
index d7982c8778..00dd1612de 100644
--- a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecmpeg2dec.c
+++ b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecmpeg2dec.c
@@ -84,7 +84,7 @@ struct _GstV4l2CodecMpeg2Dec
   GstV4l2CodecPool *src_pool;
   gint min_pool_size;
   gboolean has_videometa;
-  gboolean need_negotiation;
+  gboolean streaming;
 
   GstMemory *bitstream;
   GstMapInfo bitstream_map;
@@ -149,6 +149,16 @@ gst_v4l2_codec_mpeg2_dec_close (GstVideoDecoder * decoder)
   return gst_v4l2_decoder_close (self->decoder);
 }
 
+static void
+gst_v4l2_codec_mpeg2_dec_streamoff (GstV4l2CodecMpeg2Dec * self)
+{
+  if (self->streaming) {
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
+    self->streaming = FALSE;
+  }
+}
+
 static void
 gst_v4l2_codec_mpeg2_dec_reset_allocation (GstV4l2CodecMpeg2Dec * self)
 {
@@ -169,9 +179,7 @@ gst_v4l2_codec_mpeg2_dec_stop (GstVideoDecoder * decoder)
 {
   GstV4l2CodecMpeg2Dec *self = GST_V4L2_CODEC_MPEG2_DEC (decoder);
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
+  gst_v4l2_codec_mpeg2_dec_streamoff (self);
   gst_v4l2_codec_mpeg2_dec_reset_allocation (self);
 
   if (self->output_state)
@@ -236,15 +244,11 @@ gst_v4l2_codec_mpeg2_dec_negotiate (GstVideoDecoder * decoder)
   GstCaps *filter, *caps;
 
   /* Ignore downstream renegotiation request. */
-  if (!self->need_negotiation)
-    return TRUE;
-  self->need_negotiation = FALSE;
+  if (self->streaming)
+    goto done;
 
   GST_DEBUG_OBJECT (self, "Negotiate");
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
   gst_v4l2_codec_mpeg2_dec_reset_allocation (self);
 
   if (!gst_v4l2_decoder_set_sink_fmt (self->decoder, V4L2_PIX_FMT_MPEG2_SLICE,
@@ -285,6 +289,7 @@ gst_v4l2_codec_mpeg2_dec_negotiate (GstVideoDecoder * decoder)
   }
   gst_caps_unref (caps);
 
+done:
   if (self->output_state)
     gst_video_codec_state_unref (self->output_state);
 
@@ -300,6 +305,9 @@ gst_v4l2_codec_mpeg2_dec_negotiate (GstVideoDecoder * decoder)
   self->output_state->caps = gst_video_info_to_caps (&self->output_state->info);
 
   if (GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder)) {
+    if (self->streaming)
+      return TRUE;
+
     if (!gst_v4l2_decoder_streamon (self->decoder, GST_PAD_SINK)) {
       GST_ELEMENT_ERROR (self, RESOURCE, FAILED,
           ("Could not enable the decoder driver."),
@@ -314,6 +322,8 @@ gst_v4l2_codec_mpeg2_dec_negotiate (GstVideoDecoder * decoder)
       return FALSE;
     }
 
+    self->streaming = TRUE;
+
     return TRUE;
   }
 
@@ -418,7 +428,7 @@ gst_v4l2_codec_mpeg2_dec_new_sequence (GstMpeg2Decoder * decoder,
     GST_INFO_OBJECT (self, "Profile change %d -> %d",
         self->profile, mpeg_profile);
     self->profile = mpeg_profile;
-    self->need_negotiation = TRUE;
+    self->streaming = TRUE;
   }
 
   if (self->vinfo.finfo->format == GST_VIDEO_FORMAT_UNKNOWN)
@@ -449,7 +459,7 @@ gst_v4l2_codec_mpeg2_dec_new_sequence (GstMpeg2Decoder * decoder,
   /* *INDENT-ON* */
 
   if (negotiation_needed) {
-    self->need_negotiation = TRUE;
+    gst_v4l2_codec_mpeg2_dec_streamoff (self);
     if (!gst_video_decoder_negotiate (GST_VIDEO_DECODER (self))) {
       GST_ERROR_OBJECT (self, "Failed to negotiate with downstream");
       return GST_FLOW_ERROR;
@@ -672,6 +682,13 @@ gst_v4l2_codec_mpeg2_dec_output_picture (GstMpeg2Decoder * decoder,
   GstV4l2Request *request = gst_mpeg2_picture_get_user_data (picture);
   gint ret;
 
+  if (picture->discont_state) {
+    if (!gst_video_decoder_negotiate (vdec)) {
+      GST_ERROR_OBJECT (vdec, "Could not re-negotiate with updated state");
+      return FALSE;
+    }
+  }
+
   GST_DEBUG_OBJECT (self, "Output picture %u", picture->system_frame_number);
 
   ret = gst_v4l2_request_set_done (request);
diff --git a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp8dec.c b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp8dec.c
index 95a6df1d92..2169c96942 100644
--- a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp8dec.c
+++ b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp8dec.c
@@ -73,7 +73,7 @@ struct _GstV4l2CodecVp8Dec
   GstV4l2CodecPool *src_pool;
   gint min_pool_size;
   gboolean has_videometa;
-  gboolean need_negotiation;
+  gboolean streaming;
   gboolean copy_frames;
 
   struct v4l2_ctrl_vp8_frame frame_header;
@@ -136,6 +136,16 @@ gst_v4l2_codec_vp8_dec_close (GstVideoDecoder * decoder)
   return TRUE;
 }
 
+static void
+gst_v4l2_codec_vp8_dec_streamoff (GstV4l2CodecVp8Dec * self)
+{
+  if (self->streaming) {
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
+    self->streaming = FALSE;
+  }
+}
+
 static void
 gst_v4l2_codec_vp8_dec_reset_allocation (GstV4l2CodecVp8Dec * self)
 {
@@ -156,9 +166,7 @@ gst_v4l2_codec_vp8_dec_stop (GstVideoDecoder * decoder)
 {
   GstV4l2CodecVp8Dec *self = GST_V4L2_CODEC_VP8_DEC (decoder);
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
+  gst_v4l2_codec_vp8_dec_streamoff (self);
   gst_v4l2_codec_vp8_dec_reset_allocation (self);
 
   if (self->output_state)
@@ -185,15 +193,11 @@ gst_v4l2_codec_vp8_dec_negotiate (GstVideoDecoder * decoder)
   GstCaps *filter, *caps;
 
   /* Ignore downstream renegotiation request. */
-  if (!self->need_negotiation)
-    return TRUE;
-  self->need_negotiation = FALSE;
+  if (self->streaming)
+    goto done;
 
   GST_DEBUG_OBJECT (self, "Negotiate");
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
   gst_v4l2_codec_vp8_dec_reset_allocation (self);
 
   if (!gst_v4l2_decoder_set_sink_fmt (self->decoder, V4L2_PIX_FMT_VP8_FRAME,
@@ -234,6 +238,7 @@ gst_v4l2_codec_vp8_dec_negotiate (GstVideoDecoder * decoder)
   }
   gst_caps_unref (caps);
 
+done:
   if (self->output_state)
     gst_video_codec_state_unref (self->output_state);
 
@@ -245,6 +250,9 @@ gst_v4l2_codec_vp8_dec_negotiate (GstVideoDecoder * decoder)
   self->output_state->caps = gst_video_info_to_caps (&self->output_state->info);
 
   if (GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder)) {
+    if (self->streaming)
+      return TRUE;
+
     if (!gst_v4l2_decoder_streamon (self->decoder, GST_PAD_SINK)) {
       GST_ELEMENT_ERROR (self, RESOURCE, FAILED,
           ("Could not enable the decoder driver."),
@@ -259,6 +267,8 @@ gst_v4l2_codec_vp8_dec_negotiate (GstVideoDecoder * decoder)
       return FALSE;
     }
 
+    self->streaming = TRUE;
+
     return TRUE;
   }
 
@@ -273,6 +283,9 @@ gst_v4l2_codec_vp8_dec_decide_allocation (GstVideoDecoder * decoder,
   guint min = 0;
   guint num_bitstream;
 
+  if (self->streaming)
+    return TRUE;
+
   self->has_videometa = gst_query_find_allocation_meta (query,
       GST_VIDEO_META_API_TYPE, NULL);
 
@@ -470,7 +483,7 @@ gst_v4l2_codec_vp8_dec_new_sequence (GstVp8Decoder * decoder,
   gst_v4l2_codec_vp8_dec_fill_frame_header (self, frame_hdr);
 
   if (negotiation_needed) {
-    self->need_negotiation = TRUE;
+    gst_v4l2_codec_vp8_dec_streamoff (self);
     if (!gst_video_decoder_negotiate (GST_VIDEO_DECODER (self))) {
       GST_ERROR_OBJECT (self, "Failed to negotiate with downstream");
       return GST_FLOW_NOT_NEGOTIATED;
@@ -710,6 +723,13 @@ gst_v4l2_codec_vp8_dec_output_picture (GstVp8Decoder * decoder,
   GstV4l2Request *request = gst_vp8_picture_get_user_data (picture);
   gint ret;
 
+  if (picture->discont_state) {
+    if (!gst_video_decoder_negotiate (vdec)) {
+      GST_ERROR_OBJECT (vdec, "Could not re-negotiate with updated state");
+      return FALSE;
+    }
+  }
+
   GST_DEBUG_OBJECT (self, "Output picture %u", picture->system_frame_number);
 
   ret = gst_v4l2_request_set_done (request);
diff --git a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp9dec.c b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp9dec.c
index 5902c1bd89..164015519c 100644
--- a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp9dec.c
+++ b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2codecvp9dec.c
@@ -73,7 +73,7 @@ struct _GstV4l2CodecVp9Dec
   GstV4l2CodecAllocator *src_allocator;
   GstV4l2CodecPool *src_pool;
   gboolean has_videometa;
-  gboolean need_negotiation;
+  gboolean streaming;
   gboolean copy_frames;
 
   struct v4l2_ctrl_vp9_frame v4l2_vp9_frame;
@@ -401,6 +401,16 @@ gst_v4l2_codec_vp9_dec_close (GstVideoDecoder * decoder)
   return TRUE;
 }
 
+static void
+gst_v4l2_codec_vp9_dec_streamoff (GstV4l2CodecVp9Dec * self)
+{
+  if (self->streaming) {
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
+    gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
+    self->streaming = FALSE;
+  }
+}
+
 static void
 gst_v4l2_codec_vp9_dec_reset_allocation (GstV4l2CodecVp9Dec * self)
 {
@@ -451,15 +461,11 @@ gst_v4l2_codec_vp9_dec_negotiate (GstVideoDecoder * decoder)
 
   GstCaps *filter, *caps;
   /* Ignore downstream renegotiation request. */
-  if (!self->need_negotiation)
-    return TRUE;
-  self->need_negotiation = FALSE;
+  if (self->streaming)
+    goto done;
 
   GST_DEBUG_OBJECT (self, "Negotiate");
 
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SINK);
-  gst_v4l2_decoder_streamoff (self->decoder, GST_PAD_SRC);
-
   gst_v4l2_codec_vp9_dec_reset_allocation (self);
 
   if (!gst_v4l2_decoder_set_sink_fmt (self->decoder, V4L2_PIX_FMT_VP9_FRAME,
@@ -499,6 +505,7 @@ gst_v4l2_codec_vp9_dec_negotiate (GstVideoDecoder * decoder)
   }
   gst_caps_unref (caps);
 
+done:
   if (self->output_state)
     gst_video_codec_state_unref (self->output_state);
 
@@ -510,6 +517,9 @@ gst_v4l2_codec_vp9_dec_negotiate (GstVideoDecoder * decoder)
   self->output_state->caps = gst_video_info_to_caps (&self->output_state->info);
 
   if (GST_VIDEO_DECODER_CLASS (parent_class)->negotiate (decoder)) {
+    if (self->streaming)
+      return TRUE;
+
     if (!gst_v4l2_decoder_streamon (self->decoder, GST_PAD_SINK)) {
       GST_ELEMENT_ERROR (self, RESOURCE, FAILED,
           ("Could not enable the decoder driver."),
@@ -524,6 +534,8 @@ gst_v4l2_codec_vp9_dec_negotiate (GstVideoDecoder * decoder)
       return FALSE;
     }
 
+    self->streaming = TRUE;
+
     return TRUE;
   }
 
@@ -645,7 +657,7 @@ gst_v4l2_codec_vp9_dec_new_sequence (GstVp9Decoder * decoder,
     gst_v4l2_codec_vp9_dec_fill_prob_updates (self, frame_hdr);
 
   if (negotiation_needed) {
-    self->need_negotiation = TRUE;
+    gst_v4l2_codec_vp9_dec_streamoff (self);
     if (!gst_video_decoder_negotiate (GST_VIDEO_DECODER (self))) {
       GST_ERROR_OBJECT (self, "Failed to negotiate with downstream");
       return GST_FLOW_ERROR;
@@ -932,6 +944,13 @@ gst_v4l2_codec_vp9_dec_output_picture (GstVp9Decoder * decoder,
   GstV4l2Request *request = NULL;
   gint ret;
 
+  if (picture->discont_state) {
+    if (!gst_video_decoder_negotiate (vdec)) {
+      GST_ERROR_OBJECT (vdec, "Could not re-negotiate with updated state");
+      return FALSE;
+    }
+  }
+
   GST_DEBUG_OBJECT (self, "Output picture %u", picture->system_frame_number);
 
   if (!GST_MINI_OBJECT_FLAG_IS_SET (picture, FLAG_PICTURE_HOLDS_BUFFER))
diff --git a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2format.c b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2format.c
index 8b79287053..64c47e1be7 100644
--- a/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2format.c
+++ b/subprojects/gst-plugins-bad/sys/v4l2codecs/gstv4l2format.c
@@ -80,16 +80,16 @@ set_stride (GstVideoInfo * info, gint plane, gint stride)
   const GstVideoFormatInfo *finfo = info->finfo;
 
   if (GST_VIDEO_FORMAT_INFO_IS_TILED (finfo)) {
-    guint x_tiles, y_tiles, ws, hs, padded_height;
+    guint x_tiles, y_tiles, tile_height, padded_height;
 
-    gst_video_format_info_get_tile_sizes (finfo, plane, &ws, &hs);
+    tile_height = GST_VIDEO_FORMAT_INFO_TILE_HEIGHT (finfo, plane);
 
     padded_height = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (finfo, plane,
         info->height);
-    padded_height = GST_ROUND_UP_N (padded_height, 1 << hs);
+    padded_height = (padded_height + tile_height - 1) / tile_height;
 
-    x_tiles = stride >> ws;
-    y_tiles = padded_height >> hs;
+    x_tiles = stride / GST_VIDEO_FORMAT_INFO_TILE_STRIDE (finfo, plane);
+    y_tiles = padded_height / tile_height;
     info->stride[plane] = GST_VIDEO_TILE_MAKE_STRIDE (x_tiles, y_tiles);
   } else {
     info->stride[plane] = stride;
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvaav1dec.c b/subprojects/gst-plugins-bad/sys/va/gstvaav1dec.c
index 4ca8f4b5c5..3530654f1f 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvaav1dec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvaav1dec.c
@@ -1035,6 +1035,13 @@ gst_va_av1_dec_class_init (gpointer g_class, gpointer class_data)
 
   parent_class = g_type_class_peek_parent (g_class);
 
+  /**
+   * GstVaAV1Dec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   *
+   * Since: 1.22
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), AV1,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.c b/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.c
index 1f61246a20..be36f069c0 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.c
@@ -68,6 +68,7 @@ gst_va_base_enc_reset_state_default (GstVaBaseEnc * base)
   base->profile = VAProfileNone;
   base->rt_format = 0;
   base->codedbuf_size = 0;
+  g_atomic_int_set (&base->reconf, FALSE);
 }
 
 static void
@@ -450,7 +451,6 @@ _push_buffer_to_downstream (GstVaBaseEnc * base, GstVideoCodecFrame * frame)
 {
   GstVaEncodePicture *enc_picture;
   GstVaBaseEncClass *base_class = GST_VA_BASE_ENC_GET_CLASS (base);
-  GstFlowReturn ret;
   GstBuffer *buf;
 
   if (base_class->prepare_output)
@@ -475,8 +475,7 @@ _push_buffer_to_downstream (GstVaBaseEnc * base, GstVideoCodecFrame * frame)
       GST_TIME_ARGS (frame->dts), GST_TIME_ARGS (frame->duration),
       gst_buffer_get_size (frame->output_buffer));
 
-  ret = gst_video_encoder_finish_frame (GST_VIDEO_ENCODER (base), frame);
-  return ret;
+  return gst_video_encoder_finish_frame (GST_VIDEO_ENCODER (base), frame);
 
 error:
   gst_clear_buffer (&frame->output_buffer);
@@ -500,103 +499,12 @@ _push_out_one_buffer (GstVaBaseEnc * base)
 
   ret = _push_buffer_to_downstream (base, frame_out);
 
-  if (ret != GST_FLOW_OK)
-    GST_ERROR_OBJECT (base, "fails to push one buffer, "
-        "system_frame_number %d", system_frame_number);
-
-  return ret;
-}
-
-static GstFlowReturn
-gst_va_base_enc_handle_frame (GstVideoEncoder * venc,
-    GstVideoCodecFrame * frame)
-{
-  GstVaBaseEnc *base = GST_VA_BASE_ENC (venc);
-  GstVaBaseEncClass *base_class = GST_VA_BASE_ENC_GET_CLASS (base);
-  GstFlowReturn ret;
-  GstBuffer *in_buf = NULL;
-  GstVideoCodecFrame *frame_encode = NULL;
-
-  GST_LOG_OBJECT (venc,
-      "handle frame id %d, dts %" GST_TIME_FORMAT ", pts %" GST_TIME_FORMAT,
-      frame->system_frame_number,
-      GST_TIME_ARGS (GST_BUFFER_DTS (frame->input_buffer)),
-      GST_TIME_ARGS (GST_BUFFER_PTS (frame->input_buffer)));
-
-  ret = gst_va_base_enc_import_input_buffer (base,
-      frame->input_buffer, &in_buf);
-  if (ret != GST_FLOW_OK)
-    goto error_buffer_invalid;
-
-  gst_buffer_replace (&frame->input_buffer, in_buf);
-  gst_clear_buffer (&in_buf);
-
-  if (!base_class->new_frame (base, frame))
-    goto error_new_frame;
-
-  if (!base_class->reorder_frame (base, frame, FALSE, &frame_encode))
-    goto error_reorder;
-
-  /* pass it to reorder list and we should not use it again. */
-  frame = NULL;
-
-  while (frame_encode) {
-    ret = base_class->encode_frame (base, frame_encode, FALSE);
-    if (ret != GST_FLOW_OK)
-      goto error_encode;
-
-    while (g_queue_get_length (&base->output_list) > 0) {
-      ret = _push_out_one_buffer (base);
-      if (ret != GST_FLOW_OK)
-        goto error_push_buffer;
-    }
-
-    frame_encode = NULL;
-    if (!base_class->reorder_frame (base, NULL, FALSE, &frame_encode))
-      goto error_reorder;
+  if (ret != GST_FLOW_OK) {
+    GST_DEBUG_OBJECT (base, "fails to push one buffer, system_frame_number "
+        "%d: %s", system_frame_number, gst_flow_get_name (ret));
   }
 
   return ret;
-
-error_buffer_invalid:
-  {
-    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
-        ("Failed to import the input frame."), (NULL));
-    gst_clear_buffer (&in_buf);
-    gst_clear_buffer (&frame->output_buffer);
-    gst_video_encoder_finish_frame (venc, frame);
-    return ret;
-  }
-error_new_frame:
-  {
-    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
-        ("Failed to create the input frame."), (NULL));
-    gst_clear_buffer (&frame->output_buffer);
-    gst_video_encoder_finish_frame (venc, frame);
-    return GST_FLOW_ERROR;
-  }
-error_reorder:
-  {
-    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
-        ("Failed to reorder the input frame."), (NULL));
-    gst_clear_buffer (&frame->output_buffer);
-    gst_video_encoder_finish_frame (venc, frame);
-    return GST_FLOW_ERROR;
-  }
-error_encode:
-  {
-    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
-        ("Failed to encode the frame."), (NULL));
-    gst_clear_buffer (&frame_encode->output_buffer);
-    gst_video_encoder_finish_frame (venc, frame_encode);
-    return ret;
-  }
-error_push_buffer:
-  {
-    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
-        ("Failed to push the buffer."), (NULL));
-    return ret;
-  }
 }
 
 static GstFlowReturn
@@ -688,6 +596,112 @@ error_and_purge_all:
   return ret;
 }
 
+static gboolean
+gst_va_base_enc_reset (GstVaBaseEnc * base)
+{
+  GstVaBaseEncClass *base_class = GST_VA_BASE_ENC_GET_CLASS (base);
+
+  GST_DEBUG_OBJECT (base, "Reconfiguration");
+  if (gst_va_base_enc_drain (GST_VIDEO_ENCODER (base)) != GST_FLOW_OK)
+    return FALSE;
+
+  if (!base_class->reconfig (base)) {
+    GST_ERROR_OBJECT (base, "Error at reconfiguration error");
+    return FALSE;
+  }
+
+  return TRUE;
+}
+
+static GstFlowReturn
+gst_va_base_enc_handle_frame (GstVideoEncoder * venc,
+    GstVideoCodecFrame * frame)
+{
+  GstVaBaseEnc *base = GST_VA_BASE_ENC (venc);
+  GstVaBaseEncClass *base_class = GST_VA_BASE_ENC_GET_CLASS (base);
+  GstFlowReturn ret;
+  GstBuffer *in_buf = NULL;
+  GstVideoCodecFrame *frame_encode = NULL;
+
+  GST_LOG_OBJECT (venc,
+      "handle frame id %d, dts %" GST_TIME_FORMAT ", pts %" GST_TIME_FORMAT,
+      frame->system_frame_number,
+      GST_TIME_ARGS (GST_BUFFER_DTS (frame->input_buffer)),
+      GST_TIME_ARGS (GST_BUFFER_PTS (frame->input_buffer)));
+
+  if (g_atomic_int_compare_and_exchange (&base->reconf, TRUE, FALSE)) {
+    if (!gst_va_base_enc_reset (base))
+      return GST_FLOW_ERROR;
+  }
+
+  ret = gst_va_base_enc_import_input_buffer (base,
+      frame->input_buffer, &in_buf);
+  if (ret != GST_FLOW_OK)
+    goto error_buffer_invalid;
+
+  gst_buffer_replace (&frame->input_buffer, in_buf);
+  gst_clear_buffer (&in_buf);
+
+  if (!base_class->new_frame (base, frame))
+    goto error_new_frame;
+
+  if (!base_class->reorder_frame (base, frame, FALSE, &frame_encode))
+    goto error_reorder;
+
+  /* pass it to reorder list and we should not use it again. */
+  frame = NULL;
+
+  while (frame_encode) {
+    ret = base_class->encode_frame (base, frame_encode, FALSE);
+    if (ret != GST_FLOW_OK)
+      goto error_encode;
+
+    while (g_queue_get_length (&base->output_list) > 0)
+      ret = _push_out_one_buffer (base);
+
+    frame_encode = NULL;
+    if (!base_class->reorder_frame (base, NULL, FALSE, &frame_encode))
+      goto error_reorder;
+  }
+
+  return ret;
+
+error_buffer_invalid:
+  {
+    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
+        ("Failed to import the input frame: %s.", gst_flow_get_name (ret)),
+        (NULL));
+    gst_clear_buffer (&in_buf);
+    gst_clear_buffer (&frame->output_buffer);
+    gst_video_encoder_finish_frame (venc, frame);
+    return ret;
+  }
+error_new_frame:
+  {
+    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
+        ("Failed to create the input frame."), (NULL));
+    gst_clear_buffer (&frame->output_buffer);
+    gst_video_encoder_finish_frame (venc, frame);
+    return GST_FLOW_ERROR;
+  }
+error_reorder:
+  {
+    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
+        ("Failed to reorder the input frame."), (NULL));
+    gst_clear_buffer (&frame->output_buffer);
+    gst_video_encoder_finish_frame (venc, frame);
+    return GST_FLOW_ERROR;
+  }
+error_encode:
+  {
+    GST_ELEMENT_ERROR (venc, STREAM, ENCODE,
+        ("Failed to encode the frame %s.", gst_flow_get_name (ret)), (NULL));
+    gst_clear_buffer (&frame_encode->output_buffer);
+    gst_video_encoder_finish_frame (venc, frame_encode);
+    return ret;
+  }
+}
+
 static GstFlowReturn
 gst_va_base_enc_finish (GstVideoEncoder * venc)
 {
@@ -698,7 +712,6 @@ static gboolean
 gst_va_base_enc_set_format (GstVideoEncoder * venc, GstVideoCodecState * state)
 {
   GstVaBaseEnc *base = GST_VA_BASE_ENC (venc);
-  GstVaBaseEncClass *base_class = GST_VA_BASE_ENC_GET_CLASS (base);
 
   g_return_val_if_fail (state->caps != NULL, FALSE);
 
@@ -706,18 +719,8 @@ gst_va_base_enc_set_format (GstVideoEncoder * venc, GstVideoCodecState * state)
     gst_video_codec_state_unref (base->input_state);
   base->input_state = gst_video_codec_state_ref (state);
 
-  if (gst_va_base_enc_drain (venc) != GST_FLOW_OK)
-    return FALSE;
-
-  if (!gst_va_encoder_close (base->encoder)) {
-    GST_ERROR_OBJECT (base, "Failed to close the VA encoder");
-    return FALSE;
-  }
-
-  if (!base_class->reconfig (base)) {
-    GST_ERROR_OBJECT (base, "Reconfig the encoder error");
+  if (!gst_va_base_enc_reset (base))
     return FALSE;
-  }
 
   /* Sub class should open the encoder if reconfig succeeds. */
   return gst_va_encoder_is_open (base->encoder);
@@ -901,6 +904,11 @@ gst_va_base_enc_class_init (GstVaBaseEncClass * klass)
 
   klass->reset_state = GST_DEBUG_FUNCPTR (gst_va_base_enc_reset_state_default);
 
+  /**
+   * GstVaBaseEnc:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   */
   properties[PROP_DEVICE_PATH] = g_param_spec_string ("device-path",
       "Device Path", "DRM device path", NULL,
       G_PARAM_READABLE | G_PARAM_STATIC_STRINGS);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.h b/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.h
index 20b858d762..2db7c760b0 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.h
+++ b/subprojects/gst-plugins-bad/sys/va/gstvabaseenc.h
@@ -46,6 +46,8 @@ struct _GstVaBaseEnc
   GstVaDisplay *display;
   GstVaEncoder *encoder;
 
+  gboolean reconf;
+
   VAProfile profile;
   gint width;
   gint height;
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvacaps.c b/subprojects/gst-plugins-bad/sys/va/gstvacaps.c
index a8aed03db1..0343a10a6d 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvacaps.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvacaps.c
@@ -145,6 +145,51 @@ gst_caps_set_format_array (GstCaps * caps, GArray * formats)
   return TRUE;
 }
 
+/* Fix raw frames ill reported by drivers.
+ *
+ * Mesa Gallium reports P010 and P016 for H264 encoder:
+ * https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/19443
+ *
+ * Intel i965: reports I420 and YV12
+ * XXX: add issue or pr
+ */
+static gboolean
+fix_raw_formats (GstVaDisplay * display, VAConfigID config, GArray * formats)
+{
+  VADisplay dpy;
+  VAStatus status;
+  VAProfile profile;
+  VAEntrypoint entrypoint;
+  VAConfigAttrib *attribs;
+  GstVideoFormat format;
+  int num;
+
+  if (!(GST_VA_DISPLAY_IS_IMPLEMENTATION (display, INTEL_I965) ||
+          GST_VA_DISPLAY_IS_IMPLEMENTATION (display, MESA_GALLIUM)))
+    return TRUE;
+
+  dpy = gst_va_display_get_va_dpy (display);
+  attribs = g_new (VAConfigAttrib, vaMaxNumConfigAttributes (dpy));
+  status = vaQueryConfigAttributes (dpy, config, &profile, &entrypoint, attribs,
+      &num);
+  g_free (attribs);
+
+  if (status != VA_STATUS_SUCCESS) {
+    GST_ERROR_OBJECT (display, "vaQueryConfigAttributes: %s",
+        vaErrorStr (status));
+    return FALSE;
+  }
+
+  if (gst_va_profile_codec (profile) != H264
+      || entrypoint != VAEntrypointEncSlice)
+    return TRUE;
+
+  formats = g_array_set_size (formats, 0);
+  format = GST_VIDEO_FORMAT_NV12;
+  g_array_append_val (formats, format);
+  return TRUE;
+}
+
 GstCaps *
 gst_va_create_raw_caps_from_config (GstVaDisplay * display, VAConfigID config)
 {
@@ -196,6 +241,9 @@ gst_va_create_raw_caps_from_config (GstVaDisplay * display, VAConfigID config)
   if (formats->len == 0)
     goto bail;
 
+  if (!fix_raw_formats (display, config, formats))
+    goto bail;
+
   base_caps = gst_caps_new_simple ("video/x-raw", "width", GST_TYPE_INT_RANGE,
       min_width, max_width, "height", GST_TYPE_INT_RANGE, min_height,
       max_height, NULL);
@@ -504,12 +552,12 @@ _regroup_raw_caps (GstCaps * caps)
   va_caps = gst_caps_simplify (va_caps);
   dma_caps = gst_caps_simplify (dma_caps);
 
-  sys_caps = gst_caps_merge (sys_caps, va_caps);
-  sys_caps = gst_caps_merge (sys_caps, dma_caps);
+  va_caps = gst_caps_merge (va_caps, dma_caps);
+  va_caps = gst_caps_merge (va_caps, sys_caps);
 
   gst_caps_unref (caps);
 
-  return sys_caps;
+  return va_caps;
 }
 
 gboolean
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvacompositor.c b/subprojects/gst-plugins-bad/sys/va/gstvacompositor.c
index 21db9667f4..6dcc87a901 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvacompositor.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvacompositor.c
@@ -1400,10 +1400,20 @@ gst_va_compositor_class_init (gpointer g_class, gpointer class_data)
   vagg_class->create_output_buffer =
       GST_DEBUG_FUNCPTR (gst_va_compositor_create_output_buffer);
 
+  /**
+   * GstVaCompositor:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   */
   properties[PROP_DEVICE_PATH] = g_param_spec_string ("device-path",
       "Device Path", "DRM device path", NULL,
       G_PARAM_READABLE | G_PARAM_STATIC_STRINGS);
 
+  /**
+   * GstVaCompositor:scale-method:
+   *
+   * Sets the scale method algorithm to use when resizing.
+   */
   properties[PROP_SCALE_METHOD] = g_param_spec_enum ("scale-method",
       "Scale Method", "Scale method to use", GST_TYPE_VA_SCALE_METHOD,
       VA_FILTER_SCALING_DEFAULT, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvadeinterlace.c b/subprojects/gst-plugins-bad/sys/va/gstvadeinterlace.c
index 368ffecdb4..518c1b9bf4 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvadeinterlace.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvadeinterlace.c
@@ -425,6 +425,7 @@ gst_va_deinterlace_transform (GstBaseTransform * trans, GstBuffer * inbuf,
 
   if (!gst_va_filter_process (btrans->filter, &src, &dst)) {
     gst_buffer_set_flags (outbuf, GST_BUFFER_FLAG_CORRUPTED);
+    res = GST_BASE_TRANSFORM_FLOW_DROPPED;
   }
 
   return res;
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvaencoder.c b/subprojects/gst-plugins-bad/sys/va/gstvaencoder.c
index db836e27aa..3e0c2b3a71 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvaencoder.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvaencoder.c
@@ -534,6 +534,28 @@ gst_va_encoder_new (GstVaDisplay * display, guint32 codec,
   return self;
 }
 
+gboolean
+gst_va_encoder_get_reconstruct_pool_config (GstVaEncoder * self,
+    GstCaps ** caps, guint * max_surfaces)
+{
+  GstStructure *config;
+  gboolean ret;
+
+  g_return_val_if_fail (GST_IS_VA_ENCODER (self), FALSE);
+
+  if (!gst_va_encoder_is_open (self))
+    return FALSE;
+
+  if (!self->recon_pool)
+    return FALSE;
+
+  config = gst_buffer_pool_get_config (self->recon_pool);
+  ret = gst_buffer_pool_config_get_params (config, caps, NULL, NULL,
+      max_surfaces);
+  gst_structure_free (config);
+  return ret;
+}
+
 gboolean
 gst_va_encoder_has_profile (GstVaEncoder * self, VAProfile profile)
 {
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvaencoder.h b/subprojects/gst-plugins-bad/sys/va/gstvaencoder.h
index 2152f0b78d..9def53279d 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvaencoder.h
+++ b/subprojects/gst-plugins-bad/sys/va/gstvaencoder.h
@@ -56,6 +56,9 @@ gboolean              gst_va_encoder_open                 (GstVaEncoder * self,
                                                            guint rc_ctrl,
                                                            guint32 packed_headers);
 gboolean              gst_va_encoder_close                (GstVaEncoder * self);
+gboolean              gst_va_encoder_get_reconstruct_pool_config (GstVaEncoder * self,
+                                                                  GstCaps ** caps,
+                                                                  guint * max_surfaces);
 gboolean              gst_va_encoder_has_profile          (GstVaEncoder * self,
                                                            VAProfile profile);
 gint                  gst_va_encoder_get_max_slice_num    (GstVaEncoder * self,
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvafilter.c b/subprojects/gst-plugins-bad/sys/va/gstvafilter.c
index 1ff5a743aa..a6c197012a 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvafilter.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvafilter.c
@@ -1617,8 +1617,8 @@ _create_pipeline_buffer (GstVaFilter * self, GstVaSample * src,
     return FALSE;
   }
 
-  GST_TRACE_OBJECT (self, "Created VABufferID %#x with %u filters", *buffer,
-      num_filters);
+  GST_TRACE_OBJECT (self, "Created VABufferID %#x with %u filters: "
+      "src %#x / dst %#x", *buffer, num_filters, src->surface, dst->surface);
 
   return TRUE;
 }
@@ -1668,7 +1668,8 @@ gst_va_filter_process (GstVaFilter * self, GstVaSample * src, GstVaSample * dst)
 
   status = vaRenderPicture (dpy, self->context, &buffer, 1);
   if (status != VA_STATUS_SUCCESS) {
-    GST_ERROR_OBJECT (self, "vaRenderPicture: %s", vaErrorStr (status));
+    GST_ERROR_OBJECT (self, "vaRenderPicture: %s with buffer %#x",
+        vaErrorStr (status), buffer);
     goto fail_end_pic;
   }
 
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvah264dec.c b/subprojects/gst-plugins-bad/sys/va/gstvah264dec.c
index d7d229c0b9..d92a626039 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvah264dec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvah264dec.c
@@ -936,6 +936,13 @@ gst_va_h264_dec_class_init (gpointer g_class, gpointer class_data)
 
   parent_class = g_type_class_peek_parent (g_class);
 
+  /**
+   * GstVaH264Dec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   *
+   * Since: 1.22
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), H264,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvah264enc.c b/subprojects/gst-plugins-bad/sys/va/gstvah264enc.c
index e3427a776a..f93d87ee61 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvah264enc.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvah264enc.c
@@ -1290,7 +1290,7 @@ _init_packed_headers (GstVaH264Enc * self)
 
 
 static gboolean
-_decide_profile (GstVaH264Enc * self)
+_decide_profile (GstVaH264Enc * self, VAProfile * _profile, guint * _rt_format)
 {
   GstVaBaseEnc *base = GST_VA_BASE_ENC (self);
   gboolean ret = FALSE;
@@ -1388,8 +1388,8 @@ _decide_profile (GstVaH264Enc * self)
                 profile, GST_VA_BASE_ENC_ENTRYPOINT (base))) == 0)
       continue;
 
-    base->profile = profile;
-    base->rt_format = rt_format;
+    *_profile = profile;
+    *_rt_format = rt_format;
     ret = TRUE;
     goto out;
   }
@@ -1410,8 +1410,8 @@ _decide_profile (GstVaH264Enc * self)
                 profile, GST_VA_BASE_ENC_ENTRYPOINT (base))) == 0)
       continue;
 
-    base->profile = profile;
-    base->rt_format = rt_format;
+    *_profile = profile;
+    *_rt_format = rt_format;
     ret = TRUE;
   }
 
@@ -1420,7 +1420,7 @@ _decide_profile (GstVaH264Enc * self)
 
   if (self->use_dct8x8 && !g_strstr_len (profile_name, -1, "high")) {
     GST_INFO_OBJECT (self, "Disable dct8x8, profile %s does not support it",
-        gst_va_profile_name (base->profile));
+        gst_va_profile_name (profile));
     self->use_dct8x8 = FALSE;
     update_property_bool (base, &self->prop.use_dct8x8, self->use_dct8x8,
         PROP_DCT8X8);
@@ -1429,7 +1429,7 @@ _decide_profile (GstVaH264Enc * self)
   if (self->use_cabac && (!g_strstr_len (profile_name, -1, "main")
           && !g_strstr_len (profile_name, -1, "high"))) {
     GST_INFO_OBJECT (self, "Disable cabac, profile %s does not support it",
-        gst_va_profile_name (base->profile));
+        gst_va_profile_name (profile));
     self->use_cabac = FALSE;
     update_property_bool (base, &self->prop.use_cabac, self->use_cabac,
         PROP_CABAC);
@@ -1437,7 +1437,7 @@ _decide_profile (GstVaH264Enc * self)
 
   if (self->gop.num_bframes > 0 && g_strstr_len (profile_name, -1, "baseline")) {
     GST_INFO_OBJECT (self, "No B frames, profile %s does not support it",
-        gst_va_profile_name (base->profile));
+        gst_va_profile_name (profile));
     self->gop.num_bframes = 0;
     self->gop.b_pyramid = 0;
   }
@@ -1527,14 +1527,46 @@ gst_va_h264_enc_reconfig (GstVaBaseEnc * base)
 {
   GstVideoEncoder *venc = GST_VIDEO_ENCODER (base);
   GstVaH264Enc *self = GST_VA_H264_ENC (base);
-  GstCaps *out_caps;
-  guint max_ref_frames;
-  GstVideoCodecState *output_state;
+  GstCaps *out_caps, *reconf_caps = NULL;
+  GstVideoCodecState *output_state = NULL;
+  GstVideoFormat format, reconf_format = GST_VIDEO_FORMAT_UNKNOWN;
+  VAProfile profile = VAProfileNone;
+  gboolean do_renegotiation = TRUE, do_reopen, need_negotiation;
+  guint max_ref_frames, max_surfaces = 0, rt_format = 0, codedbuf_size;
+  gint width, height;
+
+  width = GST_VIDEO_INFO_WIDTH (&base->input_state->info);
+  height = GST_VIDEO_INFO_HEIGHT (&base->input_state->info);
+  format = GST_VIDEO_INFO_FORMAT (&base->input_state->info);
+  codedbuf_size = base->codedbuf_size;
+
+  need_negotiation =
+      !gst_va_encoder_get_reconstruct_pool_config (base->encoder, &reconf_caps,
+      &max_surfaces);
+  if (!need_negotiation && reconf_caps) {
+    GstVideoInfo vi;
+    if (!gst_video_info_from_caps (&vi, reconf_caps))
+      return FALSE;
+    reconf_format = GST_VIDEO_INFO_FORMAT (&vi);
+  }
+
+  if (!_decide_profile (self, &profile, &rt_format))
+    return FALSE;
+
+  /* first check */
+  do_reopen = !(base->profile == profile && base->rt_format == rt_format
+      && format == reconf_format && width == base->width
+      && height == base->height && self->prop.rc_ctrl == self->rc.rc_ctrl_mode);
+
+  if (do_reopen && gst_va_encoder_is_open (base->encoder))
+    gst_va_encoder_close (base->encoder);
 
   gst_va_base_enc_reset_state (base);
 
-  base->width = GST_VIDEO_INFO_WIDTH (&base->input_state->info);
-  base->height = GST_VIDEO_INFO_HEIGHT (&base->input_state->info);
+  base->profile = profile;
+  base->rt_format = rt_format;
+  base->width = width;
+  base->height = height;
 
   self->mb_width = GST_ROUND_UP_16 (base->width) / 16;
   self->mb_height = GST_ROUND_UP_16 (base->height) / 16;
@@ -1555,9 +1587,6 @@ gst_va_h264_enc_reconfig (GstVaBaseEnc * base)
       base->width, base->height, self->mb_width, self->mb_height,
       GST_TIME_ARGS (base->frame_duration));
 
-  if (!_decide_profile (self))
-    return FALSE;
-
   _validate_parameters (self);
 
   if (!_ensure_rate_control (self))
@@ -1567,6 +1596,7 @@ gst_va_h264_enc_reconfig (GstVaBaseEnc * base)
     return FALSE;
 
   _generate_gop_structure (self);
+
   _calculate_coded_size (self);
 
   /* updates & notifications */
@@ -1586,9 +1616,16 @@ gst_va_h264_enc_reconfig (GstVaBaseEnc * base)
   update_property_bool (base, &self->prop.cc, self->cc, PROP_CC);
 
   max_ref_frames = self->gop.num_ref_frames + 3 /* scratch frames */ ;
-  if (!gst_va_encoder_open (base->encoder, base->profile,
-          GST_VIDEO_INFO_FORMAT (&base->input_state->info), base->rt_format,
-          GST_ROUND_UP_16 (base->width), GST_ROUND_UP_16 (base->height),
+
+  /* second check after calculations */
+  do_reopen |=
+      !(max_ref_frames == max_surfaces && codedbuf_size == base->codedbuf_size);
+  if (do_reopen && gst_va_encoder_is_open (base->encoder))
+    gst_va_encoder_close (base->encoder);
+
+  if (!gst_va_encoder_is_open (base->encoder)
+      && !gst_va_encoder_open (base->encoder, base->profile,
+          format, base->rt_format, base->width, base->height,
           base->codedbuf_size, max_ref_frames, self->rc.rc_ctrl_mode,
           self->packed_headers)) {
     GST_ERROR_OBJECT (self, "Failed to open the VA encoder.");
@@ -1610,6 +1647,19 @@ gst_va_h264_enc_reconfig (GstVaBaseEnc * base)
       "height", G_TYPE_INT, base->height, "alignment", G_TYPE_STRING, "au",
       "stream-format", G_TYPE_STRING, "byte-stream", NULL);
 
+  if (!need_negotiation) {
+    output_state = gst_video_encoder_get_output_state (venc);
+    do_renegotiation = TRUE;
+    if (output_state) {
+      do_renegotiation = !gst_caps_is_subset (output_state->caps, out_caps);
+      gst_video_codec_state_unref (output_state);
+    }
+    if (!do_renegotiation) {
+      gst_caps_unref (out_caps);
+      return TRUE;
+    }
+  }
+
   GST_DEBUG_OBJECT (self, "output caps is %" GST_PTR_FORMAT, out_caps);
 
   output_state =
@@ -3192,15 +3242,9 @@ static void
 gst_va_h264_enc_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
 {
-  GstVaH264Enc *const self = GST_VA_H264_ENC (object);
+  GstVaH264Enc *self = GST_VA_H264_ENC (object);
   GstVaBaseEnc *base = GST_VA_BASE_ENC (self);
 
-  if (base->encoder && gst_va_encoder_is_open (base->encoder)) {
-    GST_ERROR_OBJECT (object,
-        "failed to set any property after encoding started");
-    return;
-  }
-
   GST_OBJECT_LOCK (self);
 
   switch (prop_id) {
@@ -3230,12 +3274,15 @@ gst_va_h264_enc_set_property (GObject * object, guint prop_id,
       break;
     case PROP_QP_I:
       self->prop.qp_i = g_value_get_uint (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_QP_P:
       self->prop.qp_p = g_value_get_uint (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_QP_B:
       self->prop.qp_b = g_value_get_uint (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_DCT8X8:
       self->prop.use_dct8x8 = g_value_get_boolean (value);
@@ -3273,15 +3320,19 @@ gst_va_h264_enc_set_property (GObject * object, guint prop_id,
     }
     case PROP_BITRATE:
       self->prop.bitrate = g_value_get_uint (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_TARGET_PERCENTAGE:
       self->prop.target_percentage = g_value_get_uint (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_TARGET_USAGE:
       self->prop.target_usage = g_value_get_uint (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_RATE_CONTROL:
       self->prop.rc_ctrl = g_value_get_enum (value);
+      g_atomic_int_set (&GST_VA_BASE_ENC (self)->reconf, TRUE);
       break;
     case PROP_CPB_SIZE:
       self->prop.cpb_size = g_value_get_uint (value);
@@ -3291,6 +3342,15 @@ gst_va_h264_enc_set_property (GObject * object, guint prop_id,
   }
 
   GST_OBJECT_UNLOCK (self);
+
+#ifndef GST_DISABLE_GST_DEBUG
+  if (!g_atomic_int_get (&GST_VA_BASE_ENC (self)->reconf)
+      && base->encoder && gst_va_encoder_is_open (base->encoder)) {
+    GST_WARNING_OBJECT (self, "Property `%s` change ignored while processing.",
+        pspec->name);
+  }
+#endif
+
 }
 
 static void
@@ -3391,6 +3451,8 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
   gchar *long_name;
   const gchar *name, *desc;
   gint n_props = N_PROPERTIES;
+  GParamFlags param_flags =
+      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT;
 
   if (cdata->entrypoint == VAEntrypointEncSlice) {
     desc = "VA-API based H.264 video encoder";
@@ -3475,15 +3537,14 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
   g_free (cdata);
 
   /**
-   * GstVaEncoder:key-int-max:
+   * GstVaH264Enc:key-int-max:
    *
    * The maximal distance between two keyframes.
    */
   properties[PROP_KEY_INT_MAX] = g_param_spec_uint ("key-int-max",
       "Key frame maximal interval",
       "The maximal distance between two keyframes. It decides the size of GOP"
-      " (0: auto-calculate)", 0, MAX_GOP_SIZE, 0,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      " (0: auto-calculate)", 0, MAX_GOP_SIZE, 0, param_flags);
 
   /**
    * GstVaH264Enc:b-frames:
@@ -3492,7 +3553,7 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    */
   properties[PROP_BFRAMES] = g_param_spec_uint ("b-frames", "B Frames",
       "Number of B frames between I and P reference frames", 0, 31, 0,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      param_flags);
 
   /**
    * GstVaH264Enc:i-frames:
@@ -3501,8 +3562,7 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    */
   properties[PROP_IFRAMES] = g_param_spec_uint ("i-frames", "I Frames",
       "Force the number of I frames insertion within one GOP, not including the "
-      "first IDR frame", 0, 1023, 0,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "first IDR frame", 0, 1023, 0, param_flags);
 
   /**
    * GstVaH264Enc:ref-frames:
@@ -3512,7 +3572,7 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
   properties[PROP_NUM_REF_FRAMES] = g_param_spec_uint ("ref-frames",
       "Number of Reference Frames",
       "Number of reference frames, including both the forward and the backward",
-      0, 16, 3, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      0, 16, 3, param_flags);
 
   /**
    * GstVaH264Enc:b-pyramid:
@@ -3521,15 +3581,15 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    */
   properties[PROP_B_PYRAMID] = g_param_spec_boolean ("b-pyramid", "b pyramid",
       "Enable the b-pyramid reference structure in the GOP", FALSE,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      param_flags);
+
   /**
    * GstVaH264Enc:num-slices:
    *
    * The number of slices per frame.
    */
   properties[PROP_NUM_SLICES] = g_param_spec_uint ("num-slices",
-      "Number of Slices", "Number of slices per frame", 1, 200, 1,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Number of Slices", "Number of slices per frame", 1, 200, 1, param_flags);
 
   /**
    * GstVaH264Enc:max-qp:
@@ -3537,8 +3597,7 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    * The maximum quantizer value.
    */
   properties[PROP_MAX_QP] = g_param_spec_uint ("max-qp", "Maximum QP",
-      "Maximum quantizer value for each frame", 0, 51, 51,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Maximum quantizer value for each frame", 0, 51, 51, param_flags);
 
   /**
    * GstVaH264Enc:min-qp:
@@ -3546,41 +3605,40 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    * The minimum quantizer value.
    */
   properties[PROP_MIN_QP] = g_param_spec_uint ("min-qp", "Minimum QP",
-      "Minimum quantizer value for each frame", 0, 51, 1,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Minimum quantizer value for each frame", 0, 51, 1, param_flags);
 
   /**
    * GstVaH264Enc:qpi:
    *
-   * The quantizer value for I frame. In CQP mode, it specifies the QP of
-   * I frame, in other mode, it specifies the init QP of all frames.
+   * The quantizer value for I frame.
+   *
+   * In CQP mode, it specifies the QP of I frame, in other mode, it specifies
+   * the init QP of all frames.
    */
   properties[PROP_QP_I] = g_param_spec_uint ("qpi", "I Frame QP",
       "The quantizer value for I frame. In CQP mode, it specifies the QP of I "
       "frame, in other mode, it specifies the init QP of all frames", 0, 51, 26,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   /**
    * GstVaH264Enc:qpp:
    *
-   * The quantizer value for P frame. This is available only in CQP mode.
+   * The quantizer value for P frame. Available only in CQP mode.
    */
   properties[PROP_QP_P] = g_param_spec_uint ("qpp",
       "The quantizer value for P frame",
-      "The quantizer value for P frame. This is available only in CQP mode",
-      0, 51, 26,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "The quantizer value for P frame. Available only in CQP mode",
+      0, 51, 26, param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   /**
    * GstVaH264Enc:qpb:
    *
-   * The quantizer value for B frame. This is available only in CQP mode.
+   * The quantizer value for B frame. Available only in CQP mode.
    */
   properties[PROP_QP_B] = g_param_spec_uint ("qpb",
       "The quantizer value for B frame",
-      "The quantizer value for B frame. This is available only in CQP mode",
-      0, 51, 26,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "The quantizer value for B frame. Available only in CQP mode",
+      0, 51, 26, param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   /**
    * GstVaH264Enc:dct8x8:
@@ -3588,10 +3646,8 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    * Enable adaptive use of 8x8 transforms in I-frames. This improves
    * the compression ratio but requires high profile at least.
    */
-  properties[PROP_DCT8X8] = g_param_spec_boolean ("dct8x8",
-      "Enable 8x8 DCT",
-      "Enable adaptive use of 8x8 transforms in I-frames", TRUE,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+  properties[PROP_DCT8X8] = g_param_spec_boolean ("dct8x8", "Enable 8x8 DCT",
+      "Enable adaptive use of 8x8 transforms in I-frames", TRUE, param_flags);
 
   /**
    * GstVaH264Enc:cabac:
@@ -3600,18 +3656,16 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    * but requires main profile at least.
    */
   properties[PROP_CABAC] = g_param_spec_boolean ("cabac", "Enable CABAC",
-      "Enable CABAC entropy coding mode", TRUE,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Enable CABAC entropy coding mode", TRUE, param_flags);
 
   /**
    * GstVaH264Enc:trellis:
    *
-   * It enable the trellis quantization method.
-   * Trellis is an improved quantization algorithm.
+   * It enable the trellis quantization method. Trellis is an improved
+   * quantization algorithm.
    */
   properties[PROP_TRELLIS] = g_param_spec_boolean ("trellis", "Enable trellis",
-      "Enable the trellis quantization method", FALSE,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Enable the trellis quantization method", FALSE, param_flags);
 
   /**
    * GstVaH264Enc:aud:
@@ -3619,14 +3673,12 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
    * Insert the AU (Access Unit) delimeter for each frame.
    */
   properties[PROP_AUD] = g_param_spec_boolean ("aud", "Insert AUD",
-      "Insert AU (Access Unit) delimeter for each frame", FALSE,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Insert AU (Access Unit) delimeter for each frame", FALSE, param_flags);
 
   /**
    * GstVaH264Enc:cc-insert:
    *
-   * Closed Caption Insert mode.
-   * Only CEA-708 RAW format is supported for now.
+   * Closed Caption Insert mode. Only CEA-708 RAW format is supported for now.
    */
   properties[PROP_CC] = g_param_spec_boolean ("cc-insert",
       "Insert Closed Captions",
@@ -3636,58 +3688,57 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
   /**
    * GstVaH264Enc:mbbrc:
    *
-   * Macroblock level bitrate control.
-   * This is not compatible with Constant QP rate control.
+   * Macroblock level bitrate control. Not available in CQP mode.
    */
   properties[PROP_MBBRC] = g_param_spec_enum ("mbbrc",
       "Macroblock level Bitrate Control",
-      "Macroblock level Bitrate Control. It is not compatible with CQP",
-      GST_TYPE_VA_FEATURE, GST_VA_FEATURE_AUTO,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      "Macroblock level Bitrate Control. Not available in CQP mode",
+      GST_TYPE_VA_FEATURE, GST_VA_FEATURE_AUTO, param_flags);
 
   /**
    * GstVaH264Enc:bitrate:
    *
-   * The desired target bitrate, expressed in kbps.
-   * This is not available in CQP mode.
+   * The desired target bitrate, expressed in kbps. Not available in CQP mode.
    *
-   * CBR: This applies equally to the minimum, maximum and target bitrate.
-   * VBR: This applies to the target bitrate. The driver will use the
-   * "target-percentage" together to calculate the minimum and maximum bitrate.
-   * VCM: This applies to the target bitrate. The minimum and maximum bitrate
-   * are not needed.
+   * * **CBR**: This applies equally to the minimum, maximum and target bitrate.
+   * * **VBR**: This applies to the target bitrate. The driver will use the
+   *   "target-percentage" together to calculate the minimum and maximum
+   *   bitrate.
+   * * **VCM**: This applies to the target bitrate. The minimum and maximum
+   *   bitrate are not needed.
    */
   properties[PROP_BITRATE] = g_param_spec_uint ("bitrate", "Bitrate (kbps)",
       "The desired bitrate expressed in kbps (0: auto-calculate)",
-      0, 2000 * 1024, 0,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      0, 2000 * 1024, 0, param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   /**
    * GstVaH264Enc:target-percentage:
    *
-   * The target percentage of the max bitrate, and expressed in uint,
-   * equal to "target percentage"*100.
-   * "target percentage" = "target bitrate" * 100 / "max bitrate"
-   * This is available only when rate-control is VBR.
+   * The target percentage of the max bitrate, and expressed in uint, equal to
+   * "target percentage" * 100. Available only when rate-control is VBR.
+   *
+   * "target percentage" = "target bitrate" * 100 /  "max bitrate"
+   *
    * The driver uses it to calculate the minimum and maximum bitrate.
    */
   properties[PROP_TARGET_PERCENTAGE] = g_param_spec_uint ("target-percentage",
       "target bitrate percentage",
       "The percentage for 'target bitrate'/'maximum bitrate' (Only in VBR)",
-      50, 100, 66,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      50, 100, 66, param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   /**
    * GstVaH264Enc:target-usage:
    *
-   * The target usage of the encoder. It controls and balances the encoding
-   * speed and the encoding quality. The lower value has better quality but
-   * slower speed, the higher value has faster speed but lower quality.
+   * The target usage of the encoder.
+   *
+   * It controls and balances the encoding speed and the encoding quality. The
+   * lower value has better quality but slower speed, the higher value has
+   * faster speed but lower quality.
    */
   properties[PROP_TARGET_USAGE] = g_param_spec_uint ("target-usage",
       "target usage",
       "The target usage to control and balance the encoding speed/quality",
-      1, 7, 4, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      1, 7, 4, param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   /**
    * GstVaH264Enc:cpb-size:
@@ -3697,15 +3748,15 @@ gst_va_h264_enc_class_init (gpointer g_klass, gpointer class_data)
   properties[PROP_CPB_SIZE] = g_param_spec_uint ("cpb-size",
       "max CPB size in Kb",
       "The desired max CPB size in Kb (0: auto-calculate)", 0, 2000 * 1024, 0,
-      G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+      param_flags | GST_PARAM_MUTABLE_PLAYING);
 
   if (vah264enc_class->rate_control_type > 0) {
     properties[PROP_RATE_CONTROL] = g_param_spec_enum ("rate-control",
         "rate control mode", "The desired rate control mode for the encoder",
         vah264enc_class->rate_control_type,
         vah264enc_class->rate_control[0].value,
-        GST_PARAM_CONDITIONALLY_AVAILABLE | G_PARAM_READWRITE
-        | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT);
+        GST_PARAM_CONDITIONALLY_AVAILABLE | GST_PARAM_MUTABLE_PLAYING
+        | param_flags);
   } else {
     n_props--;
     properties[PROP_RATE_CONTROL] = NULL;
@@ -3725,80 +3776,6 @@ _complete_src_caps (GstCaps * srccaps)
   return caps;
 }
 
-/* bug in mesa gallium which adds P010_10LE. Admit only 420 chroma formats */
-static GstCaps *
-_fix_sink_caps (GstVaDisplay * display, GstCaps * sinkcaps)
-{
-  GstCaps *caps;
-  guint i, j;
-
-  if (!GST_VA_DISPLAY_IS_IMPLEMENTATION (display, MESA_GALLIUM))
-    return gst_caps_ref (sinkcaps);
-
-  caps = gst_caps_copy (sinkcaps);
-  for (i = 0; i < gst_caps_get_size (caps); i++) {
-    GstStructure *st = gst_caps_get_structure (caps, i);
-    const GValue *formats = gst_structure_get_value (st, "format");
-    GArray *fmts;
-    guint num;
-
-    /* let's accept it as is */
-    if (G_VALUE_HOLDS_STRING (formats))
-      continue;
-
-    g_assert (GST_VALUE_HOLDS_LIST (formats));
-
-    num = gst_value_list_get_size (formats);
-    fmts = g_array_sized_new (FALSE, FALSE, sizeof (GstVideoFormat), num);
-    for (j = 0; j < num; j++) {
-      const gchar *format =
-          g_value_get_string (gst_value_list_get_value (formats, j));
-      GstVideoFormat f = gst_video_format_from_string (format);
-      if (f != GST_VIDEO_FORMAT_UNKNOWN
-          && gst_va_chroma_from_video_format (f) == VA_RT_FORMAT_YUV420)
-        g_array_append_val (fmts, f);
-    }
-
-    if (fmts->len == 0) {
-      GST_ERROR ("No valid formats in sink caps template.");
-      g_array_unref (fmts);
-      return caps;
-    }
-
-    if (fmts->len == 1) {
-      GValue v = G_VALUE_INIT;
-
-      /* let's accept it as is */
-      g_value_init (&v, G_TYPE_STRING);
-      g_value_set_string (&v,
-          gst_video_format_to_string (g_array_index (fmts, GstVideoFormat, 0)));
-      gst_structure_set_value (st, "format", &v);
-      g_value_unset (&v);
-    } else {
-      GValue val = G_VALUE_INIT;
-      gst_value_array_init (&val, fmts->len);
-
-      for (j = 0; j < fmts->len; j++) {
-        GValue v = G_VALUE_INIT;
-
-        g_value_init (&v, G_TYPE_STRING);
-        g_value_set_string (&v,
-            gst_video_format_to_string (g_array_index (fmts, GstVideoFormat,
-                    j)));
-        gst_value_array_append_value (&val, &v);
-        g_value_unset (&v);
-      }
-
-      gst_structure_set_value (st, "format", &val);
-      g_value_unset (&val);
-    }
-
-    g_array_unref (fmts);
-  }
-
-  return caps;
-}
-
 gboolean
 gst_va_h264_enc_register (GstPlugin * plugin, GstVaDevice * device,
     GstCaps * sink_caps, GstCaps * src_caps, guint rank,
@@ -3827,7 +3804,7 @@ gst_va_h264_enc_register (GstPlugin * plugin, GstVaDevice * device,
   cdata->entrypoint = entrypoint;
   cdata->description = NULL;
   cdata->render_device_path = g_strdup (device->render_device_path);
-  cdata->sink_caps = _fix_sink_caps (device->display, sink_caps);
+  cdata->sink_caps = gst_caps_ref (sink_caps);
   cdata->src_caps = _complete_src_caps (src_caps);
 
   /* class data will be leaked if the element never gets instantiated */
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvah265dec.c b/subprojects/gst-plugins-bad/sys/va/gstvah265dec.c
index f90b23d5b0..3cf526af88 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvah265dec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvah265dec.c
@@ -1291,6 +1291,13 @@ gst_va_h265_dec_class_init (gpointer g_class, gpointer class_data)
 
   parent_class = g_type_class_peek_parent (g_class);
 
+  /**
+   * GstVaH265Dec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   *
+   * Since: 1.22
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), HEVC,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvajpegdec.c b/subprojects/gst-plugins-bad/sys/va/gstvajpegdec.c
index c7170130a3..a6e5a3f06c 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvajpegdec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvajpegdec.c
@@ -469,6 +469,11 @@ gst_va_jpeg_dec_class_init (gpointer g_class, gpointer class_data)
   jpegdecoder_class->output_picture =
       GST_DEBUG_FUNCPTR (gst_va_jpeg_dec_output_picture);
 
+  /**
+   * GstVaJpegDec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), JPEG,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvampeg2dec.c b/subprojects/gst-plugins-bad/sys/va/gstvampeg2dec.c
index 4cfc929c01..69be39c47c 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvampeg2dec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvampeg2dec.c
@@ -631,6 +631,13 @@ gst_va_mpeg2_dec_class_init (gpointer g_class, gpointer class_data)
 
   parent_class = g_type_class_peek_parent (g_class);
 
+  /**
+   * GstVaMpeg2Dec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   *
+   * Since: 1.22
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), MPEG2,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
@@ -705,7 +712,7 @@ gst_va_mpeg2_dec_register (GstPlugin * plugin, GstVaDevice * device,
 
   type_info.class_data = cdata;
 
-  type_name = g_strdup ("GstVaMpeg2dec");
+  type_name = g_strdup ("GstVaMpeg2Dec");
   feature_name = g_strdup ("vampeg2dec");
 
   /* The first decoder to be registered should use a constant name,
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvavp8dec.c b/subprojects/gst-plugins-bad/sys/va/gstvavp8dec.c
index e4d9151385..50d721d6a4 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvavp8dec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvavp8dec.c
@@ -504,6 +504,13 @@ gst_va_vp8_dec_class_init (gpointer g_class, gpointer class_data)
 
   parent_class = g_type_class_peek_parent (g_class);
 
+  /**
+   * GstVaVp8Dec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   *
+   * Since: 1.22
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), VP8,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
@@ -574,7 +581,7 @@ gst_va_vp8_dec_register (GstPlugin * plugin, GstVaDevice * device,
 
   type_info.class_data = cdata;
 
-  type_name = g_strdup ("GstVaVp8dec");
+  type_name = g_strdup ("GstVaVp8Dec");
   feature_name = g_strdup ("vavp8dec");
 
   /* The first decoder to be registered should use a constant name,
@@ -584,7 +591,7 @@ gst_va_vp8_dec_register (GstPlugin * plugin, GstVaDevice * device,
     gchar *basename = g_path_get_basename (device->render_device_path);
     g_free (type_name);
     g_free (feature_name);
-    type_name = g_strdup_printf ("GstVa%sVP8Dec", basename);
+    type_name = g_strdup_printf ("GstVa%sVp8Dec", basename);
     feature_name = g_strdup_printf ("va%svp8dec", basename);
     cdata->description = basename;
 
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvavp9dec.c b/subprojects/gst-plugins-bad/sys/va/gstvavp9dec.c
index 86af8ceba5..45807f5c9a 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvavp9dec.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvavp9dec.c
@@ -652,6 +652,13 @@ gst_va_vp9_dec_class_init (gpointer g_class, gpointer class_data)
 
   parent_class = g_type_class_peek_parent (g_class);
 
+  /**
+   * GstVaVp9Dec:device-path:
+   *
+   * It shows the DRM device path used for the VA operation, if any.
+   *
+   * Since: 1.22
+   */
   gst_va_base_dec_class_init (GST_VA_BASE_DEC_CLASS (g_class), VP9,
       cdata->render_device_path, cdata->sink_caps, cdata->src_caps,
       src_doc_caps, sink_doc_caps);
diff --git a/subprojects/gst-plugins-bad/sys/va/gstvavpp.c b/subprojects/gst-plugins-bad/sys/va/gstvavpp.c
index ac803c908c..6355216ad3 100644
--- a/subprojects/gst-plugins-bad/sys/va/gstvavpp.c
+++ b/subprojects/gst-plugins-bad/sys/va/gstvavpp.c
@@ -845,6 +845,7 @@ gst_va_vpp_transform (GstBaseTransform * trans, GstBuffer * inbuf,
 
   if (!gst_va_filter_process (btrans->filter, &src, &dst)) {
     gst_buffer_set_flags (outbuf, GST_BUFFER_FLAG_CORRUPTED);
+    res = GST_BASE_TRANSFORM_FLOW_DROPPED;
   }
 
   gst_buffer_unref (buf);
@@ -1896,10 +1897,10 @@ static void
 _get_scale_factor (GstVaVpp * self, gdouble * w_factor, gdouble * h_factor)
 {
   GstVaBaseTransform *btrans = GST_VA_BASE_TRANSFORM (self);
-  gdouble w = GST_VIDEO_INFO_WIDTH (&btrans->in_info);
-  gdouble h = GST_VIDEO_INFO_HEIGHT (&btrans->in_info);
+  gdouble w = GST_VIDEO_INFO_WIDTH (&btrans->out_info);
+  gdouble h = GST_VIDEO_INFO_HEIGHT (&btrans->out_info);
 
-  switch (self->direction) {
+  switch (gst_va_filter_get_orientation (btrans->filter)) {
     case GST_VIDEO_ORIENTATION_90R:
     case GST_VIDEO_ORIENTATION_90L:
     case GST_VIDEO_ORIENTATION_UR_LL:
@@ -1913,10 +1914,10 @@ _get_scale_factor (GstVaVpp * self, gdouble * w_factor, gdouble * h_factor)
       break;
   }
 
-  *w_factor = GST_VIDEO_INFO_WIDTH (&btrans->out_info);
+  *w_factor = GST_VIDEO_INFO_WIDTH (&btrans->in_info);
   *w_factor /= w;
 
-  *h_factor = GST_VIDEO_INFO_HEIGHT (&btrans->out_info);
+  *h_factor = GST_VIDEO_INFO_HEIGHT (&btrans->in_info);
   *h_factor /= h;
 }
 
@@ -1938,41 +1939,41 @@ gst_va_vpp_src_event (GstBaseTransform * trans, GstEvent * event)
           || gst_va_filter_get_orientation (btrans->filter) !=
           GST_VIDEO_ORIENTATION_IDENTITY) {
 
-        event = gst_event_make_writable (event);
-
         if (!gst_navigation_event_get_coordinates (event, &x, &y))
           break;
 
+        event = gst_event_make_writable (event);
+
         /* video-direction compensation */
-        switch (self->direction) {
+        switch (gst_va_filter_get_orientation (btrans->filter)) {
           case GST_VIDEO_ORIENTATION_90R:
             new_x = y;
-            new_y = GST_VIDEO_INFO_WIDTH (in_info) - 1 - x;
+            new_y = GST_VIDEO_INFO_WIDTH (out_info) - 1 - x;
             break;
           case GST_VIDEO_ORIENTATION_90L:
-            new_x = GST_VIDEO_INFO_HEIGHT (in_info) - 1 - y;
+            new_x = GST_VIDEO_INFO_HEIGHT (out_info) - 1 - y;
             new_y = x;
             break;
-          case GST_VIDEO_ORIENTATION_UR_LL:
-            new_x = GST_VIDEO_INFO_HEIGHT (in_info) - 1 - y;
-            new_y = GST_VIDEO_INFO_WIDTH (in_info) - 1 - x;
-            break;
           case GST_VIDEO_ORIENTATION_UL_LR:
             new_x = y;
             new_y = x;
             break;
+          case GST_VIDEO_ORIENTATION_UR_LL:
+            new_x = GST_VIDEO_INFO_HEIGHT (out_info) - 1 - y;
+            new_y = GST_VIDEO_INFO_WIDTH (out_info) - 1 - x;
+            break;
           case GST_VIDEO_ORIENTATION_180:
             /* FIXME: is this correct? */
-            new_x = GST_VIDEO_INFO_WIDTH (in_info) - 1 - x;
-            new_y = GST_VIDEO_INFO_HEIGHT (in_info) - 1 - y;
+            new_x = GST_VIDEO_INFO_WIDTH (out_info) - 1 - x;
+            new_y = GST_VIDEO_INFO_HEIGHT (out_info) - 1 - y;
             break;
           case GST_VIDEO_ORIENTATION_HORIZ:
-            new_x = GST_VIDEO_INFO_WIDTH (in_info) - 1 - x;
+            new_x = GST_VIDEO_INFO_WIDTH (out_info) - 1 - x;
             new_y = y;
             break;
           case GST_VIDEO_ORIENTATION_VERT:
             new_x = x;
-            new_y = GST_VIDEO_INFO_HEIGHT (in_info) - 1 - y;
+            new_y = GST_VIDEO_INFO_HEIGHT (out_info) - 1 - y;
             break;
           default:
             new_x = x;
@@ -2005,38 +2006,20 @@ gst_va_vpp_sink_event (GstBaseTransform * trans, GstEvent * event)
 {
   GstVaVpp *self = GST_VA_VPP (trans);
   GstTagList *taglist;
-  gchar *orientation;
+  GstVideoOrientationMethod method;
 
   switch (GST_EVENT_TYPE (event)) {
     case GST_EVENT_TAG:
       gst_event_parse_tag (event, &taglist);
 
-      if (!gst_tag_list_get_string (taglist, "image-orientation", &orientation))
-        break;
-
       if (self->direction != GST_VIDEO_ORIENTATION_AUTO)
         break;
 
-      GST_DEBUG_OBJECT (self, "tag orientation %s", orientation);
+      if (!gst_video_orientation_from_tag (taglist, &method))
+        break;
 
       GST_OBJECT_LOCK (self);
-      if (!g_strcmp0 ("rotate-0", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_IDENTITY;
-      else if (!g_strcmp0 ("rotate-90", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_90R;
-      else if (!g_strcmp0 ("rotate-180", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_180;
-      else if (!g_strcmp0 ("rotate-270", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_90L;
-      else if (!g_strcmp0 ("flip-rotate-0", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_HORIZ;
-      else if (!g_strcmp0 ("flip-rotate-90", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_UL_LR;
-      else if (!g_strcmp0 ("flip-rotate-180", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_VERT;
-      else if (!g_strcmp0 ("flip-rotate-270", orientation))
-        self->tag_direction = GST_VIDEO_ORIENTATION_UR_LL;
-
+      self->tag_direction = method;
       _update_properties_unlocked (self);
       GST_OBJECT_UNLOCK (self);
 
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcutils.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcutils.cpp
new file mode 100644
index 0000000000..a8becfd339
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcutils.cpp
@@ -0,0 +1,71 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#include "gstwin32ipcutils.h"
+#include <windows.h>
+#include <string>
+#include <mutex>
+
+static ULONG global_index = 0;
+
+static DWORD
+gst_win32_ipc_get_pid (void)
+{
+  static std::once_flag once_flag;
+  static DWORD pid = 0;
+
+  std::call_once (once_flag,[&]() {
+        pid = GetCurrentProcessId ();
+      });
+
+  return pid;
+}
+
+/* Create unique prefix for named shared memory */
+gchar *
+gst_win32_ipc_get_mmf_prefix (void)
+{
+  std::string prefix = "Local\\gst.win32.ipc." +
+      std::to_string (gst_win32_ipc_get_pid ()) + std::string (".") +
+      std::to_string (InterlockedIncrement (&global_index)) + std::string (".");
+
+  return g_strdup (prefix.c_str ());
+}
+
+gboolean
+gst_win32_ipc_clock_is_qpc (GstClock * clock)
+{
+  GstClockType clock_type = GST_CLOCK_TYPE_MONOTONIC;
+  GstClock *mclock;
+
+  if (G_OBJECT_TYPE (clock) != GST_TYPE_SYSTEM_CLOCK)
+    return FALSE;
+
+  g_object_get (clock, "clock-type", &clock_type, nullptr);
+  if (clock_type != GST_CLOCK_TYPE_MONOTONIC)
+    return FALSE;
+
+  mclock = gst_clock_get_master (clock);
+  if (!mclock)
+    return TRUE;
+
+  gst_object_unref (mclock);
+
+  return FALSE;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcutils.h b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcutils.h
new file mode 100644
index 0000000000..5422c3ce20
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcutils.h
@@ -0,0 +1,30 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#pragma once
+
+#include <gst/gst.h>
+
+G_BEGIN_DECLS
+
+gchar * gst_win32_ipc_get_mmf_prefix (void);
+
+gboolean gst_win32_ipc_clock_is_qpc (GstClock * clock);
+
+G_END_DECLS
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosink.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosink.cpp
new file mode 100644
index 0000000000..e2a2756457
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosink.cpp
@@ -0,0 +1,463 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/**
+ * SECTION:element-win32ipcvideosink
+ * @title: win32ipcvideosink
+ * @short_description: Windows shared memory video sink
+ *
+ * win32ipcvideosink provides raw video memory to connected win32ipcvideossrc
+ * elements
+ *
+ * ## Example launch line
+ * ```
+ * gst-launch-1.0 videotestsrc ! queue ! win32ipcvideosink
+ * ```
+ *
+ * Since: 1.22
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "gstwin32ipcvideosink.h"
+#include "gstwin32ipcutils.h"
+#include "protocol/win32ipcpipeserver.h"
+#include <string>
+#include <string.h>
+
+GST_DEBUG_CATEGORY_STATIC (gst_win32_ipc_video_sink_debug);
+#define GST_CAT_DEFAULT gst_win32_ipc_video_sink_debug
+
+static GstStaticPadTemplate sink_template = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE (GST_VIDEO_FORMATS_ALL)));
+
+enum
+{
+  PROP_0,
+  PROP_PIPE_NAME,
+};
+
+#define DEFAULT_PIPE_NAME "\\\\.\\pipe\\gst.win32.ipc.video"
+
+struct _GstWin32IpcVideoSink
+{
+  GstBaseSink parent;
+
+  GstVideoInfo info;
+  Win32IpcPipeServer *pipe;
+  gchar *mmf_prefix;
+  guint64 seq_num;
+  LARGE_INTEGER frequency;
+
+  Win32IpcMmf *mmf;
+  Win32IpcVideoInfo minfo;
+
+  /* properties */
+  gchar *pipe_name;
+};
+
+static void gst_win32_ipc_video_sink_finalize (GObject * object);
+static void gst_win32_ipc_video_sink_set_property (GObject * object,
+    guint prop_id, const GValue * value, GParamSpec * pspec);
+static void gst_win32_video_sink_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec);
+
+static GstClock *gst_win32_ipc_video_sink_provide_clock (GstElement * elem);
+
+static gboolean gst_win32_ipc_video_sink_start (GstBaseSink * sink);
+static gboolean gst_win32_ipc_video_sink_stop (GstBaseSink * sink);
+static gboolean gst_win32_ipc_video_sink_unlock_stop (GstBaseSink * sink);
+static gboolean gst_win32_ipc_video_sink_set_caps (GstBaseSink * sink,
+    GstCaps * caps);
+static void gst_win32_ipc_video_sink_get_time (GstBaseSink * sink,
+    GstBuffer * buf, GstClockTime * start, GstClockTime * end);
+static gboolean gst_win32_ipc_video_sink_propose_allocation (GstBaseSink * sink,
+    GstQuery * query);
+static GstFlowReturn gst_win32_ipc_video_sink_prepare (GstBaseSink * sink,
+    GstBuffer * buf);
+static GstFlowReturn gst_win32_ipc_video_sink_render (GstBaseSink * sink,
+    GstBuffer * buf);
+
+#define gst_win32_ipc_video_sink_parent_class parent_class
+G_DEFINE_TYPE (GstWin32IpcVideoSink, gst_win32_ipc_video_sink,
+    GST_TYPE_BASE_SINK);
+
+static void
+gst_win32_ipc_video_sink_class_init (GstWin32IpcVideoSinkClass * klass)
+{
+  GObjectClass *object_class = G_OBJECT_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+  GstBaseSinkClass *sink_class = GST_BASE_SINK_CLASS (klass);
+
+  object_class->finalize = gst_win32_ipc_video_sink_finalize;
+  object_class->set_property = gst_win32_ipc_video_sink_set_property;
+  object_class->get_property = gst_win32_video_sink_get_property;
+
+  g_object_class_install_property (object_class, PROP_PIPE_NAME,
+      g_param_spec_string ("pipe-name", "Pipe Name",
+          "The name of Win32 named pipe to communicate with clients. "
+          "Validation of the pipe name is caller's responsibility",
+          DEFAULT_PIPE_NAME, (GParamFlags) (G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS | GST_PARAM_MUTABLE_READY)));
+
+  gst_element_class_set_static_metadata (element_class,
+      "Win32 IPC Video Sink", "Sink/Video",
+      "Send video frames to win32ipcvideosrc elements",
+      "Seungha Yang <seungha@centricular.com>");
+  gst_element_class_add_static_pad_template (element_class, &sink_template);
+
+  element_class->provide_clock =
+      GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_provide_clock);
+
+  sink_class->start = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_start);
+  sink_class->stop = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_stop);
+  sink_class->unlock_stop =
+      GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_unlock_stop);
+  sink_class->set_caps = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_set_caps);
+  sink_class->propose_allocation =
+      GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_propose_allocation);
+  sink_class->get_times = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_get_time);
+  sink_class->prepare = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_prepare);
+  sink_class->render = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_sink_render);
+
+  GST_DEBUG_CATEGORY_INIT (gst_win32_ipc_video_sink_debug, "win32ipcvideosink",
+      0, "win32ipcvideosink");
+}
+
+static void
+gst_win32_ipc_video_sink_init (GstWin32IpcVideoSink * self)
+{
+  self->pipe_name = g_strdup (DEFAULT_PIPE_NAME);
+  QueryPerformanceFrequency (&self->frequency);
+
+  GST_OBJECT_FLAG_SET (self, GST_ELEMENT_FLAG_PROVIDE_CLOCK);
+  GST_OBJECT_FLAG_SET (self, GST_ELEMENT_FLAG_REQUIRE_CLOCK);
+}
+
+static void
+gst_win32_ipc_video_sink_finalize (GObject * object)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (object);
+
+  g_free (self->pipe_name);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_win32_ipc_video_sink_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (object);
+
+  switch (prop_id) {
+    case PROP_PIPE_NAME:
+      GST_OBJECT_LOCK (self);
+      g_free (self->pipe_name);
+      self->pipe_name = g_value_dup_string (value);
+      if (!self->pipe_name)
+        self->pipe_name = g_strdup (DEFAULT_PIPE_NAME);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_win32_video_sink_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (object);
+
+  switch (prop_id) {
+    case PROP_PIPE_NAME:
+      GST_OBJECT_LOCK (self);
+      g_value_set_string (value, self->pipe_name);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static GstClock *
+gst_win32_ipc_video_sink_provide_clock (GstElement * elem)
+{
+  return gst_system_clock_obtain ();
+}
+
+static gboolean
+gst_win32_ipc_video_sink_start (GstBaseSink * sink)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+
+  GST_DEBUG_OBJECT (self, "Start");
+
+  self->pipe = win32_ipc_pipe_server_new (self->pipe_name);
+  if (!self->pipe) {
+    GST_ERROR_OBJECT (self, "Couldn't create pipe server");
+    return FALSE;
+  }
+
+  self->mmf_prefix = gst_win32_ipc_get_mmf_prefix ();
+  self->seq_num = 0;
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_sink_stop (GstBaseSink * sink)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+
+  GST_DEBUG_OBJECT (self, "Stop");
+
+  g_clear_pointer (&self->pipe, win32_ipc_pipe_server_unref);
+  g_clear_pointer (&self->mmf_prefix, g_free);
+  g_clear_pointer (&self->mmf, win32_ipc_mmf_unref);
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_sink_unlock_stop (GstBaseSink * sink)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+
+  g_clear_pointer (&self->mmf, win32_ipc_mmf_unref);
+
+  return TRUE;
+}
+
+static void
+gst_win32_ipc_video_sink_get_time (GstBaseSink * sink, GstBuffer * buf,
+    GstClockTime * start, GstClockTime * end)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+  GstClockTime timestamp;
+
+  timestamp = GST_BUFFER_PTS (buf);
+  if (!GST_CLOCK_TIME_IS_VALID (timestamp))
+    timestamp = GST_BUFFER_DTS (buf);
+
+  if (GST_CLOCK_TIME_IS_VALID (timestamp)) {
+    *start = timestamp;
+    if (GST_BUFFER_DURATION_IS_VALID (buf)) {
+      *end = timestamp + GST_BUFFER_DURATION (buf);
+    } else if (self->info.fps_n > 0) {
+      *end = timestamp +
+          gst_util_uint64_scale_int (GST_SECOND, self->info.fps_d,
+          self->info.fps_n);
+    } else if (sink->segment.rate < 0) {
+      *end = timestamp;
+    }
+  }
+}
+
+static gboolean
+gst_win32_ipc_video_sink_set_caps (GstBaseSink * sink, GstCaps * caps)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+
+  if (!gst_video_info_from_caps (&self->info, caps)) {
+    GST_WARNING_OBJECT (self, "Invalid caps");
+    return FALSE;
+  }
+
+  memset (&self->minfo, 0, sizeof (Win32IpcVideoInfo));
+  self->minfo.format =
+      (Win32IpcVideoFormat) GST_VIDEO_INFO_FORMAT (&self->info);
+  self->minfo.width = GST_VIDEO_INFO_WIDTH (&self->info);
+  self->minfo.height = GST_VIDEO_INFO_HEIGHT (&self->info);
+  self->minfo.fps_n = self->info.fps_n;
+  self->minfo.fps_d = self->info.fps_d;
+  self->minfo.par_n = self->info.par_n;
+  self->minfo.par_d = self->info.par_d;
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_sink_propose_allocation (GstBaseSink * sink,
+    GstQuery * query)
+{
+  GstCaps *caps;
+  GstBufferPool *pool = nullptr;
+  GstVideoInfo info;
+  guint size;
+  gboolean need_pool;
+
+  gst_query_parse_allocation (query, &caps, &need_pool);
+  if (!caps) {
+    GST_WARNING_OBJECT (sink, "No caps specified");
+    return FALSE;
+  }
+
+  if (!gst_video_info_from_caps (&info, caps)) {
+    GST_WARNING_OBJECT (sink, "Invalid caps %" GST_PTR_FORMAT, caps);
+    return FALSE;
+  }
+
+  /* the normal size of a frame */
+  size = info.size;
+  if (need_pool) {
+    GstStructure *config;
+
+    pool = gst_video_buffer_pool_new ();
+    config = gst_buffer_pool_get_config (pool);
+    gst_buffer_pool_config_add_option (config,
+        GST_BUFFER_POOL_OPTION_VIDEO_META);
+
+    size = GST_VIDEO_INFO_SIZE (&info);
+
+    gst_buffer_pool_config_set_params (config, caps, (guint) size, 0, 0);
+
+    if (!gst_buffer_pool_set_config (pool, config)) {
+      GST_ERROR_OBJECT (pool, "Couldn't set config");
+      gst_object_unref (pool);
+
+      return FALSE;
+    }
+  }
+
+  gst_query_add_allocation_pool (query, pool, size, 0, 0);
+  gst_clear_object (&pool);
+
+  gst_query_add_allocation_meta (query, GST_VIDEO_META_API_TYPE, NULL);
+
+  return TRUE;
+}
+
+static GstFlowReturn
+gst_win32_ipc_video_sink_prepare (GstBaseSink * sink, GstBuffer * buf)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+  std::string mmf_name;
+  GstVideoFrame frame;
+  GstMapInfo info;
+
+  g_clear_pointer (&self->mmf, win32_ipc_mmf_unref);
+
+  if (!gst_video_frame_map (&frame, &self->info, buf, GST_MAP_READ)) {
+    GST_ERROR_OBJECT (self, "Couldn't map frame");
+    return GST_FLOW_ERROR;
+  }
+
+  mmf_name = std::string (self->mmf_prefix) + std::to_string (self->seq_num);
+  self->seq_num++;
+
+  self->mmf = win32_ipc_mmf_alloc (GST_VIDEO_FRAME_SIZE (&frame),
+      mmf_name.c_str ());
+  if (!self->mmf) {
+    GST_ERROR_OBJECT (self, "Couldn't create memory with name %s",
+        mmf_name.c_str ());
+    gst_video_frame_unmap (&frame);
+    return GST_FLOW_ERROR;
+  }
+
+  self->minfo.size = GST_VIDEO_FRAME_SIZE (&frame);
+  for (guint i = 0; i < GST_VIDEO_FRAME_N_PLANES (&frame); i++) {
+    self->minfo.offset[i] = GST_VIDEO_FRAME_PLANE_OFFSET (&frame, i);
+    self->minfo.stride[i] = GST_VIDEO_FRAME_PLANE_STRIDE (&frame, i);
+  }
+  gst_video_frame_unmap (&frame);
+
+  gst_buffer_map (buf, &info, GST_MAP_READ);
+  memcpy (win32_ipc_mmf_get_raw (self->mmf), info.data, self->minfo.size);
+  gst_buffer_unmap (buf, &info);
+
+  return GST_FLOW_OK;
+}
+
+static GstFlowReturn
+gst_win32_ipc_video_sink_render (GstBaseSink * sink, GstBuffer * buf)
+{
+  GstWin32IpcVideoSink *self = GST_WIN32_IPC_VIDEO_SINK (sink);
+  LARGE_INTEGER cur_time;
+  GstClockTime pts;
+  GstClockTime now_qpc;
+  GstClockTime buf_pts;
+  GstClockTime buffer_clock = GST_CLOCK_TIME_NONE;
+
+  QueryPerformanceCounter (&cur_time);
+  pts = now_qpc = gst_util_uint64_scale (cur_time.QuadPart, GST_SECOND,
+      self->frequency.QuadPart);
+
+  buf_pts = GST_BUFFER_PTS (buf);
+  if (!GST_CLOCK_TIME_IS_VALID (buf_pts))
+    buf_pts = GST_BUFFER_DTS (buf);
+
+  if (GST_CLOCK_TIME_IS_VALID (buf_pts)) {
+    buffer_clock = gst_segment_to_running_time (&sink->segment,
+        GST_FORMAT_TIME, buf_pts) +
+        GST_ELEMENT_CAST (sink)->base_time + gst_base_sink_get_latency (sink);
+  }
+
+  if (GST_CLOCK_TIME_IS_VALID (buffer_clock)) {
+    GstClock *clock = gst_element_get_clock (GST_ELEMENT_CAST (sink));
+    gboolean is_qpc = TRUE;
+
+    is_qpc = gst_win32_ipc_clock_is_qpc (clock);
+    if (!is_qpc) {
+      GstClockTime now_gst = gst_clock_get_time (clock);
+      GstClockTimeDiff converted = buffer_clock;
+
+      GST_LOG_OBJECT (self, "Clock is not QPC");
+
+      converted -= now_gst;
+      converted += now_qpc;
+
+      if (converted < 0) {
+        /* Shouldn't happen */
+        GST_WARNING_OBJECT (self, "Negative buffer clock");
+        pts = 0;
+      } else {
+        pts = converted;
+      }
+    } else {
+      GST_LOG_OBJECT (self, "Clock is QPC already");
+      /* buffer clock is already QPC time */
+      pts = buffer_clock;
+    }
+    gst_object_unref (clock);
+  }
+
+  self->minfo.qpc = pts;
+
+  if (!self->pipe) {
+    GST_ERROR_OBJECT (self, "Pipe server was not configured");
+    return GST_FLOW_ERROR;
+  }
+
+  /* win32_ipc_pipe_server_send_mmf() takes ownership of mmf */
+  if (!win32_ipc_pipe_server_send_mmf (self->pipe,
+          (Win32IpcMmf *) g_steal_pointer (&self->mmf), &self->minfo)) {
+    GST_ERROR_OBJECT (self, "Couldn't send buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  return GST_FLOW_OK;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosink.h b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosink.h
new file mode 100644
index 0000000000..b2cbac08eb
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosink.h
@@ -0,0 +1,32 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#pragma once
+
+#include <gst/gst.h>
+#include <gst/base/gstbasesink.h>
+#include <gst/video/video.h>
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_WIN32_IPC_VIDEO_SINK (gst_win32_ipc_video_sink_get_type())
+G_DECLARE_FINAL_TYPE (GstWin32IpcVideoSink, gst_win32_ipc_video_sink,
+    GST, WIN32_IPC_VIDEO_SINK, GstBaseSink);
+
+G_END_DECLS
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosrc.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosrc.cpp
new file mode 100644
index 0000000000..1afbc98b02
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosrc.cpp
@@ -0,0 +1,543 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/**
+ * SECTION:element-win32ipcvideosrc
+ * @title: win32ipcvideosrc
+ * @short_description: Windows shared memory video source
+ *
+ * win32ipcvideosrc receives raw video frames from win32ipcvideosink
+ * and outputs the received video frames
+ *
+ * ## Example launch line
+ * ```
+ * gst-launch-1.0 win32ipcvideosrc ! queue ! videoconvert ! d3d11videosink
+ * ```
+ *
+ * Since: 1.22
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "gstwin32ipcvideosrc.h"
+#include "gstwin32ipcutils.h"
+#include "protocol/win32ipcpipeclient.h"
+#include <string>
+
+GST_DEBUG_CATEGORY_STATIC (gst_win32_ipc_video_src_debug);
+#define GST_CAT_DEFAULT gst_win32_ipc_video_src_debug
+
+static GstStaticPadTemplate src_template = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_VIDEO_CAPS_MAKE (GST_VIDEO_FORMATS_ALL)));
+
+enum
+{
+  PROP_0,
+  PROP_PIPE_NAME,
+  PROP_PROCESSING_DEADLINE,
+};
+
+#define DEFAULT_PIPE_NAME "\\\\.\\pipe\\gst.win32.ipc.video"
+#define DEFAULT_PROCESSING_DEADLINE (20 * GST_MSECOND)
+
+struct _GstWin32IpcVideoSrc
+{
+  GstBaseSrc parent;
+
+  GstVideoInfo info;
+
+  Win32IpcPipeClient *pipe;
+  GstCaps *caps;
+  gboolean flushing;
+  SRWLOCK lock;
+  gboolean have_video_meta;
+  gsize offset[GST_VIDEO_MAX_PLANES];
+  gint stride[GST_VIDEO_MAX_PLANES];
+  LARGE_INTEGER frequency;
+  GstBufferPool *pool;
+
+  /* properties */
+  gchar *pipe_name;
+  GstClockTime processing_deadline;
+};
+
+static void gst_win32_ipc_video_src_finalize (GObject * object);
+static void gst_win32_ipc_video_src_set_property (GObject * object,
+    guint prop_id, const GValue * value, GParamSpec * pspec);
+static void gst_win32_video_src_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec);
+
+static GstClock *gst_win32_video_src_provide_clock (GstElement * elem);
+
+static gboolean gst_win32_ipc_video_src_start (GstBaseSrc * src);
+static gboolean gst_win32_ipc_video_src_stop (GstBaseSrc * src);
+static gboolean gst_win32_ipc_video_src_unlock (GstBaseSrc * src);
+static gboolean gst_win32_ipc_video_src_unlock_stop (GstBaseSrc * src);
+static gboolean gst_win32_ipc_video_src_query (GstBaseSrc * src,
+    GstQuery * query);
+static gboolean gst_win32_ipc_video_src_decide_allocation (GstBaseSrc * src,
+    GstQuery * query);
+static GstFlowReturn gst_win32_ipc_video_src_create (GstBaseSrc * src,
+    guint64 offset, guint size, GstBuffer ** buf);
+
+#define gst_win32_ipc_video_src_parent_class parent_class
+G_DEFINE_TYPE (GstWin32IpcVideoSrc, gst_win32_ipc_video_src, GST_TYPE_BASE_SRC);
+
+static void
+gst_win32_ipc_video_src_class_init (GstWin32IpcVideoSrcClass * klass)
+{
+  GObjectClass *object_class = G_OBJECT_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+  GstBaseSrcClass *src_class = GST_BASE_SRC_CLASS (klass);
+
+  object_class->finalize = gst_win32_ipc_video_src_finalize;
+  object_class->set_property = gst_win32_ipc_video_src_set_property;
+  object_class->get_property = gst_win32_video_src_get_property;
+
+  g_object_class_install_property (object_class, PROP_PIPE_NAME,
+      g_param_spec_string ("pipe-name", "Pipe Name",
+          "The name of Win32 named pipe to communicate with server. "
+          "Validation of the pipe name is caller's responsibility",
+          DEFAULT_PIPE_NAME, (GParamFlags) (G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS | GST_PARAM_MUTABLE_READY)));
+  g_object_class_install_property (object_class, PROP_PROCESSING_DEADLINE,
+      g_param_spec_uint64 ("processing-deadline", "Processing deadline",
+          "Maximum processing time for a buffer in nanoseconds", 0, G_MAXUINT64,
+          DEFAULT_PROCESSING_DEADLINE, (GParamFlags) (G_PARAM_READWRITE |
+              G_PARAM_STATIC_STRINGS | GST_PARAM_MUTABLE_PLAYING)));
+
+  gst_element_class_set_static_metadata (element_class,
+      "Win32 IPC Video Source", "Source/Video",
+      "Receive video frames from the win32ipcvideosink",
+      "Seungha Yang <seungha@centricular.com>");
+  gst_element_class_add_static_pad_template (element_class, &src_template);
+
+  element_class->provide_clock =
+      GST_DEBUG_FUNCPTR (gst_win32_video_src_provide_clock);
+
+  src_class->start = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_start);
+  src_class->stop = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_stop);
+  src_class->unlock = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_unlock);
+  src_class->unlock_stop =
+      GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_unlock_stop);
+  src_class->query = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_query);
+  src_class->decide_allocation =
+      GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_decide_allocation);
+  src_class->create = GST_DEBUG_FUNCPTR (gst_win32_ipc_video_src_create);
+
+  GST_DEBUG_CATEGORY_INIT (gst_win32_ipc_video_src_debug, "win32ipcvideosrc",
+      0, "win32ipcvideosrc");
+}
+
+static void
+gst_win32_ipc_video_src_init (GstWin32IpcVideoSrc * self)
+{
+  gst_base_src_set_format (GST_BASE_SRC (self), GST_FORMAT_TIME);
+  gst_base_src_set_live (GST_BASE_SRC (self), TRUE);
+  self->pipe_name = g_strdup (DEFAULT_PIPE_NAME);
+  self->processing_deadline = DEFAULT_PROCESSING_DEADLINE;
+  QueryPerformanceFrequency (&self->frequency);
+
+  GST_OBJECT_FLAG_SET (self, GST_ELEMENT_FLAG_PROVIDE_CLOCK);
+  GST_OBJECT_FLAG_SET (self, GST_ELEMENT_FLAG_REQUIRE_CLOCK);
+}
+
+static void
+gst_win32_ipc_video_src_finalize (GObject * object)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (object);
+
+  g_free (self->pipe_name);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_win32_ipc_video_src_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (object);
+
+  switch (prop_id) {
+    case PROP_PIPE_NAME:
+      GST_OBJECT_LOCK (self);
+      g_free (self->pipe_name);
+      self->pipe_name = g_value_dup_string (value);
+      if (!self->pipe_name)
+        self->pipe_name = g_strdup (DEFAULT_PIPE_NAME);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    case PROP_PROCESSING_DEADLINE:
+    {
+      GstClockTime prev_val, new_val;
+      GST_OBJECT_LOCK (self);
+      prev_val = self->processing_deadline;
+      new_val = g_value_get_uint64 (value);
+      self->processing_deadline = new_val;
+      GST_OBJECT_UNLOCK (self);
+
+      if (prev_val != new_val) {
+        GST_DEBUG_OBJECT (self, "Posting latency message");
+        gst_element_post_message (GST_ELEMENT_CAST (self),
+            gst_message_new_latency (GST_OBJECT_CAST (self)));
+      }
+      break;
+    }
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_win32_video_src_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (object);
+
+  switch (prop_id) {
+    case PROP_PIPE_NAME:
+      GST_OBJECT_LOCK (self);
+      g_value_set_string (value, self->pipe_name);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    case PROP_PROCESSING_DEADLINE:
+      GST_OBJECT_LOCK (self);
+      g_value_set_uint64 (value, self->processing_deadline);
+      GST_OBJECT_UNLOCK (self);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static GstClock *
+gst_win32_video_src_provide_clock (GstElement * elem)
+{
+  return gst_system_clock_obtain ();
+}
+
+static gboolean
+gst_win32_ipc_video_src_start (GstBaseSrc * src)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+
+  GST_DEBUG_OBJECT (self, "Start");
+
+  gst_video_info_init (&self->info);
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_src_stop (GstBaseSrc * src)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+
+  GST_DEBUG_OBJECT (self, "Stop");
+
+  g_clear_pointer (&self->pipe, win32_ipc_pipe_client_unref);
+  gst_clear_caps (&self->caps);
+  if (self->pool) {
+    gst_buffer_pool_set_active (self->pool, FALSE);
+    gst_clear_object (&self->pool);
+  }
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_src_unlock (GstBaseSrc * src)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+
+  GST_DEBUG_OBJECT (self, "Unlock");
+
+  AcquireSRWLockExclusive (&self->lock);
+  self->flushing = TRUE;
+  if (self->pipe)
+    win32_ipc_pipe_client_shutdown (self->pipe);
+  ReleaseSRWLockExclusive (&self->lock);
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_src_unlock_stop (GstBaseSrc * src)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+
+  GST_DEBUG_OBJECT (self, "Unlock stop");
+
+  AcquireSRWLockExclusive (&self->lock);
+  g_clear_pointer (&self->pipe, win32_ipc_pipe_client_unref);
+  gst_clear_caps (&self->caps);
+  self->flushing = FALSE;
+  ReleaseSRWLockExclusive (&self->lock);
+
+  return TRUE;
+}
+
+static gboolean
+gst_win32_ipc_video_src_query (GstBaseSrc * src, GstQuery * query)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+
+  switch (GST_QUERY_TYPE (query)) {
+    case GST_QUERY_LATENCY:
+    {
+      GST_OBJECT_LOCK (self);
+      if (GST_CLOCK_TIME_IS_VALID (self->processing_deadline)) {
+        gst_query_set_latency (query, TRUE, self->processing_deadline,
+            /* pipe server can hold up to 5 memory objects */
+            5 * self->processing_deadline);
+      } else {
+        gst_query_set_latency (query, TRUE, 0, 0);
+      }
+      GST_OBJECT_UNLOCK (self);
+      return TRUE;
+    }
+    default:
+      break;
+  }
+
+  return GST_BASE_SRC_CLASS (parent_class)->query (src, query);
+}
+
+static gboolean
+gst_win32_ipc_video_src_decide_allocation (GstBaseSrc * src, GstQuery * query)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+  gboolean ret;
+
+  ret = GST_BASE_SRC_CLASS (parent_class)->decide_allocation (src, query);
+  if (!ret)
+    return ret;
+
+  self->have_video_meta = gst_query_find_allocation_meta (query,
+      GST_VIDEO_META_API_TYPE, nullptr);
+  GST_DEBUG_OBJECT (self, "Downstream supports video meta: %d",
+      self->have_video_meta);
+
+  return TRUE;
+}
+
+static GstCaps *
+gst_win32_ipc_video_src_update_info_and_get_caps (GstWin32IpcVideoSrc * self,
+    const Win32IpcVideoInfo * info)
+{
+  GstVideoInfo vinfo;
+
+  gst_video_info_set_format (&vinfo, (GstVideoFormat) info->format,
+      info->width, info->height);
+  vinfo.fps_n = info->fps_n;
+  vinfo.fps_d = info->fps_d;
+  vinfo.par_n = info->par_n;
+  vinfo.par_d = info->par_d;
+
+  if (!self->caps || !gst_video_info_is_equal (&self->info, &vinfo)) {
+    self->info = vinfo;
+    return gst_video_info_to_caps (&vinfo);
+  }
+
+  return nullptr;
+}
+
+static gboolean
+gst_win32_ipc_ensure_fallback_pool (GstWin32IpcVideoSrc * self)
+{
+  GstStructure *config;
+
+  if (self->pool)
+    return TRUE;
+
+  self->pool = gst_video_buffer_pool_new ();
+  config = gst_buffer_pool_get_config (self->pool);
+  gst_buffer_pool_config_set_params (config, self->caps,
+      GST_VIDEO_INFO_SIZE (&self->info), 0, 0);
+  if (!gst_buffer_pool_set_config (self->pool, config)) {
+    GST_ERROR_OBJECT (self, "Couldn't set config");
+    goto error;
+  }
+
+  if (!gst_buffer_pool_set_active (self->pool, TRUE)) {
+    GST_ERROR_OBJECT (self, "Couldn't set active");
+    goto error;
+  }
+
+  return TRUE;
+
+error:
+  gst_clear_object (&self->pool);
+  return FALSE;
+}
+
+static GstFlowReturn
+gst_win32_ipc_video_src_create (GstBaseSrc * src, guint64 offset, guint size,
+    GstBuffer ** buf)
+{
+  GstWin32IpcVideoSrc *self = GST_WIN32_IPC_VIDEO_SRC (src);
+  GstCaps *caps;
+  Win32IpcMmf *mmf;
+  Win32IpcVideoInfo info;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstBuffer *buffer;
+  GstClock *clock;
+  GstClockTime pts;
+  GstClockTime base_time;
+  GstClockTime now_qpc;
+  GstClockTime now_gst;
+  LARGE_INTEGER cur_time;
+  gboolean is_qpc = TRUE;
+  gboolean need_video_meta = FALSE;
+
+  AcquireSRWLockExclusive (&self->lock);
+  if (self->flushing) {
+    ReleaseSRWLockExclusive (&self->lock);
+    return GST_FLOW_FLUSHING;
+  }
+
+  if (!self->pipe) {
+    self->pipe = win32_ipc_pipe_client_new (self->pipe_name);
+    if (!self->pipe) {
+      ReleaseSRWLockExclusive (&self->lock);
+      GST_ERROR_OBJECT (self, "Couldn't create pipe");
+      return GST_FLOW_ERROR;
+    }
+  }
+  ReleaseSRWLockExclusive (&self->lock);
+
+  if (!win32_ipc_pipe_client_get_mmf (self->pipe, &mmf, &info)) {
+    AcquireSRWLockExclusive (&self->lock);
+    if (self->flushing) {
+      ret = GST_FLOW_FLUSHING;
+      GST_DEBUG_OBJECT (self, "Flushing");
+    } else {
+      ret = GST_FLOW_EOS;
+      GST_WARNING_OBJECT (self, "Couldn't get buffer from server");
+    }
+    ReleaseSRWLockExclusive (&self->lock);
+    return ret;
+  }
+
+  caps = gst_win32_ipc_video_src_update_info_and_get_caps (self, &info);
+  for (guint i = 0; i < GST_VIDEO_INFO_N_PLANES (&self->info); i++) {
+    self->offset[i] = (gsize) info.offset[i];
+    self->stride[i] = (gint) info.stride[i];
+
+    if (self->offset[i] != self->info.offset[i] ||
+        self->stride[i] != self->info.stride[i]) {
+      need_video_meta = TRUE;
+    }
+  }
+
+  if (caps) {
+    if (self->pool) {
+      gst_buffer_pool_set_active (self->pool, FALSE);
+      gst_clear_object (&self->pool);
+    }
+
+    gst_caps_replace (&self->caps, caps);
+    GST_DEBUG_OBJECT (self, "Setting caps %" GST_PTR_FORMAT, caps);
+    gst_pad_set_caps (GST_BASE_SRC_PAD (src), caps);
+    gst_caps_unref (caps);
+  }
+
+  if (self->have_video_meta || !need_video_meta) {
+    buffer = gst_buffer_new_wrapped_full (GST_MEMORY_FLAG_READONLY,
+        win32_ipc_mmf_get_raw (mmf), win32_ipc_mmf_get_size (mmf),
+        0, win32_ipc_mmf_get_size (mmf), mmf,
+        (GDestroyNotify) win32_ipc_mmf_unref);
+
+    if (self->have_video_meta) {
+      gst_buffer_add_video_meta_full (buffer,
+          GST_VIDEO_FRAME_FLAG_NONE, GST_VIDEO_INFO_FORMAT (&self->info),
+          GST_VIDEO_INFO_WIDTH (&self->info),
+          GST_VIDEO_INFO_HEIGHT (&self->info),
+          GST_VIDEO_INFO_N_PLANES (&self->info), self->offset, self->stride);
+    }
+  } else {
+    GstVideoFrame mmf_frame, frame;
+
+    if (!gst_win32_ipc_ensure_fallback_pool (self)) {
+      win32_ipc_mmf_unref (mmf);
+      return GST_FLOW_ERROR;
+    }
+
+    ret = gst_buffer_pool_acquire_buffer (self->pool, &buffer, nullptr);
+    if (ret != GST_FLOW_OK) {
+      GST_ERROR_OBJECT (self, "Couldn't acquire buffer");
+      win32_ipc_mmf_unref (mmf);
+      return GST_FLOW_ERROR;
+    }
+
+    gst_video_frame_map (&frame, &self->info, buffer, GST_MAP_WRITE);
+    mmf_frame.info = self->info;
+
+    for (guint i = 0; i < GST_VIDEO_FRAME_N_PLANES (&frame); i++) {
+      mmf_frame.info.offset[i] = self->offset[i];
+      mmf_frame.info.stride[i] = self->stride[i];
+      mmf_frame.data[i] = (guint8 *) win32_ipc_mmf_get_raw (mmf) +
+          self->offset[i];
+    }
+
+    gst_video_frame_copy (&frame, &mmf_frame);
+    gst_video_frame_unmap (&frame);
+  }
+
+  QueryPerformanceCounter (&cur_time);
+  now_qpc = gst_util_uint64_scale (cur_time.QuadPart, GST_SECOND,
+      self->frequency.QuadPart);
+  clock = gst_element_get_clock (GST_ELEMENT_CAST (self));
+  now_gst = gst_clock_get_time (clock);
+  base_time = GST_ELEMENT_CAST (self)->base_time;
+
+  is_qpc = gst_win32_ipc_clock_is_qpc (clock);
+  gst_object_unref (clock);
+
+  if (!is_qpc) {
+    GstClockTimeDiff now_pts = now_gst - base_time + info.qpc - now_qpc;
+
+    if (now_pts >= 0)
+      pts = now_pts;
+    else
+      pts = 0;
+  } else {
+    if (info.qpc >= base_time) {
+      /* Our base_time is also QPC */
+      pts = info.qpc - base_time;
+    } else {
+      GST_WARNING_OBJECT (self, "Server QPC is smaller than our QPC base time");
+      pts = 0;
+    }
+  }
+
+  GST_BUFFER_PTS (buffer) = pts;
+  GST_BUFFER_DTS (buffer) = GST_CLOCK_TIME_NONE;
+  GST_BUFFER_DURATION (buffer) = GST_CLOCK_TIME_NONE;
+
+  *buf = buffer;
+
+  return GST_FLOW_OK;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosrc.h b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosrc.h
new file mode 100644
index 0000000000..ca835da497
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/gstwin32ipcvideosrc.h
@@ -0,0 +1,32 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#pragma once
+
+#include <gst/gst.h>
+#include <gst/base/gstbasesrc.h>
+#include <gst/video/video.h>
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_WIN32_IPC_VIDEO_SRC (gst_win32_ipc_video_src_get_type())
+G_DECLARE_FINAL_TYPE (GstWin32IpcVideoSrc, gst_win32_ipc_video_src,
+    GST, WIN32_IPC_VIDEO_SRC, GstBaseSrc);
+
+G_END_DECLS
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/meson.build b/subprojects/gst-plugins-bad/sys/win32ipc/meson.build
new file mode 100644
index 0000000000..5ffdf5bf2a
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/meson.build
@@ -0,0 +1,39 @@
+win32ipc_sources = [
+  'protocol/win32ipcmmf.cpp',
+  'protocol/win32ipcpipeclient.cpp',
+  'protocol/win32ipcpipeserver.cpp',
+  'protocol/win32ipcprotocol.cpp',
+  'protocol/win32ipcutils.cpp',
+  'gstwin32ipcutils.cpp',
+  'gstwin32ipcvideosink.cpp',
+  'gstwin32ipcvideosrc.cpp',
+  'plugin.cpp',
+]
+
+if host_system != 'windows' or get_option('win32ipc').disabled()
+  subdir_done()
+endif
+
+code = '''
+#include <windows.h>
+#if !(WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_APP) && !WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_DESKTOP))
+#error "Not building for UWP"
+#endif'''
+if cc.compiles(code, name : 'building for UWP')
+  if get_option('win32ipc').enabled()
+    error('win32ipc plugin does not support UWP')
+  else
+    subdir_done()
+  endif
+endif
+
+gstwin32ipc = library('gstwin32ipc',
+  win32ipc_sources,
+  c_args : gst_plugins_bad_args,
+  cpp_args: gst_plugins_bad_args,
+  include_directories : [configinc],
+  dependencies : [gstbase_dep, gstvideo_dep],
+  install : true,
+  install_dir : plugins_install_dir,
+)
+plugins += [gstwin32ipc]
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/plugin.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/plugin.cpp
new file mode 100644
index 0000000000..b086986b14
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/plugin.cpp
@@ -0,0 +1,56 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/**
+ * plugin-win32ipc:
+ *
+ * Windows IPC plugin
+ *
+ * Since: 1.22
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <gst/gst.h>
+#include "gstwin32ipcvideosink.h"
+#include "gstwin32ipcvideosrc.h"
+
+GST_DEBUG_CATEGORY (gst_win32_ipc_debug);
+#define GST_CAT_DEFAULT gst_win32_ipc_debug
+
+static gboolean
+plugin_init (GstPlugin * plugin)
+{
+  GST_DEBUG_CATEGORY_INIT (gst_win32_ipc_debug, "win32ipc", 0, "win32ipc");
+
+  gst_element_register (plugin,
+      "win32ipcvideosink", GST_RANK_NONE, GST_TYPE_WIN32_IPC_VIDEO_SINK);
+  gst_element_register (plugin,
+      "win32ipcvideosrc", GST_RANK_NONE, GST_TYPE_WIN32_IPC_VIDEO_SRC);
+
+  return TRUE;
+}
+
+GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
+    GST_VERSION_MINOR,
+    win32ipc,
+    "Windows IPC plugin",
+    plugin_init, VERSION, "LGPL", GST_PACKAGE_NAME, GST_PACKAGE_ORIGIN)
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcmmf.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcmmf.cpp
new file mode 100644
index 0000000000..713a9109c8
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcmmf.cpp
@@ -0,0 +1,241 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "win32ipcmmf.h"
+#include "win32ipcutils.h"
+#include <string>
+
+GST_DEBUG_CATEGORY_EXTERN (gst_win32_ipc_debug);
+#define GST_CAT_DEFAULT gst_win32_ipc_debug
+
+struct Win32IpcMmf
+{
+  explicit Win32IpcMmf (HANDLE f, void * b, UINT32 s, const std::string & n)
+    : file (f), buffer (b), size (s), name (n), ref_count (1)
+  {
+  }
+
+  ~Win32IpcMmf ()
+  {
+    GST_TRACE ("Freeing %p (%s)", this, name.c_str ());
+    if (buffer)
+      UnmapViewOfFile (buffer);
+    if (file)
+      CloseHandle (file);
+  }
+
+  HANDLE file;
+  void *buffer;
+  UINT32 size;
+  std::string name;
+  ULONG ref_count;
+};
+
+static Win32IpcMmf *
+win32_pic_mmf_new (HANDLE file, UINT32 size, const char * name)
+{
+  Win32IpcMmf *self;
+  void *buffer;
+  std::string msg;
+  UINT err_code;
+
+  buffer = MapViewOfFile (file, FILE_MAP_ALL_ACCESS, 0, 0, size);
+  if (!buffer) {
+    err_code = GetLastError ();
+    msg = win32_ipc_error_message (err_code);
+    GST_ERROR ("MapViewOfFile failed with 0x%x (%s)",
+        err_code, msg.c_str ());
+    CloseHandle (file);
+    return nullptr;
+  }
+
+  self = new Win32IpcMmf (file, buffer, size, name);
+
+  return self;
+}
+
+/**
+ * win32_ipc_mmf_alloc:
+ * @size: Size of memory to allocate
+ * @name: The name of Memory Mapped File
+ *
+ * Creates named shared memory
+ *
+ * Returns: a new Win32IpcMmf object
+ */
+Win32IpcMmf *
+win32_ipc_mmf_alloc (UINT32 size, const char * name)
+{
+  HANDLE file;
+  std::string msg;
+  UINT err_code;
+
+  if (!size) {
+    GST_ERROR ("Zero size is not allowed");
+    return nullptr;
+  }
+
+  if (!name) {
+    GST_ERROR ("Name must be specified");
+    return nullptr;
+  }
+
+  file = CreateFileMappingA (INVALID_HANDLE_VALUE, nullptr,
+      PAGE_READWRITE | SEC_COMMIT, 0, size, name);
+  if (!file) {
+    err_code = GetLastError ();
+    msg = win32_ipc_error_message (err_code);
+    GST_ERROR ("CreateFileMappingA failed with 0x%x (%s)",
+        err_code, msg.c_str ());
+    return nullptr;
+  }
+
+  /* The name is already occupied, it's caller's fault... */
+  if (GetLastError () == ERROR_ALREADY_EXISTS) {
+    GST_ERROR ("File already exists");
+    CloseHandle (file);
+    return nullptr;
+  }
+
+  return win32_pic_mmf_new (file, size, name);
+}
+
+/**
+ * win32_ipc_mmf_open:
+ * @size: Size of memory to allocate
+ * @name: The name of Memory Mapped File
+ *
+ * Opens named shared memory
+ *
+ * Returns: a new Win32IpcMmf object
+ */
+Win32IpcMmf *
+win32_ipc_mmf_open (UINT32 size, const char * name)
+{
+  HANDLE file;
+  std::string msg;
+  UINT err_code;
+
+  if (!size) {
+    GST_ERROR ("Zero size is not allowed");
+    return nullptr;
+  }
+
+  if (!name) {
+    GST_ERROR ("Name must be specified");
+    return nullptr;
+  }
+
+  file = OpenFileMappingA (FILE_MAP_ALL_ACCESS, FALSE, name);
+  if (!file) {
+    err_code = GetLastError ();
+    msg = win32_ipc_error_message (err_code);
+    GST_ERROR ("OpenFileMappingA failed with 0x%x (%s)",
+        err_code, msg.c_str ());
+    return nullptr;
+  }
+
+  return win32_pic_mmf_new (file, size, name);
+}
+
+/**
+ * win32_ipc_mmf_get_name:
+ * @mmf: a Win32IpcMmf object
+ *
+ * Returns: the name of @mmf
+ */
+const char *
+win32_ipc_mmf_get_name (Win32IpcMmf * mmf)
+{
+  if (!mmf)
+    return nullptr;
+
+  return mmf->name.c_str ();
+}
+
+/**
+ * win32_ipc_mmf_get_size:
+ * @mmf: a Win32IpcMmf object
+ *
+ * Returns: the size of allocated memory
+ */
+UINT32
+win32_ipc_mmf_get_size (Win32IpcMmf * mmf)
+{
+  if (!mmf)
+    return 0;
+
+  return mmf->size;
+}
+
+/**
+ * win32_ipc_mmf_get_raw:
+ * @mmf: a Win32IpcMmf object
+ *
+ * Returns: the address of allocated memory
+ */
+void *
+win32_ipc_mmf_get_raw (Win32IpcMmf * mmf)
+{
+  if (!mmf)
+    return nullptr;
+
+  return mmf->buffer;
+}
+
+/**
+ * win32_ipc_mmf_ref:
+ * @mmf: a Win32IpcMmf object
+ *
+ * Increase ref count
+ */
+Win32IpcMmf *
+win32_ipc_mmf_ref (Win32IpcMmf * mmf)
+{
+  if (!mmf)
+    return nullptr;
+
+  InterlockedIncrement (&mmf->ref_count);
+
+  return mmf;
+}
+
+/**
+ * win32_ipc_mmf_unref:
+ * @mmf: a Win32IpcMmf object
+ *
+ * Decrease ref count
+ */
+void
+win32_ipc_mmf_unref (Win32IpcMmf * mmf)
+{
+  ULONG count;
+
+  if (!mmf)
+    return;
+
+  count = InterlockedDecrement (&mmf->ref_count);
+  if (count == 0)
+    delete mmf;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcmmf.h b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcmmf.h
new file mode 100644
index 0000000000..51b0ea6c58
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcmmf.h
@@ -0,0 +1,50 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <gst/gst.h>
+#include <windows.h>
+
+G_BEGIN_DECLS
+
+struct Win32IpcMmf;
+
+Win32IpcMmf * win32_ipc_mmf_alloc (UINT32 size,
+                                   const char * name);
+
+Win32IpcMmf * win32_ipc_mmf_open  (UINT32 size,
+                                   const char * name);
+
+const char *  win32_ipc_mmf_get_name (Win32IpcMmf * mmf);
+
+UINT32        win32_ipc_mmf_get_size (Win32IpcMmf * mmf);
+
+void *        win32_ipc_mmf_get_raw  (Win32IpcMmf * mmf);
+
+Win32IpcMmf * win32_ipc_mmf_ref      (Win32IpcMmf * mmf);
+
+void          win32_ipc_mmf_unref    (Win32IpcMmf * mmf);
+
+G_END_DECLS
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeclient.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeclient.cpp
new file mode 100644
index 0000000000..11d6934630
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeclient.cpp
@@ -0,0 +1,448 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "win32ipcpipeclient.h"
+#include "win32ipcutils.h"
+#include <mutex>
+#include <condition_variable>
+#include <memory>
+#include <thread>
+#include <queue>
+#include <string>
+
+GST_DEBUG_CATEGORY_EXTERN (gst_win32_ipc_debug);
+#define GST_CAT_DEFAULT gst_win32_ipc_debug
+
+#define CONN_BUFFER_SIZE 1024
+
+struct MmfInfo
+{
+  Win32IpcMmf *mmf;
+  Win32IpcVideoInfo info;
+};
+
+struct ClientConnection : public OVERLAPPED
+{
+  ClientConnection () : pipe (INVALID_HANDLE_VALUE), to_read (0), to_write (0),
+      seq_num (0)
+  {
+    OVERLAPPED *parent = dynamic_cast<OVERLAPPED *> (this);
+    parent->Internal = 0;
+    parent->InternalHigh = 0;
+    parent->Offset = 0;
+    parent->OffsetHigh = 0;
+  }
+
+  Win32IpcPipeClient *self;
+  HANDLE pipe;
+  UINT8 client_msg[CONN_BUFFER_SIZE];
+  UINT32 to_read;
+  UINT8 server_msg[CONN_BUFFER_SIZE];
+  UINT32 to_write;
+  UINT64 seq_num;
+};
+
+struct Win32IpcPipeClient
+{
+  explicit Win32IpcPipeClient (const std::string & n)
+    : name (n), ref_count(1), last_err (ERROR_SUCCESS)
+  {
+    cancellable = CreateEventA (nullptr, TRUE, FALSE, nullptr);
+    conn.pipe = INVALID_HANDLE_VALUE;
+    conn.self = this;
+  }
+
+  ~Win32IpcPipeClient ()
+  {
+    GST_DEBUG ("Free client %p", this);
+    win32_ipc_pipe_client_shutdown (this);
+    CloseHandle (cancellable);
+  }
+
+  std::mutex lock;
+  std::condition_variable cond;
+  std::unique_ptr<std::thread> thread;
+  std::queue<MmfInfo> queue;
+  std::string name;
+
+  ULONG ref_count;
+  HANDLE cancellable;
+  UINT last_err;
+  ClientConnection conn;
+};
+
+static DWORD
+win32_ipc_pipe_client_send_need_data_async (Win32IpcPipeClient * self);
+
+static VOID WINAPI
+win32_ipc_pipe_client_send_read_done_finish (DWORD error_code, DWORD n_bytes,
+    LPOVERLAPPED overlapped)
+{
+  ClientConnection *conn = (ClientConnection *) overlapped;
+  Win32IpcPipeClient *self = conn->self;
+
+  if (error_code != ERROR_SUCCESS) {
+    std::string msg = win32_ipc_error_message (error_code);
+    self->last_err = error_code;
+    GST_WARNING ("READ-DONE failed with 0x%x (%s)",
+        self->last_err, msg.c_str ());
+    goto error;
+  }
+
+  GST_TRACE ("READ-DONE sent");
+
+  self->last_err = win32_ipc_pipe_client_send_need_data_async (self);
+  if (self->last_err != ERROR_SUCCESS)
+    goto error;
+
+  /* All done, back to need-data state */
+  return;
+
+error:
+  SetEvent (self->cancellable);
+}
+
+static DWORD
+win32_ipc_pipe_client_send_read_done_async (Win32IpcPipeClient * self)
+{
+  ClientConnection *conn = &self->conn;
+
+  conn->to_write = win32_ipc_pkt_build_read_done (conn->client_msg,
+      CONN_BUFFER_SIZE, conn->seq_num);
+  if (conn->to_write == 0) {
+    GST_ERROR ("Couldn't build READ-DONE pkt");
+    return ERROR_BAD_FORMAT;
+  }
+
+  GST_TRACE ("Sending READ-DONE");
+
+  if (!WriteFileEx (conn->pipe, conn->client_msg, conn->to_write,
+      (OVERLAPPED *) conn, win32_ipc_pipe_client_send_read_done_finish)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+
+    GST_WARNING ("WriteFileEx failed with 0x%x (%s)", last_err, msg.c_str ());
+    return last_err;
+  }
+
+  return ERROR_SUCCESS;
+}
+
+static VOID WINAPI
+win32_ipc_pipe_client_receive_have_data_finish (DWORD error_code, DWORD n_bytes,
+    LPOVERLAPPED overlapped)
+{
+  ClientConnection *conn = (ClientConnection *) overlapped;
+  Win32IpcPipeClient *self = conn->self;
+  char mmf_name[1024] = { '\0', };
+  Win32IpcVideoInfo info;
+  Win32IpcMmf *mmf;
+  MmfInfo minfo;
+
+  if (error_code != ERROR_SUCCESS) {
+    std::string msg = win32_ipc_error_message (error_code);
+    self->last_err = error_code;
+    GST_WARNING ("HAVE-DATA failed with 0x%x (%s)",
+        self->last_err, msg.c_str ());
+    goto error;
+  }
+
+  if (!win32_ipc_pkt_parse_have_data (conn->server_msg, n_bytes,
+      &conn->seq_num, mmf_name, &info)) {
+    self->last_err = ERROR_BAD_FORMAT;
+    GST_WARNING ("Couldn't parse HAVE-DATA pkg");
+    goto error;
+  }
+
+  mmf = win32_ipc_mmf_open (info.size, mmf_name);
+  if (!mmf) {
+    GST_ERROR ("Couldn't open file %s", mmf_name);
+    self->last_err = ERROR_BAD_FORMAT;
+    goto error;
+  }
+
+  GST_TRACE ("Got HAVE-DATA %s", mmf_name);
+
+  minfo.mmf = mmf;
+  minfo.info = info;
+
+  {
+    std::lock_guard<std::mutex> lk (self->lock);
+    /* Drops too old data */
+    while (self->queue.size () > 5) {
+      MmfInfo info = self->queue.front ();
+
+      self->queue.pop ();
+      win32_ipc_mmf_unref (info.mmf);
+    }
+
+    self->queue.push (minfo);
+    self->cond.notify_all ();
+  }
+
+  self->last_err = win32_ipc_pipe_client_send_read_done_async (self);
+  if (self->last_err != ERROR_SUCCESS)
+    goto error;
+
+  return;
+
+error:
+  SetEvent (self->cancellable);
+}
+
+static DWORD
+win32_ipc_pipe_client_receive_have_data_async (Win32IpcPipeClient * self)
+{
+  ClientConnection *conn = &self->conn;
+
+  GST_TRACE ("Waiting HAVE-DATA");
+
+  if (!ReadFileEx (conn->pipe, conn->server_msg, CONN_BUFFER_SIZE,
+      (OVERLAPPED *) conn, win32_ipc_pipe_client_receive_have_data_finish)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+    GST_WARNING ("ReadFileEx failed with 0x%x (%s)", last_err, msg.c_str ());
+    return last_err;
+  }
+
+  return ERROR_SUCCESS;
+}
+
+static VOID WINAPI
+pipe_clinet_send_need_data_finish (DWORD error_code, DWORD n_bytes,
+    LPOVERLAPPED overlapped)
+{
+  ClientConnection *conn = (ClientConnection *) overlapped;
+  Win32IpcPipeClient *self = conn->self;
+
+  if (error_code != ERROR_SUCCESS) {
+    std::string msg = win32_ipc_error_message (error_code);
+    self->last_err = error_code;
+    GST_WARNING ("NEED-DATA failed with 0x%x (%s)",
+        self->last_err, msg.c_str ());
+    goto error;
+  }
+
+  self->last_err = win32_ipc_pipe_client_receive_have_data_async (self);
+  if (self->last_err != ERROR_SUCCESS)
+    goto error;
+
+  return;
+
+error:
+  SetEvent (self->cancellable);
+}
+
+static DWORD
+win32_ipc_pipe_client_send_need_data_async (Win32IpcPipeClient * self)
+{
+  ClientConnection *conn = &self->conn;
+
+  conn->to_write = win32_ipc_pkt_build_need_data (conn->client_msg,
+      CONN_BUFFER_SIZE, conn->seq_num);
+  if (conn->to_write == 0) {
+    GST_ERROR ("Couldn't build NEED-DATA pkt");
+    return ERROR_BAD_FORMAT;
+  }
+
+  GST_TRACE ("Sending NEED-DATA");
+
+  if (!WriteFileEx (conn->pipe, conn->client_msg, conn->to_write,
+      (OVERLAPPED *) conn, pipe_clinet_send_need_data_finish)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+    GST_WARNING ("WriteFileEx failed with 0x%x (%s)", last_err, msg.c_str ());
+    return last_err;
+  }
+
+  return ERROR_SUCCESS;
+}
+
+static VOID
+win32_ipc_pipe_client_loop (Win32IpcPipeClient * self)
+{
+  DWORD mode = PIPE_READMODE_MESSAGE;
+  std::unique_lock<std::mutex> lk (self->lock);
+  ClientConnection *conn = &self->conn;
+
+  conn->pipe = CreateFileA (self->name.c_str (),
+        GENERIC_READ | GENERIC_WRITE, 0, nullptr, OPEN_EXISTING,
+        FILE_FLAG_OVERLAPPED, nullptr);
+  self->last_err = GetLastError ();
+  if (conn->pipe == INVALID_HANDLE_VALUE) {
+    std::string msg = win32_ipc_error_message (self->last_err);
+    GST_WARNING ("CreateFileA failed with 0x%x (%s)", self->last_err,
+        msg.c_str ());
+    self->cond.notify_all ();
+    return;
+  }
+
+  if (!SetNamedPipeHandleState (conn->pipe, &mode, nullptr, nullptr)) {
+    self->last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (self->last_err);
+    GST_WARNING ("SetNamedPipeHandleState failed with 0x%x (%s)",
+        self->last_err, msg.c_str ());
+    CloseHandle (conn->pipe);
+    conn->pipe = INVALID_HANDLE_VALUE;
+    self->cond.notify_all ();
+    return;
+  }
+
+  self->last_err = ERROR_SUCCESS;
+  self->cond.notify_all ();
+  lk.unlock ();
+
+  /* Once connection is established, send NEED-DATA message to server,
+   * and then it will loop NEED-DATA -> HAVE-DATA -> READ-DONE */
+  self->last_err = win32_ipc_pipe_client_send_need_data_async (self);
+  if (self->last_err != ERROR_SUCCESS)
+    goto out;
+
+  do {
+    /* Enters alertable thread state and wait for I/O completion event
+     * or cancellable event */
+    DWORD ret = WaitForSingleObjectEx (self->cancellable, INFINITE, TRUE);
+    if (ret == WAIT_OBJECT_0) {
+      GST_DEBUG ("Operation cancelled");
+      CancelIoEx (conn->pipe, (OVERLAPPED *) &conn);
+      break;
+    } else if (ret != WAIT_IO_COMPLETION) {
+      GST_WARNING ("Unexpected wait return 0x%x", (UINT) ret);
+      CancelIoEx (conn->pipe, (OVERLAPPED *) &conn);
+      break;
+    }
+  } while (true);
+
+out:
+  if (conn->pipe != INVALID_HANDLE_VALUE)
+    CloseHandle (conn->pipe);
+
+  lk.lock ();
+  self->last_err = ERROR_OPERATION_ABORTED;
+  conn->pipe = INVALID_HANDLE_VALUE;
+  self->cond.notify_all ();
+}
+
+static BOOL
+win32_ipc_pipe_client_run (Win32IpcPipeClient * self)
+{
+  std::unique_lock<std::mutex> lk (self->lock);
+
+  self->thread = std::make_unique<std::thread>
+      (std::thread (win32_ipc_pipe_client_loop, self));
+  self->cond.wait (lk);
+
+  if (self->last_err != ERROR_SUCCESS) {
+    self->thread->join ();
+    self->thread = nullptr;
+    return FALSE;
+  }
+
+  return TRUE;
+}
+
+Win32IpcPipeClient *
+win32_ipc_pipe_client_new (const char * pipe_name)
+{
+  Win32IpcPipeClient *self;
+
+  if (!pipe_name) {
+    GST_ERROR ("Pipe name must be specified");
+    return nullptr;
+  }
+
+  self = new Win32IpcPipeClient (pipe_name);
+
+  if (!win32_ipc_pipe_client_run (self)) {
+    win32_ipc_pipe_client_unref (self);
+    return nullptr;
+  }
+
+  return self;
+}
+
+Win32IpcPipeClient *
+win32_ipc_pipe_client_ref (Win32IpcPipeClient * client)
+{
+  InterlockedIncrement (&client->ref_count);
+
+  return client;
+}
+
+void
+win32_ipc_pipe_client_unref (Win32IpcPipeClient * client)
+{
+  ULONG ref_count;
+
+  ref_count = InterlockedDecrement (&client->ref_count);
+  if (ref_count == 0)
+    delete client;
+}
+
+void
+win32_ipc_pipe_client_shutdown (Win32IpcPipeClient * client)
+{
+  GST_DEBUG ("Shutting down %p", client);
+
+  SetEvent (client->cancellable);
+  if (client->thread) {
+    client->thread->join ();
+    client->thread = nullptr;
+  }
+
+  std::lock_guard<std::mutex> lk (client->lock);
+  client->last_err = ERROR_OPERATION_ABORTED;
+  while (!client->queue.empty ()) {
+    MmfInfo info = client->queue.front ();
+
+    client->queue.pop ();
+    win32_ipc_mmf_unref (info.mmf);
+  }
+  client->cond.notify_all ();
+}
+
+BOOL
+win32_ipc_pipe_client_get_mmf (Win32IpcPipeClient * client, Win32IpcMmf ** mmf,
+    Win32IpcVideoInfo * info)
+{
+  std::unique_lock<std::mutex> lk (client->lock);
+  if (client->last_err != ERROR_SUCCESS) {
+    GST_WARNING ("Last error code was 0x%x", client->last_err);
+    return FALSE;
+  }
+
+  while (client->queue.empty () && client->last_err == ERROR_SUCCESS)
+    client->cond.wait (lk);
+
+  if (client->last_err != ERROR_SUCCESS || client->queue.empty ())
+    return FALSE;
+
+  MmfInfo mmf_info = client->queue.front ();
+  client->queue.pop ();
+
+  *mmf = mmf_info.mmf;
+  *info = mmf_info.info;
+
+  return TRUE;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeclient.h b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeclient.h
new file mode 100644
index 0000000000..4188832905
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeclient.h
@@ -0,0 +1,49 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <windows.h>
+#include <string.h>
+#include "win32ipcmmf.h"
+#include "win32ipcprotocol.h"
+#include <gst/gst.h>
+
+G_BEGIN_DECLS
+
+struct Win32IpcPipeClient;
+
+Win32IpcPipeClient * win32_ipc_pipe_client_new (const char * pipe_name);
+
+Win32IpcPipeClient * win32_ipc_pipe_client_ref (Win32IpcPipeClient * client);
+
+void                 win32_ipc_pipe_client_unref (Win32IpcPipeClient * client);
+
+void                 win32_ipc_pipe_client_shutdown (Win32IpcPipeClient * client);
+
+BOOL                 win32_ipc_pipe_client_get_mmf (Win32IpcPipeClient * client,
+                                                    Win32IpcMmf ** mmf,
+                                                    Win32IpcVideoInfo * info);
+
+G_END_DECLS
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeserver.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeserver.cpp
new file mode 100644
index 0000000000..53ebdf41ef
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeserver.cpp
@@ -0,0 +1,550 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "win32ipcpipeserver.h"
+#include "win32ipcutils.h"
+#include <mutex>
+#include <condition_variable>
+#include <memory>
+#include <thread>
+#include <queue>
+#include <vector>
+#include <string>
+#include <algorithm>
+#include <assert.h>
+
+GST_DEBUG_CATEGORY_EXTERN (gst_win32_ipc_debug);
+#define GST_CAT_DEFAULT gst_win32_ipc_debug
+
+#define CONN_BUFFER_SIZE 1024
+
+struct MmfInfo
+{
+  explicit MmfInfo (Win32IpcMmf * m, const Win32IpcVideoInfo * i, UINT64 s)
+  {
+    mmf = m;
+    info = *i;
+    seq_num = s;
+  }
+
+  ~MmfInfo()
+  {
+    if (mmf)
+      win32_ipc_mmf_unref (mmf);
+  }
+
+  Win32IpcMmf *mmf = nullptr;
+  Win32IpcVideoInfo info;
+  UINT64 seq_num;
+};
+
+struct ServerConnection : public OVERLAPPED
+{
+  ServerConnection(Win32IpcPipeServer * server, HANDLE p)
+    : self(server), pipe(p)
+  {
+    OVERLAPPED *parent = dynamic_cast<OVERLAPPED *> (this);
+    parent->Internal = 0;
+    parent->InternalHigh = 0;
+    parent->Offset = 0;
+    parent->OffsetHigh = 0;
+  }
+
+  Win32IpcPipeServer *self;
+  std::shared_ptr<MmfInfo> minfo;
+  HANDLE pipe = INVALID_HANDLE_VALUE;
+  UINT8 client_msg[CONN_BUFFER_SIZE];
+  UINT32 to_read = 0;
+  UINT8 server_msg[CONN_BUFFER_SIZE];
+  UINT32 to_write = 0;
+  UINT64 seq_num = 0;
+  BOOL pending_have_data = FALSE;
+};
+
+struct Win32IpcPipeServer
+{
+  explicit Win32IpcPipeServer (const std::string & n)
+    : name (n), ref_count (1), last_err (ERROR_SUCCESS), seq_num (0)
+  {
+    enqueue_event = CreateEventA (nullptr, FALSE, FALSE, nullptr);
+    cancellable = CreateEventA (nullptr, TRUE, FALSE, nullptr);
+  }
+
+  ~Win32IpcPipeServer ()
+  {
+    win32_ipc_pipe_server_shutdown (this);
+    CloseHandle (cancellable);
+    CloseHandle (enqueue_event);
+  }
+
+  std::mutex lock;
+  std::condition_variable cond;
+  std::unique_ptr<std::thread> thread;
+  std::shared_ptr<MmfInfo> minfo;
+  std::string name;
+  std::vector<ServerConnection *> conn;
+
+  ULONG ref_count;
+  HANDLE enqueue_event;
+  HANDLE cancellable;
+  UINT last_err;
+  UINT64 seq_num;
+};
+
+static void
+win32_ipc_pipe_server_receive_need_data_async (ServerConnection * conn);
+
+static void
+win32_ipc_pipe_server_close_connection (ServerConnection * conn,
+    BOOL remove_from_list)
+{
+  Win32IpcPipeServer *self = conn->self;
+
+  GST_DEBUG ("Closing connection %p", conn);
+
+  if (remove_from_list) {
+    self->conn.erase (std::remove (self->conn.begin (), self->conn.end (),
+        conn), self->conn.end ());
+  }
+
+  if (!DisconnectNamedPipe (conn->pipe)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+    GST_WARNING ("DisconnectNamedPipe failed with 0x%x (%s)",
+        last_err, msg.c_str ());
+  }
+
+  CloseHandle (conn->pipe);
+  delete conn;
+}
+
+static void WINAPI
+win32_ipc_pipe_server_receive_read_done_finish (DWORD error_code, DWORD n_bytes,
+    LPOVERLAPPED overlapped)
+{
+  ServerConnection *conn = (ServerConnection *) overlapped;
+
+  if (error_code != ERROR_SUCCESS) {
+    std::string msg = win32_ipc_error_message (error_code);
+
+    GST_WARNING ("READ-DONE failed with 0x%x (%s)",
+        (UINT) error_code, msg.c_str ());
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+    return;
+  }
+
+  GST_TRACE ("Got READ-DONE %p", conn);
+
+  conn->minfo = nullptr;
+
+  /* All done, wait for need-data again */
+  win32_ipc_pipe_server_receive_need_data_async (conn);
+}
+
+static void
+win32_ipc_pipe_server_receive_read_done_async (ServerConnection * conn)
+{
+  GST_TRACE ("Waiting READ-DONE %p", conn);
+
+  if (!ReadFileEx (conn->pipe, conn->client_msg, CONN_BUFFER_SIZE,
+      (OVERLAPPED *) conn, win32_ipc_pipe_server_receive_read_done_finish)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+    GST_WARNING ("ReadFileEx failed with 0x%x (%s)", last_err, msg.c_str ());
+
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+  }
+}
+
+static void WINAPI
+win32_ipc_pipe_server_send_have_data_finish (DWORD error_code, DWORD n_bytes,
+    LPOVERLAPPED overlapped)
+{
+  ServerConnection *conn = (ServerConnection *) overlapped;
+
+  if (error_code != ERROR_SUCCESS) {
+    std::string msg = win32_ipc_error_message (error_code);
+    GST_WARNING ("HAVE-DATA failed with 0x%x (%s)",
+        (UINT) error_code, msg.c_str ());
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+    return;
+  }
+
+  GST_TRACE ("HAVE-DATA done with %s",
+      win32_ipc_mmf_get_name (conn->minfo->mmf));
+
+  win32_ipc_pipe_server_receive_read_done_async (conn);
+}
+
+static void
+win32_ipc_pipe_server_send_have_data_async (ServerConnection * conn)
+{
+  assert (conn->minfo != nullptr);
+
+  conn->pending_have_data = FALSE;
+  conn->seq_num = conn->minfo->seq_num;
+
+  conn->to_write = win32_ipc_pkt_build_have_data (conn->server_msg,
+      CONN_BUFFER_SIZE, conn->seq_num,
+      win32_ipc_mmf_get_name (conn->minfo->mmf), &conn->minfo->info);
+  if (conn->to_write == 0) {
+    GST_ERROR ("Couldn't build HAVE-DATA pkt");
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+    return;
+  }
+
+  conn->seq_num++;
+
+  GST_TRACE ("Sending HAVE-DATA");
+
+  if (!WriteFileEx (conn->pipe, conn->server_msg, conn->to_write,
+      (OVERLAPPED *) conn, win32_ipc_pipe_server_send_have_data_finish)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+    GST_WARNING ("WriteFileEx failed with 0x%x (%s)", last_err, msg.c_str ());
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+  }
+}
+
+static void WINAPI
+win32_ipc_pipe_server_receive_need_data_finish (DWORD error_code, DWORD n_bytes,
+    LPOVERLAPPED overlapped)
+{
+  ServerConnection *conn = (ServerConnection *) overlapped;
+  UINT64 seq_num;
+
+  if (error_code != ERROR_SUCCESS) {
+    std::string msg = win32_ipc_error_message (error_code);
+    GST_WARNING ("NEED-DATA failed with 0x%x (%s)",
+        (UINT) error_code, msg.c_str ());
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+    return;
+  }
+
+  if (!win32_ipc_pkt_parse_need_data (conn->client_msg, CONN_BUFFER_SIZE,
+      &seq_num)) {
+    GST_ERROR ("Couldn't parse NEED-DATA message");
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+    return;
+  }
+
+  GST_TRACE ("Got NEED-DATA");
+
+  /* Will response later once data is available */
+  if (!conn->minfo) {
+    GST_LOG ("No data available, waiting");
+    conn->pending_have_data = TRUE;
+    return;
+  }
+
+  win32_ipc_pipe_server_send_have_data_async (conn);
+}
+
+static void
+win32_ipc_pipe_server_receive_need_data_async (ServerConnection * conn)
+{
+  GST_TRACE ("Waiting NEED-DATA");
+
+  if (!ReadFileEx (conn->pipe, conn->client_msg, CONN_BUFFER_SIZE,
+      (OVERLAPPED *) conn, win32_ipc_pipe_server_receive_need_data_finish)) {
+    UINT last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (last_err);
+
+    GST_WARNING ("ReadFileEx failed with 0x%x (%s)", last_err, msg.c_str ());
+    win32_ipc_pipe_server_close_connection (conn, TRUE);
+  }
+}
+
+static HANDLE
+win32_ipc_pipe_server_create_pipe (Win32IpcPipeServer * self,
+    OVERLAPPED * overlap, BOOL * io_pending)
+{
+  HANDLE pipe = CreateNamedPipeA (self->name.c_str (),
+      PIPE_ACCESS_DUPLEX | FILE_FLAG_OVERLAPPED,
+      PIPE_TYPE_MESSAGE | PIPE_READMODE_MESSAGE | PIPE_WAIT,
+      PIPE_UNLIMITED_INSTANCES,
+      CONN_BUFFER_SIZE, CONN_BUFFER_SIZE, 5000, nullptr);
+  if (pipe == INVALID_HANDLE_VALUE) {
+    self->last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (self->last_err);
+    GST_WARNING ("CreateNamedPipeA failed with 0x%x (%s)",
+        self->last_err, msg.c_str ());
+    return INVALID_HANDLE_VALUE;
+  }
+
+  /* Async pipe should return FALSE */
+  if (ConnectNamedPipe (pipe, overlap)) {
+    self->last_err = GetLastError ();
+    std::string msg = win32_ipc_error_message (self->last_err);
+    GST_WARNING ("ConnectNamedPipe failed with 0x%x (%s)",
+        self->last_err, msg.c_str ());
+    CloseHandle (pipe);
+    return INVALID_HANDLE_VALUE;
+  }
+
+  *io_pending = FALSE;
+  self->last_err = GetLastError ();
+  switch (self->last_err) {
+    case ERROR_IO_PENDING:
+      *io_pending = TRUE;
+      break;
+    case ERROR_PIPE_CONNECTED:
+      SetEvent (overlap->hEvent);
+      break;
+    default:
+    {
+      std::string msg = win32_ipc_error_message (self->last_err);
+      GST_WARNING ("ConnectNamedPipe failed with 0x%x (%s)",
+          self->last_err, msg.c_str ());
+      CloseHandle (pipe);
+      return INVALID_HANDLE_VALUE;
+    }
+  }
+
+  self->last_err = ERROR_SUCCESS;
+
+  return pipe;
+}
+
+static void
+win32_ipc_pipe_server_loop (Win32IpcPipeServer * self)
+{
+  BOOL io_pending = FALSE;
+  DWORD n_bytes;
+  DWORD wait_ret;
+  HANDLE waitables[3];
+  HANDLE pipe;
+  OVERLAPPED overlap;
+  std::unique_lock<std::mutex> lk (self->lock);
+
+  overlap.hEvent = CreateEvent (nullptr, TRUE, TRUE, nullptr);
+  pipe = win32_ipc_pipe_server_create_pipe (self, &overlap, &io_pending);
+  if (pipe == INVALID_HANDLE_VALUE) {
+    CloseHandle (overlap.hEvent);
+    self->cond.notify_all ();
+    return;
+  }
+
+  self->last_err = ERROR_SUCCESS;
+  self->cond.notify_all ();
+  lk.unlock ();
+
+  do {
+    ServerConnection *conn;
+
+    waitables[0] = overlap.hEvent;
+    waitables[1] = self->enqueue_event;
+    waitables[2] = self->cancellable;
+
+    /* Enters alertable state and wait for
+     * 1) Client's connection request
+     *    (similar to socket listen/accept in async manner)
+     * 2) Or, performs completion routines (finish APC)
+     * 3) Or, terminates if cancellable event was signalled
+     */
+    wait_ret = WaitForMultipleObjectsEx (3, waitables, FALSE, INFINITE, TRUE);
+    if (wait_ret == WAIT_OBJECT_0 + 2) {
+      GST_DEBUG ("Operation cancelled");
+      goto out;
+    }
+
+    switch (wait_ret) {
+      case WAIT_OBJECT_0:
+        if (io_pending) {
+          BOOL ret = GetOverlappedResult (pipe, &overlap, &n_bytes, FALSE);
+          if (!ret) {
+            UINT last_err = GetLastError ();
+            std::string msg = win32_ipc_error_message (last_err);
+            GST_WARNING ("ConnectNamedPipe failed with 0x%x (%s)",
+                last_err, msg.c_str ());
+            CloseHandle (pipe);
+            break;
+          }
+        }
+
+        conn = new ServerConnection (self, pipe);
+        GST_DEBUG ("New connection is established %p", conn);
+
+        /* Stores current buffer if available */
+        lk.lock();
+        conn->minfo = self->minfo;
+        lk.unlock ();
+
+        pipe = INVALID_HANDLE_VALUE;
+        self->conn.push_back (conn);
+        win32_ipc_pipe_server_receive_need_data_async (conn);
+        pipe = win32_ipc_pipe_server_create_pipe (self, &overlap, &io_pending);
+        if (pipe == INVALID_HANDLE_VALUE)
+          goto out;
+        break;
+      case WAIT_OBJECT_0 + 1:
+      case WAIT_IO_COMPLETION:
+      {
+        std::vector<ServerConnection *> pending_conns;
+        std::shared_ptr<MmfInfo> minfo;
+
+        lk.lock();
+        minfo = self->minfo;
+        lk.unlock();
+
+        if (minfo) {
+          for (auto iter: self->conn) {
+            if (iter->pending_have_data && iter->seq_num <= minfo->seq_num) {
+              iter->minfo = minfo;
+              pending_conns.push_back (iter);
+            }
+          }
+        }
+
+        for (auto iter: pending_conns) {
+          GST_LOG ("Sending pending have data to %p", iter);
+          win32_ipc_pipe_server_send_have_data_async (iter);
+        }
+
+        break;
+      }
+      default:
+        GST_WARNING ("Unexpected WaitForMultipleObjectsEx return 0x%x",
+            (UINT) wait_ret);
+        goto out;
+    }
+  } while (true);
+
+out:
+  /* Cancels all I/O event issued from this thread */
+  {
+    std::vector<HANDLE> pipes;
+    for (auto iter: self->conn) {
+      if (iter->pipe != INVALID_HANDLE_VALUE)
+        pipes.push_back (iter->pipe);
+    }
+
+    for (auto iter: pipes)
+      CancelIo (iter);
+  }
+
+  for (auto iter: self->conn)
+    win32_ipc_pipe_server_close_connection (iter, FALSE);
+
+  self->conn.clear ();
+
+  lk.lock ();
+  CloseHandle (overlap.hEvent);
+  self->last_err = ERROR_OPERATION_ABORTED;
+  self->cond.notify_all ();
+}
+
+static BOOL
+win32_ipc_pipe_server_run (Win32IpcPipeServer * self)
+{
+  std::unique_lock<std::mutex> lk (self->lock);
+
+  self->thread = std::make_unique<std::thread>
+      (std::thread (win32_ipc_pipe_server_loop, self));
+  self->cond.wait (lk);
+
+  if (self->last_err != ERROR_SUCCESS) {
+    self->thread->join ();
+    self->thread = nullptr;
+    return FALSE;
+  }
+
+  return TRUE;
+}
+
+Win32IpcPipeServer *
+win32_ipc_pipe_server_new (const char * pipe_name)
+{
+  Win32IpcPipeServer *self;
+
+  if (!pipe_name)
+    return nullptr;
+
+  self = new Win32IpcPipeServer (pipe_name);
+
+  if (!win32_ipc_pipe_server_run (self)) {
+    win32_ipc_pipe_server_unref (self);
+    return nullptr;
+  }
+
+  return self;
+}
+
+Win32IpcPipeServer *
+win32_ipc_pipe_server_ref (Win32IpcPipeServer * server)
+{
+  if (!server)
+    return nullptr;
+
+  InterlockedIncrement (&server->ref_count);
+
+  return server;
+}
+
+void
+win32_ipc_pipe_server_unref (Win32IpcPipeServer * server)
+{
+  ULONG ref_count;
+
+  if (!server)
+    return;
+
+  ref_count = InterlockedDecrement (&server->ref_count);
+  if (ref_count == 0)
+    delete server;
+}
+
+void
+win32_ipc_pipe_server_shutdown (Win32IpcPipeServer * server)
+{
+  GST_DEBUG ("Shutting down");
+
+  SetEvent (server->cancellable);
+  if (server->thread) {
+    server->thread->join ();
+    server->thread = nullptr;
+  }
+
+  std::lock_guard<std::mutex> lk (server->lock);
+  server->last_err = ERROR_OPERATION_ABORTED;
+  server->minfo = nullptr;
+  server->cond.notify_all ();
+}
+
+BOOL
+win32_ipc_pipe_server_send_mmf (Win32IpcPipeServer * server, Win32IpcMmf * mmf,
+    const Win32IpcVideoInfo * info)
+{
+  std::lock_guard<std::mutex> lk (server->lock);
+  server->minfo = std::make_shared<MmfInfo> (mmf, info, server->seq_num);
+
+  GST_LOG ("Enqueue mmf %s", win32_ipc_mmf_get_name (mmf));
+
+  server->seq_num++;
+
+  /* Wakeup event loop */
+  SetEvent (server->enqueue_event);
+
+  return TRUE;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeserver.h b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeserver.h
new file mode 100644
index 0000000000..2a7ccc0986
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcpipeserver.h
@@ -0,0 +1,50 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <windows.h>
+#include <string.h>
+#include "win32ipcmmf.h"
+#include "win32ipcprotocol.h"
+#include <gst/gst.h>
+
+G_BEGIN_DECLS
+
+struct Win32IpcPipeServer;
+
+Win32IpcPipeServer * win32_ipc_pipe_server_new (const char * pipe_name);
+
+Win32IpcPipeServer * win32_ipc_pipe_server_ref (Win32IpcPipeServer * server);
+
+void                 win32_ipc_pipe_server_unref (Win32IpcPipeServer * server);
+
+void                 win32_ipc_pipe_server_shutdown (Win32IpcPipeServer * server);
+
+BOOL                 win32_ipc_pipe_server_send_mmf (Win32IpcPipeServer * server,
+                                                     Win32IpcMmf * mmf,
+                                                     const Win32IpcVideoInfo * info);
+
+G_END_DECLS
+
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcprotocol.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcprotocol.cpp
new file mode 100644
index 0000000000..cc78211559
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcprotocol.cpp
@@ -0,0 +1,237 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "win32ipcprotocol.h"
+#include <string.h>
+
+const char *
+win32_ipc_pkt_type_to_string (Win32IpcPktType type)
+{
+  switch (type) {
+    case WIN32_IPC_PKT_NEED_DATA:
+      return "NEED-DATA";
+    case WIN32_IPC_PKT_HAVE_DATA:
+      return "HAVE-DATA";
+    case WIN32_IPC_PKT_READ_DONE:
+      return "READ-DONE";
+    default:
+      break;
+  }
+
+  return "Unknown";
+}
+
+Win32IpcPktType
+win32_ipc_pkt_type_from_raw (UINT8 type)
+{
+  return (Win32IpcPktType) type;
+}
+
+UINT8
+win32_ipc_pkt_type_to_raw (Win32IpcPktType type)
+{
+  return (UINT8) type;
+}
+
+#define READ_UINT32(d,v) do { \
+  (*((UINT32 *) v)) = *((UINT32 *) d); \
+  (d) += sizeof (UINT32); \
+} while (0)
+
+#define WRITE_UINT32(d,v) do { \
+  *((UINT32 *) d) = v; \
+  (d) += sizeof (UINT32); \
+} while (0)
+
+#define READ_UINT64(d,v) do { \
+  (*((UINT64 *) v)) = *((UINT64 *) d); \
+  (d) += sizeof (UINT64); \
+} while (0)
+
+#define WRITE_UINT64(d,v) do { \
+  *((UINT64 *) d) = v; \
+  (d) += sizeof (UINT64); \
+} while (0)
+
+UINT32
+win32_ipc_pkt_build_need_data (UINT8 * pkt, UINT32 pkt_len, UINT64 seq_num)
+{
+  UINT8 *data = pkt;
+
+  if (!pkt || pkt_len < WIN32_IPC_PKT_NEED_DATA_SIZE)
+    return 0;
+
+  data[0] = win32_ipc_pkt_type_to_raw (WIN32_IPC_PKT_NEED_DATA);
+  data++;
+
+  WRITE_UINT64 (data, seq_num);
+
+  return WIN32_IPC_PKT_NEED_DATA_SIZE;
+}
+
+BOOL
+win32_ipc_pkt_parse_need_data (UINT8 * pkt, UINT32 pkt_len, UINT64 * seq_num)
+{
+  UINT8 *data = pkt;
+
+  if (!pkt || pkt_len < WIN32_IPC_PKT_NEED_DATA_SIZE)
+    return FALSE;
+
+  if (win32_ipc_pkt_type_from_raw (data[0]) != WIN32_IPC_PKT_NEED_DATA)
+    return FALSE;
+
+  data++;
+
+  READ_UINT64 (data, seq_num);
+
+  return TRUE;
+}
+
+UINT32
+win32_ipc_pkt_build_have_data (UINT8 * pkt, UINT32 pkt_size, UINT64 seq_num,
+    const char * mmf_name, const Win32IpcVideoInfo * info)
+{
+  UINT8 *data = pkt;
+  size_t len;
+
+  if (!pkt || !mmf_name || !info)
+    return 0;
+
+  len = strlen (mmf_name);
+  if (len == 0)
+    return 0;
+
+  len++;
+  if (pkt_size < WIN32_IPC_PKT_HAVE_DATA_SIZE + len)
+    return 0;
+
+  data[0] = win32_ipc_pkt_type_to_raw (WIN32_IPC_PKT_HAVE_DATA);
+  data++;
+
+  WRITE_UINT64 (data, seq_num);
+
+  strcpy ((char *) data, mmf_name);
+  data += len;
+
+  WRITE_UINT32 (data, info->format);
+  WRITE_UINT32 (data, info->width);
+  WRITE_UINT32 (data, info->height);
+  WRITE_UINT32 (data, info->fps_n);
+  WRITE_UINT32 (data, info->fps_d);
+  WRITE_UINT32 (data, info->par_n);
+  WRITE_UINT32 (data, info->par_d);
+  WRITE_UINT64 (data, info->size);
+
+  for (UINT i = 0; i < 4; i++)
+    WRITE_UINT64 (data, info->offset[i]);
+
+  for (UINT i = 0; i < 4; i++)
+    WRITE_UINT32 (data, info->stride[i]);
+
+  WRITE_UINT64 (data, info->qpc);
+
+  return data - pkt;
+}
+
+BOOL
+win32_ipc_pkt_parse_have_data (UINT8 * pkt, UINT32 pkt_size, UINT64 * seq_num,
+    char * mmf_name, Win32IpcVideoInfo * info)
+{
+  UINT8 *data = pkt;
+  size_t len;
+
+  if (!pkt || pkt_size < WIN32_IPC_PKT_HAVE_DATA_SIZE)
+    return FALSE;
+
+  if (win32_ipc_pkt_type_from_raw (pkt[0]) != WIN32_IPC_PKT_HAVE_DATA)
+    return FALSE;
+
+  data++;
+
+  READ_UINT64 (data, seq_num);
+
+  len = strnlen ((const char *) data, pkt_size - (data - pkt));
+  if (len == 0)
+    return FALSE;
+
+  len++;
+  if (pkt_size < WIN32_IPC_PKT_HAVE_DATA_SIZE + len)
+    return FALSE;
+
+  strcpy (mmf_name, (const char *) data);
+  data += len;
+
+  READ_UINT32 (data, &info->format);
+  READ_UINT32 (data, &info->width);
+  READ_UINT32 (data, &info->height);
+  READ_UINT32 (data, &info->fps_n);
+  READ_UINT32 (data, &info->fps_d);
+  READ_UINT32 (data, &info->par_n);
+  READ_UINT32 (data, &info->par_d);
+  READ_UINT64 (data, &info->size);
+
+  for (UINT i = 0; i < 4; i++)
+    READ_UINT64 (data, &info->offset[i]);
+
+  for (UINT i = 0; i < 4; i++)
+    READ_UINT32 (data, &info->stride[i]);
+
+  READ_UINT64 (data, &info->qpc);
+
+  return TRUE;
+}
+
+UINT32
+win32_ipc_pkt_build_read_done (UINT8 * pkt, UINT32 pkt_len, UINT64 seq_num)
+{
+  UINT8 *data = pkt;
+
+  if (!pkt || pkt_len < WIN32_IPC_PKT_READ_DONE_SIZE)
+    return 0;
+
+  data[0] = win32_ipc_pkt_type_to_raw (WIN32_IPC_PKT_READ_DONE);
+  data++;
+
+  WRITE_UINT64 (data, seq_num);
+
+  return WIN32_IPC_PKT_READ_DONE_SIZE;
+}
+
+BOOL
+win32_ipc_pkt_parse_read_done (UINT8 * pkt, UINT32 pkt_len, UINT64 * seq_num)
+{
+  UINT8 *data = pkt;
+
+  if (!pkt || pkt_len < WIN32_IPC_PKT_READ_DONE_SIZE)
+    return FALSE;
+
+  if (win32_ipc_pkt_type_from_raw (data[0]) != WIN32_IPC_PKT_READ_DONE)
+    return FALSE;
+
+  data++;
+
+  READ_UINT64 (data, seq_num);
+
+  return TRUE;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcprotocol.h b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcprotocol.h
new file mode 100644
index 0000000000..2a21694a74
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcprotocol.h
@@ -0,0 +1,243 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <windows.h>
+#include <gst/gst.h>
+
+G_BEGIN_DECLS
+
+/*
+ * Communication Sequence
+ *
+ *            +--------+                      +--------+
+ *            | client |                      | server |
+ *            +--------+                      +--------+
+ *                |                               |
+ *                +--------- NEED-DATA ---------->|
+ *                |                               +-------+
+ *                |                               |  prepare named
+ *                |                               |  shared-memory
+ *                |                               +<------+
+ *                +<-- HAVE-DATA (w/ shm name) ---|
+ *       +--------+                               |
+ *   Open named   |                               |
+ *  shared-memory |                               |
+ *       +------->+                               |
+ *                |--------- READ-DONE ---------->|
+ */
+
+typedef enum
+{
+  WIN32_IPC_PKT_UNKNOWN,
+  WIN32_IPC_PKT_NEED_DATA,
+  WIN32_IPC_PKT_HAVE_DATA,
+  WIN32_IPC_PKT_READ_DONE,
+} Win32IpcPktType;
+
+/* Same as GstVideoFormat */
+typedef enum
+{
+  WIN32_IPC_VIDEO_FORMAT_UNKNOWN,
+  WIN32_IPC_VIDEO_FORMAT_ENCODED,
+  WIN32_IPC_VIDEO_FORMAT_I420,
+  WIN32_IPC_VIDEO_FORMAT_YV12,
+  WIN32_IPC_VIDEO_FORMAT_YUY2,
+  WIN32_IPC_VIDEO_FORMAT_UYVY,
+  WIN32_IPC_VIDEO_FORMAT_AYUV,
+  WIN32_IPC_VIDEO_FORMAT_RGBx,
+  WIN32_IPC_VIDEO_FORMAT_BGRx,
+  WIN32_IPC_VIDEO_FORMAT_xRGB,
+  WIN32_IPC_VIDEO_FORMAT_xBGR,
+  WIN32_IPC_VIDEO_FORMAT_RGBA,
+  WIN32_IPC_VIDEO_FORMAT_BGRA,
+  WIN32_IPC_VIDEO_FORMAT_ARGB,
+  WIN32_IPC_VIDEO_FORMAT_ABGR,
+  WIN32_IPC_VIDEO_FORMAT_RGB,
+  WIN32_IPC_VIDEO_FORMAT_BGR,
+  WIN32_IPC_VIDEO_FORMAT_Y41B,
+  WIN32_IPC_VIDEO_FORMAT_Y42B,
+  WIN32_IPC_VIDEO_FORMAT_YVYU,
+  WIN32_IPC_VIDEO_FORMAT_Y444,
+  WIN32_IPC_VIDEO_FORMAT_v210,
+  WIN32_IPC_VIDEO_FORMAT_v216,
+  WIN32_IPC_VIDEO_FORMAT_NV12,
+  WIN32_IPC_VIDEO_FORMAT_NV21,
+  WIN32_IPC_VIDEO_FORMAT_GRAY8,
+  WIN32_IPC_VIDEO_FORMAT_GRAY16_BE,
+  WIN32_IPC_VIDEO_FORMAT_GRAY16_LE,
+  WIN32_IPC_VIDEO_FORMAT_v308,
+  WIN32_IPC_VIDEO_FORMAT_RGB16,
+  WIN32_IPC_VIDEO_FORMAT_BGR16,
+  WIN32_IPC_VIDEO_FORMAT_RGB15,
+  WIN32_IPC_VIDEO_FORMAT_BGR15,
+  WIN32_IPC_VIDEO_FORMAT_UYVP,
+  WIN32_IPC_VIDEO_FORMAT_A420,
+  WIN32_IPC_VIDEO_FORMAT_RGB8P,
+  WIN32_IPC_VIDEO_FORMAT_YUV9,
+  WIN32_IPC_VIDEO_FORMAT_YVU9,
+  WIN32_IPC_VIDEO_FORMAT_IYU1,
+  WIN32_IPC_VIDEO_FORMAT_ARGB64,
+  WIN32_IPC_VIDEO_FORMAT_AYUV64,
+  WIN32_IPC_VIDEO_FORMAT_r210,
+  WIN32_IPC_VIDEO_FORMAT_I420_10BE,
+  WIN32_IPC_VIDEO_FORMAT_I420_10LE,
+  WIN32_IPC_VIDEO_FORMAT_I422_10BE,
+  WIN32_IPC_VIDEO_FORMAT_I422_10LE,
+  WIN32_IPC_VIDEO_FORMAT_Y444_10BE,
+  WIN32_IPC_VIDEO_FORMAT_Y444_10LE,
+  WIN32_IPC_VIDEO_FORMAT_GBR,
+  WIN32_IPC_VIDEO_FORMAT_GBR_10BE,
+  WIN32_IPC_VIDEO_FORMAT_GBR_10LE,
+  WIN32_IPC_VIDEO_FORMAT_NV16,
+  WIN32_IPC_VIDEO_FORMAT_NV24,
+  WIN32_IPC_VIDEO_FORMAT_NV12_64Z32,
+  WIN32_IPC_VIDEO_FORMAT_A420_10BE,
+  WIN32_IPC_VIDEO_FORMAT_A420_10LE,
+  WIN32_IPC_VIDEO_FORMAT_A422_10BE,
+  WIN32_IPC_VIDEO_FORMAT_A422_10LE,
+  WIN32_IPC_VIDEO_FORMAT_A444_10BE,
+  WIN32_IPC_VIDEO_FORMAT_A444_10LE,
+  WIN32_IPC_VIDEO_FORMAT_NV61,
+  WIN32_IPC_VIDEO_FORMAT_P010_10BE,
+  WIN32_IPC_VIDEO_FORMAT_P010_10LE,
+  WIN32_IPC_VIDEO_FORMAT_IYU2,
+  WIN32_IPC_VIDEO_FORMAT_VYUY,
+  WIN32_IPC_VIDEO_FORMAT_GBRA,
+  WIN32_IPC_VIDEO_FORMAT_GBRA_10BE,
+  WIN32_IPC_VIDEO_FORMAT_GBRA_10LE,
+  WIN32_IPC_VIDEO_FORMAT_GBR_12BE,
+  WIN32_IPC_VIDEO_FORMAT_GBR_12LE,
+  WIN32_IPC_VIDEO_FORMAT_GBRA_12BE,
+  WIN32_IPC_VIDEO_FORMAT_GBRA_12LE,
+  WIN32_IPC_VIDEO_FORMAT_I420_12BE,
+  WIN32_IPC_VIDEO_FORMAT_I420_12LE,
+  WIN32_IPC_VIDEO_FORMAT_I422_12BE,
+  WIN32_IPC_VIDEO_FORMAT_I422_12LE,
+  WIN32_IPC_VIDEO_FORMAT_Y444_12BE,
+  WIN32_IPC_VIDEO_FORMAT_Y444_12LE,
+  WIN32_IPC_VIDEO_FORMAT_GRAY10_LE32,
+  WIN32_IPC_VIDEO_FORMAT_NV12_10LE32,
+  WIN32_IPC_VIDEO_FORMAT_NV16_10LE32,
+  WIN32_IPC_VIDEO_FORMAT_NV12_10LE40,
+  WIN32_IPC_VIDEO_FORMAT_Y210,
+  WIN32_IPC_VIDEO_FORMAT_Y410,
+  WIN32_IPC_VIDEO_FORMAT_VUYA,
+  WIN32_IPC_VIDEO_FORMAT_BGR10A2_LE,
+  WIN32_IPC_VIDEO_FORMAT_RGB10A2_LE,
+  WIN32_IPC_VIDEO_FORMAT_Y444_16BE,
+  WIN32_IPC_VIDEO_FORMAT_Y444_16LE,
+  WIN32_IPC_VIDEO_FORMAT_P016_BE,
+  WIN32_IPC_VIDEO_FORMAT_P016_LE,
+  WIN32_IPC_VIDEO_FORMAT_P012_BE,
+  WIN32_IPC_VIDEO_FORMAT_P012_LE,
+  WIN32_IPC_VIDEO_FORMAT_Y212_BE,
+  WIN32_IPC_VIDEO_FORMAT_Y212_LE,
+  WIN32_IPC_VIDEO_FORMAT_Y412_BE,
+  WIN32_IPC_VIDEO_FORMAT_Y412_LE,
+  WIN32_IPC_VIDEO_FORMAT_NV12_4L4,
+  WIN32_IPC_VIDEO_FORMAT_NV12_32L32,
+  WIN32_IPC_VIDEO_FORMAT_RGBP,
+  WIN32_IPC_VIDEO_FORMAT_BGRP,
+  WIN32_IPC_VIDEO_FORMAT_AV12,
+  WIN32_IPC_VIDEO_FORMAT_ARGB64_LE,
+  WIN32_IPC_VIDEO_FORMAT_ARGB64_BE,
+  WIN32_IPC_VIDEO_FORMAT_RGBA64_LE,
+  WIN32_IPC_VIDEO_FORMAT_RGBA64_BE,
+  WIN32_IPC_VIDEO_FORMAT_BGRA64_LE,
+  WIN32_IPC_VIDEO_FORMAT_BGRA64_BE,
+  WIN32_IPC_VIDEO_FORMAT_ABGR64_LE,
+  WIN32_IPC_VIDEO_FORMAT_ABGR64_BE,
+  WIN32_IPC_VIDEO_FORMAT_NV12_16L32S,
+  WIN32_IPC_VIDEO_FORMAT_NV12_8L128,
+  WIN32_IPC_VIDEO_FORMAT_NV12_10BE_8L128,
+} Win32IpcVideoFormat;
+
+typedef struct
+{
+  Win32IpcVideoFormat format;
+  UINT32 width;
+  UINT32 height;
+  UINT32 fps_n;
+  UINT32 fps_d;
+  UINT32 par_n;
+  UINT32 par_d;
+  /* the size of memory */
+  UINT64 size;
+  /* plane offsets */
+  UINT64 offset[4];
+  /* stride of each plane */
+  UINT32 stride[4];
+  /* QPC time */
+  UINT64 qpc;
+} Win32IpcVideoInfo;
+
+/* 1 byte (type) + 8 byte (seq-num) */
+#define WIN32_IPC_PKT_NEED_DATA_SIZE 9
+
+/* 1 byte (type) + 8 byte (seq-num) + N bytes (name) + 4 (format) +
+ * 4 (width) + 4 (height) + 4 (fps_n) + 4 (fps_d) + 4 (par_n) + 4 (par_d) +
+ * 8 (size) + 8 * 4 (offset) + 4 * 4 (stride) + 8 (timestamp) */
+#define WIN32_IPC_PKT_HAVE_DATA_SIZE 101
+
+/* 1 byte (type) + 8 byte (seq-num) */
+#define WIN32_IPC_PKT_READ_DONE_SIZE 5
+
+const char *     win32_ipc_pkt_type_to_string  (Win32IpcPktType type);
+
+Win32IpcPktType  win32_ipc_pkt_type_from_raw   (UINT8 type);
+
+UINT8            win32_ipc_pkt_type_to_raw     (Win32IpcPktType type);
+
+UINT32           win32_ipc_pkt_build_need_data (UINT8 * pkt,
+                                                UINT32 pkt_size,
+                                                UINT64 seq_num);
+
+BOOL             win32_ipc_pkt_parse_need_data (UINT8 * pkt,
+                                                UINT32 pkt_size,
+                                                UINT64 * seq_num);
+
+UINT32           win32_ipc_pkt_build_have_data (UINT8 * pkt,
+                                                UINT32 pkt_size,
+                                                UINT64 seq_num,
+                                                const char * mmf_name,
+                                                const Win32IpcVideoInfo * info);
+
+BOOL             win32_ipc_pkt_parse_have_data (UINT8 * pkt,
+                                                UINT32 pkt_size,
+                                                UINT64 * seq_num,
+                                                char * mmf_name,
+                                                Win32IpcVideoInfo * info);
+
+UINT32           win32_ipc_pkt_build_read_done (UINT8 * pkt,
+                                                UINT32 pkt_size,
+                                                UINT64 seq_num);
+
+BOOL             win32_ipc_pkt_parse_read_done (UINT8 * pkt,
+                                                UINT32 pkt_size,
+                                                UINT64 * seq_num);
+
+G_END_DECLS
+
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcutils.cpp b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcutils.cpp
new file mode 100644
index 0000000000..098238205e
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcutils.cpp
@@ -0,0 +1,54 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#include "win32ipcutils.h"
+#include <string>
+#include <locale>
+#include <codecvt>
+#include <algorithm>
+
+static inline void rtrim(std::string &s) {
+  s.erase (std::find_if (s.rbegin(), s.rend(),
+      [](unsigned char ch) {
+        return !std::isspace (ch);
+      }).base (), s.end ());
+}
+
+std::string
+win32_ipc_error_message (DWORD error_code)
+{
+  WCHAR buffer[1024];
+
+  if (!FormatMessageW (FORMAT_MESSAGE_IGNORE_INSERTS |
+      FORMAT_MESSAGE_FROM_SYSTEM, nullptr, error_code, 0, buffer,
+      1024, nullptr)) {
+    return std::string ("");
+  }
+
+  std::wstring_convert<std::codecvt_utf8<wchar_t>, wchar_t> converter;
+  std::string ret = converter.to_bytes (buffer);
+  rtrim (ret);
+
+  return ret;
+}
diff --git a/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcutils.h b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcutils.h
new file mode 100644
index 0000000000..368b100de1
--- /dev/null
+++ b/subprojects/gst-plugins-bad/sys/win32ipc/protocol/win32ipcutils.h
@@ -0,0 +1,30 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * SPDX-License-Identifier: MIT
+ */
+
+#pragma once
+
+#include <windows.h>
+#include <string>
+
+std::string win32_ipc_error_message (DWORD error_code);
diff --git a/subprojects/gst-plugins-bad/tests/check/elements/ccconverter.c b/subprojects/gst-plugins-bad/tests/check/elements/ccconverter.c
index 127fb978a9..4e8138e905 100644
--- a/subprojects/gst-plugins-bad/tests/check/elements/ccconverter.c
+++ b/subprojects/gst-plugins-bad/tests/check/elements/ccconverter.c
@@ -476,12 +476,12 @@ GST_START_TEST (convert_cea708_cdp_cea608_raw)
       { 0x96, 0x69, 0x13, 0x5f, 0x43, 0x00, 0x00, 0x72, 0xe2, 0xfc, 0x80, 0x80,
     0xfd, 0x80, 0x80, 0x74, 0x00, 0x00, 0x8a
   };
-  const guint8 out1[] = { 0x80, 0x80, 0x80, 0x80 };
+  const guint8 out1[] = { 0x80, 0x80, };
   const guint8 in2[] =
       { 0x96, 0x69, 0x13, 0x5f, 0x43, 0x00, 0x00, 0x72, 0xe2, 0xfc, 0x80, 0x81,
     0xfd, 0x82, 0x83, 0x74, 0x00, 0x00, 0x8a
   };
-  const guint8 out2[] = { 0x80, 0x81, 0x80, 0x80 };
+  const guint8 out2[] = { 0x80, 0x81, };
   check_conversion_tc_passthrough (in1, sizeof (in1), out1, sizeof (out1),
       "closedcaption/x-cea-708,format=(string)cdp,framerate=30/1",
       "closedcaption/x-cea-608,format=(string)raw");
@@ -514,7 +514,7 @@ GST_START_TEST (convert_cea708_cdp_cea708_cc_data)
   };
   const guint8 out[] = { 0xf8, 0x80, 0x80, 0xf9, 0x80, 0x80 };
   check_conversion_tc_passthrough (in, sizeof (in), out, sizeof (out),
-      "closedcaption/x-cea-708,format=(string)cdp",
+      "closedcaption/x-cea-708,format=(string)cdp,framerate=30/1",
       "closedcaption/x-cea-708,format=(string)cc_data");
 }
 
@@ -524,17 +524,23 @@ GST_START_TEST (convert_cea708_cdp_cea708_cc_data_too_big)
 {
   /* tests that too large input is truncated */
   const guint8 in[] =
-      { 0x96, 0x69, 0x2e, 0x8f, 0x43, 0x00, 0x00, 0x72, 0xeb, 0xfc, 0x80, 0x80,
+      { 0x96, 0x69, 0x4c, 0x8f, 0x43, 0x00, 0x00, 0x72, 0xf5, 0xfc, 0x80, 0x80,
+    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
+    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
     0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
     0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
-    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0x74, 0x00, 0x00, 0x8a,
+    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
+    0x74, 0x00, 0x00, 0x8a,
   };
-  const guint8 out[] = { 0xf8, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
+  const guint8 out[] = { 0xf8, 0x80, 0x80, 0xf9, 0x80, 0x80, 0xfe, 0x80, 0x80,
+    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
     0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
-    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80
+    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
+    0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80, 0xfe, 0x80, 0x80,
+    0xfe, 0x80, 0x80
   };
   check_conversion_tc_passthrough (in, sizeof (in), out, sizeof (out),
-      "closedcaption/x-cea-708,format=(string)cdp",
+      "closedcaption/x-cea-708,format=(string)cdp,framerate=30/1",
       "closedcaption/x-cea-708,format=(string)cc_data");
 }
 
@@ -1017,6 +1023,149 @@ GST_START_TEST (convert_cea708_cdp_cea708_cc_data_double_input_data)
 
 GST_END_TEST;
 
+GST_START_TEST (convert_cea708_cc_data_cea708_cdp_double_input_data)
+{
+  /* caps say 60fps, but every buffer is cea608 field 1. Ensure data is taken
+   * alternatatively from each field even if there is too much input data */
+  const guint8 in1[] = { 0xfc, 0x81, 0x82 };
+  const guint8 in2[] = { 0xfc, 0x83, 0x84 };
+  const guint8 in3[] = { 0xfc, 0x85, 0x86 };
+  const guint8 *in[] = { in1, in2, in3, };
+  guint in_len[] = { sizeof (in1), sizeof (in2), sizeof (in3), };
+  /* two buffers from the first buffer, then the first half of the third input
+   * buffer */
+  const guint8 out1[] =
+      { 0x96, 0x69, 0x2b, 0x8f, 0x43, 0x00, 0x00, 0x72, 0xea, 0xfc, 0x81, 0x82,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0x74, 0x00, 0x00, 0x6b
+  };
+  /* padding buffer */
+  const guint8 out2[] =
+      { 0x96, 0x69, 0x2b, 0x8f, 0x43, 0x00, 0x01, 0x72, 0xea, 0xf9, 0x80, 0x80,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0x74, 0x00, 0x01, 0x6f
+  };
+  const guint8 out3[] =
+      { 0x96, 0x69, 0x2b, 0x8f, 0x43, 0x00, 0x02, 0x72, 0xea, 0xfc, 0x83, 0x84,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0x74, 0x00, 0x02, 0x63
+  };
+  const guint8 out4[] =
+      { 0x96, 0x69, 0x2b, 0x8f, 0x43, 0x00, 0x03, 0x72, 0xea, 0xf9, 0x80, 0x80,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0x74, 0x00, 0x03, 0x6b
+  };
+  const guint8 out5[] =
+      { 0x96, 0x69, 0x2b, 0x8f, 0x43, 0x00, 0x04, 0x72, 0xea, 0xfc, 0x85, 0x86,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0x74, 0x00, 0x04, 0x5b
+  };
+  const guint8 *out[] = { out1, out2, out3, out4, out5 };
+  guint out_len[] =
+      { sizeof (out1), sizeof (out2), sizeof (out3), sizeof (out4),
+    sizeof (out5)
+  };
+  check_conversion_multiple (G_N_ELEMENTS (in_len), in, in_len,
+      G_N_ELEMENTS (out_len), out, out_len,
+      "closedcaption/x-cea-708,format=(string)cc_data,framerate=(fraction)60/1",
+      "closedcaption/x-cea-708,format=(string)cdp,framerate=(fraction)60/1",
+      NULL, NULL, FLAG_SEND_EOS);
+}
+
+GST_END_TEST;
+
+static guint8
+calculate_cdp_checksum (guint8 * cdp, gsize len)
+{
+  guint8 checksum = 0;
+  gsize i;
+
+  for (i = 0; i < len; i++) {
+    checksum += cdp[i];
+  }
+  checksum &= 0xff;
+  return 256 - checksum;
+}
+
+GST_START_TEST (convert_cea708_cc_data_cea708_cdp_field1_overflow)
+{
+  /* caps say 60fps, but every buffer is cea608 field 1. Ensure data is taken
+   * alternatatively from each field even if there is too much input data.
+   * Also ensure that overflow does something sane, like dropping previous data */
+#define N_INPUTS 100
+  guint8 in_data[N_INPUTS * 3];
+  guint in_len[N_INPUTS];
+  guint8 *in[N_INPUTS];
+  guint i;
+
+#define N_OUTPUTS 100
+  guint8 out_data[N_OUTPUTS * 43];
+  guint out_len[N_OUTPUTS];
+  guint8 *out[N_OUTPUTS];
+
+  const guint8 out_template[] =
+      { 0x96, 0x69, 0x2b, 0x8f, 0x43, 0x00, 0x01, 0x72, 0xea, 0xf9, 0x80, 0x80,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00, 0xfa, 0x00, 0x00,
+    0xfa, 0x00, 0x00, 0x74, 0x00, 0x01, 0x6f
+  };
+
+  G_STATIC_ASSERT (sizeof (out_template) == 43);
+
+  /* generate input data */
+  for (i = 0; i < N_INPUTS; i++) {
+    in_len[i] = 3;
+    in_data[i * 3 + 0] = 0xfc;
+    in_data[i * 3 + 1] = 0x81 + i * 2;
+    in_data[i * 3 + 2] = 0x81 + i * 2 + 1;
+    in[i] = &in_data[i * 3];
+  }
+
+  for (i = 0; i < N_OUTPUTS; i++) {
+    out_len[i] = 43;
+    memcpy (&out_data[i * 43], out_template, sizeof (out_template));
+    /* write correct counters */
+    out_data[i * 43 + 6] = i;
+    out_data[i * 43 + 41] = i;
+    /* write the correct cea608 data */
+    if (i % 2 == 0) {
+      gsize in_data_offset;
+      /* take frames sequentially from the input */
+      gsize in_idx = i / 2;
+      /* take the first 12 input frames, then skip the next 12 frames and take
+       * the next 12 frames etc.
+       * 24 is the byte size of the internal cea608 field buffers that we are
+       * overflowing but every second buffer will have cea608 field 1 in it.
+       * 12 frames is 24 bytes stored and is enough to cause overflow */
+      in_idx = (in_idx / 6) * 12 + in_idx % 6;
+      in_data_offset = in_idx * 3;
+
+      out_data[i * 43 + 9] = in_data[in_data_offset + 0];
+      out_data[i * 43 + 10] = in_data[in_data_offset + 1];
+      out_data[i * 43 + 11] = in_data[in_data_offset + 2];
+    } else {
+      out_data[i * 43 + 9] = 0xf9;
+      out_data[i * 43 + 10] = 0x80;
+      out_data[i * 43 + 11] = 0x80;
+    }
+    out_data[i * 43 + 42] = calculate_cdp_checksum (&out_data[i * 43], 42);
+    out[i] = &out_data[i * 43];
+  }
+
+  check_conversion_multiple (G_N_ELEMENTS (in_len), (const guint8 **) in,
+      in_len, G_N_ELEMENTS (out_len), (const guint8 **) out, out_len,
+      "closedcaption/x-cea-708,format=(string)cc_data,framerate=(fraction)60/1",
+      "closedcaption/x-cea-708,format=(string)cdp,framerate=(fraction)60/1",
+      NULL, NULL, FLAG_SEND_EOS);
+}
+
+GST_END_TEST;
+
 static Suite *
 ccextractor_suite (void)
 {
@@ -1053,6 +1202,8 @@ ccextractor_suite (void)
   tcase_add_test (tc, convert_cea608_raw_cea708_cdp_double_framerate);
   tcase_add_test (tc, convert_cea608_s334_1a_cea708_cdp_double_framerate);
   tcase_add_test (tc, convert_cea708_cdp_cea708_cc_data_double_input_data);
+  tcase_add_test (tc, convert_cea708_cc_data_cea708_cdp_double_input_data);
+  tcase_add_test (tc, convert_cea708_cc_data_cea708_cdp_field1_overflow);
 
   return s;
 }
diff --git a/subprojects/gst-plugins-bad/tests/check/elements/cudaconvert.c b/subprojects/gst-plugins-bad/tests/check/elements/cudaconvert.c
index 67713d2f13..a07c6ec06e 100644
--- a/subprojects/gst-plugins-bad/tests/check/elements/cudaconvert.c
+++ b/subprojects/gst-plugins-bad/tests/check/elements/cudaconvert.c
@@ -19,6 +19,18 @@
 
 #include <gst/check/gstcheck.h>
 
+static const gchar *run_visual_test = NULL;
+
+static const gchar *YUV_FORMATS[] = {
+  "I420", "YV12", "NV12", "NV21", "P010_10LE", "P016_LE", "I420_10LE", "Y444",
+  "Y444_16LE", "Y42B", "I422_10LE", "I422_12LE",
+};
+
+static const gchar *RGB_FORMATS[] = {
+  "BGRA", "RGBA", "RGBx", "BGRx", "ARGB", "ABGR", "RGB", "BGR", "BGR10A2_LE",
+  "RGB10A2_LE", "RGBP", "BGRP", "GBR", "GBRA",
+};
+
 static gboolean
 bus_cb (GstBus * bus, GstMessage * message, gpointer data)
 {
@@ -54,9 +66,12 @@ run_convert_pipelne (const gchar * in_format, const gchar * out_format)
   GMainLoop *loop = g_main_loop_new (NULL, FALSE);
   gchar *pipeline_str =
       g_strdup_printf ("videotestsrc num-buffers=1 is-live=true ! "
-      "video/x-raw,format=%s,framerate=3/1 ! cudaupload ! "
-      "cudaconvert ! cudadownload ! video/x-raw,format=%s ! "
-      "videoconvert ! autovideosink", in_format, out_format);
+      "video/x-raw,format=%s,width=128,height=64,framerate=3/1,"
+      "pixel-aspect-ratio=1/1 ! cudaupload ! "
+      "cudaconvertscale ! cudadownload ! "
+      "video/x-raw,format=%s,width=320,height=240,pixel-aspect-ratio=1/1 ! "
+      "videoconvert ! %s", in_format, out_format,
+      run_visual_test ? "autovideosink" : "fakesink");
   GstElement *pipeline;
 
   pipeline = gst_parse_launch (pipeline_str, NULL);
@@ -78,20 +93,12 @@ run_convert_pipelne (const gchar * in_format, const gchar * out_format)
 
 GST_START_TEST (test_convert_yuv_yuv)
 {
-  const gchar *format_list[] = {
-    "I420", "YV12", "NV12", "NV21", "P010_10LE", "I420_10LE",
-    "Y444", "Y444_16LE",
-  };
-
   gint i, j;
 
-  for (i = 0; i < G_N_ELEMENTS (format_list); i++) {
-    for (j = 0; j < G_N_ELEMENTS (format_list); j++) {
-      if (i == j)
-        continue;
-
-      GST_DEBUG ("run conversion %s to %s", format_list[i], format_list[j]);
-      run_convert_pipelne (format_list[i], format_list[j]);
+  for (i = 0; i < G_N_ELEMENTS (YUV_FORMATS); i++) {
+    for (j = 0; j < G_N_ELEMENTS (YUV_FORMATS); j++) {
+      gst_println ("run conversion %s to %s", YUV_FORMATS[i], YUV_FORMATS[j]);
+      run_convert_pipelne (YUV_FORMATS[i], YUV_FORMATS[j]);
     }
   }
 }
@@ -100,22 +107,12 @@ GST_END_TEST;
 
 GST_START_TEST (test_convert_yuv_rgb)
 {
-  const gchar *in_format_list[] = {
-    "I420", "YV12", "NV12", "NV21", "P010_10LE", "I420_10LE",
-    "Y444", "Y444_16LE",
-  };
-  const gchar *out_format_list[] = {
-    "BGRA", "RGBA", "RGBx", "BGRx", "ARGB", "ABGR", "RGB", "BGR", "BGR10A2_LE",
-    "RGB10A2_LE",
-  };
-
   gint i, j;
 
-  for (i = 0; i < G_N_ELEMENTS (in_format_list); i++) {
-    for (j = 0; j < G_N_ELEMENTS (out_format_list); j++) {
-      GST_DEBUG ("run conversion %s to %s", in_format_list[i],
-          out_format_list[j]);
-      run_convert_pipelne (in_format_list[i], out_format_list[j]);
+  for (i = 0; i < G_N_ELEMENTS (YUV_FORMATS); i++) {
+    for (j = 0; j < G_N_ELEMENTS (RGB_FORMATS); j++) {
+      gst_println ("run conversion %s to %s", YUV_FORMATS[i], RGB_FORMATS[j]);
+      run_convert_pipelne (YUV_FORMATS[i], RGB_FORMATS[j]);
     }
   }
 }
@@ -124,22 +121,12 @@ GST_END_TEST;
 
 GST_START_TEST (test_convert_rgb_yuv)
 {
-  const gchar *in_format_list[] = {
-    "BGRA", "RGBA", "RGBx", "BGRx", "ARGB", "ABGR", "RGB", "BGR", "BGR10A2_LE",
-    "RGB10A2_LE",
-  };
-  const gchar *out_format_list[] = {
-    "I420", "YV12", "NV12", "NV21", "P010_10LE", "I420_10LE",
-    "Y444", "Y444_16LE",
-  };
-
   gint i, j;
 
-  for (i = 0; i < G_N_ELEMENTS (in_format_list); i++) {
-    for (j = 0; j < G_N_ELEMENTS (out_format_list); j++) {
-      GST_DEBUG ("run conversion %s to %s", in_format_list[i],
-          out_format_list[j]);
-      run_convert_pipelne (in_format_list[i], out_format_list[j]);
+  for (i = 0; i < G_N_ELEMENTS (RGB_FORMATS); i++) {
+    for (j = 0; j < G_N_ELEMENTS (YUV_FORMATS); j++) {
+      gst_println ("run conversion %s to %s", RGB_FORMATS[i], YUV_FORMATS[j]);
+      run_convert_pipelne (RGB_FORMATS[i], YUV_FORMATS[j]);
     }
   }
 }
@@ -148,20 +135,12 @@ GST_END_TEST;
 
 GST_START_TEST (test_convert_rgb_rgb)
 {
-  const gchar *format_list[] = {
-    "BGRA", "RGBA", "RGBx", "BGRx", "ARGB", "ABGR", "RGB", "BGR", "BGR10A2_LE",
-    "RGB10A2_LE",
-  };
-
   gint i, j;
 
-  for (i = 0; i < G_N_ELEMENTS (format_list); i++) {
-    for (j = 0; j < G_N_ELEMENTS (format_list); j++) {
-      if (i == j)
-        continue;
-
-      GST_DEBUG ("run conversion %s to %s", format_list[i], format_list[j]);
-      run_convert_pipelne (format_list[i], format_list[j]);
+  for (i = 0; i < G_N_ELEMENTS (RGB_FORMATS); i++) {
+    for (j = 0; j < G_N_ELEMENTS (RGB_FORMATS); j++) {
+      gst_println ("run conversion %s to %s", RGB_FORMATS[i], RGB_FORMATS[j]);
+      run_convert_pipelne (RGB_FORMATS[i], RGB_FORMATS[j]);
     }
   }
 }
@@ -174,9 +153,9 @@ check_cuda_convert_available (void)
   gboolean ret = TRUE;
   GstElement *upload;
 
-  upload = gst_element_factory_make ("cudaconvert", NULL);
+  upload = gst_element_factory_make ("cudaconvertscale", NULL);
   if (!upload) {
-    GST_WARNING ("cudaconvert is not available, possibly driver load failure");
+    GST_WARNING ("cudaconvertscale is not available");
     return FALSE;
   }
 
@@ -186,7 +165,7 @@ check_cuda_convert_available (void)
 }
 
 static Suite *
-cudaconvert_suite (void)
+cudaconvertscale_suite (void)
 {
   Suite *s;
   TCase *tc_chain;
@@ -194,23 +173,28 @@ cudaconvert_suite (void)
   /* HACK: cuda device init/deinit with fork seems to problematic */
   g_setenv ("CK_FORK", "no", TRUE);
 
-  s = suite_create ("cudaconvert");
+  run_visual_test = g_getenv ("ENABLE_CUDA_VISUAL_TEST");
+
+  s = suite_create ("cudaconvertscale");
   tc_chain = tcase_create ("general");
 
   suite_add_tcase (s, tc_chain);
 
   if (!check_cuda_convert_available ()) {
-    GST_DEBUG ("Skip cudaconvert test since cannot open device");
+    gst_println ("Skip convertscale test since cannot open device");
     goto end;
   }
 
-  tcase_add_test (tc_chain, test_convert_yuv_yuv);
-  tcase_add_test (tc_chain, test_convert_yuv_rgb);
-  tcase_add_test (tc_chain, test_convert_rgb_yuv);
-  tcase_add_test (tc_chain, test_convert_rgb_rgb);
+  /* Only run test if explicitly enabled */
+  if (g_getenv ("ENABLE_CUDA_CONVERSION_TEST")) {
+    tcase_add_test (tc_chain, test_convert_yuv_yuv);
+    tcase_add_test (tc_chain, test_convert_yuv_rgb);
+    tcase_add_test (tc_chain, test_convert_rgb_yuv);
+    tcase_add_test (tc_chain, test_convert_rgb_rgb);
+  }
 
 end:
   return s;
 }
 
-GST_CHECK_MAIN (cudaconvert);
+GST_CHECK_MAIN (cudaconvertscale);
diff --git a/subprojects/gst-plugins-bad/tests/check/elements/d3d11colorconvert.c b/subprojects/gst-plugins-bad/tests/check/elements/d3d11colorconvert.c
index 293e4db94e..6903402909 100644
--- a/subprojects/gst-plugins-bad/tests/check/elements/d3d11colorconvert.c
+++ b/subprojects/gst-plugins-bad/tests/check/elements/d3d11colorconvert.c
@@ -1,6 +1,6 @@
 /* GStreamer
  *
- * unit test for d3d11colorconvert element
+ * unit test for d3d11convert element
  * Copyright (C) 2019 Matthew Waters <matthew@centricular.com>
  * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
  *
@@ -54,11 +54,12 @@ static const gchar *YUV_FORMATS[] = {
 };
 
 static const gchar *RGB_FORMATS[] = {
-  "BGRA", "RGBA", "RGB10A2_LE", "BGRx", "RGBx", "RGBA64_LE"
+  "BGRA", "RGBA", "RGB10A2_LE", "BGRx", "RGBx", "RGBA64_LE", "RGBP", "BGRP",
+  "GBR", "GBR_10LE", "GBR_12LE", "GBRA", "GBRA_10LE", "GBRA_12LE"
 };
 
 static const gchar *PACKED_YUV_FORMATS[] = {
-  "Y410",
+  "Y410", "YUY2",
 };
 
 static const gchar *GRAY_FORMATS[] = {
@@ -70,7 +71,7 @@ static TestFrame test_rgba_reorder[] = {
   {1, 1, GST_VIDEO_FORMAT_BGRA, {(guint8 *) & bgra_reorder_data}},
 };
 
-GST_START_TEST (test_d3d11_color_convert_rgba_reorder)
+GST_START_TEST (test_d3d11_convert_rgba_reorder)
 {
   GstHarness *h =
       gst_harness_new_parse ("d3d11upload ! d3d11convert ! d3d11download");
@@ -157,8 +158,10 @@ run_convert_pipelne (const gchar * in_format, const gchar * out_format)
   GMainLoop *loop = g_main_loop_new (NULL, FALSE);
   gchar *pipeline_str =
       g_strdup_printf ("videotestsrc num-buffers=1 is-live=true ! "
-      "video/x-raw,format=%s,framerate=3/1 ! d3d11upload ! "
-      "d3d11convert ! d3d11download ! video/x-raw,format=%s ! "
+      "video/x-raw,format=%s,framerate=3/1,width=128,height=64,"
+      "pixel-aspect-ratio=1/1 ! d3d11upload ! "
+      "d3d11convert border-color=0xffffaaaaaaaaaaaa ! d3d11download ! "
+      "video/x-raw,format=%s,width=320,height=240,pixel-aspect-ratio=1/1 ! "
       "videoconvert ! %s", in_format, out_format,
       run_visual_test ? "d3d11videosink" : "fakesink");
   GstElement *pipeline;
@@ -180,15 +183,12 @@ run_convert_pipelne (const gchar * in_format, const gchar * out_format)
   g_main_loop_unref (loop);
 }
 
-GST_START_TEST (test_d3d11_color_convert_yuv_yuv)
+GST_START_TEST (test_d3d11_convert_yuv_yuv)
 {
   gint i, j;
 
   for (i = 0; i < G_N_ELEMENTS (YUV_FORMATS); i++) {
     for (j = 0; j < G_N_ELEMENTS (YUV_FORMATS); j++) {
-      if (i == j)
-        continue;
-
       GST_DEBUG ("run conversion %s to %s", YUV_FORMATS[i], YUV_FORMATS[j]);
       run_convert_pipelne (YUV_FORMATS[i], YUV_FORMATS[j]);
     }
@@ -197,15 +197,12 @@ GST_START_TEST (test_d3d11_color_convert_yuv_yuv)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_yuv_rgb)
+GST_START_TEST (test_d3d11_convert_yuv_rgb)
 {
   gint i, j;
 
   for (i = 0; i < G_N_ELEMENTS (YUV_FORMATS); i++) {
     for (j = 0; j < G_N_ELEMENTS (RGB_FORMATS); j++) {
-      if (i == j)
-        continue;
-
       GST_DEBUG ("run conversion %s to %s", YUV_FORMATS[i], RGB_FORMATS[j]);
       run_convert_pipelne (YUV_FORMATS[i], RGB_FORMATS[j]);
     }
@@ -214,15 +211,12 @@ GST_START_TEST (test_d3d11_color_convert_yuv_rgb)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_yuv_gray)
+GST_START_TEST (test_d3d11_convert_yuv_gray)
 {
   gint i, j;
 
   for (i = 0; i < G_N_ELEMENTS (YUV_FORMATS); i++) {
     for (j = 0; j < G_N_ELEMENTS (GRAY_FORMATS); j++) {
-      if (i == j)
-        continue;
-
       GST_DEBUG ("run conversion %s to %s", YUV_FORMATS[i], GRAY_FORMATS[j]);
       run_convert_pipelne (YUV_FORMATS[i], GRAY_FORMATS[j]);
     }
@@ -231,7 +225,7 @@ GST_START_TEST (test_d3d11_color_convert_yuv_gray)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_rgb_yuv)
+GST_START_TEST (test_d3d11_convert_rgb_yuv)
 {
   gint i, j;
 
@@ -245,15 +239,12 @@ GST_START_TEST (test_d3d11_color_convert_rgb_yuv)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_rgb_rgb)
+GST_START_TEST (test_d3d11_convert_rgb_rgb)
 {
   gint i, j;
 
   for (i = 0; i < G_N_ELEMENTS (RGB_FORMATS); i++) {
     for (j = 0; j < G_N_ELEMENTS (RGB_FORMATS); j++) {
-      if (i == j)
-        continue;
-
       GST_DEBUG ("run conversion %s to %s", RGB_FORMATS[i], RGB_FORMATS[j]);
       run_convert_pipelne (RGB_FORMATS[i], RGB_FORMATS[j]);
     }
@@ -262,7 +253,7 @@ GST_START_TEST (test_d3d11_color_convert_rgb_rgb)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_rgb_gray)
+GST_START_TEST (test_d3d11_convert_rgb_gray)
 {
   gint i, j;
 
@@ -276,7 +267,7 @@ GST_START_TEST (test_d3d11_color_convert_rgb_gray)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_packed_yuv_yuv)
+GST_START_TEST (test_d3d11_convert_packed_yuv_yuv)
 {
   gint i, j;
 
@@ -291,7 +282,7 @@ GST_START_TEST (test_d3d11_color_convert_packed_yuv_yuv)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_packed_yuv_rgb)
+GST_START_TEST (test_d3d11_convert_packed_yuv_rgb)
 {
   gint i, j;
 
@@ -306,7 +297,7 @@ GST_START_TEST (test_d3d11_color_convert_packed_yuv_rgb)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_packed_yuv_gray)
+GST_START_TEST (test_d3d11_convert_packed_yuv_gray)
 {
   gint i, j;
 
@@ -321,7 +312,7 @@ GST_START_TEST (test_d3d11_color_convert_packed_yuv_gray)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_gray_yuv)
+GST_START_TEST (test_d3d11_convert_gray_yuv)
 {
   gint i, j;
 
@@ -335,7 +326,7 @@ GST_START_TEST (test_d3d11_color_convert_gray_yuv)
 
 GST_END_TEST;
 
-GST_START_TEST (test_d3d11_color_convert_gray_rgb)
+GST_START_TEST (test_d3d11_convert_gray_rgb)
 {
   gint i, j;
 
@@ -350,33 +341,33 @@ GST_START_TEST (test_d3d11_color_convert_gray_rgb)
 GST_END_TEST;
 
 static Suite *
-d3d11colorconvert_suite (void)
+d3d11convert_suite (void)
 {
-  Suite *s = suite_create ("d3d11colorconvert");
+  Suite *s = suite_create ("d3d11convert");
   TCase *tc_basic = tcase_create ("general");
 
   run_visual_test = g_getenv ("ENABLE_D3D11_VISUAL_TEST");
 
   suite_add_tcase (s, tc_basic);
-  tcase_add_test (tc_basic, test_d3d11_color_convert_rgba_reorder);
+  tcase_add_test (tc_basic, test_d3d11_convert_rgba_reorder);
 
   /* XXX: Some methods for device's capability checking and initialization
    * are plugin internal. Enable conversion tests only when it's enabled */
   if (g_getenv ("ENABLE_D3D11_CONVERSION_TEST")) {
-    tcase_add_test (tc_basic, test_d3d11_color_convert_yuv_yuv);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_yuv_rgb);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_yuv_gray);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_rgb_yuv);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_rgb_rgb);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_rgb_gray);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_packed_yuv_yuv);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_packed_yuv_rgb);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_packed_yuv_gray);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_gray_yuv);
-    tcase_add_test (tc_basic, test_d3d11_color_convert_gray_rgb);
+    tcase_add_test (tc_basic, test_d3d11_convert_yuv_yuv);
+    tcase_add_test (tc_basic, test_d3d11_convert_yuv_rgb);
+    tcase_add_test (tc_basic, test_d3d11_convert_yuv_gray);
+    tcase_add_test (tc_basic, test_d3d11_convert_rgb_yuv);
+    tcase_add_test (tc_basic, test_d3d11_convert_rgb_rgb);
+    tcase_add_test (tc_basic, test_d3d11_convert_rgb_gray);
+    tcase_add_test (tc_basic, test_d3d11_convert_packed_yuv_yuv);
+    tcase_add_test (tc_basic, test_d3d11_convert_packed_yuv_rgb);
+    tcase_add_test (tc_basic, test_d3d11_convert_packed_yuv_gray);
+    tcase_add_test (tc_basic, test_d3d11_convert_gray_yuv);
+    tcase_add_test (tc_basic, test_d3d11_convert_gray_rgb);
   }
 
   return s;
 }
 
-GST_CHECK_MAIN (d3d11colorconvert);
+GST_CHECK_MAIN (d3d11convert);
diff --git a/subprojects/gst-plugins-bad/tests/check/elements/dash_mpd.c b/subprojects/gst-plugins-bad/tests/check/elements/dash_mpd.c
index c7adab8f34..1d347b0a54 100644
--- a/subprojects/gst-plugins-bad/tests/check/elements/dash_mpd.c
+++ b/subprojects/gst-plugins-bad/tests/check/elements/dash_mpd.c
@@ -4230,6 +4230,57 @@ GST_START_TEST (dash_mpdparser_get_baseURL8)
 
 GST_END_TEST;
 
+/*
+ * Test getting baseURL with query
+ *
+ */
+GST_START_TEST (dash_mpdparser_get_baseURL_with_query)
+{
+  gboolean ret;
+  gchar *uri;
+  gint64 range_start, range_end;
+  const gchar *xml =
+      "<?xml version=\"1.0\"?>"
+      "<MPD xmlns=\"urn:mpeg:dash:schema:mpd:2011\""
+      "     profiles=\"urn:mpeg:dash:profile:isoff-main:2011\">"
+      "  <Period id=\"Period0\" duration=\"P0Y0M1DT1H1M1S\">"
+      "    <AdaptationSet id=\"1\" mimeType=\"audio\" lang=\"en\">"
+      "      <Representation id=\"1\" bandwidth=\"250000\">"
+      "        <BaseURL>http://example.com/test?param1=value1&amp;param2=value2</BaseURL>"
+      "        <SegmentBase indexRange=\"100-200\" indexRangeExact=\"true\">"
+      "          <Initialization range=\"0-100\" />"
+      "        </SegmentBase>"
+      "      </Representation></AdaptationSet></Period></MPD>";
+
+  GstMPDClient *mpdclient = setup_mpd_client (xml);
+
+  /* get segment url and range from segment Initialization */
+  ret =
+      gst_mpd_client_get_next_header (mpdclient, &uri, 0, &range_start,
+      &range_end);
+  assert_equals_int (ret, TRUE);
+  assert_equals_string (uri,
+      "http://example.com/test?param1=value1&param2=value2");
+  assert_equals_int64 (range_start, 0);
+  assert_equals_int64 (range_end, 100);
+  g_free (uri);
+
+  /* get segment url and range from segment indexRange */
+  ret =
+      gst_mpd_client_get_next_header_index (mpdclient, &uri, 0, &range_start,
+      &range_end);
+  assert_equals_int (ret, TRUE);
+  assert_equals_string (uri,
+      "http://example.com/test?param1=value1&param2=value2");
+  assert_equals_int64 (range_start, 100);
+  assert_equals_int64 (range_end, 200);
+  g_free (uri);
+
+  gst_mpd_client_free (mpdclient);
+}
+
+GST_END_TEST;
+
 /*
  * Test getting mediaPresentationDuration
  *
@@ -6631,6 +6682,7 @@ dash_suite (void)
   tcase_add_test (tc_complexMPD, dash_mpdparser_get_baseURL6);
   tcase_add_test (tc_complexMPD, dash_mpdparser_get_baseURL7);
   tcase_add_test (tc_complexMPD, dash_mpdparser_get_baseURL8);
+  tcase_add_test (tc_complexMPD, dash_mpdparser_get_baseURL_with_query);
   tcase_add_test (tc_complexMPD, dash_mpdparser_get_mediaPresentationDuration);
   tcase_add_test (tc_complexMPD, dash_mpdparser_get_streamPresentationOffset);
   tcase_add_test (tc_complexMPD, dash_mpdparser_segments);
diff --git a/subprojects/gst-plugins-bad/tests/check/elements/h264timestamper.c b/subprojects/gst-plugins-bad/tests/check/elements/h264timestamper.c
new file mode 100644
index 0000000000..b7206bae6b
--- /dev/null
+++ b/subprojects/gst-plugins-bad/tests/check/elements/h264timestamper.c
@@ -0,0 +1,172 @@
+/*
+ * GStreamer
+ *
+ * unit test for h264timestamper
+ *
+ * Copyright (C) 2022 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <gst/check/check.h>
+#include <gst/video/video.h>
+/* SPS */
+static guint8 h264_sps[] = {
+  0x00, 0x00, 0x00, 0x01, 0x67, 0x4d, 0x40, 0x15,
+  0xec, 0xa4, 0xbf, 0x2e, 0x02, 0x20, 0x00, 0x00,
+  0x03, 0x00, 0x2e, 0xe6, 0xb2, 0x80, 0x01, 0xe2,
+  0xc5, 0xb2, 0xc0
+};
+
+/* PPS */
+static guint8 h264_pps[] = {
+  0x00, 0x00, 0x00, 0x01, 0x68, 0xeb, 0xec, 0xb2
+};
+
+/* keyframes all around */
+static guint8 h264_idrframe[] = {
+  0x00, 0x00, 0x00, 0x01, 0x65, 0x88, 0x84, 0x00,
+  0x10, 0xff, 0xfe, 0xf6, 0xf0, 0xfe, 0x05, 0x36,
+  0x56, 0x04, 0x50, 0x96, 0x7b, 0x3f, 0x53, 0xe1
+};
+
+static GstBuffer *
+create_keyframe_with_sps_pps (void)
+{
+  gsize size =
+      G_N_ELEMENTS (h264_sps) + G_N_ELEMENTS (h264_pps) +
+      G_N_ELEMENTS (h264_idrframe);
+  GstBuffer *buffer = gst_buffer_new_allocate (NULL, size, NULL);
+  GstMapInfo map_info;
+  gsize offset = 0;
+
+  g_assert (gst_buffer_map (buffer, &map_info, GST_MAP_WRITE));
+  memcpy (&map_info.data[offset], h264_sps, G_N_ELEMENTS (h264_sps));
+  offset += G_N_ELEMENTS (h264_sps);
+  memcpy (&map_info.data[offset], h264_pps, G_N_ELEMENTS (h264_pps));
+  offset += G_N_ELEMENTS (h264_pps);
+  memcpy (&map_info.data[offset], h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  offset += G_N_ELEMENTS (h264_idrframe);
+
+  gst_buffer_unmap (buffer, &map_info);
+
+  return buffer;
+}
+
+GST_START_TEST (test_input_dts_none)
+{
+  GstHarness *h = gst_harness_new ("h264timestamper");
+  GstBuffer *buffer;
+  int i;
+
+  gst_harness_set_src_caps_str (h,
+      "video/x-h264,stream-format=byte-stream,alignment=au");
+  gst_harness_set_sink_caps_str (h,
+      "video/x-h264,stream-format=byte-stream,alignment=au");
+
+  buffer = create_keyframe_with_sps_pps ();
+  GST_BUFFER_PTS (buffer) = 0;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = 1 * GST_MSECOND;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = 2 * GST_MSECOND;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = 3 * GST_MSECOND;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = 4 * GST_MSECOND;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+
+  gst_harness_push_event (h, gst_event_new_eos ());
+
+  for (i = 0; i < 5; i++) {
+    buffer = gst_harness_pull (h);
+    fail_unless (buffer != NULL);
+    fail_unless (GST_CLOCK_TIME_IS_VALID (GST_BUFFER_PTS (buffer)));
+    fail_unless (GST_CLOCK_TIME_IS_VALID (GST_BUFFER_DTS (buffer)));
+    fail_unless (GST_BUFFER_PTS (buffer) >= GST_BUFFER_DTS (buffer));
+    gst_buffer_unref (buffer);
+  }
+
+  gst_harness_teardown (h);
+}
+
+GST_END_TEST;
+
+GST_START_TEST (test_input_pts_none)
+{
+  GstHarness *h = gst_harness_new ("h264timestamper");
+  GstBuffer *buffer;
+  int i;
+
+  gst_harness_set_src_caps_str (h,
+      "video/x-h264,stream-format=byte-stream,alignment=au");
+  gst_harness_set_sink_caps_str (h,
+      "video/x-h264,stream-format=byte-stream,alignment=au");
+
+  buffer = create_keyframe_with_sps_pps ();
+  GST_BUFFER_PTS (buffer) = 0;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = GST_CLOCK_TIME_NONE;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = 2 * GST_MSECOND;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = GST_CLOCK_TIME_NONE;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+  buffer = gst_buffer_new_memdup (h264_idrframe, G_N_ELEMENTS (h264_idrframe));
+  GST_BUFFER_PTS (buffer) = 4 * GST_MSECOND;
+  fail_unless_equals_int (gst_harness_push (h, buffer), GST_FLOW_OK);;
+
+  gst_harness_push_event (h, gst_event_new_eos ());
+
+  for (i = 0; i < 5; i++) {
+    buffer = gst_harness_pull (h);
+    fail_unless (buffer != NULL);
+    fail_unless (GST_CLOCK_TIME_IS_VALID (GST_BUFFER_PTS (buffer)));
+    fail_unless (GST_CLOCK_TIME_IS_VALID (GST_BUFFER_DTS (buffer)));
+    fail_unless (GST_BUFFER_PTS (buffer) >= GST_BUFFER_DTS (buffer));
+    gst_buffer_unref (buffer);
+  }
+
+  gst_harness_teardown (h);
+}
+
+GST_END_TEST;
+static Suite *
+h264timestamper_suite (void)
+{
+  Suite *s = suite_create ("h264timestamper");
+  TCase *tc = tcase_create ("general");
+
+  tcase_add_test (tc, test_input_dts_none);
+  tcase_add_test (tc, test_input_pts_none);
+
+  suite_add_tcase (s, tc);
+
+  return s;
+}
+
+GST_CHECK_MAIN (h264timestamper);
diff --git a/subprojects/gst-plugins-bad/tests/check/elements/hlsdemux_m3u8.c b/subprojects/gst-plugins-bad/tests/check/elements/hlsdemux_m3u8.c
index a418fe9f12..beb492b9ac 100644
--- a/subprojects/gst-plugins-bad/tests/check/elements/hlsdemux_m3u8.c
+++ b/subprojects/gst-plugins-bad/tests/check/elements/hlsdemux_m3u8.c
@@ -572,7 +572,7 @@ GST_START_TEST (test_live_playlist_rotated)
 
   ret = gst_m3u8_update (pl, g_strdup (LIVE_ROTATED_PLAYLIST));
   assert_equals_int (ret, TRUE);
-  file = gst_m3u8_get_next_fragment (pl, TRUE, NULL, NULL);
+  file = gst_m3u8_get_next_fragment (pl, TRUE, NULL, NULL, NULL);
   fail_unless (file != NULL);
   gst_m3u8_media_file_unref (file);
 
@@ -805,7 +805,7 @@ GST_START_TEST (test_get_next_fragment)
   pl = master->default_variant->m3u8;
 
   /* Check the next fragment */
-  mf = gst_m3u8_get_next_fragment (pl, TRUE, &timestamp, &discontinuous);
+  mf = gst_m3u8_get_next_fragment (pl, TRUE, &timestamp, NULL, &discontinuous);
   fail_unless (mf != NULL);
   assert_equals_int (discontinuous, FALSE);
   assert_equals_string (mf->uri, "http://media.example.com/all.ts");
@@ -818,7 +818,7 @@ GST_START_TEST (test_get_next_fragment)
   gst_m3u8_advance_fragment (pl, TRUE);
 
   /* Check next media segments */
-  mf = gst_m3u8_get_next_fragment (pl, TRUE, &timestamp, &discontinuous);
+  mf = gst_m3u8_get_next_fragment (pl, TRUE, &timestamp, NULL, &discontinuous);
   fail_unless (mf != NULL);
   assert_equals_int (discontinuous, FALSE);
   assert_equals_string (mf->uri, "http://media.example.com/all.ts");
@@ -831,7 +831,7 @@ GST_START_TEST (test_get_next_fragment)
   gst_m3u8_advance_fragment (pl, TRUE);
 
   /* Check next media segments */
-  mf = gst_m3u8_get_next_fragment (pl, TRUE, &timestamp, &discontinuous);
+  mf = gst_m3u8_get_next_fragment (pl, TRUE, &timestamp, NULL, &discontinuous);
   assert_equals_int (discontinuous, FALSE);
   assert_equals_string (mf->uri, "http://media.example.com/all.ts");
   assert_equals_uint64 (timestamp, 20 * GST_SECOND);
diff --git a/subprojects/gst-plugins-bad/tests/check/libs/h264bitwriter.c b/subprojects/gst-plugins-bad/tests/check/libs/h264bitwriter.c
index 0d1483ac81..402d783842 100644
--- a/subprojects/gst-plugins-bad/tests/check/libs/h264bitwriter.c
+++ b/subprojects/gst-plugins-bad/tests/check/libs/h264bitwriter.c
@@ -526,7 +526,7 @@ GST_END_TEST;
 static Suite *
 h264bitwriter_suite (void)
 {
-  Suite *s = suite_create ("H264 Parser library");
+  Suite *s = suite_create ("H264 bitwriter library");
 
   TCase *tc_chain = tcase_create ("general");
 
diff --git a/subprojects/gst-plugins-bad/tests/check/libs/h265bitwriter.c b/subprojects/gst-plugins-bad/tests/check/libs/h265bitwriter.c
index 7d0852178d..00377391e1 100644
--- a/subprojects/gst-plugins-bad/tests/check/libs/h265bitwriter.c
+++ b/subprojects/gst-plugins-bad/tests/check/libs/h265bitwriter.c
@@ -950,7 +950,7 @@ GST_END_TEST;
 static Suite *
 h265bitwriter_suite (void)
 {
-  Suite *s = suite_create ("H265 Parser library");
+  Suite *s = suite_create ("H265 bitwriter library");
 
   TCase *tc_chain = tcase_create ("general");
 
diff --git a/subprojects/gst-plugins-bad/tests/check/meson.build b/subprojects/gst-plugins-bad/tests/check/meson.build
index ac96323dfc..59b76cd86e 100644
--- a/subprojects/gst-plugins-bad/tests/check/meson.build
+++ b/subprojects/gst-plugins-bad/tests/check/meson.build
@@ -40,6 +40,7 @@ base_tests = [
   [['elements/gdppay.c'], get_option('gdp').disabled()],
   [['elements/h263parse.c'], false, [libparser_dep, gstcodecparsers_dep]],
   [['elements/h264parse.c'], false, [libparser_dep, gstcodecparsers_dep]],
+  [['elements/h264timestamper.c'], false, [libparser_dep, gstcodecparsers_dep]],
   [['elements/h265parse.c'], false, [libparser_dep, gstcodecparsers_dep]],
   [['elements/hlsdemux_m3u8.c'], not hls_dep.found(), [hls_dep]],
   [['elements/id3mux.c'], get_option('id3tag').disabled()],
diff --git a/subprojects/gst-plugins-bad/tests/examples/codecs/decoder-caps-update.cpp b/subprojects/gst-plugins-bad/tests/examples/codecs/decoder-caps-update.cpp
new file mode 100644
index 0000000000..6dd4acabe3
--- /dev/null
+++ b/subprojects/gst-plugins-bad/tests/examples/codecs/decoder-caps-update.cpp
@@ -0,0 +1,324 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include <gst/gst.h>
+#include <gst/video/video.h>
+#include <stdlib.h>
+#include <string>
+#include <mutex>
+#include "../key-handler.h"
+
+static GMainLoop *loop = nullptr;
+static std::mutex input_lock;
+static gint par = 1;
+static gint fps = 30;
+static gboolean set_hdr10 = FALSE;
+static GstElement *setter = nullptr;
+static gboolean updated = FALSE;
+
+static void
+print_keyboard_help (void)
+{
+  static struct
+  {
+    const gchar *key_desc;
+    const gchar *key_help;
+  } key_controls[] = {
+    {
+    "q", "Quit"}, {
+    "right arrow", "Increase framerate"}, {
+    "left arrow", "Decrease framerate"}, {
+    "up arrow", "Increase pixel-aspect-ratio"}, {
+    "down arrow", "Decrease pixel-aspect-ratio"}, {
+    "m", "Toggle HDR10 metadata"}, {
+    "k", "show keyboard shortcuts"}
+  };
+
+  guint i, chars_to_pad, desc_len, max_desc_len = 0;
+
+  gst_print ("\n\n%s\n\n", "Keyboard controls:");
+
+  for (i = 0; i < G_N_ELEMENTS (key_controls); ++i) {
+    desc_len = g_utf8_strlen (key_controls[i].key_desc, -1);
+    max_desc_len = MAX (max_desc_len, desc_len);
+  }
+  ++max_desc_len;
+
+  for (i = 0; i < G_N_ELEMENTS (key_controls); ++i) {
+    chars_to_pad = max_desc_len - g_utf8_strlen (key_controls[i].key_desc, -1);
+    gst_print ("\t%s", key_controls[i].key_desc);
+    gst_print ("%-*s: ", chars_to_pad, "");
+    gst_print ("%s\n", key_controls[i].key_help);
+  }
+  gst_print ("\n");
+}
+
+static void
+keyboard_cb (gchar input, gboolean is_ascii, gpointer user_data)
+{
+  std::lock_guard<std::mutex> lk (input_lock);
+
+  if (!is_ascii) {
+    switch (input) {
+      case KB_ARROW_UP:
+        par++;
+        updated = TRUE;
+        gst_println ("Increasing pixel-aspect-ratio to %d", par);
+        break;
+      case KB_ARROW_DOWN:
+        if (par == 1)
+          return;
+        par--;
+        updated = TRUE;
+        gst_println ("Decreasing pixel-aspect-ratio to %d", par);
+        break;
+      case KB_ARROW_RIGHT:
+        fps++;
+        updated = TRUE;
+        gst_println ("Increasing framerate to %d", fps);
+        break;
+      case KB_ARROW_LEFT:
+        if (fps == 1)
+          return;
+        fps--;
+        updated = TRUE;
+        gst_println ("Decreasing framerate to %d", fps);
+        break;
+      default:
+        break;
+    }
+  } else {
+    switch (input) {
+      case 'k':
+      case 'K':
+        print_keyboard_help ();
+        break;
+      case 'q':
+      case 'Q':
+        g_main_loop_quit (loop);
+        break;
+      case 'm':
+      case 'M':
+        set_hdr10 = !set_hdr10;
+        updated = TRUE;
+        gst_println ("%sable HDR10 metadata", set_hdr10 ? "En" : "Dis");
+        break;
+      default:
+        break;
+    }
+  }
+
+  if (updated && setter) {
+    GstPad *pad = gst_element_get_static_pad (setter, "sink");
+    GstCaps *caps = gst_pad_get_current_caps (pad);
+    gst_object_unref (pad);
+
+    if (!caps)
+      return;
+
+    if (gst_caps_is_any (caps) || gst_caps_is_empty (caps)) {
+      gst_caps_unref (caps);
+      return;
+    }
+
+    caps = gst_caps_make_writable (caps);
+    gst_caps_set_simple (caps, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+        par, 1, "framerate", GST_TYPE_FRACTION, fps, 1, nullptr);
+
+    if (set_hdr10) {
+      gst_caps_set_simple (caps, "mastering-display-info", G_TYPE_STRING,
+          "34000:16000:13250:34500:7500:3000:15635:16450:10000000:1",
+          "content-light-level", G_TYPE_STRING, "1000:400", nullptr);
+    }
+
+    g_object_set (setter, "caps", caps, nullptr);
+    gst_caps_unref (caps);
+  }
+}
+
+static void
+decoder_caps_notify (GstPad * pad, GParamSpec * pspec, gpointer user_data)
+{
+  GstCaps *caps;
+  gchar *caps_str;
+
+  g_object_get (pad, "caps", &caps, nullptr);
+  if (!caps)
+    return;
+
+  caps_str = gst_caps_to_string (caps);
+  gst_println ("\nDecoder output caps\n%s\n", caps_str);
+
+  g_free (caps_str);
+  gst_caps_unref (caps);
+}
+
+static gboolean
+bus_msg (GstBus * bus, GstMessage * msg, gpointer user_data)
+{
+  switch (GST_MESSAGE_TYPE (msg)) {
+    case GST_MESSAGE_ERROR:{
+      GError *err;
+      gchar *dbg;
+
+      gst_message_parse_error (msg, &err, &dbg);
+      gst_printerrln ("ERROR %s", err->message);
+      if (dbg != NULL)
+        gst_printerrln ("ERROR debug information: %s", dbg);
+      g_clear_error (&err);
+      g_free (dbg);
+
+      g_main_loop_quit (loop);
+      break;
+    }
+    case GST_MESSAGE_EOS:
+      gst_println ("Got EOS");
+      g_main_loop_quit (loop);
+      break;
+    default:
+      break;
+  }
+
+  return TRUE;
+}
+
+gint
+main (gint argc, gchar ** argv)
+{
+  GstElement *pipeline;
+  GError *error = nullptr;
+  GOptionContext *option_ctx;
+  gchar *decoder_name = nullptr;
+  gchar *encoder_name = nullptr;
+  gchar *sink_name = nullptr;
+  gchar *location = nullptr;
+  GOptionEntry options[] = {
+    {"decoder", 0, 0, G_OPTION_ARG_STRING, &decoder_name,
+        "Video decoder to use"},
+    {"encoder", 0, 0, G_OPTION_ARG_STRING, &encoder_name,
+        "Video encoder description. Ignored if \"location\" is set "
+        "(example: \"x264enc speed-preset=ultrafast\""},
+    {"videosink", 0, 0, G_OPTION_ARG_STRING, &sink_name,
+        "Video sink to use"},
+    {"location", 0, 0, G_OPTION_ARG_STRING, &location, "File location"},
+    {nullptr}
+  };
+
+  option_ctx =
+      g_option_context_new ("Video decoder caps update example");
+  g_option_context_add_main_entries (option_ctx, options, nullptr);
+  g_option_context_set_help_enabled (option_ctx, TRUE);
+  if (!g_option_context_parse (option_ctx, &argc, &argv, &error)) {
+    gst_printerrln ("option parsing failed: %s\n", error->message);
+    g_clear_error (&error);
+    exit (1);
+  }
+
+  g_option_context_free (option_ctx);
+  gst_init (nullptr, nullptr);
+
+  if (!decoder_name) {
+    gst_printerrln ("Decoder must be specified");
+    exit (1);
+  }
+
+  if (!encoder_name && !location) {
+    gst_printerrln ("Encoder or file location must be specified");
+    exit (1);
+  }
+
+  std::string pipeline_desc;
+  if (location) {
+    pipeline_desc = "filesrc location=" + std::string (location)
+      + " ! parsebin ! capssetter name=setter ! "
+      + std::string (decoder_name) + " name=dec";
+  } else {
+    pipeline_desc = "videotestsrc ! " + std::string (encoder_name)
+      + " ! parsebin ! capssetter name=setter ! "
+      + std::string (decoder_name) + " name=dec";
+  }
+
+  if (sink_name) {
+    pipeline_desc += " ! " + std::string (sink_name);
+  } else {
+    pipeline_desc += " ! fakevideosink";
+  }
+
+  gst_println ("Constructing test pipeline \"%s\"", pipeline_desc.c_str());
+
+  loop = g_main_loop_new (nullptr, FALSE);
+  pipeline = gst_parse_launch (pipeline_desc.c_str(), &error);
+  if (error) {
+    gst_printerrln ("Could not construct pipeline, error: %s",
+        error->message);
+    exit(1);
+  }
+
+  setter = gst_bin_get_by_name (GST_BIN (pipeline), "setter");
+  if (!setter) {
+    gst_printerrln ("Could not get capssetter from pipeline");
+    exit(1);
+  }
+
+  GstElement *dec = gst_bin_get_by_name (GST_BIN (pipeline), "dec");
+  if (!dec) {
+    gst_printerrln ("Could not get decoder from pipeline");
+    exit(1);
+  }
+
+  GstPad *pad = gst_element_get_static_pad (dec, "src");
+  g_signal_connect (pad, "notify::caps", G_CALLBACK (decoder_caps_notify),
+      nullptr);
+  gst_object_unref (pad);
+  gst_object_unref (dec);
+
+  gst_bus_add_watch (GST_ELEMENT_BUS (pipeline), bus_msg, nullptr);
+
+  /* run the pipeline */
+  GstStateChangeReturn ret =
+      gst_element_set_state (pipeline, GST_STATE_PLAYING);
+  if (ret == GST_STATE_CHANGE_FAILURE) {
+    gst_printerrln ("Pipeline doesn't want to playing");
+  } else {
+    set_key_handler ((KeyInputCallback) keyboard_cb, nullptr);
+    gst_println ("Press k to see supported keyboard inputs");
+    g_main_loop_run (loop);
+    unset_key_handler ();
+  }
+
+  input_lock.lock();
+  gst_clear_object (&setter);
+  input_lock.unlock();
+
+  gst_element_set_state (pipeline, GST_STATE_NULL);
+  gst_bus_remove_watch (GST_ELEMENT_BUS (pipeline));
+
+  gst_object_unref (pipeline);
+  g_main_loop_unref (loop);
+
+  g_free (decoder_name);
+  g_free (encoder_name);
+  g_free (location);
+
+  return 0;
+}
diff --git a/subprojects/gst-plugins-bad/tests/examples/codecs/meson.build b/subprojects/gst-plugins-bad/tests/examples/codecs/meson.build
new file mode 100644
index 0000000000..b04181abc9
--- /dev/null
+++ b/subprojects/gst-plugins-bad/tests/examples/codecs/meson.build
@@ -0,0 +1,10 @@
+if host_system not in ['windows', 'linux']
+  subdir_done()
+endif
+
+executable('decoder-caps-update',
+  ['decoder-caps-update.cpp', '../key-handler.c'],
+  include_directories : [configinc],
+  dependencies: [gst_dep, gstbase_dep, gstvideo_dep],
+  c_args : gst_plugins_bad_args,
+  install: false)
diff --git a/subprojects/gst-plugins-bad/tests/examples/meson.build b/subprojects/gst-plugins-bad/tests/examples/meson.build
index 9fb4015d52..29838f7167 100644
--- a/subprojects/gst-plugins-bad/tests/examples/meson.build
+++ b/subprojects/gst-plugins-bad/tests/examples/meson.build
@@ -2,6 +2,7 @@ subdir('audiomixmatrix')
 subdir('avsamplesink')
 subdir('camerabin2')
 subdir('codecparsers')
+subdir('codecs')
 subdir('d3d11')
 subdir('directfb')
 subdir('gtk')
diff --git a/subprojects/gst-plugins-bad/tests/examples/va/meson.build b/subprojects/gst-plugins-bad/tests/examples/va/meson.build
index 4f50b3eb53..222901b184 100644
--- a/subprojects/gst-plugins-bad/tests/examples/va/meson.build
+++ b/subprojects/gst-plugins-bad/tests/examples/va/meson.build
@@ -24,3 +24,10 @@ executable('multiple-vpp',
   dependencies : [gst_dep, gstvideo_dep, gstva_dep, gstcontroller_dep],
   c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API'],
 )
+
+executable('vaenc-dynamic-reconfigure',
+  ['vaenc-dynamic-reconfigure.c', '../key-handler.c'],
+  include_directories : [configinc],
+  dependencies: [gst_dep, gstbase_dep, gstvideo_dep],
+  c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API'],
+  install: false)
diff --git a/subprojects/gst-plugins-bad/tests/examples/va/vaenc-dynamic-reconfigure.c b/subprojects/gst-plugins-bad/tests/examples/va/vaenc-dynamic-reconfigure.c
new file mode 100644
index 0000000000..2c696ba721
--- /dev/null
+++ b/subprojects/gst-plugins-bad/tests/examples/va/vaenc-dynamic-reconfigure.c
@@ -0,0 +1,573 @@
+/* GStreamer
+ * Copyright (C) 2022 Seungha Yang <seungha@centricular.com>
+ *               2022 Vctor Jquez <vjaquez@igalia.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include <gst/gst.h>
+#include <gst/video/video.h>
+#include <stdlib.h>
+#include "../key-handler.h"
+
+static GMainLoop *loop = NULL;
+static gint width = 640;
+static gint height = 480;
+static guint rc_ctrl = 0;
+
+G_LOCK_DEFINE_STATIC (input_lock);
+
+typedef struct
+{
+  GstElement *pipeline;
+  GstElement *capsfilter;
+  GstElement *encoder;
+  gulong probe_id;
+
+  gint prev_width;
+  gint prev_height;
+} TestCallbackData;
+
+static gboolean
+check_encoder_available (const gchar * encoder_name)
+{
+  gboolean ret = TRUE;
+  GstElement *elem;
+
+  elem = gst_element_factory_make (encoder_name, NULL);
+  if (!elem) {
+    gst_printerrln ("%s is not available", encoder_name);
+    return FALSE;
+  }
+
+  if (gst_element_set_state (elem,
+          GST_STATE_PAUSED) != GST_STATE_CHANGE_SUCCESS) {
+    gst_printerrln ("cannot open device");
+    ret = FALSE;
+  }
+
+  gst_element_set_state (elem, GST_STATE_NULL);
+  gst_object_unref (elem);
+
+  return ret;
+}
+
+static gboolean
+bus_msg (GstBus * bus, GstMessage * msg, gpointer user_data)
+{
+  switch (GST_MESSAGE_TYPE (msg)) {
+    case GST_MESSAGE_ERROR:{
+      GError *err;
+      gchar *dbg;
+
+      gst_message_parse_error (msg, &err, &dbg);
+      gst_printerrln ("ERROR %s", err->message);
+      if (dbg != NULL)
+        gst_printerrln ("ERROR debug information: %s", dbg);
+      g_clear_error (&err);
+      g_free (dbg);
+
+      g_main_loop_quit (loop);
+      break;
+    }
+    case GST_MESSAGE_PROPERTY_NOTIFY:{
+      const GValue *val;
+      const gchar *name;
+      GstObject *obj;
+      gchar *val_str = NULL;
+      gchar *obj_name;
+
+      gst_message_parse_property_notify (msg, &obj, &name, &val);
+
+      if (!GST_IS_VIDEO_ENCODER (obj))
+        break;
+
+      obj_name = gst_object_get_name (GST_OBJECT (obj));
+      if (val) {
+        if (G_VALUE_HOLDS_STRING (val))
+          val_str = g_value_dup_string (val);
+        else if (G_VALUE_TYPE (val) == GST_TYPE_CAPS)
+          val_str = gst_caps_to_string (g_value_get_boxed (val));
+        else if (G_VALUE_HOLDS_BOOLEAN (val) || G_VALUE_HOLDS_INT (val)
+            || G_VALUE_HOLDS_UINT (val) || G_VALUE_HOLDS_ENUM (val))
+          val_str = gst_value_serialize (val);
+        else
+          val_str = g_strdup ("(unknown type)");
+      } else {
+        val_str = g_strdup ("(no value)");
+      }
+
+      gst_println ("%s: %s = %s", obj_name, name, val_str);
+      g_free (obj_name);
+      g_free (val_str);
+      break;
+    }
+    default:
+      break;
+  }
+
+  return TRUE;
+}
+
+static void
+loop_rate_control (GstElement * encoder)
+{
+  GParamSpec *pspec =
+      g_object_class_find_property (G_OBJECT_GET_CLASS (encoder),
+      "rate-control");
+  GEnumClass *enum_class;
+  gint i, default_value;
+
+  if (!pspec)
+    return;
+
+  enum_class = G_PARAM_SPEC_ENUM (pspec)->enum_class;
+
+  if (rc_ctrl == 0) {
+    default_value = G_PARAM_SPEC_ENUM (pspec)->default_value;
+    for (i = 0; i < enum_class->n_values; i++) {
+      if (enum_class->values[i].value == default_value) {
+        rc_ctrl = i;
+        break;
+      }
+    }
+  }
+
+  i = ++rc_ctrl % enum_class->n_values;
+  g_object_set (encoder, "rate-control", enum_class->values[i].value, NULL);
+}
+
+static GstPadProbeReturn
+resolution_change_probe (GstPad * pad, GstPadProbeInfo * info,
+    gpointer user_data)
+{
+  GstPadProbeReturn ret = GST_PAD_PROBE_OK;
+  TestCallbackData *data = (TestCallbackData *) user_data;
+
+  G_LOCK (input_lock);
+
+  if (GST_IS_BUFFER (GST_PAD_PROBE_INFO_DATA (info))) {
+    GstBuffer *buffer = GST_PAD_PROBE_INFO_BUFFER (info);
+    GstPad *peer = gst_pad_get_peer (pad);
+    GstFlowReturn flow_ret = GST_FLOW_OK;
+
+    ret = GST_PAD_PROBE_HANDLED;
+
+    if (peer) {
+      flow_ret = gst_pad_chain (peer, buffer);
+
+      if (flow_ret != GST_FLOW_OK) {
+        gst_pad_remove_probe (pad, data->probe_id);
+        data->probe_id = 0;
+      } else {
+        if (data->prev_width != width || data->prev_height != height) {
+          GstCaps *caps = NULL;
+          gint next_width, next_height;
+
+          next_width = width;
+          next_height = height;
+
+          g_object_get (data->capsfilter, "caps", &caps, NULL);
+          caps = gst_caps_make_writable (caps);
+          gst_caps_set_simple (caps,
+              "width", G_TYPE_INT, next_width, "height", G_TYPE_INT,
+              next_height, NULL);
+          g_object_set (data->capsfilter, "caps", caps, NULL);
+          gst_caps_unref (caps);
+
+          data->prev_width = next_width;
+          data->prev_height = next_height;
+        }
+      }
+    }
+  }
+
+  G_UNLOCK (input_lock);
+
+  return ret;
+}
+
+static void
+print_keyboard_help (void)
+{
+  /* *INDENT-OFF* */
+  static struct
+  {
+    const gchar *key_desc;
+    const gchar *key_help;
+  } key_controls[] = {
+    {
+    "q", "Quit"}, {
+    "right arrow", "Increase Width"}, {
+    "left arrow", "Decrease Width"}, {
+    "up arrow", "Increase Height"}, {
+    "down arrow", "Decrease Height"}, {
+    "r", "Loop rate control"}, {
+    ">", "Increase bitrate by 100 kbps"}, {
+    "<", "Decrease bitrate by 100 kbps"}, {
+    "]", "Increase target usage"}, {
+    "[", "Decrease target usage"}, {
+    "}", "Increase target percentage by 10% (only in VBR)"}, {
+    "{", "Decrease target percentage by 10% (only in VBR)"}, {
+    "I", "Increase QP-I"}, {
+    "i", "Decrease QP-I"}, {
+    "P", "Increase QP-P (only in CQP)"}, {
+    "p", "Decrease QP-P (only in CQP)"}, {
+    "B", "Increase QP-B (only in CQP)"}, {
+    "b", "Decrease QP-B (only in CQP)"}, {
+    "k", "show keyboard shortcuts"}
+  };
+  /* *INDENT-ON* */
+
+  guint i, chars_to_pad, desc_len, max_desc_len = 0;
+
+  gst_print ("\n\n%s\n\n", "Keyboard controls:");
+
+  for (i = 0; i < G_N_ELEMENTS (key_controls); ++i) {
+    desc_len = g_utf8_strlen (key_controls[i].key_desc, -1);
+    max_desc_len = MAX (max_desc_len, desc_len);
+  }
+  ++max_desc_len;
+
+  for (i = 0; i < G_N_ELEMENTS (key_controls); ++i) {
+    chars_to_pad = max_desc_len - g_utf8_strlen (key_controls[i].key_desc, -1);
+    gst_print ("\t%s", key_controls[i].key_desc);
+    gst_print ("%-*s: ", chars_to_pad, "");
+    gst_print ("%s\n", key_controls[i].key_help);
+  }
+  gst_print ("\n");
+}
+
+static inline gboolean
+is_ratectl (GstElement * encoder, guint rc)
+{
+  guint ratectl = 0;
+
+  g_object_get (encoder, "rate-control", &ratectl, NULL);
+  return (ratectl == rc);
+}
+
+static void
+keyboard_cb (gchar input, gboolean is_ascii, gpointer user_data)
+{
+  TestCallbackData *data = (TestCallbackData *) user_data;
+
+  G_LOCK (input_lock);
+
+  if (!is_ascii) {
+    switch (input) {
+      case KB_ARROW_UP:
+        height += 2;
+        break;
+      case KB_ARROW_DOWN:
+        height -= 2;
+        height = MAX (height, 16);
+        break;
+      case KB_ARROW_LEFT:
+        width -= 2;
+        width = MAX (width, 16);
+        break;
+      case KB_ARROW_RIGHT:
+        width += 2;
+        break;
+      default:
+        break;
+    }
+  } else {
+    switch (input) {
+      case 'k':
+      case 'K':
+        print_keyboard_help ();
+        break;
+      case 'q':
+      case 'Q':
+        gst_element_send_event (data->pipeline, gst_event_new_eos ());
+        g_main_loop_quit (loop);
+        break;
+      case 'r':
+      case 'R':
+        loop_rate_control (data->encoder);
+        break;
+      case '>':{
+        guint bitrate;
+
+        if (is_ratectl (data->encoder, 0x00000010 /* VA_RC_CQP */ ))
+          break;
+
+        g_object_get (data->encoder, "bitrate", &bitrate, NULL);
+        bitrate += 100;
+        if (bitrate <= 2048000)
+          g_object_set (data->encoder, "bitrate", bitrate, NULL);
+        break;
+      }
+      case '<':{
+        gint bitrate;
+
+        if (is_ratectl (data->encoder, 0x00000010 /* VA_RC_CQP */ ))
+          break;
+
+        g_object_get (data->encoder, "bitrate", &bitrate, NULL);
+        bitrate -= 100;
+        if (bitrate < 0)
+          bitrate = 0;
+        g_object_set (data->encoder, "bitrate", bitrate, NULL);
+        break;
+      }
+      case ']':{
+        guint usage;
+
+        g_object_get (data->encoder, "target-usage", &usage, NULL);
+        usage += 1;
+        if (usage <= 7)
+          g_object_set (data->encoder, "target-usage", usage, NULL);
+        break;
+      }
+      case '[':{
+        guint usage;
+
+        g_object_get (data->encoder, "target-usage", &usage, NULL);
+        usage -= 1;
+        if (usage >= 1)
+          g_object_set (data->encoder, "target-usage", usage, NULL);
+        break;
+      }
+      case '}':{
+        guint target;
+
+        if (!is_ratectl (data->encoder, 0x00000004 /* VA_RC_VBR */ ))
+          break;
+
+        g_object_get (data->encoder, "target-percentage", &target, NULL);
+        target += 10;
+        if (target <= 100)
+          g_object_set (data->encoder, "target-percentage", target, NULL);
+        break;
+      }
+      case '{':{
+        guint target;
+
+        if (!is_ratectl (data->encoder, 0x00000004 /* VA_RC_VBR */ ))
+          break;
+
+        g_object_get (data->encoder, "target-percentage", &target, NULL);
+        target -= 10;
+        if (target >= 50)
+          g_object_set (data->encoder, "target-percentage", target, NULL);
+        break;
+      }
+      case 'I':{
+        guint qpi;
+
+        g_object_get (data->encoder, "qpi", &qpi, NULL);
+        qpi += 1;
+        if (qpi <= 51)
+          g_object_set (data->encoder, "qpi", qpi, NULL);
+        break;
+      }
+      case 'i':{
+        gint qpi;
+
+        g_object_get (data->encoder, "qpi", &qpi, NULL);
+        qpi -= 1;
+        if (qpi >= 0)
+          g_object_set (data->encoder, "qpi", qpi, NULL);
+        break;
+      }
+      case 'P':{
+        guint qpp;
+
+        if (!is_ratectl (data->encoder, 0x00000010 /* VA_RC_CQP */ ))
+          break;
+
+        g_object_get (data->encoder, "qpp", &qpp, NULL);
+        qpp += 1;
+        if (qpp <= 51)
+          g_object_set (data->encoder, "qpp", qpp, NULL);
+        break;
+      }
+      case 'p':{
+        gint qpp;
+
+        if (!is_ratectl (data->encoder, 0x00000010 /* VA_RC_CQP */ ))
+          break;
+
+        g_object_get (data->encoder, "qpp", &qpp, NULL);
+        qpp -= 1;
+        if (qpp >= 0)
+          g_object_set (data->encoder, "qpp", qpp, NULL);
+        break;
+      }
+      case 'B':{
+        guint qpb;
+
+        if (!is_ratectl (data->encoder, 0x00000010 /* VA_RC_CQP */ ))
+          break;
+
+        g_object_get (data->encoder, "qpb", &qpb, NULL);
+        qpb += 1;
+        if (qpb <= 51)
+          g_object_set (data->encoder, "qpb", qpb, NULL);
+        break;
+      }
+      case 'b':{
+        gint qpb;
+
+        if (!is_ratectl (data->encoder, 0x00000010 /* VA_RC_CQP */ ))
+          break;
+
+        g_object_get (data->encoder, "qpb", &qpb, NULL);
+        qpb -= 1;
+        if (qpb >= 0)
+          g_object_set (data->encoder, "qpb", qpb, NULL);
+        break;
+      }
+      default:
+        break;
+    }
+  }
+
+  G_UNLOCK (input_lock);
+}
+
+gint
+main (gint argc, gchar ** argv)
+{
+  GstElement *pipeline;
+  GstElement *src, *capsfilter, *enc, *dec, *parser, *sink;
+  GstStateChangeReturn sret;
+  GError *error = NULL;
+  GOptionContext *option_ctx;
+  GstCaps *caps;
+  GstPad *pad;
+  TestCallbackData data = { 0, };
+  gchar *encoder_name = NULL;
+  gulong deep_notify_id = 0;
+
+  /* *INDENT-OFF* */
+  GOptionEntry options[] = {
+    {"encoder", 0, 0, G_OPTION_ARG_STRING, &encoder_name,
+        "VA video encoder element to test, default: vah264enc"},
+    {NULL}
+  };
+  /* *INDENT-ON* */
+
+#define MAKE_ELEMENT_AND_ADD(elem, name) G_STMT_START { \
+  GstElement *_elem = gst_element_factory_make (name, NULL); \
+  if (!_elem) { \
+    gst_printerrln ("%s is not available", name); \
+    exit (1); \
+  } \
+  gst_println ("Adding element %s", name); \
+  elem = _elem; \
+  gst_bin_add (GST_BIN (pipeline), elem); \
+} G_STMT_END
+
+  option_ctx =
+      g_option_context_new ("VA video encoder dynamic reconfigure example");
+  g_option_context_add_main_entries (option_ctx, options, NULL);
+  g_option_context_add_group (option_ctx, gst_init_get_option_group ());
+  g_option_context_set_help_enabled (option_ctx, TRUE);
+  if (!g_option_context_parse (option_ctx, &argc, &argv, &error)) {
+    gst_printerrln ("option parsing failed: %s\n", error->message);
+    g_clear_error (&error);
+    exit (1);
+  }
+
+  g_option_context_free (option_ctx);
+  gst_init (NULL, NULL);
+
+  if (!encoder_name)
+    encoder_name = g_strdup ("vah264enc");
+
+  if (!check_encoder_available (encoder_name)) {
+    gst_printerrln ("Cannot load %s plugin", encoder_name);
+    exit (1);
+  }
+
+  /* prepare the pipeline */
+  loop = g_main_loop_new (NULL, FALSE);
+
+  pipeline = gst_pipeline_new (NULL);
+
+  MAKE_ELEMENT_AND_ADD (src, "videotestsrc");
+  g_object_set (src, "pattern", 1, NULL);
+
+  MAKE_ELEMENT_AND_ADD (capsfilter, "capsfilter");
+  MAKE_ELEMENT_AND_ADD (enc, encoder_name);
+
+  /* gst_util_set_object_arg (G_OBJECT (enc), "rate-control", rate_control); */
+
+  if (g_strcmp0 (encoder_name, "vah264enc") == 0) {
+    MAKE_ELEMENT_AND_ADD (parser, "h264parse");
+    MAKE_ELEMENT_AND_ADD (dec, "vah264dec");
+  } else {
+    g_assert_not_reached ();
+  }
+
+  MAKE_ELEMENT_AND_ADD (sink, "autovideosink");
+
+  if (!gst_element_link_many (src, capsfilter, enc, parser, dec, sink, NULL)) {
+    gst_printerrln ("Failed to link element");
+    exit (1);
+  }
+
+  caps = gst_caps_new_simple ("video/x-raw", "width", G_TYPE_INT,
+      width, "height", G_TYPE_INT, height, NULL);
+  g_object_set (capsfilter, "caps", caps, NULL);
+  gst_caps_unref (caps);
+
+  data.pipeline = pipeline;
+  data.capsfilter = capsfilter;
+  data.encoder = enc;
+
+  pad = gst_element_get_static_pad (capsfilter, "src");
+  data.probe_id = gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_BUFFER,
+      resolution_change_probe, &data, NULL);
+  gst_object_unref (pad);
+  data.prev_width = width;
+  data.prev_height = height;
+
+  deep_notify_id =
+      gst_element_add_property_deep_notify_watch (pipeline, NULL, TRUE);
+
+  gst_bus_add_watch (GST_ELEMENT_BUS (pipeline), bus_msg, &data);
+
+  /* run the pipeline */
+  sret = gst_element_set_state (pipeline, GST_STATE_PLAYING);
+  if (sret == GST_STATE_CHANGE_FAILURE) {
+    gst_printerrln ("Pipeline doesn't want to playing\n");
+  } else {
+    set_key_handler ((KeyInputCallback) keyboard_cb, &data);
+    g_main_loop_run (loop);
+    unset_key_handler ();
+  }
+
+  if (deep_notify_id != 0)
+    g_signal_handler_disconnect (pipeline, deep_notify_id);
+
+  gst_element_set_state (pipeline, GST_STATE_NULL);
+  gst_bus_remove_watch (GST_ELEMENT_BUS (pipeline));
+
+  gst_object_unref (pipeline);
+  g_main_loop_unref (loop);
+  g_free (encoder_name);
+
+  return 0;
+}
